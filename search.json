[{"title":"Golang 开发“疑难杂症”解决办法 🤔⁉️","path":"/2024/11/28/go4/","content":"提升编程水平和高效解决问题的能力 工程架构不合理性项目难维护难扩展设计模式不清晰数据类型内存碎片化CPU 缓存命中错误运行时紊乱和 GC 超负荷指令并行错误内存堆积和 GC 无效栈空间逃逸和堆碎片化GC 三色标记算法效率大对象生命周期管理并发数据竞争优化错误管理低效 I&#x2F;O 多路复用CPU 缓存行伪共享调度器负载过重频繁触发 CG 写屏障CG 写屏障卡表更新错误CPU 多级告诉缓存未命中总线监视异常测试颗粒度混乱测试不充分&#x2F;逻辑过度复杂CPU 高速缓存一致性错误缓存污染和数据竞争代码优化的复杂问题参考资料 Go 开发疑难杂症终结者通关指南","tags":["Golang"],"categories":["Golang"]},{"title":"A Logic based Network Security Analyzer","path":"/2024/11/16/mulval/","content":"MulVAL：基于逻辑推理的攻击图生成及风险评估工具 官网 论文 仓库 MulVAL基本概念 背景和需求：如何帮助系统管理员自动化漏洞评估和安全措施的选择 （主要是运维阶段+策略验证） 漏洞数量增长：由于每年不断发现新的安全漏洞，系统管理员很难在所有网络机器上确保软件完全没有漏洞 日常任务：系统管理员需要从不同的来源（如 CERT、BugTraq 等）阅读漏洞报告，并判断哪些漏洞是网络中实际存在的安全问题 漏洞评估：对于新发现的漏洞，管理员需要评估这些漏洞对网络的安全影响，从而决定采取哪些应对措施（例如打补丁、重启、重新配置防火墙等） 根据汽车行业标准（例如 ISO&#x2F;SAE 21434 中的定义），TARA（Threat Analysis and Risk Assessment，威胁分析与风险评估）是一个贯穿 全生命周期 的过程，而不仅仅局限于概念阶段或特定阶段 概念阶段 在车辆开发的早期阶段，TARA 用于识别资产、威胁场景和潜在风险 在这一阶段的目标是为网络安全设计奠定基础，确定需要保护的关键资产和可能面临的威胁 开发阶段 在开发过程中，TARA 持续更新，以评估新发现的威胁和漏洞 包括详细的攻击路径分析和风险评估，确保安全措施能够覆盖所有识别出的风险 验证阶段 验证阶段会结合 TARA 确保已实施的安全措施有效降低风险 此阶段重点验证是否实现了预期的风险减缓效果 运营阶段 在车辆运营期间，TARA 需要持续应用，以应对新出现的威胁和漏洞 随着时间推移，资产和威胁场景可能会变化，需要定期更新评估 维护和退役阶段 即使在车辆的维护或退役阶段，也需要考虑 TARA 的应用，尤其是针对遗留系统的安全风险 根据 ISO 26262 标准，HARA（Hazard Analysis and Risk Assessment，危害分析与风险评估） 是在 概念阶段 进行的核心活动 HARA 的主要目标是在概念阶段识别潜在的危害，评估其风险，并为后续的功能安全开发制定适当的安全目标和安全要求 虽然 HARA 主要在概念阶段进行，但其结果会贯穿整个开发生命周，安全目标和要求会传递到系统、硬件、软件开发阶段，确保整个系统的功能安全设计 HARA vs TARA 的比较 特性 HARA TARA 关注点 系统功能性故障及其导致的危害 外部威胁或攻击行为及其对安全性的影响 应用领域 功能安全（如汽车、航空） 网络安全（如物联网、汽车通信） 风险来源 内部（如设备故障、人为失误） 外部（如恶意攻击、网络威胁） 标准支持 ISO 26262、IEC 61508 ISO&#x2F;SAE 21434、NIST Cybersecurity Framework 常用指标 严重性、概率、可检测性 可能性、影响 分析工具 故障模式与影响分析（FMEA）、故障树分析（FTA） 攻击图（Attack Graph）、威胁情报分析 结果用途 安全功能设计、故障管理 安全控制设计、防御策略优化 漏洞分析工具有效的前提 能够自动整合来自漏洞报告社区的 正式漏洞规范 且其分析能力能够扩展到包含数千台机器的网络中 这两个问题在之前的相关工作中尚未得到解决（ - 2005） MulVAL 是一个端到端的框架和推理系统，用于 多主机、多阶段 的网络漏洞分析 “端到端”（end-to-end）指的是 MulVAL 能够覆盖漏洞分析的整个过程，从输入到输出结果，无需依赖其他外部工具或模块 采用 Datalog 作为分析中元素的建模语言（如漏洞规格、配置描述、推理规则、操作系统权限和特权模型等） 漏洞报告社区提供的漏洞数据库信息、每台机器及网络的配置信息以及其他相关信息都被编码为 Datalog 事实 一旦收集到所有信息，对于拥有数千台机器的网络，其分析可以在几秒内完成 MulVAL 分析的输入包括以下内容 公告信息（Advisories）：已报告的漏洞有哪些？这些漏洞是否存在于我的机器上？ 主机配置（Host configuration）：我的主机上运行了哪些软件和服务？它们是如何配置的？ 网络配置（Network configuration）：我的网络路由器和防火墙是如何配置的？ 主体（Principals）：谁是我网络的用户？ 交互（Interaction）：这些组件之间的交互模型是什么？ 策略（Policy）：我希望允许哪些访问权限？ 形式化表示MulVAL 包括两个主要模块：扫描器（scanner）和 分析器（analyzer） 扫描器在 每台 主机上异步运行，并大范围利用现有工具（如 OVAL） 分析器在接收到来自扫描器的新信息时，在 单台 主机上运行 漏洞公告（Advisories） 开放漏洞评估语言（OVAL） 用于 标准化如何识别计算机系统上的漏洞，OVAL 扫描器基于这些标准化的漏洞定义，对主机进行测试并检查是否存在漏洞，将这些测试结果转化为 Datalog 子句，例如： 1vulExists(webServer, &#x27;CAN-2002-0392&#x27;, httpd). 这里表示扫描器在 webServer 主机上发现了编号为 CAN-2002-0392 的漏洞，该漏洞涉及到服务器程序 httpd 然而，OVAL 并未正式化（形式化）描述 漏洞的利用方式及其后果，ICAT，由美国国家标准与技术研究院（NIST）开发的漏洞数据库，提供了有关漏洞影响的信息，将 ICAT 中的相关信息转化为 Datalog 子句，例如： 1vulProperty(&#x27;CAN-2002-0392&#x27;, remoteExploit, privilegeEscalation). 表示该漏洞使远程攻击者能够以程序的全部权限执行任意代码 主机配置（Host Configuration） OVAL 扫描器还可以被配置为提取主机的配置信息，例如输出服务程序的配置信息（包括端口号、权限等），将其输出转化为 Datalog 子句，例如： 1networkService(webServer, httpd, TCP, 80, apache). 这表示程序 httpd 在主机 webServer 上以用户 apache 的身份运行，并监听 TCP 协议的 80 端口 网络配置（Network Configuration） MulVAL 使用抽象的 主机访问控制列表（HACL） 来建模网络（路由器和防火墙）的配置。相关信息可以通过防火墙管理工具（如 Smart Firewall）提供，以下是一个 HACL 条目示例，表示允许从互联网发送 TCP 流量到 webServer 的 80 端口： 1hacl(internet, webServer, TCP, 80). 主体（Principals） 主体绑定（principal binding）将主体符号映射到其在网络主机上的用户账户。管理员可以定义这些主体绑定，例如： 12hasAccount(user, projectPC, userAccount).hasAccount(sysAdmin, webServer, root). 交互（Interaction） 在多阶段攻击中，漏洞的语义和操作系统的行为决定了攻击者在每个阶段的选项。我们用 Horn 子句（即 Prolog 子句）对其进行编码，其中第一行是结论，其余是启用条件。例如： 123456execCode(Attacker, Host, Priv) :- vulExists(Host, VulID, Program), vulProperty(VulID, remoteExploit, privilegeEscalation), networkService(Host, Program, Protocol, Port, Priv), netAccess(Attacker, Host, Protocol, Port), malicious(Attacker). 这条规则的意思是，如果某程序在某主机上存在可远程利用的漏洞，并且该漏洞会导致权限提升；且程序运行在特定协议和端口上，而攻击者能够通过网络访问该服务，则攻击者可以以该程序的权限在目标主机上执行任意代码。这条规则适用于任何匹配该模式的漏洞。 策略（Policy） 在 MulVAL 中，策略描述了哪些主体可以访问哪些数据。任何未明确允许的操作都被禁止。例如，以下是一个简单的策略： 12allow(Everyone, read, webPages).allow(sysAdmin, write, webPages). 其中 Everyone 是一个 Prolog 变量，可以匹配任何用户 分析框架（Analysis Framework） 由于 Datalog 是 Prolog 的子集，编码的信息可以直接加载到 Prolog 环境中执行。MulVAL 使用 XSB 作为运行环境，因为它支持 Prolog 程序的表格化执行（tabling），表格化是一种动态规划技术，可以避免重复计算已得出的事实。此外，表格化还提供了完全声明式的逻辑编程，因为规则的顺序不会影响执行结果 MulVAL 框架： OVAL 扫描器在每台机器上运行，并输出漏洞报告和相关的配置信息 扫描器的元组、网络配置（以 HACL 表示）、推导规则和管理员定义的安全策略被加载到 XSB 环境中 Prolog 查询可用于搜索策略违规情况，并生成详细的攻击树 漏洞规范一个安全漏洞的规范通常包括两个部分： 如何在系统中识别漏洞的存在 漏洞对系统造成的影响 识别规范 仅用于主机扫描，而 影响规范 则用于漏洞分析推理过程。漏洞报告社区已经开始以正式、机器可读的格式提供这些信息 OVAL（一种用于识别漏洞的正式语言） 开放漏洞评估语言（OVAL） 是一种基于 XML 的语言，用于指定机器配置的检测规则。当发现新的软件漏洞时，OVAL 定义可以描述如何检查机器是否存在该漏洞。OVAL 定义文件可以被 OVAL 兼容的扫描器使用，执行指定的测试并报告结果。 目前，OVAL 漏洞定义适用于 Windows、Red Hat Linux 和 Solaris 平台，并且 OVAL 兼容扫描器可用于 Windows 和 Red Hat Linux 平台。自 2002 年以来，OVAL 漏洞定义不断更新，截至 2005 年 1 月 31 日，每个平台的定义数量如下： 平台 提交数 通过审核数 Microsoft Windows 543 489 Red Hat Linux 203 202 Sun Solaris 73 57 总计 819 748 例如，使用最新的 OVAL 定义文件对某台机器运行了 OVAL 扫描器，发现了以下漏洞： 1234567OVAL Id CVE Id-------------------------OVAL2819 CAN-2004-0427OVAL2915 CAN-2004-0554OVAL2961 CAN-2004-0495OVAL3657 CVE-2002-1363------------------------- 将 OVAL 扫描器的输出转换为 Datalog 子句，例如： 1vulExists(webServer, &#x27;CVE-2002-0392&#x27;, httpd). 除了生成漏洞列表，OVAL 扫描器还可以按照系统特征模式（System Characteristics Schema）输出详细的机器配置信息。其中一些信息在分析多阶段攻击时非常有用。例如： 服务程序监听的协议和端口 与防火墙规则和网络拓扑结合，可确定攻击者是否能向某个易受攻击的程序发送恶意数据包 以下关于机器配置的谓词用于 MulVAL 推理引擎： 123456networkService(Host, Program, Protocol, Port, Priv).clientProgram(Host, Program, Priv).setuidProgram(Host, Program, Owner).filePath(H, Owner, Path).nfsExport(Server, Path, Access, Client).nfsMountTable(Client, ClientPath, Server, ServerPath). networkService：描述服务程序监听的端口号、协议以及程序的用户权限 clientProgram：描述客户端程序的权限 setuidProgram：指定系统中的一个 setuid 可执行文件及其所有者 filePath：描述文件系统中某路径的所有者 nfsExport：描述 NFS 服务器向客户端导出的文件系统部分 nfsMountTable：描述客户端机器上的 NFS 挂载表条目 MulVAL 的扫描器通过增强标准的 OVAL 扫描器实现，它不仅报告漏洞的存在，还以上述谓词的形式输出机器配置信息 ICAT（一种描述漏洞影响的数据库） 关于漏洞的详细信息可以在 OVAL 的网站上找到。例如，漏洞 OVAL2961 的描述是： 1Linux kernel 2.4 和 2.6 中的多个未知漏洞允许本地用户提升权限或访问内核内存…… 这种非正式的简短描述强调了漏洞的影响（例如如何被利用以及可能的后果）。如果存在机器可读的数据库来提供类似的信息，例如 “漏洞 2961 仅能被本地利用”，就可以正式证明一些属性，例如 “如果所有本地用户都是可信的，那么网络将免受远程攻击者的威胁”。 遗憾的是，OVAL 未以机器可读的形式呈现漏洞影响的信息。不过，ICAT 数据库 通过两个维度对漏洞的影响进行分类： 可利用范围（exploitable range）： 本地（local） 远程（remote） 后果（consequence）： 机密性丧失（confidentiality loss） 数据完整性丧失（integrity loss） 服务拒绝（denial of service） 权限提升（privilege escalation） 例如 本地利用 表示攻击者需要已在主机上获得某种访问权限 远程利用 则不需要这种前提条件 最常见的漏洞后果是权限提升和服务拒绝 目前，所有 OVAL 定义均有对应的 ICAT 条目（通过 CVE Id 可交叉引用）。如果 OVAL 和 ICAT 能够合并为单一数据库，将能同时提供两类信息。 将 ICAT 数据库中的分类转化为 Datalog 子句，例如： 1vulProperty(&#x27;CVE-2004-00495&#x27;, localExploit, privEscalation) 推理系统MulVAL 推理系统的规则被声明为 Datalog 子句，在 Datalog 的形式主义中，一个 literal，$p(t_1,\\ldots,t_k)$ 是一个谓词应用于其参数，每个参数要么是一个常量要么是一个变量（在 Datalog 中，变量是一个以大写字母开头的标识符，常量则是以小写字母开头的） 设 $L_0,\\ldots,L_n$ 是 literal，MulVAL 中的一个句子被表示为一个 Horn 子句：$L_0 \\coloneqq L_1, \\ldots, L_n$ 语义上，这意味着如果 $L_1,\\ldots,L_n$ 是真的，那么 $L_0$ 也是真的，左边被称为 head，右边被称为 body，一个空 body 的子句被称为 事实，一个非空 body 的子句被称为规则 推理规则MulVAL 推理规则指定了不同类型的漏洞利用、妥协传播和多跳网络访问的语义，其被精心设计以便将关于特定漏洞的信息分解到从 OVAL 和 ICAT 生成的数据中，交互规则描述了一般的攻击方法（例如“特洛伊木马客户端程序”），而不是特定的漏洞，因此，即使新的漏洞频繁报告，规则也不需要经常改变 漏洞利用规则（Exploit rules） 入侵传播（Compromise propagation） 多跳网络访问（Multihop network access） 主机访问控制列表策略规范绑定信息分析算法更复杂的策略Example 论文使用 Example（示例） 还是 Case Study（案例研究），取决于作者希望传达的重点： 如果论文聚焦于 方法或理论的描述和初步验证，更适合用 example 如果论文聚焦于 实践中的实际应用和深度分析，更适合用 case study 两者也可以结合使用，例如先用 example 快速解释理论或方法，再用 case study 深入分析实际应用，增强理论的说服力和实用性 小型真实示例多阶段攻击示例假设性分析性能和可扩展性相关工作与总结源码分析系统架构核心文件MulVAL 目录 123456789101112131415├── bin # src目录下功能文件编译后存放该目录下│ ├── adapter│ └── metrics├── doc # 说明文档├── docker # 构建镜像├── kb # 默认规则目录├── lib # 库文件├── src # 功能实现│ ├── adapter│ ├── analyzer│ ├── attack_graph│ └── metrics├── testcases # 测试案例│ └── 3host└── utils # 部分调用脚本，功能脚本 技术细节 参考：MulVAL: 基于逻辑推理的攻击图生成及风险评估工具 README工具概述Multi host, multi stage Vulnerability Analysis tool 安装与配置 安装 XSB 逻辑引擎 安装 GraphViz 确保都在 PATH 路径 设置环境变量 MULVALROOT 应指向此软件包的根文件夹。在 PATH 中包含 $MULVALROOT$/bin 和 $MULVALROOT/utils。键入 make 来编译所有内容。可以直接运行 MulVAL 攻击图生成器，如果您已经有了一个输入文件；或者您可以运行相应的适配器来创建输入文件，然后运行攻击图生成器。 基本使用graph_gen.sh INPUT_FILE [OPTIONS]在 testcases&#x2F;3host 文件夹中有一个简单的输入文件 input.P。这个输入文件用于 MulVAL 文献中的 3 主机示例 [1,2]。您可以运行它来检查攻击图生成器是否正常工作。graph_gen.sh input.P -v -p这将生成一个与论文中描述相符的攻击图。请注意，对于生产环境，不应调用 -p 选项，因为它会指数级减慢攻击图生成过程，而且它只是使攻击图在视觉上更美观（尝试使用上面的命令但不带 -p 选项）。默认情况下，MulVAL 以文本格式（AttackGraph.txt）和 XML 格式（AttackGraph.xml）输出攻击图。这些格式的含义是不言自明的。当调用 -v 选项时，攻击图的可视化表示将通过 GraphViz 生成在 AttackGraph.pdf 中。如果设置了环境变量 PDF_READER，程序将自动使用该程序打开 pdf 文件。当指定适当的选项时（请参阅下文），MulVAL 还会以 CSV 格式输出攻击图信息：VERTICES.CSV 和 ARCS.CSV。CSV 文件可供渲染程序稍后生成攻击图的各种视图（请参阅下文）。MulVAL 还将在运行程序的文件夹中输出一些其他临时文件。因此，最好在单独的文件夹中运行它以避免杂乱。 参数说明 图形生成选项： -l：以 .CSV 格式输出攻击图 -v：以 .CSV 和 .PDF 格式输出攻击图 -p：对攻击图进行深度修剪以改善可视化效果（在生产环境中不要调用） 推理选项： -r | --rulefile RULE_FILE：将 RULE_FILE 用作交互规则集 -a | --additional ADDITIONAL_RULE_FILE：除了指定的交互规则集外，还使用 ADDITIONAL_RULE_FILE -g | --goal ATTACK_GOAL：指定单个攻击目标 --cvss：使用输入文件中包含的 CVSS 信息 -ma：使用输入文件中包含的 CVSS 信息，并对输入文件进行分组。使用此选项时，输入文件必须包含分组信息（见下文第 II 节） 渲染选项： --arclabel：输出弧的标签 --reverse：以相反的顺序输出弧 --nometric：不显示度量信息 --simple：不显示顶点事实标签。当攻击图变得过大无法可视化时使用此选项。 --nopdf：不生成 PDF。当您需要 DOT 文件但不需要 PDF 文件时使用此选项。 在运行 graph_gen.sh 脚本之后，您还可以调用 render.sh 使用不同的渲染选项。只需在相同目录中发出 render.sh [RENDERING OPTIONS]。 辅助工具该软件包包含了一些适配器程序，可帮助从企业网络中创建 MulVAL 输入文件。需要按照以下步骤进行操作。 … 高级用法Creating customized rule set 要开发自己的交互规则，您可以创建新的规则文件，例如 “my_interaction_rules.P”，并使用 -r 或 -a 选项来加载您的规则文件。默认的规则文件可以在该软件包的 kb&#x2F; 文件夹中找到。 在规则文件的开头，您必须声明原始和派生谓词，并将所有派生谓词进行表格化。具有原始谓词的事实来自输入，具有派生谓词的事实由交互规则定义。每个交互规则使用的谓词必须具有 “primitive” 或 “derived” 的声明，否则在评估过程中可能会收到 “undefined predicate” 的错误消息，并且攻击图生成可能会因缺少谓词声明而失败，并显示一条警告消息，告诉您缺少哪个谓词的声明。通过表格化，可以防止 XSB 推理引擎陷入无限循环，并通过对中间结果进行记忆化来提高推理的效率。 每个交互规则由 “interaction_rule(Rule, Label)” 引入，其中 Rule 是一个 Datalog 规则，Label 是一些说明其含义的纯文本。标签将成为攻击图中的注释。一旦开发了自己的规则集，您可以使用 -r RULEFILE 选项来测试它，该选项将让 graph_gen.sh 加载 RULEFILE 而不是使用默认规则集。如果您希望您的规则文件添加到默认规则集中，您可以使用 -a RULEFILE 选项。 Calculating risk metrics based on CVSS and MulVAL attack graph 我们已经包含了一个基于 Wang 等人的定量风险评估算法 [4]。它结合了 CVSS 指标和攻击图，为企业网络计算概率风险指标。要运行度量程序，请在攻击图输出所在的位置输入以下命令：probAssess.sh 还有一个脚本集成了多个步骤：创建 MulVAL 攻击图、运行风险度量算法并显示带有度量的攻击图：riskAssess.sh INPUT [OPTIONS] 它将在输入文件上运行 MulVAL。此脚本将始终使用 -ma（模型化工件）选项来生成攻击图。请使用 summ_oval.P（由 oval_translate.sh 生成）或 summ_nessus.P（由 nessus_translate.sh 生成）作为输入。使用 OPTIONS 将任何其他选项传递给 MulVAL 攻击图生成器（graph_gen.sh）。 参考文献 Xinming Ou, Wayne F. Boyer, and Miles A.McQueen. A scalable approach to attack graph generation. In 13th ACM Conference on Computer and Communications Security (CCS), 2006. Xinming Ou, Sudhakar Govindavajhala, and Andrew W. Appel. MulVAL: A logic-based network security analyzer. In 14th USENIX Security Symposium, 2005. Su Zhang, Xinming Ou, and John Homer. Effective network vulnerability assessment through model abstraction. In Eighth Conference on Detection of Intrusions and Malware &amp; Vulnerability Assessment (DIMVA), Amsterdam, The Netherlands, 2011. Lingyu Wang, Tania Islam, Tao Long, Anoop Singhal, and Sushil Jajodia. An attack graph-based probabilistic security metric. In Proceedings of The 22nd Annual IFIP WG 11.3 Working Conference on Data and Applications Security (DBSEC’08), 2008.","tags":["Automotive"],"categories":["Research"]},{"title":"《凤凰架构：构建可靠的大型分布式系统》🪽","path":"/2024/11/04/phoenix/","content":"有老朽，有消亡，有重生，有更迭，才是生态运行的合理规律 作者：周志明，出版时间：2021-06 凤凰架构：构建可靠的大型分布式系统架构演变最重要的驱动力，或者说这种“从大到小”的变化趋势的最根本驱动力，始终都是 为了方便某个服务能够顺利地“死去”与“重生”，个体服务的生死更迭，是关系到整个系统能否可靠存续的关键因素。 演进中的架构graph LR A[大型机Mainframe] -->|演变| B[原始分布式Distributed] B -->|演变| C[大型单体Monolithic] C -->|演变| D[面向服务Service-Oriented] D -->|演变| E[微服务Microservice] E -->|演变| F[服务网格Service Mesh] F -->|演变| G[无服务Serverless] style A fill:#e0e0e0,stroke:#333,stroke-width:1px; style B fill:#c8e6c9,stroke:#333,stroke-width:1px; style C fill:#bbdefb,stroke:#333,stroke-width:1px; style D fill:#ffe0b2,stroke:#333,stroke-width:1px; style E fill:#f8bbd0,stroke:#333,stroke-width:1px; style F fill:#d1c4e9,stroke:#333,stroke-width:1px; style G fill:#f0f4c3,stroke:#333,stroke-width:1px; 原始分布式时代 在 20 世纪 70 年代末期到 80 年代初，计算机科学刚经历了从以 大型机 为主向以 微型机 为主的蜕变 为突破硬件算力的限制，寻找使用多台计算机共同协作来支撑同一套软件系统的可行方案 负责制定 UNIX 系统技术标准的“开放软件基金会”（Open Software Foundation，OSF（邀请当时业界主流的计算机厂商一起参与，共同制订了名为“分布式运算环境”（Distributed Computing Environment，DCE）的分布式技术体系 由于 OSF 本身的 UNIX 背景，当时对这些技术的研究都带着浓厚的 UNIX 设计风格，有一个预设的重要原则是要使分布式环境中的服务调用、资源访问、数据存储等操作尽可能 透明化、简单化，从而使开发人员不必过于关注他们访问的方法或其他资源是位于本地还是远程 尽管“调用远程方法”与“调用本地方法”只有两字之差，但若要兼顾简单、透明、性能、正确、鲁棒、一致等特点，两者的复杂度就完全不可同日而语了，光是“远程”二字带来的网络环境下的新问题，例如： 远程的服务在哪里（服务发现） 有多少个（负载均衡） 网络出现分区、超时或者服务出错了怎么办（熔断、隔离、降级） 方法的参数与返回结果如何表示（序列化协议） 信息如何传输（传输协议） 服务权限如何管理（认证、授权） 如何保证通信安全（网络安全层） 如何令调用不同机器的服务返回相同的结果（分布式数据一致性） 为解决这样做带来的服务发现、跟踪、通信、容错、隔离、配置、传输、数据一致性和编码复杂度等方面的问题所付出的代价已远远超过了分布式所取得的收益 在那个时代的机器硬件条件下，为了让程序在运行效率上可被用户接受，开发者只能在方法本身运行时间很长、可以相对忽略远程调用成本时的情况下考虑分布式 以上结论是有违 UNIX 设计哲学的，却是当时现实情况下不得不做出的让步。摆在计算机科学面前有两条通往更大规模软件系统的道路： 一条是尽快提升单机的处理能力，以避免分布式带来的种种问题 另一条是找到更完美的、解决如何构建分布式系统的解决方案 原始分布式时代提出的构建符合 UNIX 设计哲学的、如同本地调用一般简单透明的分布式系统的这个目标，是软件开发者对分布式系统最初的美好愿景，但迫于现实，它会在一定时期内被妥协、被舍弃。 在三十多年后的 21 世纪 10 年代，随着分布式架构逐渐成熟、完善，并取代单体成为大型软件的主流架构风格以后，这个美好的愿景终将会重新被开发者拾起。 单体系统时代 单体架构风格的应用也称作“巨石系统”(Monolithic Application)，是出现时间最早（小型单体）、应用范围最广、使用人数最多、统治历史最长的一种架构风格，但“单体”这个名称，却是在微服务开始流行之后才“事后追认”所形成的概念 单体系统的不足，必须在软件的性能需求超过了单机、软件的开发人员规模明显超过了“2 Pizza Team”（6-12 人）范畴的前提下才有讨论的价值 使用多个独立的分布式服务共同构建一个更大型系统的设想与实际尝试，反而要比今天大家所了解的 大型单体系统 出现的时间更早 在“拆分”这方面： 从纵向角度来看，分层架构（Layered Architecture）已是现在所有信息系统建设中普遍认可、采用的软件设计方法，无论是单体还是微服务，抑或是其他架构风格 从横向角度来看，单体架构也支持按照技术、功能、职责等维度，将软件拆分为各种模块，以便重用和管理代码 即使是从横向扩展（Scale Horizontally）的角度来衡量，在负载均衡器之后同时部署若干个相同的单体系统副本，以达到分摊流量压力的效果，也是非常常见的需求 单体系统的真正缺陷不在如何拆分，而在拆分之后的 自治与隔离 能力上 由于所有代码都运行在同一个进程内，在获得进程内调用的简单、高效等好处的同时，也意味着如果任何一部分代码出现缺陷，过度消耗了进程空间内的资源，所造成的影响也是全局性的、难以隔离的（“单点故障”） 由于所有代码都共享同一个进程，不能隔离，也就无法（不便）做到单独停止、更新、升级某一部分代码，从 可维护性 来说，单体系统也是不占优势的 由于隔离能力的缺失，单体除了难以阻断错误传播、不便于动态更新程序以外，还面临难以 技术异构的困难，每个模块的代码通常都需要使用一样的程序语言，乃至一样的编程框架去开发 随着软件架构演进，构建可靠系统的观念从“追求尽量不出错”到正视“出错是必然”的转变，以微服务取代单体系统成为潮流趋势的根本原因是：单体系统很难兼容“Phoenix”的特性 为了 允许程序出错，获得 自治与隔离的能力，以及实现可以 技术异构 等目标，是继 性能与算力 之后，再次选择分布式的理由 开发分布式程序也并不意味着一定要依靠今天的微服务架构才能实现，在新旧世纪之交，将一个大的单体系统拆分为若干个更小的、不运行在同一个进程的 独立服务，这些服务拆分方法后来带来了 面向服务架构（Service-Oriented Architecture） 的一段兴盛期 SOA 时代为了对大型的单体系统进行拆分，让每一个子系统都能独立地部署、运行、更新，三种较有代表性的架构模式： 烟囱式架构（Information Silo Architecture）：信息烟囱又名信息孤岛（Information Island），使用这种架构的系统也被称为孤岛式信息系统或者烟囱式信息系统，它指的是一种与其他相关信息系统完全没有互操作或者协调工作的设计模式。 微内核架构（Microkernel Architecture）：微内核架构也被称为插件式架构（Plug-in Architecture）， 既然在烟囱式架构中，没有业务往来关系的系统也可能需要共享人员、组织、权限等一些公共的主数据，那不妨就将这些主数据，连同其他可能被各子系统用到的公共服务、数据、资源集中到一块，组成一个被所有业务系统共同依赖的核心（Kernel，也称为 Core System） 具体的业务系统以插件模块(Plug-in Module)的形式存在，这样也可提供可扩展的、灵活的、天然隔离的功能特性，即微内核架构 微内核架构也有局限性，它假设系统中各个插件模块之间互不认识，且不可预知系统将安装哪些模块，因此这些插件可以访问内核中一些公共的资源，但不会直接交互 事件驱动架构（Event-Driven Architecture）：为了能让子系统互相通信，一种可行的方案是在子系统之间建立一套事件队列管道(Event Queue) 来自系统外部的消息将以事件的形式发送至管道中，各个子系统可以从管道里获取自己感兴趣、能够处理的事件消息 也可以为事件新增或者修改其中的附加信息，甚至可以自己发布一些新的事件到管道队列中去 如此，每一条消息的处理者都是独立的、高度解耦的，但又能与其他处理者（如果存在其他消息处理者的话）通过事件管道进行交互 软件架构来到 SOA 时代，其包含的许多概念、思想都已经能在今天的微服务中找到对应的身影了，譬如服务之间的松散耦合、注册、发现、治理，隔离、编排等，这些在微服务中耳熟能详的概念，大多数也是在分布式服务刚被提出时就已经可以预见的困难点。SOA 针对这些问题，甚至是针对“软件开发”这件事情本身，都进行了更具体、更系统的探索。 “更具体”：尽管 SOA 本身还属于抽象概念，而不是特指某一种具体的技术，但它比单体架构和前面所列举的三种架构模式的操作性更强，已经不能简单视为一种架构风格，而是 一套软件设计的基础平台 有领导制定技术标准的组织 Open CSA，有清晰的软件设计的指导原则 明确了采用 SOAP 作为远程调用协议，依靠 SOAP 协议族（WSDL、UDDI 和 WS-*协议）来完成服务的发布、发现和治理 利用企业服务总线（Enterprise Service Bus，ESB）的消息管道来实现各个子系统之间的交互 使用服务数据对象（Service Data Object，SDO）来访问和表示数据 使用服务组件架构（Service Component Architecture，SCA）来定义服务封装的形式和服务运行的容器 “更系统”：SOA 的终极目标是希望总结出一套自上而下的软件研发方法论，做到企业只需要跟着 SOA 的思路，就能够一揽子解决掉软件开发过程中的全部问题，譬如该如何挖掘需求、如何将需求分解为业务能力、如何编排已有服务、如何开发&#x2F;测试&#x2F;部署新的功能等 经过三十年的技术发展，信息系统经历了巨石、烟囱、插件、事件、SOA 等架构模式，应用受架构复杂度的牵绊却越来越大，已经 距离“透明”二字越来越远 了，这是否算不自觉间忘掉了当年的初心呢？（SOA → 微服务） 微服务时代“微服务”这个技术名词最早在 2005 年就已经被提出，由 Peter Rodgers 博士在 2005 年的云计算博览会（Web Services Edge 2005）上首次使用，当时的说法是“Micro-Web-Service”，指的是一种专注于单一职责的、与语言无关的细粒度 Web 服务（Granular Web Service），它 最初 可以说是 SOA 发展时催生的产物，这一阶段的微服务是作为 SOA 的一种轻量化的补救方案而被提出的，是 SOA 的一种变体。 2012 年，在波兰克拉科夫举行的“33rd Degree Conference”大会上，Thoughtworks 首席咨询师 James Lewis 做了题为“Microservices-Java, the UNIX Way”的主题演讲，其中提到了 单一服务职责、康威定律、自动扩展、领域驱动设计 等原则，却只字未提 SOA，反而号召应该重拾 UNIX 的设计哲学(As Well Behaved UNIX Service)。 微服务真正崛起是在 2014 年，Martin Fowler 与 James Lewis 合写的文章“Microservices：A Definition of This New Architectural Term”，此文首先给出了现代微服务的概念：“微服务是一种 通过多个小型服务组合来构建单个应用的架构风格，这些服务围绕业务能力而非特定的技术标准来构建，各个服务可以采用 不同的编程语言、不同的数据存储技术，运行在不同的进程之中，服务采取 轻量级的通信机制 和 自动化的部署机制 实现通信与运维。” 此外，文中列举了微服务的 九个核心的业务与技术特征： 围绕业务能力构建（Organized around Business Capability） 分散治理（Decentralized Governance） 通过服务来实现独立自治的组件（Componentization via Service） 产品化思维（Product not Project） 数据去中心化（Decentralized Data Management） 强终端弱管道（Smart Endpoint and Dumb Pipe） 容错性设计（Design for Failure） 演进式设计（Evolutionary Design） 基础设施自动化（Infrastructure Automation） 微服务追求的是更加自由的架构风格，摒弃了几乎所有 SOA 里可以抛弃的约束和规定，提倡以“实践标准”代替“规范标准”，对于服务的注册发现、跟踪治理、负载均衡、故障隔离、认证授权、伸缩扩展、传输通信、事务处理等问题，微服务中将 不再有统一的解决方案。 仅一个服务间远程调用问题，可以列入解决方案的候选清单的就有：RMI(Sun&#x2F;Oracle)、Thrift(Facebook)、Dubbo（阿里巴巴）、gRPC(Google)、Motan2（新浪）、Finagle(Twitter)、brpc（百度）、Arvo(Hadoop)、JSON-RPC、REST 等 仅一个服务发现问题，可以选择的就有 Eureka(Netflix)、Consul(HashiCorp)、Nacos（阿里巴巴）、ZooKeeper(Apache)、etcd(CoreOS)、CoreDNS(CNCF)等，其他领域也与此类似 技术架构者的第一职责就是决策权衡，有利有弊才需要决策，有取有舍才需要权衡，如果架构者本身的知识面不足以覆盖所需要决策的内容，不清楚其中利弊，恐怕将无可避免地陷入选择困难症的境遇之中。微服务时代充满着自由的气息，微服务时代充斥着迷茫的选择。 后微服务时代布式架构中出现的问题，如 注册发现、跟踪治理、负载均衡、传输通信 等，其实在 SOA 时代甚至从原始分布式时代起就已经存在了，只要是分布式架构的系统，就无法完全避免，这些问题一定要由软件系统自己来解决吗？如果不局限于采用软件的方式，这些问题几乎都有对应的硬件解决方案，譬如： 某个系统需要 伸缩扩容，通常会购买新的服务器，部署若干副本实例来分担压力 如果某个系统需要解决 负载均衡 问题，通常会布置负载均衡器，选择恰当的均衡算法来分流 如果需要解决 传输安全 问题，通常会布置 TLS 传输链路，配置好 CA 证书以保证通信不被窃听篡改 如果需要解决 服务发现 问题，通常会设置 DNS 服务器，让服务访问依赖稳定的记录名而不是易变的 IP 地址 在微服务时代，人们之所以选择在软件的代码层面而不是硬件的基础设施层面去解决这些分布式问题，很大程度上是因为由 硬件构成的基础设施跟不上由软件构成的应用服务的灵活性 的无奈之举，软件可以只使用键盘命令就拆分出不同的服务，只通过拷贝、启动就能够实现伸缩扩容服务，硬件难道就不可以通过键盘命令变出相应的应用服务器、负载均衡器、DNS 服务器、网络链路这些设施吗？ 微服务时代所取得的成就，本身就离不开以 Docker 为代表的早期容器化技术的巨大贡献。早期的容器只被简单地视为一种可快速启动的服务运行环境，目的是方便程序的分发部署，在这个阶段，针对单个应用进行封装的容器并未真正解决分布式架构问题。 一场持续了三年时间，以 Docker Swarm、Apache Mesos 与 Kubernetes 为主要竞争者的“容器编排战争”，Kubernetes 登基加冕是容器发展中一个时代的终章，也将是软件架构发展下一个纪元的开端。Kubernetes 中提供的 基础设施层面的解决方案 与传统 Spring Cloud 中提供的 应用层面的解决方案 的对比，尽管因为各自出发点不同，解决问题的方法和效果都有所差异，但这无疑是提供了一条全新的、前途更加广阔的解题思路。 功能 Kubernetes Spring Cloud 弹性伸缩 Autoscaling N&#x2F;A 服务发现 KubeDNS &#x2F; CoreDNS Spring Cloud Eureka 配置中心 ConfigMap &#x2F; Secret Spring Cloud Config 服务网关 Ingress Controller Spring Cloud Zuul 负载均衡 Load Balancer Spring Cloud Ribbon 服务安全 RBAC API Spring Cloud Security 跟踪监控 Metrics API &#x2F; Dashboard Spring Cloud Turbine 降级熔断 N&#x2F;A Spring Cloud Hystrix 当虚拟化的基础设施从单个服务的容器扩展至由多个容器构成的服务集群、通信网络和存储设施时，软件与硬件的界限便已模糊。一旦虚拟化的硬件能够跟上软件的灵活性，那些与业务无关的技术性问题便有可能从软件层面剥离，悄无声息地在硬件基础设施之内解决，让软件得以只专注业务，真正围绕业务能力构建团队与产品。 从 软件层面独立应对 分布式架构所带来的各种问题，发展到 应用代码与基础设施软、硬一体，合力应对 架构问题，这个新的时代现在常被媒体冠以“云原生”这个颇为抽象的名字加以宣传。云原生时代追求的目标与此前微服务时代追求的目标并没有本质改变，都是在服务架构演进的历史进程中，称云原生时代为“后微服务时代”。 服务网格（Service Mesh） 基础设施是针对整个容器来管理的，粒度相对粗犷，只能到容器层面，对单个远程服务则很难有效管控，类似的，在服务的监控、认证、授权、安全、负载均衡等方面都有可能面临细化管理的需求。为了解决这一类问题，虚拟化的基础设施很快完成了第二次进化，引入了今天被称为“服务网格”（Service Mesh）的“边车代理模式”（Sidecar Proxy）。 在虚拟化场景中的边车指的是由系统自动在服务容器（通常是指 Kubernetes 的 Pod）中注入一个通信代理服务器，以类似网络安全里中间人攻击的方式进行流量劫持，在应用毫无感知的情况下，悄然接管应用所有对外通信。 这个代理除了实现正常的服务间通信外（称为数据平面通信），还接收来自控制器的指令（称为控制平面通信），根据控制平面中的配置，对数据平面通信的内容进行分析处理，以实现熔断、认证、度量、监控、负载均衡等各种附加功能 通过边车代理模式，便实现了既不需要在应用层面加入额外的处理代码，也提供了几乎不亚于程序代码的 精细管理能力 无服务时代对软件研发而言，不去做分布式无疑是最简单的，如果单台服务器的性能可以是无限的，那架构演进的结果肯定会与今天有很大差别。 绝对意义上的无限性能必然是不存在的，但在云计算落地已有十余年的今天，相对意义的无限性能已经成为现实。 无服务现在还没有一个特别权威的“官方”定义，它只涉及两块内容：后端设施（Backend）和函数（Function）： 后端设施 是指 数据库、消息队列、日志、存储 等这类用于支撑业务逻辑运行，但本身无业务含义的技术组件，这些后端设施都运行在云中，在无服务中将它们称为“后端即服务”（Backend as a Service，BaaS） 函数 是指业务逻辑代码，这里函数的概念与粒度都已经很接近于程序编码角度的函数了，其区别是无服务中的函数运行在云端，不必考虑算力问题，也不必考虑容量规划（从技术角度），在无服务中将其称为“函数即服务”（Function as a Service，FaaS） 无服务的愿景是让开发者只需要纯粹地关注业务： 不需要考虑 技术组件，后端的技术组件是现成的，可以直接取用，没有采购、版权和选型的烦恼 不需要考虑如何 部署，部署过程完全托管到云端，由云端自动完成 不需要考虑 算力，有整个数据中心支撑，算力可以认为是无限的 不需要操心 运维，维护系统持续平稳运行是云计算服务商的责任而不再是开发者的责任 在 UC Berkeley 的论文中，把无服务架构下开发者不再关心这些技术层面的细节，类比成 当年软件开发从汇编语言踏进高级语言的发展过程，开发者可以不去关注寄存器、信号、中断等与机器底层相关的细节，从而令生产力得到极大解放。 无服务架构能够降低一些应用的开发和运维环节的成本，但无服务云函数会有冷启动时间，不便依赖服务端状态，响应的性能不太好： 优势：不需要交互的 离线大规模计算、多数 Web 资讯类网站、小程序、公共 API 服务、移动应用服务端等都契合于无服务架构所擅长的短链接、无状态、适合 事件驱动的交互形式 劣势：对于那些信息管理系统、网络游戏等应用，或者说对于 具有业务逻辑复杂、依赖服务端状态、响应速度要求较高、需要长链接等特征的应用，至少目前是相对不那么适合的 如果说微服务架构是分布式系统这条路当前所能做到的极致，那无服务架构，也许就是“不分布式”的云端系统这条路的起点。 将无服务作为技术层面的架构，将微服务视为应用层面的架构，把它们组合起来使用是完全合理可行的。以后，无论是物理机、虚拟机、容器，抑或是无服务云函数，都会是微服务实现方案的候选项之一。 （微服务与无服务并存） 架构师的视角访问远程服务远程服务调用 远程服务调用（Remote Procedure Call，RPC）在计算机科学中已经存在超过四十年时间 最初计算机科学家们的想法，就是将 RPC 作为 IPC 的一种特例来看待，这个观点在今天，仅从分类上说也仍然合理，只是到具体操作手段上就不合适了 进程间通信 一个进程内的函数调用依赖 栈内存 不同进程之间交换数据的问题被称为“进程间通信”（Inter-Process Communication，IPC） 管道（Pipe）&#x2F; 具名管道（Named Pipe） 普通管道只用于有亲缘关系的进程（由一个进程启动的另外一个进程）间的通信 具名管道允许无亲缘关系的进程间的通信，管道典型的应用就是命令行中的“|”操作符 信号（Signal）用于通知目标进程有某种事件发生，除进程间通信外，进程还可以给自身发送信号 kill -9 pid 表示由 Shell 进程向指定 PID 的进程发送 SIGKILL 信号 信号量（Semaphore）用于在两个进程之间同步协作手段，相当于操作系统提供的一个特殊变量 消息队列（Message Queue） 克服了信号承载信息量少、管道只能用于无格式字节流以及缓冲区大小受限等缺点 但实时性相对受限 共享内存（Shared Memory）允许多个进程访问共同一块公共内存空间，这是效率最高的进程间通信形式 本地套接字接口（UNIX&#x2F;IPC Socket），套接字接口则是更普适的进程间通信机制，可用于不同机器之间的进程通信 当 仅限于本机进程间通信时，套接字接口被优化，不会经过网络协议栈，不需要打包拆包、计算校验和、维护序号和应答等操作 将应用层数据从一个进程复制到另一个进程，这种进程间通信方式即本地套接字接口（UNIX Domain Socket &#x2F; IPC Socket） 由于 Socket 是网络栈的统一接口，它也能支持基于网络的跨机进程间通信 通信的成本 由于 Socket 是各个操作系统都提供的标准接口，完全有可能把远程方法调用的通信细节隐藏在操作系统底层，从应用层面上来看可以做到远程调用与本地的进程间通信在编码上完全一致，在原始分布式时代的早期确实是奔着这个目标去做的 1987 年，在“透明的 RPC 调用”一度成为主流范式的时候，Andrew Tanenbaum 教授曾发表论文“A Critique of The Remote Procedure Call Paradigm”，对这种透明的 RPC 范式提出一系列质问：把本地调用与远程调用当作同样的调用来处理，这是犯了方向性的错误，把系统间的调用透明化，反而会增加程序员工作的复杂度 到 1994 年至 1997 年间，由 ACM 和 Sun 院士 Peter Deutsch、套接字接口发明者 Bill Joy、Java 之父 James Gosling 等一众在 Sun 公司工作的专家们共同总结了通过网络进行分布式运算的八宗罪（8 Fallacies of Distributed Computing） The network is reliable —— 网络是可靠的 Latency is zero—— 延迟是不存在的 Bandwidth is infinite —— 带宽是无限的 The network is secure —— 网络是安全的 Topology doesn’t change —— 拓扑结构是一成不变的 There is one administrator —— 总会有一个管理员 Transport cost is zero —— 不必考虑传输成本 The network is homogeneous —— 网络都是同质化的 以上这八条反话被认为是程序员在网络编程中经常忽略的八大问题，潜台词就是如果远程服务调用要透明化，就必须为这些罪过买单，这算是给 RPC 能否等同于 IPC 来 暂时 定下了一个具有公信力的结论 至此，RPC 应该是一种高层次的或者说语言层次的特征，而不是像 IPC 那样，是低层次的或者说系统层次的特征”的观点成为工业界、学术界的主流观点 远程服务调用是指位于互不重合的内存地址空间中的两个程序，在语言层面上，以同步的方式使用带宽有限的信道来传输程序控制信息。——Bruce Jay Nelson，Remote Procedure Call，Xerox PARC，1981 三个基本问题 这几十年所有流行过的 RPC 协议，都不外乎变着花样使用各种手段来解决以下三个基本问题： 如何表示数据，数据包括传递给方法的参数以及方法执行后的返回 对于进程内的方法调用，使用程序语言预置和程序员自定义的数据类型，就很容易解决数据表示问题 对于远程方法调用，则完全可能面临交互双方各自使用不同程序语言的情况 即使只支持一种程序语言的 RPC 协议，在不同硬件指令集&#x2F;操作系统下，同样的数据类型也可能有不一样的表现细节 有效的做法是将交互双方所涉及的数据转换为某种事先约定好的中立数据流格式来进行传输，将数据流转换回不同语言中对应的数据类型来使用 —— 就是序列化与反序列化，例如： ONC RPC 的外部数据表示（External Data Representation，XDR） CORBA 的通用数据表示（Common Data Representation，CDR） Java RMI 的 Java 对象序列化流协议（Java Object Serialization Stream Protocol） gRPC 的 Protocol Buffers Web Service 的 XML 序列化 众多轻量级 RPC 支持的 JSON 序列化 如何传递数据，如何通过网络，在两个服务的 Endpoint 之间相互操作、交换数据（通常指的是应用层协议数据） 两个服务交互不是只扔个序列化数据流来表示参数和结果就行 许多在此之外的信息，譬如异常、超时、安全、认证、授权、事务等，都可能产生双方需要交换信息的需求 在计算机科学中，专门有一个名词“Wire Protocol”来表示这种两个 Endpoint 之间交换这类数据的行为，常见的如下： Java RMI 的 Java 远程消息交换协议（Java Remote Message Protocol，JRMP，也支持 RMI-IIOP） CORBA 的互联网 ORB 间协议（Internet Inter ORB Protocol，IIOP，是 GIOP 协议在 IP 协议上的实现版本） DDS 的实时发布订阅协议（Real Time Publish Subscribe Protocol，RTPS） Web Service 的简单对象访问协议（Simple Object Access Protocol，SOAP） 如果要求足够简单，双方都是 HTTP Endpoint，直接使用 HTTP 协议也是可以的（如 JSON-RPC） 如何表示方法，一套与语言无关的接口描述语言(Interface Description Language，IDL) 在本地方法调用中，编译器或者解释器会根据语言规范，将调用的方法签名转换为进程空间中子过程入口位置的指针 不过一旦要考虑不同语言，“如何表示同一个方法”“如何找到对应的方法”需要一个统一的跨语言的标准，用于表示方法的协议有： Android 的 Android 接口定义语言（Android Interface Definition Language，AIDL） CORBA 的 OMG 接口定义语言（OMG Interface Definition Language，OMG IDL） Web Service 的 Web 服务描述语言（Web Service Description Language，WSDL） JSON-RPC 的 JSON Web 服务协议（JSON Web Service Protocol，JSON-WSP） 以上 RPC 中的三个基本问题，全部都可以在本地方法调用过程中找到对应的解决方案 统一的 RPC 1998 年，XML 1.0 发布，并成为万维网联盟（World Wide Web Consortium，W3C）的推荐标准 1999 年末，SOAP 1.0（Simple Object Access Protocol）规范的发布，标志着一种被称为“Web Service”的全新的 RPC 协议的诞生 Web Service 采用 XML 作为远程过程调用的序列化、接口描述、服务发现等所有编码的载体 Web Service 采用 XML 每一次数据交互都包含大量的冗余信息，性能奇差 Web Service 希望在一套协议上一揽子解决分布式计算中可能遇到的所有问题，让开发者学习负担沉重 总结 那些面向透明的、简单的 RPC 协议，如 DCE&#x2F;RPC、DCOM、Java RMI，要么依赖于操作系统，要么依赖于特定语言（约束） 那些面向通用的、普适的 RPC 协议，如 CORBA，无法逃过使用 复杂性 的困扰（CORBA 烦琐的 OMG IDL、ORB ） 那些意图通过技术手段来屏蔽复杂性的 RPC 协议，如 Web Service，又不免受到 性能 问题的束缚 简单、普适、高性能 这三点，似乎真的很难同时满足 分裂的 RPC 由于一直没有一个同时满足以上三点的“完美 RPC 协议”出现，所以远程服务器调用这个小小的领域，逐渐进入群雄混战、百家争鸣的战国时代，距离“统一”越来越远，并一直延续至今 现在，已经相继出现过许多难以穷举的协议和框架： RMI（sun&#x2F;Oracle） Thrift（Facebook&#x2F;Apache） Dubbo（阿里巴巴&#x2F;Apache） gRPC（Google） Motan1&#x2F;2（新浪） Finagle（Twitter） brpc（百度&#x2F;Apache） .NET Remoting（微软） Arvo（Hadoop） JSON-RPC 2.0（公开规范，JSON-RPC 工作组） 这些 RPC 功能、特点不尽相同，有的是某种语言私有，有的支持跨越多种语言，有的运行在应用层 HTTP 协议之上，有的直接运行于传输层 TCP&#x2F;UDP 协议之上，但并不存在哪一款是“最完美的 RPC”，任何一款具有生命力的 RPC 框架，都不再去追求大而全的“完美”，而是以某个具有针对性的特点作为主要的发展方向： 朝着性能发展，代表为 gRPC 和 Thrift，决定 RPC 性能的主要因素有序列化效率和信息密度 序列化输出结果的容量越小，速度越快，效率自然越高 信息密度则取决于协议中有效负载（Payload）所占总传输数据的比例大小，使用传输协议的层次越高，信息密度就越低 gRPC 和 Thrift 都有自己优秀的专有序列化器 gRPC 是基于 HTTP&#x2F;2 的，支持多路复用和 Header 压缩 Thrift 则直接基于传输层的 TCP 协议来实现，省去了应用层协议的额外开销 朝着简化发展，代表为 JSON-RPC 牺牲了功能和效率，换来的是协议的简单轻便，接口与格式都更为通用 尤其适合用于 Web 浏览器这类一般不会有额外协议支持、额外客户端支持的应用场合 到了最近几年，RPC 框架有明显向 更高层次（不仅仅负责调用远程服务，还管理远程服务）与 插件化 方向发展的趋势 不再追求独立地解决 RPC 的全部三个问题（表示数据、传递数据、表示方法），而是将一部分功能设计成扩展点 框架聚焦于提供核心的、更高层次的能力，譬如提供负载均衡、服务注册、可观察性等方面的支持 REST 设计风格事务处理本地事务全局事务共享事务分布式事务透明多级分流系统架构安全性分布式的基石不可变基础设施技术方法论","tags":["architecture","distributed"],"categories":["Reading"]},{"title":"《深入架构原理与实践》📖✍🏻","path":"/2024/10/28/availability/","content":"一本关于架构设计的开源书籍：https://www.thebyte.com.cn 深入架构原理与实践第一章：云原生技术概论云计算的演进变革 物理机时代，业务的工作负载是整台物理机，资源没有隔离，也完全没有服务&#x2F;资源供应商一说 虚拟化技术成熟，可以在一台物理机器上运行多个虚拟机 1959 年，Christopher Strachey 在国际信息处理大会上发表《Time Sharing in Large Fast Computer》论文，首次提出了“虚拟化”的概念 如果业务需要扩容，那就再开通一个虚拟机，整个过程只要几分钟 业务的工作负载由物理机转向虚拟机，资源有了初级的隔离，并且分配&#x2F;利用更加合理，服务部署的速度和弹性也远超物理机 云计算技术成熟，虚拟化技术的成熟使得云计算市场开始真正形成 2006 年 8 月 9 日，Google 首席执行官 Eric Schmidt 在搜索引擎大会（SES San Jose 2006）首次提出“云计算”（Cloud Computing）的概念 基于虚拟化技术诞生了众多的云计算产品，陆续出现了 IaaS、PaaS、SaaS 以及公有云、私有云、混合云等多种云服务模型 容器技术的兴起，打破了 PaaS 行业面临应用分发和交付的困境，大力推动了云原生的发展 2013 年，Docker 发布，容器逐步替代虚拟机（Virtual Machine，VM），云计算进入容器时代 2017 年底，Kubernetes 赢得容器编排的胜利，云计算进入 Kubernetes 时代 云计算从仅提供计算、存储、网络资源的初级阶段，发展成为具备强大软件交付和维护能力的综合性服务平台 云计算的演进总结 工作负载的变化：从早期的 物理服务器，通过虚拟化技术演进为 虚拟机，再通过容器化技术演进为目前的 容器 隔离单元：无论是启动时间还是单元大小，物理机、虚拟机、容器一路走来，实现了 从重量级到轻量级的转变 供应商：从闭源到开源（从 VMware 到 KVM、OpenStack，再到 Kubernetes）从单一供应商到跨越多个供应商（从公有云到自建云，再到混合云） 云原生出现的背景 软件正在吞噬世界 2011 年 8 月 20 日华尔街日报上，Mark Andreessen 发表了名为“Why Software Is Eating the World”的文章 部分软件已经变成水电煤一样的社会经济中的基础设施 移动互联网在加剧变化 按照 规模和变更速度 将软件企业划分为四个象限&#x2F;四种类型 企业 IT（Enterprise IT）：规模小、变化慢，容易处理 电信（Telcos）：规模大、变化慢，主要应对硬件失败 初创公司（Startups）：规模小、变化快，主要应对软件失败 网络规模的互联网企业（Web-Scale）：规模大、变化快，软硬件或者说所有东西都会出问题 移动互联网时代的用户规模已经开始向人口基数看齐，开始出现各类亿级 DAU 规模的移动应用 在移动互联网时代，能够成长并发展起来的这些公司，它们的共同点是： 快速变更，不断创新，随时调整 提供持续可用的服务，应对各种可能的错误和中断 弹性可扩展的系统，应对用户规模的快速增长 提供新的用户体验，以移动为中心 这样的背景下，对软件质量有了更高的要求，首当其冲的就是 如何解决规模越来越大同时变更越来越快的难题 云原生诞生 软件对各行各业的渗透和对世界的改变，以及移动互联网时代巨大的用户基数下快速变更和不断创新的需求 对软件开发方式带来的巨大推动力 在过去二十年，云的底层基础设施和平台越来越强大，软件架构的发展也逐渐和云匹配： 通过不可变基础设施（镜像）解决本地和远程一致性问题 通过服务网格（ServiceMesh）将非业务逻辑从应用程序中剥离 通过声明式 API 描述应用程序的状态，而不用管中间的处理过程 通过 DevOps 方法论以及一系列工具来提升研发&#x2F;运维效率 应用程序中的非业务逻辑不断被剥离，并下沉到云&#x2F;基础设施层，代码越来越轻量，工程师的开发工作回归本质 软件开发的本质是 解决业务需求，各类“高深”、“复杂”的技术难题是 业务需求的副产物，并不是软件开发的主题 云原生的定义与目标 云原生是一个组合词，“云”表示应用程序运行于分布式云环境中，“原生”表示应用程序在设计之初就充分考虑到了云平台的弹性和分布式特性，充分利用云计算优势对应用程序进行设计、实现、部署、交付的理念方法 2015 年，来自 Pivotal 公司的技术产品经理 Matt Stine，首次提出了云原生（Cloud Native）的概念 在 Pivotal 最新的官方网站中，对云原生的介绍则是关注 4 个要点： DevOps（开发运维） Continuous Delivery（持续交付） Microservices（微服务） Containers（容器化） CNCF 对云原生的定义 2015 年 CNCF（Cloud Native Computing Foundation，云原生计算基金会）建立，开始围绕云原生的概念打造云原生生态体系 CNCF 是 Linux 基金会旗下的基金会，成立这个组织的初衷或者愿景是推动云原生计算可持续发展，帮助云原生技术开发人员快速地构建出色的产品 起初 CNCF 对云原生的定义包含以下三个方面： 应用容器化：容器化是云原生的基础 面向微服务架构：实施微服务是构建大规模系统的必备要素 应用支持容器的编排调度：编排调度是指能够对容器应用的部署、扩展、运行和生命周期进行自动化管理 2018 年 6 月，CNCF 正式对外公布了更新之后的云原生的定义 v1.0 版本： 云原生技术有利于各组织在公有云、私有云和混合云等新型动态环境中，**构建和运行可弹性扩展的应用** 云原生的代表技术包括：**容器、服务网格、微服务、不可变基础设施和声明式 API** 这些技术能够构建 **容错性好、易于管理和便于观察的松耦合系统** 结合可靠的 **自动化手段**，云原生技术使工程师能够轻松地对系统作出频繁和可预测的重大变更 云原生的定义是什么并不重要，关键还是理解实施云原生有什么好处，以及实施云原生所涉及的技术&#x2F;工具、架构设计的依据等 云原生的目标主要是帮助企业和开发者 构建、运行和管理现代化应用，以便在云环境中实现高效、敏捷和弹性的业务交付 可用（Available）：通过各种机制来实现应用的高可用，以保证服务提供的连续性 规模（Scale）：能够适应不同的规模（包括但不限于用户规模&#x2F;部署规模&#x2F;请求量），并能够在部署时动态分配资源，以便在不同的规模之间快速和平滑的伸缩，典型场景如： 初创公司或新产品线快速成长，用户规模和应用部署规模在短时间内十倍百倍增长 促销、季节性、节假日带来的访问量波动 高峰时间段的突发流量等 敏捷（Agility）：快速响应市场需求 成本（Cost）：充分有效的利用资源 这 4 个核心目标之间，存在彼此冲突的情况： 规模和敏捷之间的冲突：规模大而又要求敏捷，比喻为“巨人绣花” 规模和可用性之间的冲突：规模大而要求可用性高，比喻为“大象起舞” 敏捷和可用性之间的冲突：敏捷而要求高可用，比喻为“空中换发” 而云原生架构必须要在同时满足这 3 个彼此冲突目标的前提下，还要实现成本控制 云原生代表技术概览 容器技术 chroot 阶段：隔离文件系统 一个叫做 chroot（Change Root）的系统调用被认为是最早的容器化技术之一 可以重定向进程及其子进程的 root 目录到文件系统上的新位置，即分离每个进程的 文件访问权限，使得该进程无法接触到外面的文件 通过 chroot 隔离出来的新环境得到了一个非常形象的命名 Jail（监狱），这便是容器最重要的特性 —— 隔离 LXC 阶段：封装系统 2008 年 Linux 内核版本 2.6.24 刚开始提供 cgroups（Control Groups），提供操作系统级别的 资源限制、优先级控制、资源审计和进程控制能力 社区开发者就将 cgroups 资源管理能力和 Linux namespace 资源隔离 能力组合在一起，形成了完整的容器技术 LXC（Linux Container） Docker 阶段：封装应用 Docker 的核心创新“容器镜像（container image）” 容器镜像打包了整个容器运行依赖的环境，以避免依赖运行容器的服务器的操作系统，从而实现“build once，run anywhere” 容器镜像一但构建完成，就变成只读状态，成为不可变基础设施的一份子 与操作系统发行版无关，核心解决的是容器进程对操作系统包含的库、工具、配置的依赖（注意，容器镜像 无法解决容器进程对内核特性的特殊依赖） 开发者基于镜像打包应用所依赖的环境，而不是改造应用来适配 PaaS 定义的运行环境 现阶段容器技术体系已经解决了 最核心的两个问题“如何运行软件和如何发布软件”，云计算开始进入容器阶段 OCI 阶段：容器标准化 Linux 基金会联合 Docker 带头成立 OCI（Open Container Initiative，开放容器标准）项目 OCI 组织着力解决容器的构建、分发和运行标准问题，其宗旨是制定并维护 OCI Specifications（容器镜像格式和容器运行时的标准规范） 容器编排阶段：封装集群 以 Docker 为代表的容器引擎，是把软件的发布流程从分发二进制安装包，转变为了直接分发虚拟化后的整个运行环境 以 Kubernetes 为代表的容器编排框架，就是把大型软件系统运行所依赖的集群环境也进行了虚拟化 云原生阶段：百花齐放 2015 年 7 月 21 日，Google 带头成立了 Cloud Native Computing Foundation（CNCF，云原生基金会） OCI 和 CNCF 这两个围绕容器的基金会共同制定了一系列行业事实标准，基于接口标准的具体实现不断涌现，呈现出一片百花齐放的景象 微服务 微服务架构是一种面向服务的架构，由松耦合的具有有限上下文的元素组成 松耦合（Loosely Coupled）：意味着每个服务可以独立的更新，更新一个服务无需要求改变其他服务 限界上下文（Bounded Contexts）：意味着每个服务要有明确的边界性，你可以只关注自身软件的发布，而无需考虑谁在依赖你的发布版本 微服务和它的消费者严格通过 API 进行交互，不共享数据结构、数据库等，基于契约的微服务规范要求服务接口是稳定的，而且向下兼容 微服务架构的特征是：服务之间独立部署，拥有各自的技术栈，各自界定上下文 微服务带来的技术挑战 微服务架构首先是一个分布式的架构，软件架构从巨石应用向微服务架构转型的过程中带来了一系列的非功能性需求，例如： 服务发现（Service Discovery）问题：解决“我想调用你，如何找到你”的问题 服务熔断（Circuit Breaker）问题：缓解服务之间依赖的不可靠问题 负载均衡（Load Balancing）问题：通过均匀分配流量，让请求处理更加及时 安全通讯问题：包括协议加密（TLS）、身份认证（证书&#x2F;签名）、访问鉴权（RBAC）等 解决这些问题需要编写和维护大量非功能性代码，这些代码与业务代码逻辑混在一起，基础设施不完善的话，实施微服务会很痛苦，服务越多越悲剧 后微服务时代 之所以选择在应用服务层面，而非基础设施层面去解决这些分布式问题，主要是 因为硬件构建的基础设施无法追赶上软件构成的应用服务的灵活性 被业界广泛认可、普遍采用的 通过虚拟化基础设施去解决分布式架构问题 的开端，应该要从 2017 年 Kubernetes 赢得容器战争的胜利开始算起 一旦虚拟化的硬件能够跟上软件的灵活性，那些与业务无关的技术性问题便有可能从软件层面剥离，并悄无声息地解决于硬件基础设施之内 但对于 Kubernetes，由于基础设施粒度更粗糙，通常只能管理到容器层面，对单个远程服务的有效管理就相对困难，服务的监控、认证、授权、安全、负载均衡等都有可能面临细化管理的需求 为了解决这一类问题，微服务基础设施很快进行了第二次进化，引入了今天被称为“服务网格”（Service Mesh）的模式 服务网格 服务网格（ServiceMesh）是一个 基础设施层，用于处理服务间通信。云原生应用有着复杂的服务拓扑，服务网格保证 请求在这些拓扑中可靠地穿梭。在实际应用当中，服务网格通常是由一系列轻量级的 网络代理 组成的，它们与应用程序部署在一起，但 对应用程序透明 服务网格的关键在于 Sidecar 模式，服务网格将具有流控能力的网络代理以 Sidecar 的方式部署，各个微服务之间通过 Sidecar 发现和调用目标服务，从而在服务之间形成一种网络状依赖关系 在 Kubernetes 的工作负载 Pod 中可以运行多个容器，其中 所有业务容器之外的其他容器均可称为 Sidecar，如日志收集 Sidecar、请求代理 Sidecar 和链路追踪 Sidecar 等 服务网格本质是通过 iptables 劫持发送到应用容器的流量，将原本在业务层处理的分布式通信治理相关的技术问题，下沉到具有流控能力的 Sidecar 中处理，实现业务与非业务逻辑解耦 的目的 不可变基础设施 “可变”的基础实施与传统运维操作相关，比如手动对服务器进行变更，部署的是 Apache，换成 Nginx（在原有的基础上做原地更新） 不可变基础设施的 核心思想是任何基础设施的运行实例一旦创建之后就变成只读状态，如需修改应先修改基础设施的配置模版（例如 yaml、Dockerfile） 从容器的角度看，镜像就是一个不可变基础设施，开发工程师交付的产物从一个有着各种依赖条件的安装包变成一个不依赖任何环境的镜像文件 对比可变基础设施，不可变基础设施的最大的优势是一致性，快速拉起成千上万一模一样的服务，服务的版本升级、回滚也成为常态 声明式设计 声明式设计是一种软件设计理念和做法：“向一个工具描述想要让一个事物达到的目标状态，由工具内部去解决如何令这个事物达到目标状态” 命令式设计：命令“机器”如何去做事情（how），这样不管你想要的是什么（what），它都会按照你的命令实现 声明式设计：告诉“机器”你想要的是什么（what），让机器想出如何去做（how），比如 SQL、Kubernetes 的 YAML DevOps 发展，瀑布 → 敏捷 瀑布开发，该模型下整个软件开发流程严格遵循需求、设计、开发、测试和部署几个阶段，需要等上一个阶段完成工作后，才会进行下一阶段的工作 敏捷开发，一种持续增量、不断迭代的开发模式，快速发布一个可运行但不完美的版本投入市场，在后续迭代中根据用户的反馈改进产品，从而逼近产品的最终形态 迭代是敏捷开发理论的核心，具体的敏捷研发方法有极限编程、精益软件开发、Scrum 等 DevOps 出现的背景 虽然敏捷开发提升了开发效率，但它的范围仅限于开发和测试阶段，并没有覆盖到部署端，运维部门并没有在这其中得到收益 相反的，甚至可以说“敏捷”加重了运维的负担。因为运维追求的目标是稳定，而频繁的变更往往就是出现问题的根源 从存在的意义上说，DevOps 完善了敏捷开发存在的短板，实现了真正的闭环 DevOps（Development 和 Operations 的合成词）是一种重视“软件开发人员（Dev）”和“IT 运维技术人员（Ops）”之间沟通合作的文化、运动或惯例 通过自动化“软件交付”和“架构变更”的流程，来使得构建、测试、发布软件能够更加地快捷、频繁和可靠 运维会在项目开发阶段就介入，了解开发所使用的系统架构和技术路线，并制定好相关的运维方案；而开发人员也会参与到后期的系统部署和日常发布中，并提供优化建议，而不再是把代码甩给运维了事 DevOps 的成功实践也离不开工具的支持，这其中就包括最重要的自动化 CI&#x2F;CD 流水线，通过自动化的方式打通软件从构建、测试到部署发布的整个流程，还有包括实时监控、事件管理、配置管理、协作平台等一系列工具的配合 微服务架构理念、容器技术和云计算的发展，让 DevOps 的实施更加便捷，这也解释了为何 DevOps 理念在十多年前就已提出，但直到近几年才开始被企业广泛关注和实践 传统架构向云原生架构的演进之路 为了解决单体架构“复杂度问题”，使用微服务架构 为了解决微服务间“通讯异常问题”，使用治理框架 + 监控 为了解决微服务架构下大量应用“部署问题”，使用容器 为了解决容器的“编排和调度问题”，使用 Kubernetes 为了解决微服务框架的“侵入性问题”，使用服务网格 为了让服务网格有“更好的底层支撑”，将服务网格运行在 Kubernetes 上 但站在整个系统的角度看，复杂度并没有减少和消失，要实现“强大底层系统”付出的成本（人力成本、资源成本、技术试错成本）是非常昂贵的，为了降低成本，选择上云托管，将底层系统的复杂度交给云基础设施，让云提供保姆式服务，最终演变为无基础架构设计 云原生架构技术栈 第二章: 构建“足够快”的网络服务Latency Numbers Every Programmer Should Know 秒(s)、毫秒(ms)、微秒 (μs)、纳秒 (ns）之间关系：$1s &#x3D; 10^3ms&#x3D;10^6μs&#x3D;10^9ns$ HTTPS 优化分析 cURL 是一个开源项目，主要的产品是 curl（命令行工具）和 libcurl（C 语言的 API 库），两者功能均是：基于网络协议，对指定 URL 进行网络传输 请求阶段分析 一个完整、未复用连接的 HTTPS 请求需要经过以下 5 个阶段：DNS 域名解析、TCP 握手、SSL 握手、服务器处理、内容传输 各阶段耗时分析 HTTPS 请求的各个阶段可以使用 curl 命令进行详细的延迟分析 HTTPS 的优化总结 域名解析优化：减少域名解析产生的延迟，例如使用预解析提前获取域名解析结果，那么 HTTPS 连接就能减少一个 RTT 对传输内容进行压缩：传输数据的大小与耗时成正比，压缩传输内容是降低请求耗时最有效的手段之一 SSL 层优化：升级 TLS 算法和 HTTPS 证书，例如升级 TLS 1.3 协议，可将 SSL 握手的 RTT 从 2 个减少到 1 个 传输层优化：升级拥塞控制算法以提高网络吞吐量，将默认的 Cubic 升级为 BBR 对于大带宽、长链路的弱网环境尤其有效 网络层优化：使用商业化的网络加速服务，通过路由优化数据包，实现动态服务加速 使用更现代的 HTTP 协议：升级至 HTTP&#x2F;2，进一步升级到基于 QUIC 协议的 HTTP&#x2F;3 RTT（Round-Trip Time）一个网络数据包从起点到目的地然后再回到起点所花费的时长 域名解析的原理DNS（Domain Name System，域名系统）是互联网中最重要的基础设施，它的主要职责是实现域名的解析，也就是 将域名转换为 IP 地址 graph TB root[\".\"] --- com[\".com\"] root --- org[\".org\"] root --- be[\".be\"] com --- google[\"google.com\"] com --- chess[\"chess.com\"] be --- linux[\"linux-training.be\"] %% 样式定义 style root fill:#FFFFFF,stroke:#333,stroke-width:2px style com fill:#FFDDC1,stroke:#333,stroke-width:2px,rx:10px,ry:10px style org fill:#FFDDC1,stroke:#333,stroke-width:2px,rx:10px,ry:10px style be fill:#FFDDC1,stroke:#333,stroke-width:2px,rx:10px,ry:10px style google fill:#D4E4FF,stroke:#333,stroke-width:2px,rx:10px,ry:10px style chess fill:#D4E4FF,stroke:#333,stroke-width:2px,rx:10px,ry:10px style linux fill:#D4E4FF,stroke:#333,stroke-width:2px,rx:10px,ry:10px %% 连接线样式 linkStyle default stroke:#FF6347,stroke-width:2px,stroke-opacity:0.8 域名是一种 树状结构，最顶层的域名是根域名（注意是一个点“.”，它是 .root 的含义，不过现在“.root”已经默认被隐藏），然后是顶级域名（Top Level Domain，简写 TLD，例如 .com），再是二级域名（例如 google.com） 通常情况下的域名解析过程，其实就是从“域名树”的根部到顶部，不断 递归查询 的过程： 用户向“DNS 解析器”（Recursive resolver）发出解析域名请求，“DNS 解析器”也称 LocalDNS，例如电信运营商的 114.114.114.114 “DNS 解析器” 判断是否存在解析缓存 如存在，直接返回缓存的结果 如不存在，向就近的“根域名服务器”查询域名所属“TLD 域名服务器”（Top-Level Domains nameserver） 根域名服务器返回相应的 TLD 域名服务器地址 “DNS 解析器”向 TLD 服务器请求该域名的“权威域名服务器”（Authoritative nameserver） TLD 服务器返回权威域名服务器的地址 “DNS 解析器”向权威域名服务器查询域名的具体解析记录（如 A 记录或 CNAME 记录） 获取解析记录后，“DNS 解析器”将结果返回给用户 sequenceDiagram participant Client as 用户 participant Resolver as DNS 解析器 (LocalDNS) participant Root as 根域名服务器 participant TLD as TLD 域名服务器 participant Authoritative as 权威域名服务器 Client->>Resolver: 请求解析域名 alt 存在缓存 Resolver->>Client: 返回缓存的结果 else 不存在缓存 Resolver->>Root: 查询 TLD 域名服务器 Root->>Resolver: 返回 TLD 域名服务器地址 Resolver->>TLD: 查询权威域名服务器 TLD->>Resolver: 返回权威域名服务器地址 Resolver->>Authoritative: 查询域名解析记录 Authoritative->>Resolver: 返回解析记录 Resolver->>Client: 转发解析记录 end 实际上“根域名服务器”的数量远不止 13 台，截止 2024 年 7 月，全世界共有 1,845 台根域名服务器 权威域名服务器通常是指顶级域名以下的管理二级、三级、四级等域名的服务器，多个域名解析到同一个 IP 地址（通过 CNAME 记录），服务器仍然可以根据 Host 头信息准确区分并响应不同的请求 域名解析故障时排查 如果请求一个 HTTPS 接口，出现服务不可用、Unknown host 等错误时，除了用 ping 测试连通性外，可以用 nslookup 或者 dig 命令确认域名解析是否出现问题 nslookup 返回的结果比较简单，但从中可以看出用的哪个“DNS 解析器”，域名的解析是否正常 当怀疑系统默认的“DNS 解析器”异常时，可以使用 dig 命令，通过切换不同的“DNS 解析器”，分析解析哪里出现异常 使用 HTTPDNS 解决“中间商”问题“域名解析器”是 DNS 查询中的第一站，它作为客户端与“域名服务器”的中间人帮我们去整棵 DNS 树上进行解析，然后将解析的结果返回给客户端但作为一个“中间商”，“域名解析器”很容易出现域名劫持、解析时间过长、解析调度不精准等问题，这些问题的根源在于 域名解析经历了过多的中间环节，服务质量不可控，为了解决上述问题，一种新型的 DNS 解析模式 —— HTTPDNS 应运而生 HTTPDNS 的工作原理： 客户端内部集成 HTTPDNS 模块，跳过“操作系统定义的解析服务”（LocalDNS，也就是默认基于 UDP 协议的域名解析系统） 替换为使用 HTTPS 协议请求更可靠的“软件定义的解析服务”，直接从“权威域名服务器”同步解析记录 避免了“中间商赚差价”，逻辑更可控，也能准确判断客户端地区和运营商，得到更精准的解析结果通过使用 HTTPDNS ，再结合客户端解析缓存、热点域名预解析、懒加载等优化策略，能明显改善传统域名解析带来的各类问题 对传输内容进行压缩对传输内容进行压缩是提升 HTTP 服务可用性的关键手段，一般使用 Gzip 对内容进行压缩，但针对 HTTP 类型的文本内容还有一个更高压缩率的算法 Brotli，压缩效果 Gzip 高出 17% - 30% sequenceDiagram autonumber participant Client as Client participant Server as Server Client->>+Server: 请求资源GET /doc HTTP/1.1Accept-Encoding: br, gzip Note right of Client: 客户端通过Accept-Encoding告知服务器支持压缩算法：br, gzip Server-->>-Client: 返回资源HTTP/1.1 200 OKContent-Encoding: brVary: Accept-Encoding Note left of Server: 服务器通过 Vary告知客户端资源已使用 br 算法压缩 HTTPS 原理及实践HTTPS 加密原理 非对称加密 算法通常需要更多的计算资源，尤其在加密或解密大量数据时计算消耗更大。因此使用计算效率更高的 对称加密 算法来加密 HTTP 内容，非对称加密算法来加密对称加密的密钥： 客户端与服务端会进行协商，确定一个双方都支持的对称加密算法，例如 AES 确认对称加密算法后，客户端会随机生成一个对称加密密钥 K 客户端使用服务端的公钥加密密钥 K，并将密文传输给服务端，此时，只有服务端的私钥能够解密密钥 K 实现了”降低加&#x2F;解密的耗时，同时又保证密钥传输的安全性“，，达成既要安全又要效率的目标 （机密性 + 完整性），但“如何将服务器公钥传输给客户端呢？” 公钥仍有被劫持的可能性： sequenceDiagram participant Client as Client participant Middle as Middle participant Server as Server Client->>Server: 请求公钥 Server->>Middle: 发送公钥 Middle->>Client: 替换公钥 Client->>Client: 本地保存假公钥 Client->>Middle: 假公钥加密 hello Middle->>Middle: 内容篡改 Middle->>Server: 真公钥加密 hi Server->>Middle: 真私钥加密 good Middle->>Middle: 内容篡改 Middle->>Client: 假私钥加密 bad 上述问题的根本原因是，浏览器无法确认收到的公钥是不是网站自己的, 因为公钥本身是明文传输的 所有证明的源头都是一条或多条不证自明的“公理”，若想证明某身份证号一定是小明的，可以看他身份证，而身份证是由政府作证的，这里的“公理”就是“政府机构可信”，这也是社会正常运作的前提 CA 机构（CA，Certificate Authority，证书认证机构）是如今互联网世界正常运作的前提，而 CA 机构颁发的“身份证”就是数字证书 网站在使用 HTTPS 前，需要向 CA 机构申领一份数字证书，数字证书里含有 证书持有者、域名、公钥、过期时间等信息，服务器把证书传输给浏览器，浏览器从证书里获取公钥就行了，那“证书本身的传输过程中，如何防止被篡改？” 把证书原本的内容生成一份“签名”，比对证书内容和签名是否一致就能判别是否被篡改。这就是数字证书的“防伪技术”，这里的“签名”就叫数字签名： CA 机构拥有非对称加密的私钥和公钥 CA 机构对证书明文数据 T 进行 hash （完整性） 对 hash 后的值用私钥加密，得到数字签名 S 明文和数字签名共同组成了数字证书，这样一份数字证书就可以颁发给网站了，数字证书是为了证明某公钥是可信的，即“该公钥是否对应该网站”（身份认证） 拥有 CA 的公钥 是验证数字证书真伪的关键，浏览器通常内置了多个受信任的 CA 的公钥，以便自动验证网站的数字证书，浏览器收到该证书后会校验证书原文的 hash 和签名解密后的 hash 值是否一致 CA 机构的公钥本身也可以用数字证书来证明，操作系统、浏览器本身会预装一些它们信任的根证书，由根证书为起点，透过层层信任，使终端实体证书的持有者可以获得转授的信任，以证明身份（信任链或数字证书链） 从整个流程来看，HTTPS 安全性的关键在于根证书是否被篡改。如果根证书被篡改，那么信息传递也就不再是‘绝对’安全的 HTTPS 优化实践 使用 TLS1.3 协议 2018 年发布的 TLS 1.3 协议优化了 SSL 握手过程，将握手时间缩短至 1 次 RTT，如果复用之前的连接，甚至可以实现 0 RTT 使用 ECC 证书 HTTPS 数字证书分为 RSA 证书和 ECC 证书，二者的区别在于： RSA 证书使用的是 RSA 算法生成的公钥，兼容性好，但不支持 PFS（Perfect Forward Secrecy，完美前向保密，保证即使私钥泄露，也无法破解泄露之前通信内容） ECC 证书使用的是椭圆曲线算法（Elliptic Curve Cryptography）生成的公钥，它的 计算速度快，安全性高，支持 PFS，能以 更小的密钥长度提供更高的安全性 相较于 RSA 证书，ECC 证书的唯一缺点是兼容性稍差，例如 Android 4.0 以上版本才能支持 ECC 证书 ECC 证书的生效与客户端和服务端协商的密码套件（Cipher Suite）直接相关，密码套件决定了通信双方使用的加密、认证算法和密钥交换算法 调整 https 会话缓存 在 HTTPS 连接建立后，会生成一个 session，用于保存客户端和服务器之间的安全连接信息，如果 session 未过期，后续连接可以复用先前的握手结果，从而提高连接效率 开启 OCSP stapling 客户端在首次下载数字证书时会向 CA 发起 OCSP（在线证书状态协议）请求，以验证证书是否被撤销或过期 OCSP Stapling 是一种 TLS 扩展，它将 OCSP 查询的工作交由服务器处理，服务器会预先获取 OCSP 响应并将其缓存 当客户端发起 TLS 握手请求时，服务器将证书的 OCSP 信息与证书链一起发送给客户端，从而避免了客户端在验证证书时可能出现的阻塞问题 使用 https://myssl.com/ 服务验证优化是否生效 第三章：深入 Linux 内核网络技术OSI 网络分层模型 层级 名称 含义 7 应用层（Application Layer） 应用层是 OSI 模型的顶层，直接与用户的应用程序交互，提供网络服务如电子邮件、文件传输、网页浏览等，常见的应用层协议有 HTTP、FTP、SMTP 等 6 表示层（Presentation Layer） 表示层负责数据的格式化和转换，确保发送方和接收方能够理解彼此传输的数据格式，它还处理数据的加密、解密和压缩等操作 5 会话层（Session Layer） 会话层管理应用程序之间的会话或连接，负责建立、维护和终止通信会话，它还提供会话恢复功能，使得通信中断后可以从上次中断的位置继续传输 4 传输层（Transport Layer） 传输层负责端到端的数据传输管理，提供可靠的传输服务，如数据分段、重组、流量控制和错误校正等，常见的传输层协议有 TCP 和 UDP 3 网络层（Network Layer） 网络层负责不同网络之间的数据路由和转发，它使用 IP 地址来确定数据包的传输路径，并确保数据能够从源设备传输到目的设备，即使它们位于不同的网络中 2 数据链路层（Data Link Layer） 数据链路层负责节点之间的数据传输，提供错误检测和纠正功能，它确保数据帧能够在同一局域网（LAN）内可靠传输，数据链路层使用 MAC（Media Access Control，介质访问控制）地址来标识网络上的设备 1 物理层（Physical Layer） 物理层是 OSI 模型的第一层，负责实际的硬件传输，如电缆、光纤、开关和集线器等，它处理二进制数据（即 bit）在物理介质上的传输，包括信号的电气&#x2F;光学特性、传输速率和传输模式等 数据链路层的数据单元被称为 帧（Frames），网络层的数据单元为称为 数据包（Packets），传输层的数据单元被称为 数据段（Segments），应用层数据单元被称为 数据（Data），用“数据包”泛指以上数据单元 Linux 系统收包流程数据包进入网卡（eth0）后，Linux 内核中各个模块相互协作 当外部网络发送数据包到服务器时，首先由网卡 eth0 接收该数据包 网卡通过 DMA（Direct Memory Access，直接内存访问）技术，将数据包直接拷贝到内核中的 RingBuffer（环形缓冲区）等待 CPU 处理 RingBuffer 是一种首尾相接的环形数据结构，它的主要作用是作为缓冲区，缓解网卡接收数据的速度快于 CPU 处理数据的速度问题 数据包成功写入 RingBuffer 后，网卡产生 IRQ（Hardware Interrupt Request，硬件中断），通知内核有新的数据包到达 内核收到硬件中断后，立即调用对应的中断处理函数，通常情况下，中断处理函数会简单地标记有新数据到达，并唤醒 ksoftirqd 内核线程来处理 软中断（SoftIRQ） 软中断处理过程中，内核调用网卡驱动 提前在内核中注册的 NAPI（New API）poll 接口，从 RingBuffer 中提取数据包，并生成 skb（Socket Buffer）数据 skb 是 Linux 内核中用于管理网络数据包的主要结构，它包含了网络包的所有信息，包括头部、数据负载等，并在内核的各个网络协议层之间传递 skb 被传递到内核协议栈中进行处理。这里涉及多个网络层次的处理操作： 网络层（L3 Network layer）：根据主机中的路由表，判断数据包路由到哪一个网络接口（Network Interface），这里的网络接口可能是稍后介绍的虚拟设备，也可能是物理网卡 eth0 接口 传输层（L4 Transport layer）：如解&#x2F;封数据包，处理网络地址转换（NAT）、连接跟踪（conntrack）等操作 内核协议栈处理完成后，数据包被传递到 socket 接收缓冲区，应用程序随后利用 系统调用（如 Socket API）从缓冲区中读取数据 数据包的处理流在不同层级之间需要进行多次上下文切换和拷贝操作，导致延迟增加，对于处理大规模并发连接的网络密集型系统，Linux 内核造成的瓶颈就变得不可忽视，除了优化内核网络协议栈外，业界出现了“绕过内核”这一思想的技术，例如 XDP 和 DPDK 技术 第四章：负载均衡技术负载均衡概述graph LR Client([Clients]) --> LB([Load Balancer]) LB --> RS1([RealServer1]) LB --> RS2([RealServer2]) LB --> RS3([RealServer3]) %% 节点样式 style Client fill:#C0C0C0,stroke:#333,stroke-width:2px style LB fill:#FFD700,stroke:#333,stroke-width:2px style RS1 fill:#ADD8E6,stroke:#333,stroke-width:2px style RS2 fill:#ADD8E6,stroke:#333,stroke-width:2px style RS3 fill:#ADD8E6,stroke:#333,stroke-width:2px %% 箭头样式 linkStyle default stroke:#333,stroke-width:2px 从整体架构来看，中间的 负载均衡器 承担下述职责： 服务发现：识别系统中可用的后端服务器，并获取它们的地址，以便负载均衡器与后端通信 健康检查：确定哪些后端服务器处于健康状态并能够接收请求 负载均衡：基于适当的算法将请求均匀分配到健康的后端服务器上 合理使用负载均衡能为分布式系统带来诸多好处： 命名抽象：客户端通过预设机制（如 DNS 或内置库）访问负载均衡器，而 无需了解后端服务器的拓扑结构或配置 容错：通过健康检查和多种负载均衡算法，将请求均匀转发至正常的后端服务器，故障服务器则会被移出 负载均衡池，便于运维人员从容修复 成本和性能收益：分布式系统通常是异构的，后端服务器分布在多个网络区域（Zone&#x2F;Region），负载均衡器通过策略 优先将请求保持在同一网络区域内，从而提高服务性能（减少延迟）并降低资源成本（减少跨区域带宽费用） 从网络层处理请求的层面看，所有的负载均衡可总结为两类： 四层负载均衡（比如 K8s 的 Service， K8s 是在应用层通过抽象和控制维护了一个集群内的“虚拟网络系统”） 并非仅指其在 OSI 模型的第四层传输层工作 而是指四层负载均衡所有工作模式的共同特点是，维持传输层连接（如 TCP、UDP）特性 沿用惯例，来自客户端的请求，无论是在网络层处理，还是在传输层的处理，统称为四层负载均衡处理 七层负载均衡（比如 K8s 的 Ingress） 特性 四层负载均衡（L4） 七层负载均衡（L7） 工作层次 传输层（TCP&#x2F;UDP） 应用层（HTTP&#x2F;HTTPS） 处理速度 较快（在内核层面处理，低延迟） 相对较慢（增加了应用层的处理开销） 灵活性 较低，基于 IP 和端口进行路由 高，基于内容、请求头等进行路由 功能 主要实现流量分发 支持内容缓存、内容路由、SSL 终止（SSL Termination）等高级功能 适用场景 实时应用、简单的 TCP&#x2F;UDP 服务 Web 应用、微服务架构、复杂请求处理 负载均衡调度算法负载均衡的另一个重要职责：“选择谁来处理用户请求”，也就是负载均衡器所采用的调度算法 一些常见的负载均衡算法： 轮询均衡算法（Round-Robin）：按依次循环的方式将请求调度到不同的服务器上 该算法最大的特点是实现简单，轮询算法假设所有的服务器处理请求的能力都一样 调度器会将所有的请求平均分配给每个真实服务器 随机均衡算法（Random）：此种负载均衡算法类似于轮询调度，不过在分配处理请求时是随机的过程 由概率论可以得知，随着客户端调用服务端的次数增多，其实际效果趋近于平均分配请求到服务端的每一台服务器也就是达到轮询的效果 最小连接均衡算法（Least-Connection）：该算法中 调度器需要记录各个服务器已建立连接的数量，然后把新的连接请求分配到当前连接数最小的服务器 最小连接均衡算法特别适合于服务器处理时间不一致的场景 例如，当某些请求可能占用较长时间，而另一些请求很快就会完成时，最小连接算法可以有效避免某些服务器因处理大量复杂请求而过载 哈希均衡算法（Consistency Hash）：将请求中的某些特征数据（例如 IP、MAC 或者更上层应用的某些信息）作为特征值来计算需要落在的节点 哈希算法会保证同一个特征值的请求每一次都会落在相同的服务器上 一致性哈希是一种改进的哈希算法，设计目的是解决传统哈希均衡在节点增减时的 重分布 问题 不考虑服务器的处理能力的负载均衡算法，实际上是一种“伪均衡”算法，考虑各个服务器的处理能力存在差异，负载均衡算法又有了对服务器“加权”的补充 负载均衡拓扑类型中间代理拓扑 graph LR Client([Client]) --> LB([Load Balancer]) LB --> RS1([RealServer1]) LB --> RS2([RealServer2]) LB --> RS3([RealServer3]) %% 节点样式 style Client fill:#C0C0C0,stroke:#333,stroke-width:2px,rx:10px,ry:10px style LB fill:#FFD700,stroke:#333,stroke-width:2px,rx:10px,ry:10px style RS1 fill:#ADD8E6,stroke:#333,stroke-width:2px,rx:10px,ry:10px style RS2 fill:#ADD8E6,stroke:#333,stroke-width:2px,rx:10px,ry:10px style RS3 fill:#ADD8E6,stroke:#333,stroke-width:2px,rx:10px,ry:10px %% 箭头样式 linkStyle default stroke:#333,stroke-width:2px 典型的中间代理拓扑的方案有： 硬件设备：Cisco、Juniper、F5 Networks 等公司的产品 云软件解决方案：阿里云的 SLB（Server Load Balancer），AWS 的 ELB（Elastic Load Balancer）、Azure 的 Load Balancer 和 Google Cloud 的 Cloud Load Balancing 等 纯软件方案：Nginx、HAProxy、Envoy 等 中间代理模式的优点在于简单，用户只需通过 DNS 连接到负载均衡器，无需关注其他细节，缺点是，中间代理可能存在单点故障风险，尤其是负载均衡这种集中式的设计，如果负载均衡器出现问题，会导致整个系统的访问中断 边缘代理拓扑（中间代理拓扑的一个变种） graph LR Client([Client]) --> Internet([Internet]) Internet --> LB([Load Balancer]) LB --> RS1([RealServer1]) LB --> RS2([RealServer2]) LB --> RS3([RealServer3]) %% 节点样式 style Client fill:#C0C0C0,stroke:#333,stroke-width:2px,rx:10px,ry:10px style Internet fill:#F5F5F5,stroke:#333,stroke-width:2px,stroke-dasharray: 5 5,rx:10px,ry:10px style LB fill:#FFD700,stroke:#333,stroke-width:2px,rx:10px,ry:10px style RS1 fill:#ADD8E6,stroke:#333,stroke-width:2px,rx:10px,ry:10px style RS2 fill:#ADD8E6,stroke:#333,stroke-width:2px,rx:10px,ry:10px style RS3 fill:#ADD8E6,stroke:#333,stroke-width:2px,rx:10px,ry:10px %% 箭头样式 linkStyle default stroke:#333,stroke-width:2px 将负载均衡器以 SDK 库的形式嵌入到客户端 graph LR subgraph Client Service[Service]:::service ClientLibrary[Client library]:::client end ClientLibrary --> RS1[RealServer1] ClientLibrary --> RS2[RealServer2] ClientLibrary --> RS3[RealServer3] %% 样式定义 classDef service fill:#FFFFFF,stroke:#333,stroke-width:2px,rx:5px,ry:5px classDef client fill:#C0C0C0,stroke:#333,stroke-width:2px,rx:5px,ry:5px style Client fill:none,stroke:#333,stroke-width:2px,rx:10px,ry:10px style RS1 fill:#ADD8E6,stroke:#333,stroke-width:2px,rx:10px,ry:10px style RS2 fill:#ADD8E6,stroke:#333,stroke-width:2px,rx:10px,ry:10px style RS3 fill:#ADD8E6,stroke:#333,stroke-width:2px,rx:10px,ry:10px %% 箭头样式 linkStyle default stroke:#333,stroke-width:2px Sidecar 拓扑（客户端内嵌库拓扑的一个变种） graph LR subgraph Container Service[Service] Sidecar[Sidecar Proxy]:::sidecar Service Sidecar end Sidecar --> RS1[RealServer1] Sidecar --> RS2[RealServer2] Sidecar --> RS3[RealServer3] %% 节点样式 style Service fill:#FFFFFF,stroke:#333,stroke-width:2px,rx:5px,ry:5px style Sidecar fill:#C0C0C0,stroke:#333,stroke-width:2px,rx:5px,ry:5px style Container fill:none,stroke:#333,stroke-width:2px,rx:15px,ry:15px style RS1 fill:#ADD8E6,stroke:#333,stroke-width:2px,rx:10px,ry:10px style RS2 fill:#ADD8E6,stroke:#333,stroke-width:2px,rx:10px,ry:10px style RS3 fill:#ADD8E6,stroke:#333,stroke-width:2px,rx:10px,ry:10px %% 箭头样式 linkStyle default stroke:#333,stroke-width:2px 四层负载均衡所谓的“四层负载均衡”（Layer 4 Load Balancer，简称 L4），并非仅指其在 OSI 模型的第四层（传输层）工作，而是指四层负载均衡所有工作模式的共同特点是，维持传输层连接（如 TCP、UDP）特性，沿用惯例，来自客户端的请求，无论是在网络层处理，还是在传输层的处理，统称为四层负载均衡处理 四层负载均衡器的不同工作模式涉及多个网络层： 在第二层（数据链路层）通过改写 MAC 地址实现请求转发 在第三层（网络层）改写 IP 地址完成请求路由 在第四层（传输层）修改 UDP 或 TCP 的端口和连接地址，并通过 NAT 方式实现请求转发 网络地址转换（Network Address Transform）是指将专用网络地址转换为网络中的公用地址，实现将 公网&#123;IP:PORT&#125; 映射成 内网&#123;IP:PORT&#125; 由于专用网本地 IP 地址是可重用的，所以 NAT 大大节省了 IP 地址的消耗 同时，它隐藏了内部网络结构，从而降低了内部网络受到攻击的风险 四层负载均衡工作模式 DR 模式 Tunnel 模式 NAT 模式 七层负载均衡早期的七层负载均衡，仅实现应用层请求的代理，如把非业务功能，如 路由请求、鉴权、监控、缓存、限流和日志记录 等集中在一层处理，并在一个控制台统一管理，此即为集群入口的高阶模式 —— 网关（API Gateway） 网关 特点 OpenResty 基于 Nginx 和 LuaJIT 的高性能 Web 平台。通过 LuaJIT 引擎，用户可以在 Nginx 中编写 Lua 脚本，在请求处理的不同阶段（如请求、响应、重写、日志等）动态地执行自定义逻辑 Kong 社区活跃、成熟度高、Postgres 存储、二次开发成本高 Spring Cloud Gateway Spring Cloud Gateway 是 Spring 生态系统中的一个网关解决方案，适用于 SpringBoot 和 SpringCloud 构建的微服务系统 Traefik 与 Docker、Kubernetes 等容器编排系统紧密结合 Envoy Envoy 是 Lyft 开发的一款面向服务网格的高性能网络代理，支持高级的路由控制、负载均衡策略、服务发现和健康检查等，Envoy 与 Istio 等服务网格解决方案紧密结合，通常作为它们的数据平面代理使用 协议支持：网关对应用层协议了解的越多，就可以处理更复杂的事情，如系统可观测、高级负载均衡和路由等 云原生网关的典型代表 Envoy 支持如下七层协议的解析和路由：HTTP&#x2F;1、HTTP&#x2F;2、gRPC、Redis、MongoDB、DynamoDB 等等 动态配置： 服务管理的动态配置包括路由、上游服务（Upstream）、SSL 证书、消费者等，数据的替换和更新不会产生任何中断，从而将线上流量的影响降低到最低 SSL 卸载：通过 SSL 卸载将业务的 SSL 协商以及加解密处理从原来的服务器迁移到负载均衡设备上来，从而减轻服务器的 SSL 协商以及加解密的工作负担 流量治理：微服务架构中，服务间的通信治理是必不可少的环节，如超时、重试、限速、熔断、流量镜像、缓存等等 现代网关系统在服务以及流量的管理上可对多业务进行收敛统一处理，降低多套网关的运维成本 可观测性：传统的监控方式已经无法适应云原生的场景，服务治理的可观测性输出是网关系统提供的最重要的特性 系统度量、分布式跟踪以及自定义日志等功能现在几乎是七层负载均衡解决方案的标配 需丰富的可观测数据并不是没有代价的，负载均衡器需要做一些额外的工作才能产生这些数据 但是这些数据带来的收益要远远大于为产生它们而增加的那点性能损失 可扩展性：例如典型网关 OpenResty，通过编写可插拔的插件能够轻松地对网关系统实现各种流量处理以及各类自定义功能 譬如流量限速、日志记录、安全检测、故障注入等等 高可用以及无状态设计：现代网关系统不仅提供数据面实现，还提供控制面实现，二者目标都在朝向无状态设计，可以轻松地实现水平扩展，网关架构整体上也默认高可用，不存在单点故障 第五章：数据一致性与分布式事务数据一致性一致性与可用性的权衡分布式事务模型服务幂等性设计第六章：分布式共识及算法第七章：容器编排技术第八章：服务网格技术第九章：系统可观测性第十章 GitOps 理念与实现设计","tags":["availability","architecture"],"categories":["Reading"]},{"title":"Kubernetes 基础概念与原理解析 ☸","path":"/2024/10/15/k8s/","content":"K8s 本质上是应用服务和服务器之间的中间层，通过暴露一系列 API 能力，简化了服务的部署运维流程 整体架构K8s 整体上遵循 C&#x2F;S 架构，左侧是一个官方提供的名为 kubectl 的 CLI （Command Line Interface）工具，用于使用 K8s 开放的 API 来管理集群和操作对象等，右侧则是 K8s 集群的后端服务及开放出的 API 等。 1234567891011121314 +-------------+ | | | | +---------------+ | | +-----&gt; | Node 1 | | Kubernetes | | +---------------++-----------------+ | Server | | | CLI | | | | +---------------+| (Kubectl) |-----------&gt;| ( Master ) |&lt;------+-----&gt; | Node 2 || | | | | +---------------++-----------------+ | | | | | | +---------------+ | | +-----&gt; | Node 3 | | | +---------------+ +-------------+ Node 是用于工作的机器，Master 是一种角色（Role），表示在这个 Node 上包含着管理集群的一些必要组件，生产环境中，为了保障集群的高可用，通常会部署多个 Master。 MasterMaster 是整个 K8s 集群的“大脑”，与大脑类似，它有几个重要的功能： 接收：外部的请求和集群内部的通知反馈 发布：对集群整体的调度和管理 存储：负责集群状态的存储 这些功能，也通过一些组件来共同完成，将其称为 control plane 1234567891011121314151617+----------------------------------------------------------+ | Master | | +-------------------------+ | | +-------&gt;| API Server |&lt;--------+ | | | | | | | | v +-------------------------+ v | | +----------------+ ^ +--------------------+ | | | | | | | | | | Scheduler | | | Controller Manager | | | | | | | | | | +----------------+ v +--------------------+ | | +------------------------------------------------------+ | | | | | | | Cluster state store | | | | | | | +------------------------------------------------------+ | +----------------------------------------------------------+ Cluster state store 存储集群所有需持久化的状态，并且提供 watch 的功能支持，可以快速的通知各组件的变更等操作，目前 Kubernetes 的存储层选择是 etcd，一般情况下直接以 etcd 来代表集群状态存储服务，即将所有状态存储到 etcd 实例中。 得益于 etcd 的开发团队较为活跃，而且根据 K8s 社区的反馈做了相当大的改进，并且当时 K8s 团队主要的关注点也不在此，所以直到现在 etcd 仍不是一个可选项，后续也许将此处插件化也不是不可能 API Server 整个集群的入口，接收外部的信号和请求，并将一些信息写入到 etcd 中，它提供了认证相关的功能，用于判断是否有权限进行操作，API Server 支持多种认证方法，一般情况下都使用 X.509 证书进行认证。 X.509 是一种公钥基础设施（PKI）中使用的 数字证书标准，用于验证实体（例如用户、设备或服务器）的 身份。X.509 证书广泛应用于互联网安全、加密通信等领域，包括 HTTPS、电子邮件加密等。X.509 证书由一个可信任的证书颁发机构（CA）签名，用于证明证书中包含的公钥与持有证书的实体是可信的。 API Server 的目标是成为一个极简的 server，只提供 REST 操作，更新 etcd ，并充当着集群的网关，至于其他的业务逻辑之类的，通过插件或者在其他组件中完成。 Controller Manager 是 K8s 集群中最繁忙的部分，它在后台运行着许多不同的控制器进程，用来调节集群的状态，当集群的配置发生变更，控制器就会朝着预期的状态开始工作。 Scheduler 集群的调度器，它会持续的关注集群中未被调度的 Pod ，并根据各种条件，比如资源的可用性，节点的亲和性或者其他的一些限制条件，通过绑定的 API 将 Pod 调度&#x2F;绑定到 Node 上。 节点亲和性 (Node Affinity) 是一种控制 Pod 调度位置的机制，可以指定 Pod 必须或优先调度到具有特定标签的节点上。节点亲和性比节点选择器 (Node Selector) 更为灵活，可以实现更复杂的调度规则，在资源优化、工作负载隔离、可用性提升等场景中有广泛应用，是 K8s 重要的 调度策略 之一。 Node(Worker) Node 是加入集群中的机器，Node 加入集群并接受调度、运行服务，归功于运行在 Node 上的几个核心组件。 12345678910111213141516+--------------------------------------------------------+ | +---------------------+ +---------------------+ | | | kubelet | | kube-proxy | | | | | | | | | +---------------------+ +---------------------+ | | +----------------------------------------------------+ | | | Container Runtime (Docker) | | | | +---------------------+ +---------------------+ | | | | |Pod | |Pod | | | | | | +-----+ +-----+ | |+-----++-----++-----+| | | | | | |C1 | |C2 | | ||C1 ||C2 ||C3 || | | | | | | | | | | || || || || | | | | | +-----+ +-----+ | |+-----++-----++-----+| | | | | +---------------------+ +---------------------+ | | | +----------------------------------------------------+ | +--------------------------------------------------------+ Kubelet Kubelet 实现了集群中最重要的关于 Node 和 Pod 的控制功能，如果没有 Kubelet 的存在，那 K8s 很可能是一个纯粹的通过 API Server CRUD 的应用程序。 K8s 原生的执行模式是 操作应用程序的容器，而不像传统模式那样，直接操作某个包或者是操作某个进程。基于这种模式，可以让应用程序之间相互隔离，和主机也是相互隔离的，毕竟它不依赖于主机，在任何的容器运行时（比如 Docker）上都可以部署和运行。 Pod 可以是一组容器（也可以包含存储卷），K8s 将 Pod 作为可调度的基本单位， 分离开了构建时和部署时的关注点： 构建时，重点关注某个容器是否能正确构建，如何快速构建 部署时，关心某个应用程序的服务是否可用，是否符合预期，依赖的相关资源是否都能访问到 这种隔离的模式，可以很方便的将应用程序与底层的基础设施解耦，极大的提高集群扩&#x2F;缩容，迁移的灵活性。 Master 节点的 Scheduler 组件，它会调度未绑定的 Pod 到符合条件的 Node 上，而至于最终该 Pod 是否能运行于 Node 上，则是由 Kubelet 来裁定的。 Container runtime 容器运行时最主要的功能是下载镜像和运行容器，最常见的实现是 Docker , 目前还有其他的一些实现，比如 rkt, cri-o。 K8s 提供了一套通用的容器运行时接口 CRI (Container Runtime Interface), 凡是符合这套标准的容器运行时实现，均可在 K8ss 上使用。 Kube Proxy 想要访问某个服务，那要么通过域名，要么通过 IP。每个 Pod 在创建后都会有一个虚拟 IP，K8s 中有一个抽象的概念，叫做 Service ，kube-proxy 便是提供一种代理的服务，可以通过 Service 访问到 Pod。 实际的工作原理是在每个 Node 上启动一个 kube-proxy 的进程，通过编排 iptables 规则来达到此效果。 基本概念 Pod 是 K8s 中最小的可部署单元，中文可以翻译为“容器组”它是用于承载和管理容器的抽象层。一个 Pod 可以包含一个或多个紧密关联的容器，它们共享相同的网络命名空间、IP 地址和存储卷，并在同一个宿主机上运行。 ReplicaSet 的目的是维护一组在任何时候都处于运行状态的 Pod 副本的稳定集合。因此，它通常用来保证给定数量的、完全相同的 Pod 的可用性。通常不直接使用 ReplicaSet，而是在 Deployment 中声明。 Deployment 是对 ReplicaSet 和 Pod 更高级的抽象，它可以指挥 Kubernetes 如何创建和更新部署的应用实例，创建 Deployment 后，Kubernetes master 会将应用程序调度到集群中的各个节点上，一般用来部署无状态应用。 自愈、缩放 滚动更新、版本回滚 Service 是将运行在一个或一组 Pod 上的网络应用程序公开为网络服务的抽象方法。Service 为一组 Pod 提供相同的 DNS 名，并且在它们之间进行负载均衡。Kubernetes 为 Pod 提供分配了 IP 地址，但 IP 地址可能会发生变化，集群内的容器可以通过 service 名称访问服务，而不需要担心 Pod 的 IP 发生变化。 ClusterIP：将服务公开在 集群内部。kubernetes 会给服务分配一个集群内部的 IP，集群内的所有主机都可以通过这个 Cluster-IP 访问服务。集群内部的 Pod 可以通过 service 名称访问服务。 NodePort：通过每个节点的主机 IP 和静态端口（NodePort）暴露服务。 集群外部 的主机可以使用节点 IP 和 NodePort 访问服务。 ExternalName：将集群外部的网络引入集群内部。 LoadBalancer：使用云提供商的负载均衡器向外部暴露服务。 Ingress 是对集群中服务的外部访问进行管理的 API 对象，典型的访问方式是 HTTP。可以通过 Ingress 资源来配置不同的转发规则，从而达到根据不同的规则设置访问集群内不同的 Service 所对应的后端 Pod。当集群位于公有云或私有云上时，要从互联网进行访问，需要使用公网 IP 或者域名，公网 IP 是相对稀缺的资源，不可能给所有主机都分配公网 IP，并且随着公开的服务变多，众多的端口也变得难以管理。面对这种情况，可以使用 Ingress。 Kubectl 是 K8s 提供的命令行工具。 Namespace 是一种资源隔离机制，将同一集群中的资源划分为相互隔离的组。命名空间作用域仅针对带有名字空间的对象，例如 Deployment、Service 等。Kubernetes 会创建四个初始命名空间： default 默认的命名空间，不可删除，未指定命名空间的对象都会被分配到 default 中。 kube-system Kubernetes 系统对象(控制平面和 Node 组件)所使用的命名空间。 kube-public 自动创建的公共命名空间，所有用户（包括未经过身份验证的用户）都可以读取它。通常我们约定，将整个集群中公用的可见和可读的资源放在这个空间中。 kube-node-lease 租约（Lease）对象使用的命名空间。每个节点都有一个关联的 lease 对象，lease 是一种轻量级资源。lease 对象通过发送心跳，检测集群中的每个节点是否发生故障。 管理对象的方式 命令行指令，使用 kubectl 命令来创建和管理 Kubernetes 对象。命令行就好比口头传达，简单、快速、高效。但它功能有限，不适合复杂场景，操作不容易追溯，多用于开发和调试。 声明式配置，kubernetes 使用 yaml 文件来描述 Kubernetes 对象。声明式配置就好比申请表，学习难度大且配置麻烦。好处是操作留痕，适合操作复杂的对象，多用于生产。 可视化界面，如云平台容器服务 服务部署流程，YAML 文件 → kubectl → [API Server → etcd → Scheduler → Controller Mgr] → [Kubelet → Container runtime → Pod] 服务调用流程，request → Ingress 控制器 → [Kube Proxy → Pod] kubectlK8s 遵循 C&#x2F;S 架构，官方也提供了 CLI 工具 kubectl 用于完成大多数集群管理相关的功能。 基础配置 使用 kubectl options 可以看到所有全局可用的配置项 $HOME/.kube/config 中主要包含着： K8s 集群的 API 地址 用于认证的证书地址 也可以使用 --kubeconfig 或者环境变量 KUBECONFIG 来传递配置文件 也可以直接传递相关参数来使用，kubectl -client-key=&#39;xxx&#39; --client-certificate=&#39;xxx&#39; get（读取数据类） **kubectl cluster-info**：查看集群控制平面的信息，包括 API server 和 DNS 服务的访问地址 **kubectl get nodes**：获取集群节点的详细信息，可以通过 -o 参数选择输出格式 **kubectl api-resources**：列出集群中支持的所有 API 资源，帮助了解 Kubernetes 中可用的资源 **kubectl explain node**：查看 Node 资源的详细字段说明，帮助理解各字段的作用 kubectl run，运行容器，NAME 和 --image 是必需项，分别代表此次部署的名字及所使用的镜像 实际使用时，推荐编写配置文件并通过 kubectl create 进行部署 kubectl get all，列出当前命名空间中核心资源类型，比如 Pod、Service、ReplicaSet、Deployment、DaemonSet 等 部署一个 Redis 实例 12➜ ~ kubectl run redis --image=&#x27;redis:alpine&#x27;deployment.apps/redis created 123456789➜ ~ kubectl get allNAME READY STATUS RESTARTS AGEpod/redis-7c7545cbcb-2m6rp 1/1 Running 0 30sNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEservice/kubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 32sNAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGEdeployment.apps/redis 1 1 1 1 30sNAME DESIRED CURRENT READY AGEreplicaset.apps/redis-7c7545cbcb 1 1 1 30s 使用 kubectl get all 输出内容的格式 / 前代表类型，/ 后是名称 Deployment 是一种高级别的抽象，允许进行扩容，滚动更新及降级等操作 利用 Deployment 也能很方便的进行金丝雀发布（Canary deployments），这主要也依赖 Label 和 Selector Deployment 的创建更推荐的方式便是使用 yaml 格式的配置文件 Deployment 主要是声明一种预期的状态，并且会将 Pod 托管给 ReplicaSet ReplicaSet 会检查当前的 Pod 数量及状态是否符合预期，并尽量满足这一预期 Service 是为了能有个稳定的入口访问应用服务或者是一组 Pod 通过 Service 可以很方便的实现 服务发现和负载均衡 Service 目前有 4 种类型： ClusterIP： 是 K8s 当前默认的 Service 类型，将 service 暴露于一个 仅集群内 可访问的虚拟 IP 上 集群内主机 通过 ClusterIP:port 访问服务 集群内容器 通过 service name:port 访问服务 NodePort： 是通过在集群内所有 Node 上都绑定固定端口的方式将服务暴露出来 集群外主机 通过 &lt;NodeIP&gt;:&lt;NodePort&gt; 访问服务 LoadBalancer： 是通过 Cloud Provider 创建一个外部的负载均衡器，将服务暴露出来，并且会自动创建外部负载均衡器路由请求所需的 Nodeport 或 ClusterIP ExternalName： 是通过将服务由 DNS CNAME 的方式转发到指定的域名上将服务暴露出来 123456➜ ~ kubectl expose deploy/redis --port=6379 --protocol=TCP --target-port=6379 --name=redis-server service/redis-server exposed➜ ~ kubectl get svc -o wide NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTORkubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 49m &lt;none&gt;redis-server ClusterIP 10.108.105.63 &lt;none&gt; 6379/TCP 4s run=redis 通过 kubectl expose 命令将 redis server 这个 Service 暴露出来 port： 是 Service 暴露出来的端口，可通过此端口访问 Service protocol： 是所用协议，当前 K8s 支持 TCP&#x2F;UDP 协议，默认是 TCP 协议 target-port： 是实际服务所在的目标端口，请求由 port 进入通过上述指定 protocol 最终流向这里配置的端口 name： Service 的名字，它的用处主要在 dns 方面 type： 是前面提到的类型，如果没指定默认是 ClusterIP redis 是使用的默认类型 ClusterIP，所以并不能直接通过外部进行访，使用 port-forward 的方式让它可在集群外部访问 1234➜ ~ kubectl port-forward svc/redis-server 6379:6379Forwarding from 127.0.0.1:6379 -&gt; 6379Forwarding from [::1]:6379 -&gt; 6379Handling connection for 6379 也可以使用 NodePort 的方式对外暴露服务，可以通过任意 Node 上的 NodePort 端口连接 redis 服务，这个端口范围其实是可以通过 kube-apiserver 的 service-node-port-range 进行配置的，默认是 30000-32767 12345➜ ~ kubectl expose deploy/redis --port=6379 --protocol=TCP --target-port=6379 --name=redis-server-nodeport --type=NodePortservice/redis-server-nodeport exposed➜ ~ kubectl get service/redis-server-nodeport -o wide NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTORredis-server-nodeport NodePort 10.109.248.204 &lt;none&gt; 6379:31913/TCP 11s run=redis 认证和授权K8s 中几乎所有的操作都需要经过 kube-apiserver 处理，所以为了安全起见，K8s 为它提供了三类安全访问的措施： 用于识别用户身份的 认证（Authentication） 用于控制用户对资源访问的 授权（Authorization） 用于资源管理方面的 准入控制（Admission Control） 来自客户端的请求分别经过认证，授权，准入控制之后，才能真正执行 123456789101112131415+-----------------------------------------------------------------------------------------------------------+| || +---------------------------------------------------------------------------+ +--------+ || | | | | || +--------+ | +------------------+ +----------------+ +--------------+ +------+ | | | || | | | | | | | | Admission | | | | | | || | Client +------&gt; | Authentication +-&gt; | Authorization +-&gt; | Control +-&gt; |Logic | +--&gt; | Others | || | | | | | | | | | | | | | | || +--------+ | +------------------+ +----------------+ +--------------+ +------+ | | | || | | | | || | | | | || | Kube-apiserver | | | || +---------------------------------------------------------------------------+ +--------+ || |+-----------------------------------------------------------------------------------------------------------+ 认证（Authentication） 认证是判断当前发起请求的用户身份是否正确。例如，通常登录服务器时候需要输入用户名和密码，或者 SSH Keys 之类的。K8S 支持以下认证机制，可选择同时开启多个认证机制： X509 客户端证书 引导 Token 静态 Token 文件 静态密码文件 Service Account Token OpenID 认证代理 Webhook 授权（Authorization） 授权就是在验证当前发起请求的用户是否有相关的权限。例如，在 Linux 系统中常见的文件夹权限之类的。授权是以认证的结果为基础的，授权机制检查用户通过认证后的请求中所包含的属性来进行判断。K8S 支持以下授权机制： ABAC（Attribute-Based Access Control）基于属性的访问控制 RBAC（Role-based access control）基于角色的访问控制 Node：这是一种特殊用途的授权机制，专门用于对 kubelet 发出的 API 请求做授权验证 Webhook：使用外部的 Server 通过 API 进行授权校验 AlwaysAllow：默认配置，允许全部 AlwaysDeny：通常用于测试，禁止全部 HelmHelm 是构建于 K8S 之上的包管理器，可与平时接触到的 Yum，APT，Homebrew 或者 Pip 等包管理器相类比。使用 Helm 可简化包分发，安装，版本管理等操作流程。同时它也是 CNCF 孵化项目。 Helm 是 C&#x2F;S 架构，主要分为客户端 helm 和服务端 Tiller。helm 通过 gRPC 将 chart 发送至 Tiller ，Tiller 则通过内置的 kubernetes 客户端库与 K8S 的 API server 进行交流，将 chart 进行部署，并生成 Release 用于管理。 原理解析kube-apiserver1234567891011121314151617+----------------------------------------------------------+ | Master | | +-------------------------+ | | +-------&gt;| API Server |&lt;--------+ | | | | | | | | v +-------------------------+ v | | +----------------+ ^ +--------------------+ | | | | | | | | | | Scheduler | | | Controller Manager | | | | | | | | | | +----------------+ v +--------------------+ | | +------------------------------------------------------+ | | | | | | | Cluster state store | | | | | | | +------------------------------------------------------+ | +----------------------------------------------------------+ kube-apiserver 作为集群的统一入口，接收来自外部的信号和请求，并将一些信息存储至 etcd 中 REST API Server 对外提供接口，可处理来自客户端（无论 kubeclt 或者 curl 或者其他语言实现的客户端）的请求，并作出响应 kube-apiserver 有个 --secure-port 的参数，通过这个参数来配置它将要监听在哪个端口，默认情况下是 6443 认证（Authentication） kubectl version -v 8 获取集群版本号的时候，其实也是向 kube-apiserver 发送了一个请求进行查询的，可以通过传递 -v 参数来改变 log level 首先会加载 $HOME/.kube/config 下的配置，获的集群地址，进而请求 /version 接口，最后格式化输出 curl -k https://172.17.0.99:6443/version 使用 curl -k 相当于忽略认证的过程，忽略掉认证过程的 curl 被判定为 system:anonymous 用户 授权（Authorization） K8S 支持多种授权机制，现在多数都在使用 RBAC 准入控制（Admission Control） 在请求进来时，会先经过认证、授权接下来会进入准入控制环节 准入控制和前两项内容不同，它不只是关注用户和行为，它还会处理请求的内容，不过它对读操作无效 准入控制与认证、授权插件类似，支持同时开启多个，几个比较常见的插件： NamespaceLifecycle：它可以保证正在终止的 Namespace 不允许创建对象，不允许请求不存在的 Namespace 以及保证默认的 default, kube-system 之类的命名空间不被删除 LimitRanger：为 Pod 设置默认请求资源的限制 ServiceAccount：可按照预设规则创建 Serviceaccount，比如都有统一的前缀：system:serviceaccount: DefaultStorageClass：为 PVC 设置默认 StorageClass DefaultTolerationSeconds：设置 Pod 的默认 forgiveness toleration 为 5 分钟 MutatingAdmissionWebhook 和 ValidatingAdmissionWebhook：这两个都是通过 Webhook 验证或者修改请求，唯一的区别是一个是顺序进行，一个是并行进行的 ResourceQuota：限制 Pod 请求配额 AlwaysPullImages：总是拉取镜像 AlwaysAdmit：总是接受所有请求 处理请求 一个请求依次会经过认证，授权，准入控制等环节，当这些环节都已经通过后，该请求便到了 kube-apiserver 的实际处理逻辑中了 和普通的 Web server 类似，kube-apiserver 提供了 restful 的接口，增删改查等基本功能都基本类似 kube-apiserver 包含的东西有很多，除了认证，授权，准入控制相关功能外，还有审计，证书，存储等配置 etcd etcd is a consistent distributed key-value store. Mainly used as a separate coordination service, in distributed systems. And designed to hold small amounts of data that can fit entirely in memory. etcd 是由 CoreOS 团队发起的一个分布式，强一致的键值存储。它用 Go 语言编写，使用 Raft 协议作为一致性算法。多数情况下会用于分布式系统中的服务注册发现，或是用于存储系统的关键数据。etcd 在 K8S 中，最主要的作用便是其 高可用，强一致 的键值存储以及 监听机制 在 kube-apiserver 收到对应请求经过一系列的处理后，最终如果是集群所需要存储的数据，便会存储至 etcd 中，主部分主要是 集群状态信息 和 元信息 默认集群中的 etcd 会放到 kube-system Namespace 中，kubectl -n kube-system get pods | grep etcd etcd2 使用 HTTP&#x2F;JSON 作为默认的 API 通信协议，允许客户端通过 HTTP API 与 etcd 集群进行交互 etcd3 引入了 gRPC 作为主要的通信协议，虽然 etcd3 仍支持 HTTP API，但推荐使用 gRPC 进行高效通信，因为 gRPC 比传统的 HTTP API 更高效、更加支持双向流和更好的负载均衡 etcd3 中，HTTP API 一般仅用于兼容性和简单操作，在 K8s 1.13 发布时，etcd 2 的相关代码已经移除 由于 etcd 集群使用 Raft 一致性算法，通常情况下 etcd 集群需要部署奇数个节点，如 3，5，7 等，etcd 集群维护也相对容易，很容易可以做成高可用集群 controller-manager Controller Manager 实际由 kube-controller-manager 和 cloud-controller-manager 两部分组成，cloud-controller-manager 则是为各家云厂商提供了一个抽象的封装，便于让各厂商使用各自的 provide kube-controller-manager 是一个 嵌入 了 K8s 核心 控制循环 的 守护进程，负责在集群中运行核心控制循环，以确保集群的状态达到并维持在用户期望的状态 kube-controller-manager 运行多个控制器（例如节点控制器、资源配额控制器等），每个控制器都嵌入了特定的逻辑来管理和协调集群资源的状态 控制：kube-controller-manager 的任务是维护集群的目标状态。例如，当资源发生变化时，它会通过调用 API Server 将实际状态调整为目标状态 循环：每个控制器都在一个循环中运行，反复检查资源的状态，并采取必要的操作以确保资源达到预期的状态。循环的执行间隔是可以通过参数配置的，例如 --sync-period 参数，控制各控制器的检查频率 kube-controller-manager 是独立部署的一个 守护进程，可以在 Kubernetes 集群的控制平面节点上以独立的进程或容器形式运行, 持续监视并管理资源的状态。守护进程的特点是持久运行，不间断地执行控制循环，确保集群资源的一致性和健康状态 kube-controller-manager 在 10252 端口上不仅暴露出来了一个 /healthz 接口，还暴露出了一个 /metrics 的接口，可用于进行监控之类的 通过 kubectl -n kube-system describe pods -l component=kube-controller-manager 命令可以查看 kube-controller-manager 的 Pod 详细信息 kube-scheduler The Kubernetes scheduler is a policy-rich, topology-aware, workload-specific function that significantly impacts availability, performance, and capacity. kube-scheduler 是一个策略丰富，拓扑感知的调度程序，会显著影响可用性，性能和容量。 资源调度本就是 K8s 这类系统中的一个很复杂的事情，既要能满足系统对资源利用率的需要，同样还需要避免资源竞争，比如说端口冲突之类的，为了能完成这样的需求，kube-scheduler 便在不断的迭代和发展，通过支持多种策略满足各类需求，通过感知拓扑避免资源竞争和保障系统的可用性及容量等。 从上层的角度来看，kube-scheduler 的作用就是将待调度的 Pod 调度至最佳的 Node 上，而这个过程中则需要根据不同的策略，考虑到 Node 的资源使用情况，比如端口，内存，存储等。 kube-scheduler 将处理阶段主要分为三个阶段 Computing predicates，Prioritizing 和 Selecting host： Computing predicates：主要解决的问题是 Pod 能否调度到集群的 Node 上 过一个名为 podFitsOnNode 的函数进行实现，在检查的过程中也会先去检查下是否已经有已缓存的判断结果 当然也会检查 Pod 是否是可调度的，以防有 Pod Affinity (亲合性) 之类的存在 Prioritizing：主要解决的问题是在上个阶段通过 findNodesThatFit 得到了 filteredNodes 的基础之上解决哪些 Node 是最优的，得到一个优先级列表 priorityList 给每个经过第一步筛选出来的 Node 一个 Score，再按照各种条件进行打分，最终得到一个优先级列表 Selecting host：则是最终选择 Node 调度到哪台机器上 当实际进行部署操作的时候： 通过 kubectl 之类的客户端工具与 kube-apiserver 进行交互 在经过一系列的处理后，数据将持久化到 etcd 中 kube-controller-manager 通过持续的观察，开始按照配置，将集群的状态调整至预期状态 kube-scheduler 也在发挥作用，决定 Pod 应该调度至哪个或者哪些 Node 上 之后则通过其他组件的协作，最总将该 Pod 在相应的 Node 上部署启动 kubelet12345678910111213141516+--------------------------------------------------------+ | +---------------------+ +---------------------+ | | | kubelet | | kube-proxy | | | | | | | | | +---------------------+ +---------------------+ | | +----------------------------------------------------+ | | | Container Runtime (Docker) | | | | +---------------------+ +---------------------+ | | | | |Pod | |Pod | | | | | | +-----+ +-----+ | |+-----++-----++-----+| | | | | | |C1 | |C2 | | ||C1 ||C2 ||C3 || | | | | | | | | | | || || || || | | | | | +-----+ +-----+ | |+-----++-----++-----+| | | | | +---------------------+ +---------------------+ | | | +----------------------------------------------------+ | +--------------------------------------------------------+ 按照一般架构设计上的习惯，kubelet 所承担的角色一般会被叫做 agent，这里叫做 kubelet 很大程度上受 Borg 的命名影响，Borg 里面也有一个 Borglet 的组件存在，kubelet 便是 K8s 中的 agent，负责 Node 和 Pod 相关的管理任务 kubelet 的作用 节点管理 当执行 kubelet --help 的时候，会看到它所支持的可配置参数，其中有一个 --register-node 参数便是用于控制是否向 kube-apiserver 注册节点 的，默认是开启的 kubelet 不仅将自己注册给了 kube-apiserver，同时它所在机器的信息也都进行了上报，包括 CPU，内存，IP 信息等 向 kube-apiserver 发送心跳包等 Pod 管理 kube-scheduler 处理了 Pod 应该调度至哪个 Node，而 kubelet 则是保障该 Pod 能按照预期，在对应 Node 上启动并保持工作（ kubelet 的作用之一就是负责镜像拉取） kubelet 在保障 Pod 能按预期工作，主要是做了两方面的事情 健康检查：通过 LivenessProbe 和 ReadinessProbe 探针进行检查，判断是否健康及是否已经准备好接受请求 资源监控：通过 cAdvisor 进行资源监控 kubelet 还承担着清理 Node 上一些由 K8s 调度 Pod 所造成的磁盘占用之类的工作 kube-proxykube-proxy 是 K8s 运行于每个 Node 上的 网络代理组件，提供了 TCP 和 UDP 的连接转发支持，当 Pod 在创建和销毁的过程中，IP 可能会发生变化，而这就容易造成对其有依赖的服务的异常，所以通常情况下，我们都会使用 Service 将后端 Pod 暴露出来，而 Service 则较为稳定 kube-proxy 对于服务注册发现和代理访问等起到了很大的作用，在 Linux 系统上当前支持三种模式，可通过 --proxy-mode 配置： userspace：这是很早期的一种方案，但效率上显著不足，不推荐使用 iptables：当前的默认模式，比 userspace 要快，但问题是会给机器上产生很多 iptables 规则 ipvs：为了解决 iptables 的性能问题而引入，采用增量的方式进行更新 默认情况下使用 iptables 的代理模式，当创建新的 Service ，或者 Pod 进行变化时，kube-proxy 便会去维护 iptables 规则，以确保请求可以正确的到达后端服务、 kube-proxy 和 Ingress 都是 Kubernetes 中用于网络管理的组件，两者都可以实现流量的负载均衡和分发，kube-proxy 更底层、面向内部流量，而 Ingress 更高层、面向外部流量，比如负载均衡层级： kube-proxy：在四层（传输层）工作，只支持基于 IP 的负载均衡 Ingress：工作在七层（应用层），支持基于 HTTP&#x2F;HTTPS 的请求路由 Container Runtimekube-scheduler 决定了 Pod 将被调度到哪个 Node 上，而 kubelet 则负责 Pod 在此 Node 上可按预期工作，如果没有 Container Runtime，那 Pod 中的 container 在该 Node 上也便无法正常启动运行 Container Runtime （容器运行时）这一概念的产生也是由于容器化技术和 K8s 的大力发展，为了统一工业标准，也为了避免 K8s 绑定于特定的容器运行时，所以便成立了 OCI （Open Container Initiative）组织，致力于将容器运行时标准化和容器镜像标准化 自 K8s 1.5 （2016 年 11 月）开始，新增了一个容器运行时的插件 API，并称之为 CRI （Container Runtime Interface），通过 CRI 可以支持 kubelet 使用不同的容器运行时，而不需要重新编译 当前使用最为广泛的是 Docker，当前还支持的主要有 runc，Containerd，runV 以及 rkt 等 Troubleshoot 使用 describe 排查问题，kubectl -n work describe pod/xxx 使用 events 排查问题，kubectl -n work get events 通过详细内容排查错误，比如 kubectl -n work get endpoints 扩展增强 Dashboard - Web 端操作界面 Dashboard 并不能完全取代 kubectl，两者应该是相辅相成的 后端使用 Kubernetes 的 client-go 库来与 API Server 通信，前端基于 Angular 框架开发 CoreDNS - K8s 集群中的 DNS 和服务发现插件 CoreDNS 是一个独立项目，它不仅可支持在 K8s 中使用，也可以在任何需要 DNS 服务的时候使用它 自 K8s1.13 版本起，CoreDNS 成为了集群中的默认 DNS 服务器，替代了以前的 kube-dns 插件 提供域名解析和服务发现功能，使 Pod 之间能通过服务名称直接访问 Ingress - K8s 中的流量管理资源 Ingress 是 Kubernetes 中的流量管理资源，主要用于集群外部的 HTTP&#x2F;HTTPS 负载均衡、路由和SSL 终止等 允许定义基于路径、主机名等的路由规则，引导流量到集群内的正确服务，需要一个 Ingress Controller 实现，常用的有 NGINX Ingress Controller 和 Traefik 等 集群监控，K8s 是一个典型的分布式系统，组件很多，监控的目标就变的很重要了 节点情况、K8s 集群自身状态、部署在 K8s 内的应用的状态 用于实时收集和监测 Kubernetes 集群的性能和资源使用情况，帮助管理员发现潜在问题和优化集群资源 rometheus、Grafana 等工具常用于 Kubernetes 的集群监控，帮助展示 CPU、内存、存储等资源的使用情况，还能设置报警和警报管理 部署前后端应用使用云平台的容器服务 Code → App → Docker Image → Hub → K8s Golang构建 Docker 镜像 交叉编译 1234567# Windows → Linux# powershell$env:GOOS=&quot;linux&quot;$env:GOARCH=&quot;amd64&quot;go build -o .\\build\\webook# Mac → LinuxGOOS=linux GOARCH=amd64 go build -o /build/webook 编写 Dockerfile 12345678# 基础镜像FROM ubuntu:20.04# 把编译后的打包进这个镜像，放到工作目录 /appCOPY /build/wechatpay /app/wechatpay# 拷贝配置文件COPY ./etc /app/etcWORKDIR /appENTRYPOINT [&quot;/app/webook&quot;] 打包镜像 1234567# 构建docker build -t wechatpay:v0.0.1 .# 查看镜像信息docker images wechatpay:v0.0.1# 删除docker rmi -f wechatpay:v0.0.1# 可以将上述命令都写在 Makefile 里面 启动服务 12docker run --rm -it -p 8888:8888 wechatpay:v0.0.1 Starting server at 0.0.0.0:8888... 推送到远程仓库 12345# 登录腾讯云容器镜像服务 Docker Registrydocker login xxx.tencentcloudcr.com --username xxx --password xxx# 向 Registry 中推送镜像docker tag [imageId] xxx.tencentcloudcr.com/xxx/xxx:[tag]docker push xxx.tencentcloudcr.com/xxx/xxx:[tag] CI&#x2F;CDJenkinsfile Check Workspace Go Mod Tidy Build Go Application Build Docker Image Push Docker Image ReactDockerfile 12345678910111213141516171819202122# 使用较新的 Node.js 镜像作为构建环境FROM node:18-alpine AS build# 设置工作目录WORKDIR /app# 复制 package.json 和 package-lock.jsonCOPY package*.json ./# 安装依赖RUN npm install &amp;&amp; npm cache clean --force# 复制项目文件COPY . .# 构建项目RUN npm run build# 使用 Nginx 作为生产环境的 web 服务器FROM nginx:alpine# 复制构建的文件到 Nginx 的默认公共目录COPY --from=build /app/build /usr/share/nginx/html# 将 Nginx 配置文件替换为自定义配置文件COPY nginx.conf /etc/nginx/conf.d/default.conf# 暴露端口EXPOSE 9999# 启动 NginxCMD [&quot;nginx&quot;, &quot;-g&quot;, &quot;daemon off;&quot;] 相关资料 Kubernetes 从上手到实践 Kubernetes 入门实战课 深入高可用架构原理与实践 Kubernetes 官网文档","tags":["Docker","Kubernetes"],"categories":["Kubernetes"]},{"title":"容器技术实践与探索 - Docker 🐳","path":"/2024/09/23/docker/","content":"梳理 Docker 知识体系 基础概念与操作容器技术容器技术通过使用 chroot 更改进程根目录、Namespace 隔离系统资源、Cgroups 限制资源使用、UnionFS 实现文件系统的高效分层管理，为容器提供安全、隔离和轻量的运行环境。 chroot chroot 是在 Unix 和 Linux 系统的一个操作，针对正在运作的进程和它的子进程，改变它外显的根目录。一个运行在这个环境下，经由 chroot 设置根目录的程序，它不能够对这个指定根目录之外的文件进行访问动作，不能读取，也不能更改它的内容。 通俗地说 ，chroot 就是可以改变某进程的根目录，使这个程序不能访问目录之外的其他目录 Namespace Namespace 是 Linux 内核的一项功能，该功能对内核资源进行隔离，使得容器中的进程都可以在单独的命名空间中运行，并且 只能访问当前容器命名空间的资源 Namespace 可以隔离 进程 ID、主机名、用户 ID、文件名、网络访问和进程间通信 等相关资源 Cgroups Cgroups 是一种 Linux 内核功能，可以 限制和隔离进程的资源使用情况（CPU、内存、磁盘 I&#x2F;O、网络等） 在容器的实现中，Cgroups 通常用来 限制容器的 CPU 和内存 等资源的使用 UnionFS 联合文件系统是一种通过 创建文件层进程操作的文件系统，因此联合文件系统非常轻快 Docker 使用联合文件系统为容器提供构建层，使得容器可以实现写时复制以及镜像的分层构建和存储 常用的联合文件系统有 AUFS、Overlay 和 Devicemapper 等 容器技术从 1979 年 chroot 的首次问世便已崭露头角，但是到了 2013 年，Dokcer 的横空出世才使得容器技术迅速发展。另外， Docker 还提供了工具和平台来管理容器的生命周期： 使用容器 开发应用程序及其支持组件 容器成为 分发和测试应用程序的单元 可以 将应用程序作为容器或协调服务部署到生产环境中，无论生产环境是本地数据中心，云提供商还是两者的混合，其工作原理都相同 核心概念镜像镜像是一个 只读的文件和文件夹组合，它包含了容器运行时所需要的所有基础文件和配置信息，是容器启动的基础，如果想要使用一个镜像，可以用这两种方式： 自己创建镜像：在 基础镜像 上添加一些用户自定义的内容制作 业务镜像 从功能镜像仓库拉取别人制作好的镜像 镜像操作 镜像是一个特殊的文件系统，它提供了容器运行时所需的程序、软件库、资源、配置等静态数据。即 镜像不包含任何动态数据，镜像内容在构建后不会被改变。镜像的操作可分为： 拉取镜像，使用 docker pull 命令拉取远程仓库的镜像到本地； docker pull [Registry]/[Repository]/[Image]:[Tag] 重命名镜像，使用 docker tag 命令“重命名”镜像； docker tag [SOURCE_IMAGE][:TAG] [TARGET_IMAGE][:TAG]，两者指向同一个镜像文件，IMAGE ID 一样； 查看镜像，使用 docker image ls&#x2F;docker images 命令查看本地已经存在的镜像； 删除镜像，使用 docker rmi&#x2F;docker image rm 命令删除无用镜像； 构建镜像，构建镜像有两种方式 第一种方式是使用 docker build 命令基于 Dockerfile 构建镜像，也是我比较推荐的镜像构建方式； Dockerfile 是一个包含了用户所有构建命令的文本，通过 docker build 命令可以从 Dockerfile 生成镜像 第二种方式是使用 docker commit 命令基于已经运行的容器提交为镜像 需要先进入运行中的容器：docker run --rm --name=xxx -it busybox sh Dockerfile 常用的指令 Dockerfile 指令 指令简介 FROM Dockerfile 除了注释第一行必须是 FROM ，FROM 后面跟镜像名称，代表我们要基于哪个基础镜像构建我们的容器 RUN RUN 后面跟一个具体的命令，类似于 Linux 命令行执行命令 ADD 拷贝本机文件或者远程文件到镜像内 COPY 拷贝本机文件到镜像内 USER 指定容器启动的用户 ENTRYPOINT 容器的启动命令 CMD CMD 为 ENTRYPOINT 指令提供默认参数，也可以单独使用 CMD 指定容器启动参数 ENV 指定容器运行时的环境变量，格式为 key &#x3D; value ARG 定义外部变量，构建镜像时可以使用 build-arg &#x3D; 的格式传递参数用于构建 EXPOSE 指定容器监听的端口，格式为 [port]&#x2F;tcp 或者 [port]&#x2F;udp WORKDIR 为 Dockerfile 中跟在其后的所有 RUN、CMD、ENTRYPOINT、COPY 和 ADD 命令设置工作目录 镜像的实现原理 Docker 镜像是由一系列镜像层（layer）组成的，每一层代表了镜像构建过程中的一次提交，Dockerfile 的每一行命令，都生成了一个镜像层，每一层的 diff 夹下只存放了增量数据。 Docker 镜像是静态的分层管理的文件组合，镜像底层的实现依赖于联合文件系统（UnionFS）。分层的结构使得 Docker 镜像非常轻量，每一层根据镜像的内容都有一个唯一的 ID 值，当不同的镜像之间有相同的镜像层时，便可以实现不同的镜像之间共享镜像层的效果。 容器容器是镜像的运行实体，镜像是静态的只读文件，而容器带有运行时需要的可写文件层，并且容器中的进程属于运行状态，即容器运行着真正的应用进程。 虽然容器的本质是主机上运行的一个进程，但是容器有自己独立的命名空间隔离和资源限制（在容器内部，无法看到主机上的进程、环境变量、网络等信息，这是容器与直接运行在主机上进程的本质区别）。 OCI 全称为开放容器标准（Open Container Initiative），它是一个轻量级，开放的治理结构。OCI 组织在 Linux 基金会的大力支持下，于 2015 年 6 月份正式注册成立。基金会旨在为用户围绕工业化容器的格式和镜像运行时，制定一个开放的容器标准。目前主要有两个标准文档：容器运行时标准 （runtime spec）和容器镜像标准（image spec）。 运行容器化环境时，实际上是在容器内部创建该文件系统的读写副本。 这将添加一个容器层，该层允许修改镜像的整个副本。 容器的生命周期 容器的生命周期是容器可能处于的状态，容器的生命周期分为 5 种： created：初建状态 running：运行状态 stopped：停止状态 paused： 暂停状态 deleted：删除状态，处于初建状态、运行状态、停止状态、暂停状态的容器都可以直接删除 graph LR; A[Docker 镜像] -->|docker create| B[初建状态]; B -->|docker start| C[运行状态]; C -->|docker stop| D[停止状态]; D -->|docker rm| E[删除状态]; C -->|docker restart| C; C -->|docker pause| F[暂停状态]; F -->|docker unpause| C; A -->|docker run| C; D -->|docker start| C; 仓库仓库（Repository）是存储和分发 Docker 镜像的地方 graph LR; 镜像(Image) -->|创建| 容器(Container); 镜像(Image) -->|存放| 仓库(Repository); 仓库(Repository) -->|拉取| 镜像(Image); 注册服务器（Registry）和仓库（Repository） 注册服务器是存放仓库的实际服务器，而仓库则可以被理解为一个具体的项目或者目录 注册服务器可以包含很多个仓库，每个仓库又可以包含多个镜像 例如：镜像地址为 docker.io&#x2F;centos，docker.io 是注册服务器，centos 是仓库名 graph TB subgraph 注册服务器 Registry subgraph 仓库 Repository ubuntu16[ubuntu:16] ubuntu18[ubuntu:18] ubuntu14[...] end subgraph 仓库 Repository centos7[centos:7] centos8[centos:8] centos6[...] end end 公共镜像仓库 公共镜像仓库一般是 Docker 官方或者其他第三方组织（阿里云，腾讯云，网易云等）提供的，允许所有人注册和使用的镜像仓库 Docker Hub 是全球最大的镜像市场，这些容器镜像主要来自软件供应商、开源组织和社区 需要使用 docker login 命令先登录一下镜像服务器，因为只有已经登录的用户才可以推送镜像到仓库 docker login 命令默认会请求 Docker Hub，如果想登录第三方镜像仓库或者自建的镜像仓库，在 docker login 后面加上注册服务器即可 例如：登录访问阿里云镜像服务器，则使用 docker login registry.cn-beijing.aliyuncs.com 在本地镜像推送到自定义仓库前，需要先用 docker tag 命令将镜像“重命名” 镜像“重命名”后使用 docker push 命令就可以推送镜像到自己创建的仓库中 搭建私有仓库 启动本地仓库 Docker 官方提供了开源的镜像仓库 Distribution，并且镜像存放在 Docker Hub 的 Registry 仓库下供下载 docker run -d -p 5000:5000 --name registry registry:2.7，此时就拥有了一个私有镜像仓库，访问地址为 localhost，端口号为 5000 持久化镜像存储 容器是无状态的，上面私有仓库的启动方式可能会导致镜像丢失，因为并没有把仓库的数据信息持久化到主机磁盘上 使用以下命令将镜像持久化到主机目录 docker run -v /var/lib/registry/data:/var/lib/registry -d -p 5000:5000 --name registry registry:2.7 -v 的含义是把 Docker 容器的某个目录或文件挂载到主机上，保证容器被重建后数据不丢失 -v 参数冒号前面为 主机目录，冒号后面为 容器内目录 registry 的持久化存储除了支持本地文件系统还支持很多种类型，例如 S3、Google Cloud Platform、Microsoft Azure Blob Storage Service 等多种存储类型 构建外部可访问的镜像仓库 Docker 要求非 localhost 访问的镜像仓库必须使用 HTTPS，这时候就需要构建外部可访问的镜像仓库 使用 -v 参数把镜像数据持久化在 /var/lib/registry/data 目录中 同时把主机上的证书文件挂载到了容器的 /certs 目录下 同时通过 -e 参数设置 HTTPS 相关的环境变量参数，最后让仓库在主机上监听 443 端口 私有仓库进阶 Docker 官方开源的镜像仓库 Distribution 仅满足了镜像存储和管理的功能，用户权限管理相对较弱，并且没有管理界面 Harbor 是一个基于 Distribution 项目开发的一款企业级镜像管理软件，拥有 RBAC （基于角色的访问控制）、管理用户界面以及审计等非常完善的功能 12345678910# 构建外部可访问的镜像仓库$ docker run -d \\ --name registry \\ -v &quot;/var/lib/registry/data:/var/lib/registry \\ -v &quot;/var/lib/registry/certs:/certs \\ -e REGISTRY_HTTP_ADDR=0.0.0.0:443 \\ -e REGISTRY_HTTP_TLS_CERTIFICATE=/certs/regisry.xxxdocker.io.crt \\ -e REGISTRY_HTTP_TLS_KEY=/certs/regisry.xxxdocker.io.key \\ -p 443:443 \\ registry:2.7 架构Docker 整体架构采用 C&#x2F;S（客户端 &#x2F; 服务器）模式。客户端负责发送操作指令，服务端负责接收和处理指令。客户端和服务端通信有多种方式，即可以在同一台机器上通过 UNIX 套接字通信，也可以通过网络连接远程通信。 Docker 客户端 Docker 命令是 Docker 客户端与 Docker 服务端交互的主要方式。除了使用 docker 命令的方式，还可以使用直接请求 REST API 的方式与 Docker 服务端交互，甚至还可以使用各种语言的 SDK 与 Docker 服务端交互。 Docker 服务端 Docker 服务端是 Docker 所有后台服务的统称。其中 dockerd 是一个非常重要的后台管理进程，它负责响应和处理来自 Docker 客户端的请求，然后将客户端的请求转化为 Docker 的具体操作。例如镜像、容器、网络和挂载卷等具体对象的操作和管理。 Docker 重要组件 Docker 的两个至关重要的组件：runC 和 containerd： runC 是 Docker 官方按照 OCI 容器运行时标准的一个实现。通俗地讲，runC 是一个用来运行容器的轻量级工具，是真正用来运行容器的 containerd 是 Docker 服务端的一个核心组件，它是从 dockerd 中剥离出来的 ，它的诞生完全遵循 OCI 标准，是容器标准化后的产物。containerd 通过 containerd-shim 启动并管理 runC，可以说 containerd 真正管理了容器的生命周期 graph TD; subgraph Docker 服务端 B[Docker Daemon dockerd] --> C[containerd]; C --> D1[containerd-shim]; C --> D2[containerd-shim]; C --> D3[containerd-shim]; C --> D4[containerd-shim]; D1 --> E1[runc]; D2 --> E2[runc]; D3 --> E3[runc]; D4 --> E4[runc]; end dockerd 通过 gRPC 与 containerd 通信，由于 dockerd 与真正的容器运行时，runC 中间有了 containerd 这一 OCI 标准层，使得 dockerd 可以确保接口向下兼容。 containerd-shim 的意思是垫片，类似于拧螺丝时夹在螺丝和螺母之间的垫片。containerd-shim 的主要作用是将 containerd 和真正的容器进程解耦，使用 containerd-shim 作为容器进程的父进程，从而实现重启 containerd 不影响已经启动的容器进程。 事实上，dockerd 启动的时候， containerd 就随之启动了。当执行 docker run 命令时，containerd 会创建 containerd-shim 充当 “垫片” 进程，然后启动容器的真正进程。 容器操作1234567docker create -it --name=busybox busyboxdocker start busyboxdocker run -it --name=busybox busybox# -t 参数的作用是分配一个伪终# -i 参数则可以终端的 STDIN 打开# 同时使用 -it 参数可以让我们进入交互模式# 在交互模式下，用户可以通过所创建的终端来输入命令 当使用 docker run 创建并启动容器时，Docker 后台执行的流程为： Docker 会检查本地是否存在 busybox 镜像，如果镜像不存在则从 Docker Hub 拉取 busybox 镜像； 使用 busybox 镜像创建并启动一个容器； 分配文件系统，并且在镜像只读层外创建一个读写层； 从 Docker IP 池中分配一个 IP 给容器； 执行用户的启动命令运行镜像。 对于容器来说，杀死容器中的主进程，则容器也会被杀死。 1234567# docker stop [-t|–time[=10]]# 向运行中的容器发送 SIGTERM 信号# 如果容器内 1 号进程接受并能够处理 SIGTERM，则等待 1 号进程处理完毕后退出# 如果等待一段时间后，容器仍然没有退出，则会发送 SIGKILL 强制终止容器docker stop busybox# 通过 docker start 命令来重新启动# docker restart命令会将一个运行中的容器终止，并且重新启动它 查看停止状态的容器信息，可以使用 docker ps -a 命令 1234# 处于运行状态的容器可以通过docker attach、docker exec、nsenter等多种方式进入容器docker attach busybox# 由于docker attach命令不够灵活，一般使用 docker exec 命令进入容器docker exec -it busybox sh 使用 docker attach 命令同时在多个终端运行时，所有的终端窗口将同步显示相同内容，当某个命令行窗口的命令阻塞时，其他命令行窗口同样也无法操作。 进入容器后，可以看到容器内有两个 sh 进程，这是因为以 exec 的方式进入容器，会单独启动一个 sh 进程，每个窗口都是独立且互不干扰的，也是使用最多的一种方式。 123456# 删除容器命令的使用方式如下：docker rm [OPTIONS] CONTAINER [CONTAINER...]# 删除一个停止状态的容器docker rm busybox# 删除正在运行中的容器# 添加 -f (或 –force) 参数， Docker 会发送 SIGKILL 信号强制终止正在运行的容器docker rm -f busybox 123456789# 使用docker export CONTAINER命令导出一个容器到文件# 导出容器前先进入容器docker exec -it busybox shdocker export busybox &gt; busybox.tar# 将该文件拷贝到其他机器上，通过导入命令实现容器的迁移# 导入容器的命令格式为 docker import [OPTIONS] file|URL [REPOSITORY[:TAG]]# busybox.tar 被导入成为新的镜像，镜像名称为 busybox:test docker import busybox.tar busybox:testdocker run -it busybox:test sh 镜像包含了容器运行所需要的文件系统结构和内容，是 静态的只读文件，而容器则是在镜像的只读层上创建了 可写层，并且容器中的进程属于运行状态，容器是真正的应用载体。 Dockerfile生产实践中一定优先使用 Dockerfile 的方式构建镜像， Dockerfile 构建镜像可以带来很多好处： 易于版本化管理，Dockerfile 本身是一个文本文件，方便存放在代码仓库做版本管理 过程可追溯，Dockerfile 的每一行指令代表一个镜像层，根据 Dockerfile 的内容即可很明确地查看镜像的完整构建过程 屏蔽构建环境异构，使用 Dockerfile 构建镜像无须考虑构建环境 Dockerfile 应该尽量遵循的原则 单一职责，容器的本质是进程，一个容器代表一个进程，因此不同功能的应用应该尽量拆分为不同的容器，每个容器只负责单一业务进程 提供注释信息，Dockerfile 也是一种代码 保持容器最小化，避免安装无用的软件包，加快容器构建速度，而且可以避免镜像体积过大 合理选择基础镜像，容器的核心是应用，因此只要基础镜像能够满足应用的运行环境即可 使用 .dockerignore 文件，使用 .dockerignore 文件允许我们在构建时，忽略一些不需要参与构建的文件，从而提升构建效率 尽量使用构建缓存 Docker 构建过程中，每一条 Dockerfile 指令都会提交为一个镜像层，下一条指令都是基于上一条指令构建的 如果构建时发现要构建的镜像层的父镜像层已经存在，并且下一条命令使用了相同的指令，即可命中构建缓存 基于 Docker 构建时的缓存特性，我们可以把不轻易改变的指令放到 Dockerfile 前面，例如安装软件包 而可能经常发生改变的指令放在 Dockerfile 末尾，例如编译应用程序 正确设置时区 从 Docker Hub 拉取的官方操作系统镜像大多数都是 UTC 时间（世界标准时间） 想要在容器中使用中国区标准时间（东八区），需要根据使用的操作系统修改相应的时区信息 例如，Ubuntu、CentOS 和 Debian RUN ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime RUN echo &quot;Asia/Shanghai&quot; &gt;&gt; /etc/timezone 使用国内软件源加快镜像构建速度 最小化镜像层数，尽可能地减少 Dockerfile 指令行数 Dockerfile 指令书写建议 RUN 指令在构建时将会生成一个新的镜像层并且执行 RUN 指令后面的内容 当 RUN 指令后面跟的内容比较复杂时，建议使用反斜杠（\\） 结尾并且换行 RUN 指令后面的内容尽量按照字母顺序排序，提高可读性 CMD 和 ENTRYPOINT 指令都是容器运行的命令入口 CMD 和 ENTRYPOINT 的基本使用格式分为两种 第一种为 CMD/ENTRYPOINT[“command” , “param”]，这种格式是使用 Linux 的 exec 实现的， 一般称为 exec 模式，这种书写格式为 CMD&#x2F;ENTRYPOINT 后面跟 json 数组，也是 Docker 推荐的使用格式 ✅ 另外一种格式为 CMD/ENTRYPOINT command param ，这种格式是基于 shell 实现的， 通常称为 shell 模式。当使用 shell 模式时，Docker 会以 &#x2F;bin&#x2F;sh -c command 的方式执行命令 Dockerfile 中如果使用了 ENTRYPOINT 指令，启动 Docker 容器时需要使用 –entrypoint 参数才能覆盖 Dockerfile 中如果没有使用 ENTRYPOINT 指令 ，而使用 CMD 设置的命令则可以被 docker run 后面的参数直接覆盖 ENTRYPOINT 指令可以结合 CMD 指令使用，也可以单独使用，而 CMD 指令只能单独使用 如果镜像只执行单一的具体程序，并且不希望用户在执行 docker run 时覆盖默认程序，建议使用 ENTRYPOINT ADD 和 COPY 都是从外部往容器内添加文件 COPY 指令只支持基本的文件和文件夹拷贝功能 ADD 则支持更多文件来源类型，比如自动提取 tar 包，并且可以支持源文件为 URL 格式 WORKDIR 为了使构建过程更加清晰明了，推荐使用 WORKDIR 来指定容器的工作路径 应该尽量避免使用 RUN cd /work/path &amp;&amp; do some work 这样的指令 Docker 安全Docker 与虚拟机区别 虚拟机 虚拟机是通过管理系统（Hypervisor）模拟出 CPU、内存、网络等硬件，然后在这些模拟的硬件上 创建客户内核和操作系统 虚拟机有自己的内核和操作系统，并且硬件都是通过虚拟机管理系统模拟出来的，用户程序无法直接使用到主机的操作系统和硬件资源，隔离性和安全性有着更好的保证 Docker 容器 Docker 容器是通过 Linux 内核的 Namespace 技术 实现了 文件系统、进程、设备以及网络 的隔离 再 通过 Cgroups 对 CPU、 内存等资源进行限制，最终实现了容器之间相互不受影响 容器与虚拟机相比，容器的性能损耗非常小，并且镜像也非常小，在业务快速开发和迭代的今天，容器秒级的启动等特性也非常匹配业务快速迭代的业务场景 Docker 的安全问题 Docker 自身安全，Docker 作为一款容器引擎，本身也会存在一些安全漏洞 CVE（Common Vulnerabilities and Exposures）目前已经记录了多项与 Docker 相关的安全漏洞，主要有权限提升、信息泄露等几类安全问题，具体 Docker 官方记录的安全问题可以参考 这里 镜像安全，镜像的安全直接影响到容器的安全 镜像软件存在安全漏洞，如果软件包存在漏洞，则可能会被不法分子利用并且侵入容器，影响其他容器或主机安全 仓库漏洞，无论是 Docker 官方的镜像仓库还是我们私有的镜像仓库，都有可能被攻击，然后篡改镜像 用户程序漏洞，用户自己构建的软件包可能存在漏洞或者被植入恶意脚本，这样会导致运行时提权影响其他容器或主机安全 Linux 内核隔离性不够 目前 Namespace 已经提供了非常多的资源隔离类型，但是仍有部分关键内容没有被完全隔离，其中包括一些系统的关键性目录（如 &#x2F;sys、&#x2F;proc 等） 这些关键性的目录可能会泄露主机上一些关键性的信息，让攻击者利用这些信息对整个主机甚至云计算中心发起攻击 一旦内核的 Namespace 被突破，使用者就有可能直接提权获取到主机的超级权限，从而影响主机安全 所有容器共享主机内核 由于同一宿主机上所有容器共享主机内核，所以攻击者可以利用一些特殊手段导致内核崩溃，进而导致主机宕机影响主机上其他服务 如何解决容器的安全问题 Docker 自身安全性改进 Docker 自身是基于 Linux 的多种 Namespace 实现的，其中有一个很重要的 Namespace 叫作 User Namespace Docker 从 1.10 版本开始，使用 User Namespace 做 用户隔离，实现了容器中的 root 用户映射到主机上的非 root 用户，从而大大减轻了容器被突破的风险 保障镜像安全 可以在私有镜像仓库安装镜像安全扫描组件，对上传的镜像进行检查 在拉取镜像时，要确保只从受信任的镜像仓库拉取，并且与镜像仓库通信一定要使用 HTTPS 协议 加强内核安全和管理 宿主机及时升级内核漏洞，宿主机内核应该尽量安装最新补丁，因为更新的内核补丁往往有着更好的安全性和稳定性 使用 Capabilities 划分权限，Capabilities 是 Linux 内核的概念，Linux 将系统权限分为了多个 Capabilities，Capabilities 实现了系统更细粒度的访问控制 在虚拟机内我们可以赋予用户所有的权限，例如设置 cron 定时任务、操作内核模块、配置网络等权限 而容器则需要针对每一项 Capabilities 更细粒度的去控制权限，例如容器是共享主机内核的，因此在容器内部一般不允许直接操作主机内核 使用安全加固组件 Linux 的 SELinux、AppArmor、GRSecurity 组件都是 Docker 官方推荐的安全加固组件 SELinux (Secure Enhanced Linux): 是 Linux 的一个内核安全模块，提供了安全访问的策略机制，通过设置 SELinux 策略可以实现某些进程允许访问某些文件 AppArmor: 类似于 SELinux，也是一个 Linux 的内核安全模块，普通的访问控制仅能控制到用户的访问权限，而 AppArmor 可以控制到用户程序的访问权限 GRSecurity 是一个对内核的安全扩展，可通过智能访问控制，提供内存破坏防御，文件系统增强等多种防御形式 这三个组件可以限制一个容器对主机的内核或其他资源的访问控制，容器报告的一些安全漏洞中，很多都是通过对内核进行加强访问和隔离来实现的 资源限制 在生产环境中，建议每个容器都添加相应的资源限制 例如想要启动一个 1 核 2G 的容器，并且限制在容器内最多只能创建 1000 个 PID，启动命令如下： docker run -it --cpus=1 -m=2048m --pids-limit=1000 busybox sh 在生产环境中限制 CPU、内存、PID 等资源，这样即便应用程序有漏洞，也不会导致主机的资源完全耗尽，最大限度降低安全风险 使用 安全容器 容器有着 轻便快速启动 的优点，虚拟机有着 安全隔离 的优点 安全容器是相较于普通容器的，安全容器与普通容器的主要区别在于，安全容器中的每个容器都运行在一个单独的微型虚拟机中，拥有独立的操作系统和内核，并且有虚拟化层的安全隔离 Kata Containers 并不包含一个完整的操作系统，只有一个精简版的 Guest Kernel 运行着容器本身的应用，并且通过减少不必要的内存，尽量共享可以共享的内存来进一步减少内存的开销 Kata Container 实现了 OCI 规范，可以直接使用 Docker 的镜像启动 Kata 容器，具有开销更小、秒级启动、安全隔离等许多优点 Docker 容器的安全问题 解决办法 1. Docker 作为一款容器引擎，本身也会存在一些安全漏洞（权限提升、信息泄露） 使用 Docker 最新版本就可以得到更好的安全保障 2. 镜像软件存在安全漏洞、仓库漏洞、用户程序漏洞 在私有镜像仓库库中安装安全扫描插件，对上传的镜像进行检查，通过与 CVE 数据库对比，一旦发现有漏洞的镜像及时通报并可中止相关镜像继续构建和分发 3. Linux 内核 Namespace 隔离不够，仍有部分关键内容没有极完全隔离 1. 宿主机内核应该尽量安装更新补丁 2. 使用 Capabilities 划分权限 3. 使用 SELinux、AppArmor、GRSecurity 等安全组件加强安全 4. 每个容器都需要限制资源使用 4. 所有容器共享主机内内核，攻击者可以利用一些特殊手段导致内核崩溃，进而导致主机宕机或影响其他服务 使用更安全容器（例如 Kata Containers）来替代 runc 容器监控通过监控可以随时掌握容器的运行状态，做到线上隐患和问题早发现，早解决。容器的监控面临着更大的挑战，因为容器的行为和本质与传统的虚拟机是不一样的，总的来说，容器具有以下特性： 容器是短期存活的，并且可以动态调度 容器的本质是 进程，而不是一个完整操作系统 由于容器非常轻量，容器的创建和销毁也会比传统虚拟机更加频繁 Docker 容器的监控方案有很多，除了 Docker 自带的 docker stats 命令，还有很多开源的解决方案，例如 sysdig、cAdvisor、Prometheus 等 使用 docker stats 命令 查看容器 CPU、内存、网络 IO、磁盘 IO、PID 等资源的使用情况 只能获取本机数据，无法查看历史监控数据，没有可视化展示面板 cAdvisor 特点 不仅可以监控容器的资源使用情况，还可以监控主机的资源使用情况 还提供了基础的查询界面和 HTTP 接口，方便与外部系统结合 Kubernetes 也集成了 cAdvisor 作为容器监控指标的默认工具 监控原理 Docker 是基于 Namespace、Cgroups 和联合文件系统实现的 Cgroups 不仅可以用于容器资源的限制，还可以提供容器的资源使用率，无论何种监控方案的实现，底层数据都来源于 Cgroups 容器的监控原理其实就是定时读取 Linux 主机上相关的文件并展示给用户，例如，通过读取 memory.limit_in_bytes 文件即可获取到容器内存的限制值 工作原理组件组成Docker 整体架构采用 C&#x2F;S（客户端 &#x2F; 服务器）模式，主要由客户端和服务端两大部分组成。客户端负责发送操作指令，服务端负责接收和处理指令。客户端和服务端通信有多种方式，即可以在同一台机器上通过 UNIX 套接字通信，也可以通过网络连接远程通信。 Docker 组件大体分为 Docker 相关组件、containerd 相关组件和容器运行时。件根据工作职责可以分为以下三大类： Docker 相关的组件：docker、dockerd、docker-init 和 docker-proxy containerd 相关的组件：containerd、containerd-shim 和 ctr 容器运行时相关的组件：runc Docker 相关的组件 docker docker 是 Docker 客户端的一个完整实现，它是一个二进制文件，对用户可见的操作形式为 docker 命令，通过 docker 命令可以完成所有的 Docker 客户端与服务端的通信（还可以通过 REST API、SDK 等多种形式与 Docker 服务端通信） Docker 客户端与服务端的交互过程是：docker 组件向服务端发送请求后，服务端根据请求执行具体的动作并将结果返回给 docker，docker 解析服务端的返回结果，并将结果通过命令行标准输出展示给用户 dockerd dockerd 是 Docker 服务端的后台常驻进程，用来接收客户端发送的请求，执行具体的处理任务，处理完成后将结果返回给客户端 Docker 客户端可以通过多种方式向 dockerd 发送请求，常用的 Docker 客户端与 dockerd 的交互方式有三种：通过 UNIX 套接字（Unix domain socket） 与服务端通信、通过 TCP 与服务端通信、通过文件描述符的方式与服务端通信 Docker 客户端和服务端的通信形式必须保持一致，否则将无法通信，只有当 dockerd 监听了 UNIX 套接字客户端才可以使用 UNIX 套接字的方式与服务端通信，UNIX 套接字也是 Docker 默认的通信方式 如果想要通过远程的方式访问 dockerd，可以在 dockerd 启动的时候添加 -H 参数指定监听的 HOST 和 PORT docker-init 在容器内部，自己的业务进程没有回收子进程的能力时，在执行 docker run 启动容器时可以添加 –init 参数，此时 Docker 会使用 docker-init 作为 1 号进程，帮助管理容器内子进程，例如回收僵尸进程等 docker-proxy docker-proxy 主要是用来做 端口映射 的，当使用 docker run 命令启动容器时，如果使用了 -p 参数，docker-proxy 组件就会把容器内相应的端口映射到主机上来 当启动一个容器时需要端口映射时， Docker 创建了一个 docker-proxy 进程，并且通过参数把我们的容器 IP 和端口传递给 docker-proxy 进程，然后 docker-proxy 通过 iptables 实现了 nat 转发 Unix domain socket 或者 IPC socket 是一种终端，可以使同一台操作系统上的两个或多个进程进行数据通信。与 管道相比，Unix domain sockets 既可以使用 字节流，又可以使用数据队列，而管道通信则只能使用字节流。Unix domain sockets 的接口和 Internet socket 很像，但它不使用网络底层协议来通信。 docker 是官方实现的标准客户端，dockerd 是 Docker 服务端的入口，负责接收客户端发送的指令并返回相应结果，而 docker-init 在业务主进程没有进程回收功能时则十分有用，docker-proxy 组件则是实现 Docker 网络访问的重要组件 containerd 相关的组件 containerd containerd 组件是从 Docker 1.11 版本正式从 dockerd 中剥离出来的（由 docker 团队开源的容器运行时） 它的诞生完全遵循 OCI 标准，是容器标准化后的产物，专注于提供轻量级、高性能的容器运行环境 containerd 不仅负责容器生命周期的管理，同时还负责一些其他的功能： 镜像的管理，例如容器运行前从镜像仓库拉取镜像到本地 接收 dockerd 的请求，通过适当的参数调用 runc 启动容器 管理存储相关资源 管理网络相关资源 containerd 包含一个后台常驻进程，默认的 socket 路径为 &#x2F;run&#x2F;containerd&#x2F;containerd.sock，dockerd 通过 UNIX 套接字向 containerd 发送请求，containerd 接收到请求后负责执行相关的动作并把执行结果返回给 dockerd 如果不想使用 dockerd，也可以直接使用 containerd 来管理容器，由于 containerd 更加简单和轻量，生产环境中越来越多的人开始直接使用 containerd 来管理容器 containerd-shim containerd-shim 的意思是垫片，类似于拧螺丝时夹在螺丝和螺母之间的垫片 containerd-shim 的主要作用是将 containerd 和真正的容器进程解耦，使用 containerd-shim 作为容器进程的父进程，从而实现重启 containerd 不影响已经启动的容器进程 ctr ctr 实际上是 containerd-ctr，它是 containerd 的客户端，主要用来开发和调试 在没有 dockerd 的环境中，ctr 可以充当 docker 客户端的部分角色，直接向 containerd 守护进程发送操作容器的请求 容器运行时组件 runc runc 是一个标准的 OCI 容器运行时的实现，它是一个命令行工具，可以直接用来创建和运行容器 Docker 的组件虽然很多，但每个组件都有自己清晰的工作职责，Docker 相关的组件负责发送和接受 Docker 请求，contianerd 相关的组件负责管理容器的生命周期，而 runc 负责真正意义上创建和启动容器。这些组件相互配合，才使得 Docker 顺利完成了容器的管理工作。 组件分类 组件名称 作用剖析 Docker 相关组件 docker Docker 的客户端，负责发送 Docker 操作请求 dockerd Docker 服务端入口，负责接收客户端请求并返回请求结果 docker-init 当业务主进程退出回收能力时，docker-init 可以作为容器的 1 号进程，负责管理容器的子进程 docker-proxy 用来做 Docker 的网络实现，通过设置 iptables 规则可以使得访问到主机的流量可以转发到容器中 containerd 相关组件 containerd 负责管理容器的生命周期，负责接收 dockerd 的请求，执行启动或者销毁 containerd-shim 将 containerd 和真正的容器进程解耦，使用 containerd-shim 作为容器进程的父进程，可以实现重启 containerd 不影响已经启动的容器进程 ctr containerd 的客户端，可以直接向 containerd 发送容器操作请求，主要用来开发和调试 容器运行时组件 runc 通过调用 Namespace、cgroups 等系统接口，实现容器的创建和运行 资源隔离Namespace 是 Linux 内核的一个特性，该特性可以实现在同一主机系统中，对进程 ID、主机名、用户 ID、文件名、网络和进程间通信等资源的隔离，Docker 利用 Linux 内核的 Namespace 特性，实现了每个容器的资源相互隔离，从而保证容器内部只能访问到自己 Namespace 的资源。 Namespace 是 Linux 内核的一项功能，该功能对内核资源进行分区，以使一组进程看到一组资源，而另一组进程看到另一组资源。Namespace 的工作方式通过为一组资源和进程设置相同的 Namespace 而起作用，但是这些 Namespace 引用了不同的资源。资源可能存在于多个 Namespace 中。这些资源可以是 进程 ID、主机名、用户 ID、文件名、与网络访问相关的名称和进程间通信。 Linux 5.6 内核中提供了 8 种类型的 Namespace： Namespace 名称 作用 内核版本 Mount（mnt） 隔离挂载点 2.4.19 Process ID (pid) 隔离进程 ID 2.6.24 Network (net) 隔离网络设备，端口号等 2.6.29 Interprocess Communication (ipc) 隔离 System V IPC 和 POSIX message queues 2.6.19 UTS Namespace(uts) 隔离主机名和域名 2.6.19 User Namespace (user) 隔离用户和用户组 3.8 Control group (cgroup) Namespace 隔离 Cgroups 根目录 4.6 Time Namespace 隔离系统时间 5.6 unshare 是 util-linux 工具包中的一个工具，使用 unshare 命令可以实现创建并访问不同类型的 Namespace。 各种 Namespace 的作用 Mount Namespace 用来隔离不同的进程或进程组看到的挂载点，可以实现在 不同的进程中看到不同的挂载目录 实现容器内只能看到自己的挂载信息，在容器内的挂载操作不会影响主机的挂载目录 PID(Process Identification) Namespace PID Namespace 的作用是用来 隔离进程，在不同的 PID Namespace 中，进程可以拥有相同的 PID 号 利用 PID Namespace 可以实现每个容器的主进程为 1 号进程，而容器内的进程在主机上却拥有不同的 PID UTS(UNIX Time Sharing) namespace UTS Namespace 主要是用来 隔离主机名 的，它允许每个 UTS Namespace 拥有一个独立的主机名。 IPC(Interprocess communication) Namespace IPC Namespace 主要是用来 隔离进程间通信 的 PID Namespace 和 IPC Namespace 一起使用可以实现同一 IPC Namespace 内的进程彼此可以通信，不同 IPC Namespace 的进程却不能通信 User Namespace User Namespace 主要是用来 隔离用户和用户组 的，一个比较典型的应用场景就是在主机上以非 root 用户运行的进程可以在一个单独的 User Namespace 中映射成 root 用户 使用 User Namespace 可以实现进程在容器内拥有 root 权限，而在主机上却只是普通用户 在隔离的 User Namespace 中，并不能获取到主机的 root 权限，也就是说 User Namespace 实现了用户和用户组的隔离 Net Namespace Net Namespace 用来 隔离网络设备、IP 地址和端口 等信息，可以让每个进程拥有自己独立的 IP 地址，端口和网卡信息 Linux 内核从 2002 年 2.4.19 版本开始加入了 Mount Namespace，而直到内核 3.8 版本加入了 User Namespace 才为容器提供了足够的支持功能，当 Docker 新建一个容器时， 它会创建这六种 Namespace，然后将容器中的进程加入这些 Namespace 之中，使得 Docker 容器中的进程只能看到当前 Namespace 中的系统资源。 正是由于 Docker 使用了 Linux 的这些 Namespace 技术，才实现了 Docker 容器的隔离，可以说没有 Namespace，就没有 Docker 容器。 资源限制cgroups（全称：control groups）是 Linux 内核的一个功能，它可以实现 限制进程或者进程组的资源（如 CPU、内存、磁盘 IO 等）。 在 2006 年，Google 的工程师（ Rohit Seth 和 Paul Menage 为主要发起人） 发起了这个项目，起初项目名称并不是 cgroups，而被称为进程容器（process containers）。在 2007 年 cgroups 代码计划合入 Linux 内核，但是当时在 Linux 内核中，容器（container）这个词被广泛使用，并且拥有不同的含义。为了避免命名混乱和歧义，进程容器被重名为 cgroups，并在 2008 年成功合入 Linux 2.6.24 版本中。cgroups 目前已经成为 systemd、Docker、Linux Containers（LXC） 等技术的基础。 cgroups 功能及核心概念 cgroups 主要提供了如下功能 资源限制： 限制资源的使用量，例如可以通过限制某个业务的内存上限，从而保护主机其他业务的安全运行 优先级控制：不同的组可以有不同的资源（ CPU 、磁盘 IO 等）使用优先级 审计：计算控制组的资源使用情况 控制：控制进程的挂起或恢复 cgroups 功能的实现依赖于三个核心概念：子系统、控制组、层级树 子系统（subsystem）：是一个内核的组件，一个子系统代表一类资源调度控制器，例如内存子系统可以限制内存的使用量，CPU 子系统可以限制 CPU 的使用时间 控制组（cgroup）：表示一组进程和一组带有参数的子系统的关联关系，例如一个进程使用了 CPU 子系统来限制 CPU 的使用时间，则这个 进程和 CPU 子系统的关联关系 称为控制组 层级树（hierarchy）：是由一系列的控制组按照树状结构排列组成的。这种排列方式可以使得控制组拥有父子关系，子控制组默认拥有父控制组的属性，也就是子控制组会继承于父控制组。 比如，系统中定义了一个控制组 c1，限制了 CPU 可以使用 1 核，然后另外一个控制组 c2 想实现既限制 CPU 使用 1 核，同时限制内存使用 2G，那么 c2 就可以直接继承 c1，无须重复定义 CPU 限制。 cgroups 的三个核心概念中，子系统是最核心的概念，因为子系统是真正实现某类资源的限制的基础，cpu 和 memory 子系统是容器环境中使用最多的子系统。 Docker 创建容器时，Docker 会根据启动容器的参数，在对应的 cgroups 子系统下创建以容器 ID 为名称的目录，然后根据容器启动时设置的资源限制参数，修改对应的 cgroups 子系统资源限制文件，从而达到资源限制的效果。 Cgroups 不仅可以实现资源的限制，还可以为用来统计资源的使用情况，容器监控系统的数据来源也是 cgroups 提供的。Cgroups 虽然可以实现资源的限制，但是不能保证资源的使用。例如，cgroups 限制某个容器最多使用 1 核 CPU，但不保证总是能使用到 1 核 CPU，当 CPU 资源发生竞争时，可能会导致实际使用的 CPU 资源产生竞争。 网络模型利用 Linux 的 Namespace 和 Cgroups 技术可以实现各种资源的隔离和主机资源的限制，让容器可以像一台虚拟机一样。但这时容器就像一台未联网的电脑，不能被外部访问到，也不能主动与外部通信，这样的容器只能做一些离线的处理任务，无法通过外部访问。容器的网络标准便分为两大阵营： 以 Docker 公司为代表的 CNM（Container Network Model） 以 Google、Kubernetes、CoreOS 为代表的 CNI（Container Network Interface） CNM（Container Network Model） CNM 抽象了容器的网络接口 ，使得只要满足 CNM 接口的网络方案都可以接入到 Docker 容器网络，CNM 定义的网络标准包含三个重要元素： 沙箱（Sandbox）：沙箱代表了一系列网络堆栈的配置，其中包含路由信息、网络接口等网络资源的管理，沙箱的实现通常是 Linux 的 Net Namespace，但也可以通过其他技术来实现，比如 FreeBSD jail 等 接入点（Endpoint）：接入点将沙箱连接到网络中，代表容器的网络接口，接入点的实现通常是 Linux 的 veth 设备对 网络（Network）：网络是一组可以互相通信的接入点，它将多接入点组成一个子网，并且多个接入点之间可以相互通信 为了更好地构建容器网络标准，Docker 团队把网络功能从 Docker 中剥离出来，成为独立的项目 libnetwork，它通过插件的形式为 Docker 提供网络功能。Libnetwork 是开源的，使用 Golang 编写，它完全 遵循 CNM 网络规范，是 CNM 的官方实现。 Libnetwork 工作流程 Libnetwork 是 Docker 启动容器时，用来为 Docker 容器提供网络接入功能的插件，它可以让 Docker 容器顺利接入网络，实现主机和容器网络的互通。 Docker 通过调用 libnetwork.New 函数来创建 NetworkController 实例 通过调用 NewNetwork 函数创建指定名称和类型的 Network 通过调用 CreateEndpoint 来创建接入点（Endpoint） 调用 NewSandbox 来创建容器沙箱，主要是初始化 Namespace 相关的资源 调用 Endpoint 的 Join 函数将沙箱和网络接入点关联起来，此时容器就加入了 Docker 网络并具备了网络访问能力 Libnetwork 常见网络模式 Libnetwork 比较典型的网络模式主要有四种，这四种网络模式基本满足了我们单机容器的所有场景 null 空网络模式，可以帮助构建一个没有网络接入的容器环境 （离线） 处理一些保密数据，出于安全考虑，需要一个隔离的网络环境执行一些纯计算任务 这时候容器就像一个没有联网的电脑，处于一个相对较安全的环境，确保数据不被从网络窃取 bridge 桥接模式，可以打通容器与容器间网络通信的需求 （与主机进行通信） 启动容器时默认的网络模式，使用 bridge 网络可以实现 容器与容器的互通 可以实现 主机与容器的互通，我们在容器内启动的业务，可以从主机直接请求 Docker 的 bridge 模式是由 Linux 的 veth 和 bridge 技术实现的 Docker 启动时，libnetwork 会在主机上创建 docker0 网桥，而 Docker 创建出的 brige 模式的容器则都会连接 docker0 上，从而实现网络互通 host 主机网络模式，可以让容器内的进程共享主机网络，从而监听或修改主机网络 （没用网路隔离） 有些基础业务需要创建或更新主机的网络配置，使用 host 主机网络模式时 libnetwork 不会为容器创建新的网络配置和 Net Namespace Docker 容器中的进程直接共享主机的网络配置，可以直接使用主机的网络信息，此时，在容器内监听的端口，也将直接占用到主机的端口 除了网络共享主机的网络外，其他的包括进程、文件系统、主机名等都是与主机隔离的 container 网络模式，可以将两个容器放在同一个网络命名空间内，让两个业务通过 localhost 即可实现访问 当两个容器需要共享网络，但其他资源仍然需要隔离时就可以使用 container 网络模式 （不同容器使用同一个网络命名空间） 例如开发了一个 http 服务，但又想使用 nginx 的一些特性，让 nginx 代理外部的请求然后转发给自己的业务，这时使用 container 网络模式将自己开发的服务和 nginx 服务部署到 同一个网络命名空间 中 Libnetwork 常见的网络模式 作用 业务场景 null 空网络模式 不提供任何容器网络 处理一些保密数据，出于安全考虑，需要一个隔离的网络环境执行一些纯计算任务 bridge 桥接模式 使得容器和容器之间网络可以互通 容器需要实现网络通信或者提供网络服务 host 主机网络模式 让容器内的程序可以使用到主机的网络 容器需要控制主机网络或者用主机网络提供服务 container 网络模式 将两个容器放到同一网络空间中，可以直接通过 localhost 本地访问 两个容器之间需要直接通过 localhost 通信，一般用于网络接入较少的场景或本地通信任务 数据存储Docker 网络实现为容器插上了网线，Docker 的卷为容器插上磁盘，实现容器数据的持久化。容器按照业务类型，总体可以分为两类： 无状态的（数据不需要被持久化） 有状态的（数据需要被持久化） Docker 提供了卷（Volume）的功能，使用 docker volume 命令可以实现对卷的创建、查看和删除等操作。 Docker 卷的操作 创建数据卷 使用 docker volume create 命令可以创建一个数据卷 以在 Docker 启动时使用 -v 的方式指定容器内需要被持久化的路径 默认情况下 ，Docker 创建的数据卷为 local 模式，仅能提供本主机的容器访问 查看数据卷 已经创建的数据卷可以使用 docker volume ls 命令查看 docker volume inspect 查看卷的创建日期、命令、挂载路径信息 使用数据卷 使用 docker volume 创建的卷在容器启动时，添加 –mount 参数指定卷的名称即可使用 使用 Docker 卷后数据不会随着容器的删除而消失 删除数据卷 docker volume rm ，正在被使用中的数据卷无法删除 容器与容器之间数据共享 两个容器之间会有共享数据的需求，很典型的一个场景就是容器内产生的日志需要一个专门的日志采集程序去采集日志内容 docker volume create 创建一个共享日志的数据卷，使用 --volumes-from 参数可以在启动新的容器时来挂载已经存在的容器的卷 就像主机上的两个进程，一个向主机目录写数据，一个从主机目录读数据，利用主机的目录，实现了容器之间的数据共享 主机与容器之间数据共享 Docker 卷的目录默认在 &#x2F;var&#x2F;lib&#x2F;docker 下，想把主机的其他目录映射到容器内时，就需要用到主机与容器之间数据共享的方式 例如，想把 MySQL 容器中的 &#x2F;var&#x2F;lib&#x2F;mysql 目录映射到主机的 &#x2F;var&#x2F;lib&#x2F;mysql 目录中 只需要在启动容器的时候添加 -v 参数即可，使用格式为：-v HOST_PATH:CONTIANAER_PATH 操作 命令 备注 创建数据卷 docker volume create 还可以使用 docker run -v 参数启动容器并创建数据卷 查看数据卷 docker volume ls 可以列出所有数据卷 使用数据卷 --mount source=&#123;volume-name&#125;,target=&#123;directory&#125; 使用 mount 参数可以指定把卷挂载到容器中的特定目录 删除数据卷 docker volume rm 删除后数据不可恢复 容器与容器之间的数据共享 --mount source=&#123;volume-name&#125;,target=&#123;directory&#125; 先使用 docker volume create 创建数据卷，然后需要共享数据卷的容器启动时使用 mount 参数挂载 主机与容器之间的数据共享 docker run -v 可以映射主机目录到容器 Docker 卷的实现原理 镜像和容器的文件系统原理： 镜像是由多层文件系统组成的，当我们想要启动一个容器时，Docker 会在镜像上层创建一个可读写层，容器中的文件都工作在这个读写层中，当容器删除时，与容器相关的工作文件将全部丢失 Docker 容器的文件系统不是一个真正的文件系统，而是 通过联合文件系统实现的一个伪文件系统，而 Docker 卷则是直接利用主机的某个文件或者目录，它可以绕过联合文件系统，直接挂载主机上的文件或目录到容器中。 123456$ docker volume create volume-data$ sudo ls -l /var/lib/docker/volumesdrwxr-xr-x. 3 root root 19 Sep 8 10:59 volume-data$ sudo ls -l /var/lib/docker/volumes/volume-datatotal 0drwxr-xr-x. 2 root root 6 Sep 8 10:59 _data Docker 卷的实现原理是在主机的 &#x2F;var&#x2F;lib&#x2F;docker&#x2F;volumes 目录下，根据卷的名称创建相应的目录，然后在每个卷的目录下创建 _data 目录，在容器启动时如果使用 –mount 参数，Docker 会把主机上的目录直接映射到容器的指定目录下，实现数据持久化。 文件存储驱动联合文件系统（Union File System，Unionfs）是一种分层的轻量级文件系统，它可以把多个目录内容联合挂载到同一目录下，从而形成一个单一的文件系统，这种特性可以让使用者像是使用一个目录一样使用联合文件系统。联合文件系统只是一个概念，Docker 中最常用的联合文件系统有三种：AUFS、Devicemapper 和 OverlayFS。 通常情况下， overlay2 会比 AUFS 和 Devicemapper 性能更好，而且更加稳定，因为 overlay2 在 inode 优化上更加高效。因此在生产环境中推荐使用 overlay2 作为 Docker 的文件驱动，OverlayFS 的发展分为两个阶段： 2014 年，OverlayFS 第一个版本被合并到 Linux 内核 3.18 版本中，此时的 OverlayFS 在 Docker 中被称为 overlay 文件驱动 由于第一版的 overlay 文件系统存在很多弊端（例如运行一段时间后 Docker 会报 “too many links problem” 的错误）， Linux 内核在 4.0 版本对 overlay 做了很多必要的改进，此时的 OverlayFS 被称之为 overlay2 overlay2 是如何存储文件的 overlay2 和 AUFS 类似，它将所有目录称之为层（layer），overlay2 的目录是镜像和容器分层的基础，而把这些层统一展现到同一的目录下的过程称为联合挂载（union mount）。overlay2 把目录的下一层叫作 lowerdir，上一层叫作 upperdir，联合挂载后的结果叫作 merged。 overlay2 文件系统最多支持 128 个层数叠加，也就是说你的 Dockerfile 最多只能写 128 行，不过这在日常使用中足够了。 overlay2 将镜像层和容器层都放在单独的目录，并且有唯一 ID，每一层仅存储发生变化的文件，最终使用联合挂载技术将容器层和镜像层的所有文件统一挂载到容器中，使得容器中看到完整的系统文件。 overlay2 如何读取、修改文件 读取文件 文件在容器层中存在：当文件存在于容器层并且不存在于镜像层时，直接从容器层读取文件 当文件在容器层中不存在：当容器中的进程需要读取某个文件时，如果容器层中不存在该文件，则从镜像层查找该文件，然后读取文件内容 文件既存在于镜像层，又存在于容器层：当我们读取的文件既存在于镜像层，又存在于容器层时，将会从容器层读取该文件 修改文件或目录 overlay2 对文件的修改采用的是写时复制的工作机制，这种工作机制可以最大程度节省存储空间 当第一次在容器中修改某个文件时，overlay2 会触发 写时复制 操作，首先从镜像层复制文件到容器层，然后在容器层执行对应的文件修改操作 overlay2 写时复制的操作将会复制整个文件，如果文件过大，将会大大降低文件系统的性能，因此当有大量文件需要被修改时，overlay2 可能会出现明显的延迟，好在写时复制操作只在第一次修改文件时触发，对日常使用没有太大影响 当文件或目录被删除时，overlay2 并不会真正从镜像中删除它，因为镜像层是只读的，overlay2 会创建一个特殊的文件或目录，这种特殊的文件或目录会阻止容器的访问 容器的本质Docker 容器的本质是进程，容器化技术 依赖操作系统层面的 虚拟化，它通过一系列关键技术实现 进程隔离和资源控制，从而使得多个容器可以在同一台宿主机上运行，且相互之间互不干扰。 Linux 内核的 Namespaces（命名空间） Namespaces 是 Linux 内核中用于进程隔离的技术。每个容器实际上是一个进程或进程组，但通过使用 Namespaces，它们被隔离到自己的虚拟空间，彼此之间以及与宿主系统的其他进程隔离。Docker 使用了多种命名空间来隔离容器的不同方面，包括： PID Namespace：隔离进程 ID，容器中的进程有自己独立的 PID 范围。 Network Namespace：隔离网络栈，容器有自己的虚拟网卡、IP 地址、路由表等。 Mount Namespace：隔离文件系统挂载点，容器只能看到分配给它的目录。 UTS Namespace：隔离主机名和域名，使得容器可以设置自己的主机名。 IPC Namespace：隔离进程间通信的资源，如消息队列、信号量等。 User Namespace：隔离用户和用户组的 ID，使得容器中的用户可以有不同于宿主机的用户 ID。 通过 Namespaces，容器看起来像是独立的系统，它们有自己的文件系统、网络环境、进程表等，但实际上是在 共享同一个宿主机的内核。 Cgroups（控制组） Cgroups 是 Linux 内核提供的一种资源管理机制，Docker 使用它来限制容器对系统资源的使用。Cgroups 允许对 CPU、内存、磁盘 I&#x2F;O 和网络带宽等资源进行配额管理和监控。这意味着即使多个容器运行在同一内核上，Cgroups 可以确保每个容器只使用分配给它的资源，不会相互影响。 Union File Systems（联合文件系统） Docker 使用联合文件系统（如 AUFS、OverlayFS 等）来 管理镜像和容器 的文件系统。Docker 镜像由一系列只读层组成，而容器启动时，会在这些只读层上叠加一个可写层。镜像层保存了应用程序的依赖环境和文件，而容器层是运行时动态生成的，存储容器进程的修改。这种文件系统设计使得 Docker 容器启动非常高效，只需增加一个可写层，而无需复制整个镜像。 容器和进程的关系 从技术上看，容器实际上只是一个运行在隔离环境中的进程或进程组。容器内部的每个进程都由宿主机的操作系统内核管理。由于 Docker 容器不包含自己的操作系统内核，它们直接与宿主机的 Linux 内核进行交互。这与虚拟机的不同之处在于，虚拟机会运行一个完整的操作系统，包括内核和用户空间，而 容器只共享宿主机的内核，因此 更轻量、更高效。 Docker 镜像的启动过程 Docker 镜像包含了应用程序及其运行所需的所有依赖环境。当启动一个 Docker 容器时，Docker Daemon 会做以下几件事： 加载镜像：Docker 根据镜像生成容器的文件系统，加载镜像的只读层，并创建一个新的可写层。 分配资源：通过 Cgroups 给容器分配指定的 CPU、内存、I&#x2F;O 等资源。 隔离环境：通过 Namespaces 创建一个独立的隔离环境，使得容器中的进程看不到宿主机的其他进程或资源。 启动进程：使用 runc 或类似工具在隔离环境中启动容器的主进程。这个主进程就是用户指定的应用（如 nginx、mysql 等），它运行在容器的可写层中。 在容器化技术中，”可写层”（Writable Layer）是指容器文件系统中的一部分，允许容器内的进程进行写操作。 通常，容器内的数据（如 MySQL 的数据库文件）并不建议直接保存在容器的可写层中，因为容器的生命周期通常是短暂的，容器的删除会丢失所有容器内的数据。因此，容器化应用通常会将数据持久化到外部存储（如 Docker volume）中。尽管如此，容器的可写层仍然必须能够处理一些运行时数据的写入需求，如临时文件、缓存和日志。 Docker 容器本质上是 操作系统级别的虚拟化，它通过 Linux 内核的 Namespaces 和 Cgroups 实现了进程的隔离和资源管理，从而使得容器能够高效地共享宿主机的内核。容器不需要虚拟化硬件，因此 比传统的虚拟机更轻量，启动速度更快，资源利用率更高。 容器编排容器编排工具可以帮助我们批量地创建、调度和管理容器，帮助我们解决规模化容器的部署问题。 Docker compose现阶段 Docker Compose 是 Docker 官方的单机多容器管理系统，它本质是一个 Python 脚本，它通过解析用户编写的 yaml 文件，调用 Docker API 实现动态的创建和管理多个容器。在 macOS 和 Windows 系统下 ，Docker Compose 都是随着 Docker 的安装一起安装好的，Linux 系统下需要额外安装。 编写 Docker Compose 模板文件 Docker Compose 会默认使用 docker-compose.yml 文件，Docker Compose 文件主要分为三部分： services（服务）、networks（网络） 和 volumes（数据卷）： services：服务定义了容器启动的各项配置，就像执行 docker run 命令时传递的容器启动的参数一样，指定了容器应该如何启动，例如容器的启动参数，容器的镜像和环境变量等 networks：网络定义了容器的网络配置，就像执行 docker network create 命令创建网络配置一样 volumes：数据卷定义了容器的卷配置，就像执行 docker volume create 命令创建数据卷一样 Docker Compose 操作命令 使用 docker-compose -h 命令来查看 docker-compose 的用法，docker-compose 的基本使用格式为：docker-compose [-f &lt;arg&gt;...] [options] [--] [COMMAND] [ARGS...] Docker SwarmSwarm 是 Docker 官方推出的容器集群管理工具，Swarm 最大的优势之一就是原生支持 Docker API，给用户带来了极大的便利，原来的 Docker 用户可以很方便地将服务迁移到 Swarm 中来。Swarm 还内置了对 Docker 网络插件的支持，用户可以很方便地部署需要跨主机通信的容器集群，此外： 分布式： Swarm 使用 Raft（一种分布式一致性协议）协议来做集群间数据一致性保障，使用多个容器节点组成管理集群，从而避免单点故障。 安全： Swarm 使用 TLS 双向认证来确保节点之间通信的安全，利用双向 TLS 进行节点之间的身份认证，角色授权和加密传输，并且可以自动执行证书的颁发和更换。 简单： Swarm 的操作简单，除 Docker 外基本无其他外部依赖，Swarm 直接被内置到了 Docker 1.12 及之后版本，开箱即用。 Swarm 的架构 管理节点： 管理节点负责接受用户的请求，用户的请求中包含用户定义的容器运行状态描述，然后 Swarm 负责调度和管理容器，并且努力达到用户所期望的状态。 工作节点： 工作节点运行执行器（Executor）负责执行具体的容器管理任务（Task），例如容器的启动、停止、删除等操作。 管理节点和工作节点的角色并不是一成不变的，可以手动将工作节点转换为管理节点，也可以将管理节点转换为工作节点 Swarm 核心概念 Swarm 集群：一组被 Swarm 统一管理和调度的节点，被 Swarm 纳管的节点可以是物理机或者虚拟机 其中一部分节点作为管理节点，负责集群状态的管理和协调 另一部分作为工作节点，负责执行具体的任务来管理容器，实现用户服务的启停等功能 节点：集群中的每一台物理机或者虚拟机称为节点 节点按照工作职责分为管理节点和工作节点，管理节点由于需要使用 Raft 协议来协商节点状态 生产环境中通常建议将管理节点的数量设置为奇数个，一般为 3 个、5 个或 7 个 服务：为了支持容器编排所提出的概念，它是一系列复杂容器环境互相协作的统称 一个服务的声明通常包含容器的启动方式、启动的副本数、环境变量、存储、配置、网络等一系列配置 用户通过声明一个服务，将它交给 Swarm，Swarm 负责将用户声明的服务实现 服务分为全局服务（global services）和副本服务（replicated services） 全局服务：每个工作节点上都会运行一个任务，类似于 Kubernetes 中的 Daemonset 副本服务：按照指定的副本数在整个集群中调度运行 任务：集群中的最小调度单位，它包含一个真正运行中的 Docker 容器 当管理节点根据服务中声明的副本数将任务调度到节点时，任务则开始在该节点启动和运行，当节点出现异常时，任务会运行失败，此时调度器会把失败的任务重新调度到其他正常的节点上正常运行，以确保运行中的容器副本数满足用户所期望的副本数 服务外部访问 Swarm 使用入口负载均衡（ingress load balancing）的模式将服务暴露在主机上，该模式下每一个服务会被分配一个公开端口（PublishedPort），可以指定使用某个未被占用的公开端口，也可以让 Swarm 自动分配一个。 Swarm 集群的公开端口可以从集群内的任意节点上访问到，当请求达到集群中的一个节点时，如果该节点没有要请求的服务，则会将请求转发到实际运行该服务的节点上，从而响应用户的请求。公有云的云负载均衡器（cloud load balancers）可以利用这一特性将流量导入到集群中的一个或多个节点，从而实现利用公有云的云负载均衡器将流量导入到集群中的服务。 KubernetesDocker 虽然在容器领域有着不可撼动的地位，然而在容器的编排领域，却有着另外一个事实标准，那就是 Kubernetes 云计算这个概念是 2006 年由 Google 提起的，云计算从起初的概念演变为现在的 AWS、阿里云等实实在在的云产品。当大家以为云计算领域已经变成了以虚拟机为代表的云平台时，Docker 在 2013 年横空出世，提出了镜像、仓库等核心概念，规范了服务的交付标准，使得复杂服务的落地变得更加简单，之后 Docker 又定义了 OCI 标准，可以说在容器领域 Docker 已经成了事实的标准。 然而 Docker 诞生只是帮助我们定义了开发和交付标准，如果想要在生产环境中大批量的使用容器，还离不开的容器的编排技术。于是，在 2014 年 6 月 7 日，Kubernetes（Kubernetes 简称为 K8S，8 代表 ubernete 8 个字母） 的第一个 commit（提交）拉开了容器编排标准定义的序幕。 Kubernetes 是舵手的意思，我们把 Docker 比喻成一个个集装箱，而 Kubernetes 正是运输这些集装箱的舵手。早期的 Kubernetes 主要参考 Google 内部的 Borg 系统，经过将近一年的沉淀和积累，Kubernetes 于 2015 年 7 月 21 日对外发布了第一个正式版本 v1.0，正式走入了大众的视线。 Kubernetes 架构 Kubernetes 采用典型的 主从架构，分为 Master 和 Node 两个角色 Mater 是 Kubernetes 集群的控制节点，负责对集群中所有容器的调度，各种资源对象的控制，以及响应集群的所有请求 kube-apiserver，负责提供 Kubernetes 的 API 服务，所有的组件都需要与 kube-apiserver 交互获取或者更新资源信息，它是 Kubernetes Master 中最前端组件 kube-scheduler，用于监听未被调度的 Pod，然后根据一定调度策略将 Pod 调度到合适的 Node 节点上运行 kube-controller-manager，一系列资源控制器的总称，负责维护整个集群的状态和资源的管理，例如多个副本数量的保证 etcd，k8s 的“数据中心”，生产环境中 etcd 一定要部署多个实例以确保集群的高可用 Node 为工作节点，负责业务容器的生命周期管理 kubelet，负责管理容器的生命周期 kube-proxy，通过维护集群上的网络规则，实现集群内部可以通过负载均衡的方式访问到后端的容器 Kubernetes 核心概念 集群 集群是一组被 Kubernetes 统一管理和调度的节点，被 Kubernetes 纳管的节点可以是物理机或者虚拟机，其中一部分节点作为 Master 节点，另一部分作为 Node 节点 标签（Label） 一组键值对，每一个资源对象都会拥有此字段。Kubernetes 中使用 Label 对资源进行标记，然后根据 Label 对资源进行分类和筛选 命名空间（Namespace） 通过命名空间来实现资源的虚拟化隔离，将一组相关联的资源放到同一个命名空间内，避免不同租户的资源发生命名冲突，从逻辑上实现了多租户的资源隔离 容器组（Pod） Pod 是 Kubernetes 中的最小调度单位，它由一个或多个容器组成，一个 Pod 内的容器共享相同的网络命名空间和存储卷 Pod 是真正的业务进程的载体，在 Pod 运行前，Kubernetes 会先启动一个 Pause 容器开辟一个网络命名空间，完成网络和存储相关资源的初始化，然后再运行业务容器 部署（Deployment） Deployment 是一组 Pod 的抽象，通过 Deployment 控制器保障用户指定数量的容器副本正常运行，并且实现了滚动更新等高级功能 当需要更新业务版本时，Deployment 会按照我们指定策略自动的杀死旧版本的 Pod 并且启动新版本的 Pod 状态副本集（StatefulSet） StatefulSet 和 Deployment 类似，也是一组 Pod 的抽象，但是 StatefulSet 主要用于有状态应用的管理，StatefulSet 生成的 Pod 名称是固定且有序的，确保每个 Pod 独一无二的身份标识 守护进程集（DaemonSet） DaemonSet 确保每个 Node 节点上运行一个 Pod，当我们集群有新加入的 Node 节点时，Kubernetes 会自动帮助我们在新的节点上运行一个 Pod 一般用于日志采集，节点监控等场景 任务（Job） Job 可以帮助创建一个 Pod 并且保证 Pod 的正常退出 如果 Pod 运行过程中出现了错误，Job 控制器可以帮助我们创建新的 Pod，直到 Pod 执行成功或者达到指定重试次数 服务（Service） 一组 Pod 访问配置的抽象，由于 Pod 的地址是动态变化的，我们不能直接通过 Pod 的 IP 去访问某个服务，Service 通过在主机上配置一定的网络规则，帮助我们实现通过一个固定的地址访问一组 Pod 配置集（ConfigMap） 用于存放我们业务的配置信息，使用 Key-Value 的方式存放于 Kubernetes 中，使用 ConfigMap 可以帮助 将配置数据和应用程序代码分开 加密字典（Secret） 用于存放业务的敏感配置信息，类似于 ConfigMap，使用 Key-Value 的方式存在于 Kubernetes 中，主要用于存放密码和证书等敏感信息 综合实践多阶段构建Docker 镜像是分层的，并且每一层镜像都会额外占用存储空间，一个 Docker 镜像层数越多，这个镜像占用的存储空间则会越多，镜像构建最重要的一个原则就是要保持镜像体积尽可能小，要实现这个目标通常可以从两个方面入手： 基础镜像体积应该尽量小 尽量减少 Dockerfile 的行数，因为 Dockerfile 的每一条指令都会生成一个镜像层 Docker 在 17.05 推出了多阶段构建（multistage-build）的解决方案，允许在 Dockerfile 中使用多个 FROM 语句，而每个 FROM 语句都可以使用不同基础镜像，最终生成的镜像，是以最后一条 FROM 为准。 所以可以在一个 Dockerfile 中声明多个 FROM，然后选择性地将一个阶段生成的文件拷贝到另外一个阶段中，从而实现最终的镜像只保留我们需要的环境和文件，多阶段构建的主要使用场景是 分离编译环境和运行环境。（比如 Go 语言可以直接编译为特定平台的可执行文件，不需要安装 Go） 多阶段构建的其他使用方式 为构建阶段命名，使用 AS 指令 停止在特定的构建阶段，将构建阶段停止在指定阶段，从而方便我们调试代码编译过程 使用现有镜像作为构建阶段，可以使用 COPY --from 指令从一个指定的镜像（本地或远程仓库）中拷贝文件 DevOps早期的计算软件交付流程：设计—开发—自测—发布—部署—维护，随着计算机软件规模的增大，软件也越来越复杂，这时一个人已经无法完成一个软件完整的生命周期管理。分工之后软件开发流程：研发工程师做代码设计和开发，测试工程师做专业的测试工作，运维工程师负责将软件部署并负责维护软件。 瀑布模型，这种模式将软件生命周期划分为制定计划、需求分析、软件设计、程序编写、软件测试和运行维护等六个基本活动，并且规定了它们自上而下、相互衔接的固定次序，如瀑布流水一样，逐级的下降。随着互联网的出现，软件迭代速度越来越快，软件开发越来越“敏捷”，敏捷开发”把大的时间点变成细小的时间点，快速迭代开发，软件更新速度也越来越快。敏捷开发使得开发和运维工程师之间的矛盾变得越来越深，为了解决这个问题，DevOps 诞生了。 DevOps（Development 和 Operations 的组合词）是一种重视“软件开发人员（Dev）”和“IT 运维技术人员（Ops）”之间沟通合作的文化、运动或惯例。透过自动化“软件交付”和“架构变更”的流程，来使得构建、测试、发布软件能够更加地快捷、频繁和可靠。 DevOps 的整体目标是促进开发和运维人员之间的配合，并且通过自动化的手段缩短软件的整个交付周期，提高软件的可靠性。Docker 几乎满足了微服务的所有需求，Docker 为 DevOps 提供了很好的基础支撑。 DevOps 1.0 - 在 Docker 技术出现之前 通常更加关注如何做好 CI（Continuous Integration，持续集成）&#x2F;CD（Continuous Delivery 持续交付）以及 IAAS（基础设施即服务） DevOps 2.0 - 随着 Docker 技术的诞生 Docker 足够轻量，微服务实现快速迭代 Docker 可以构建任何语言的运行环境 Docker 更好地隔离开发环境和生产环境 这时的研发和运维都开始关注软件统一交付的格式和软件生命周期的管理，而不像之前一样研发只关注“打包前”，而运维只关注“打包后”的模式，DevOps 无论是研发环境还是生产环境都开始围绕 Docker 进行构建。 微服务、Docker 与 DevOps 三者之间的关系 云平台作为底层基础，采用 Docker 技术将服务做容器化部署，并且使用资源管理和调度平台（例如 Kubernetes 或 Swarm）来自动化地管理容器 DevOps 平台在云基础平台之上，通过流程自动化以及工具自动化的手段，为可持续集成和交付提供能力支持 有了云平台和 DevOps 的支撑，微服务才能够发挥更大的作用，使得我们的业务更加成熟和稳定 容器如何助力 DevOps Docker 可以在 DevOps 各个阶段发挥重要作用，例如 Docker 可以帮助我们在开发阶段提供统一的开发环境，在持续集成阶段帮助我们快速构建应用，在部署阶段帮助我们快速发布或更新生产环境的应用 开发流程 在本地或者开发机上快速安装一个 Docker 环境，然后使用 Docker 可以快速启动和部署一个复杂的开发环境 相比传统的配置开发环境的方式，不仅大大提升了开发环境部署的效率，同时也保证了不同开发人员的环境一致 集成流程 通过编写 Dockerfile 可以将业务容器化 基于已有的 Dockerfile 来构建应用镜像，可以极大提升持续集成的构建速度 Docker 镜像使用了写时复制（Copy On Write）和联合文件系统（Union FileSystem）的机制 Docker 镜像分层存储，相同层仅会保存一份，不同镜像的相同层可以复用 当开始新一轮的测试时，可以直接复用已有的镜像层，大大提升了构建速度 部署流程 镜像仓库的存在使得 Docker 镜像分发变得十分简单 Docker 结合 Kubernetes 或者其他容器管理平台，可以轻松地实现蓝绿发布等流程，当升级应用观察到流量异常时，可以快速回滚到稳定版本 DevOps 工具介绍 Git - 分布式的版本控制工具 Jenkins - CI&#x2F;CD 构建工具 Ansible - 配置管理工具 Kubernetes - 容器编排工具 CI&#x2F;CD CI 持续集成（Continuous Integration）- 小步快走 CI 持续集成要求开发人员频繁地（甚至是每天）将代码提交到共享分支中，一旦开发人员的代码被合并，将会自动触发构建流程来构建应用，并通过触发自动化测试（单元测试或者集成测试）来验证这些代码的提交，确保这些更改没有对应用造成影响 如果发现提交的代码在测试过程中或者构建过程中有问题，则会马上通知研发人员确认，修改代码并重新提交 通过将以往的定期合并代码的方式，改变为频繁提交代码并且自动构建和测试的方式，可以帮助我们 及早地发现问题和解决冲突，减少代码出错 当应用容器化后，应用构建的结果就是 Docker 镜像。代码检查完毕没有缺陷后合并入主分支，此时启动构建流程，构建系统会自动将应用打包成 Docker 镜像，并且推送到镜像仓库 CD 持续交付（Continuous Delivery）- 测试工作 持续交付要求实现自动化准备测试环境、自动化测试应用、自动化监控代码质量，并且自动化交付生产环境镜像 借助于容器技术可以很方便地构建出一个测试环境，并且可以保证开发和测试环境的一致性，这样不仅可以提高测试效率，还可以提高敏捷性 CD 持续部署（Continuous Deployment）- 部署到生产环境 持续部署是最后阶段，它作为持续交付的延伸，可以自动将生产环境的镜像 发布到生产环境 中 构建和部署一个应用的流程可以分为五部分： 首先需要配置 GitLab SSH 访问公钥，使得我们可以直接通过 SSH 拉取或推送代码到 GitLab 接着将代码通过 SSH 上传到 GitLab 再在 Jenkins 创建构建任务，使得 Jenkins 可以成功拉取 GitLab 的代码并进行构建 然后配置代码变更自动构建流程，使得代码变更可以触发自动构建 Docker 镜像 最后配置自动部署流程，镜像构建完成后 自动将镜像发布到测试或生产环境 参考资料 由浅入深吃透 Docker","tags":["Docker"],"categories":["Docker"]},{"title":"基于 Nginx 的异构后端统一鉴权服务🛡️","path":"/2024/08/04/ingress/","content":"JWT authorization with NGINX Ingress Controller JWT基本概念JWT（JSON Web Token）是一种开放标准（RFC 7519），用于在网络应用环境中安全地传递信息。JWT 的设计目的是为了在各方之间安全地传输声明（claim），这些声明可以包含关于用户身份（ID）、权限或其他元数据的信息。 JWT 的结构 一个 JWT 通常由三部分组成，分别用点（.）分隔： 头部（Header） 包含令牌的类型（通常是 “JWT”）和所使用的签名算法（如 HMAC SHA256、RSA、ECDSA） 负载（Payload） 包含实际的数据（声明）。这些声明可以是公开声明、私有声明或注册声明。 公开声明：可以包含在 JWT 中的标准化声明，例如 iss（发行者）、exp（过期时间）、sub（主题）等。 私有声明：用户自定义的数据，不是标准化的声明，需要双方协商一致。 注册声明：一些预定义的声明，用于在 JWT 中传递用户相关的基本信息。 负载部分的内容是 Base64Url 编码的 JSON 对象。 签名（Signature） 由头部和负载部分的数据以及一个密钥经过特定算法（如 HMAC SHA256、RSA 等）生成，用于验证 JWT 的完整性。 无状态特性 JWT 包含了所有必要的用户身份和权限信息（如用户 ID、权限等），并通过签名保证数据的完整性。当客户端每次发送请求时，会将 JWT 令牌包含在请求头中，服务器通过验证该令牌来进行身份验证和授权，而不需要维护和查询服务器端的会话数据。服务器只需检查 JWT 的签名和有效性，而不需要存储任何会话数据。 安全性考虑 JWT（JSON Web Token）的数据通常不被加密，而是签名来保证数据的完整性和真实性，签名的目的是确保 JWT 的数据没有被篡改。接收方使用相同的签名算法和密钥来验证签名是否匹配。如果不匹配，表明数据可能被篡改。 JWT 的头部（Header）和负载（Payload）部分一般不加密，只进行 Base64Url 编码。这种编码只是将数据转换为 URL 安全的字符串形式，并不提供任何安全性，任何人都可以解码 JWT，查看其中的内容。这意味着敏感信息不应该直接存储在 JWT 的负载中，除非数据经过加密或采取了其他安全措施。 数据加密：如果需要在 JWT 中存储敏感信息，可以对数据进行加密后再放入负载中。这样，即使 JWT 被截获，未经授权的第三方也无法解密和查看数据。 使用 HTTPS：为了防止 JWT 在传输过程中被截获，应该使用 HTTPS 进行加密通信。 如果使用 JWE（JSON Web Encryption） 规范，可以对 JWT 进行加密，只有持有解密密钥的方能读取。 相关扩展 OAuth 2.0 类型：授权框架 用途：主要用于在不同的应用程序或服务之间提供授权。常用于第三方应用程序访问用户数据，而不暴露用户的凭证。 特点：使用访问令牌（Access Token）来代表用户的权限。访问令牌通常有有限的寿命，可以由刷新令牌（Refresh Token）延长。 工作流程：包括授权代码流程、隐式流程、密码凭据流程和客户端凭据流程等多种方式。OAuth 2.0 不依赖于特定的认证方法，可以结合多种认证方式使用。 Cookie 类型：客户端存储技术 用途：用于存储少量的数据（如会话标识、用户偏好）在用户的浏览器中，以便在不同的网页之间共享状态。 特点：数据存储在客户端，由服务器生成和管理。可以设置失效时间或设置为会话结束时失效。 安全性：可标记为 HttpOnly 和 Secure，以提高安全性。HttpOnly 标记可防止 JavaScript 访问，Secure 标记可确保通过 HTTPS 传输。 Session 类型：服务器端存储技术 用途：用于在服务器上存储用户会话数据。常用于跟踪用户的登录状态和在会话中的状态信息。 特点：数据存储在服务器端，客户端通常只持有一个 Session ID（通常通过 Cookie 传递）。Session 数据在用户会话结束后可以被清除。 安全性：Session 数据不直接暴露给客户端，较为安全。需要保护 Session ID 的传输和存储安全。 JWT 类型：自包含的身份验证令牌 用途：用于在各方之间安全地传输信息，尤其是用户身份信息。常用于 API 的身份验证和授权。 特点：JWT 是一个自包含的令牌，包含用户信息和签名。通常由三个部分组成：头部（Header）、负载（Payload）和签名（Signature）。 安全性：使用签名确保数据未被篡改。可以通过公钥&#x2F;私钥对（非对称加密）或共享密钥（对称加密）签名。 联系与区别 OAuth 2.0、Cookie、Session 和 JWT 都可以用于身份验证和授权。 JWT 可以用作 OAuth 2.0 的访问令牌。 Cookie 和 Session 都可以用来管理用户的登录状态，通常是结合使用的。 OAuth 2.0 是一个授权框架，不直接处理认证，而是授权第三方访问资源。 Cookie 是客户端存储的数据，Session 是服务器端存储的数据。 JWT 是一种令牌形式，可以在无状态的环境中使用，而 Session 通常需要服务器维护状态。 鉴权服务用户服务做 JWT 的签发与注销（需要依赖第三方组件做记录），鉴权服务这边只做 JWT 的验证和 JWT 声明的解析，后续可以进行一系列的扩展，如限流、RBAC等 请求不带 JWT 或 JWT 校验失败： 123456789101112131415$hcjjj: ~ ❯ curl -i http://127.0.0.1:7777/api/auth HTTP/1.1 401 UnauthorizedAccess-Control-Allow-Headers: Content-Type, Origin, X-CSRF-Token, Authorization, AccessToken, Token, RangeAccess-Control-Allow-Methods: GET, HEAD, POST, PATCH, PUT, DELETEAccess-Control-Allow-Origin: *Access-Control-Expose-Headers: Content-Length, Access-Control-Allow-Origin, Access-Control-Allow-HeadersAccess-Control-Max-Age: 86400Content-Type: text/plain; charset=utf-8Traceparent: 00-229a8d047c093eb9637d020dd9471d3a-b59927828a3f7d87-00Vary: OriginX-Content-Type-Options: nosniffDate: Mon, 05 Aug 2024 11:42:26 GMTContent-Length: 13Unauthorized 请求带正确的 JWT ： 12345678910111213$hcjjj: ~ ❯ curl -H &quot;Authorization:Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VySWQiOiI1IiwidHlwZSI6IkFDQ0VTU19UT0tFTiIsInJvbGUiOiJVU0VSIiwiZXhwIjoxNzI1Njc3NjEzLCJpYXQiOjE3MjA0OTM2MTN9.Z0CXV0B-7USnB6VhHRT4RsN3lxv11R_5h7wxvGoeoLQ&quot; -i http://127.0.0.1:7777/api/authHTTP/1.1 200 OKAccess-Control-Allow-Headers: Content-Type, Origin, X-CSRF-Token, Authorization, AccessToken, Token, RangeAccess-Control-Allow-Methods: GET, HEAD, POST, PATCH, PUT, DELETEAccess-Control-Allow-Origin: *Access-Control-Expose-Headers: Content-Length, Access-Control-Allow-Origin, Access-Control-Allow-HeadersAccess-Control-Max-Age: 86400Traceparent: 00-02f50d29723ccdd50dfab510b294e763-17fb6226dc8b5e07-00Vary: OriginX-User-Id: 5X-User-Role: USERDate: Mon, 05 Aug 2024 11:43:47 GMTContent-Length: 0 Nginx基本概念Nginx 是目前最流行的 Web 服务器，最初由一位俄罗斯程序员 Igor Sysoev 开发。2019 年，Nginx 被美国的 F5 公司以 6.7 亿美元收购。 Nginx 的开源版本主要分为两种： 主线版 (mainline)：最新版本，包含较多新功能和正在开发的实验性模块功能，可能存在一些新的 bug。 稳定版 (stable)：经过长时间测试，bug 较少，功能较为稳定。 安装方式： 源码编译安装：拉取源代码后自己编译为可执行文件。 预编译二进制包：直接下载编译好的可执行文件。 Docker Compose：拉取镜像后运行在容器中。 主要用途： 正向&#x2F;反向代理：为客户端发出请求或为服务器接收请求。 负载均衡：将请求分发到多个操作单元上执行。 HTTP 服务器：Nginx 也可以作为静态资源服务器使用。 配置文件Nginx 的主要配置文件通常是 nginx.conf，并且一般位于 /etc/nginx/ 目录下。使用 nginx -t 命令可以测试配置文件的有效性而不需要实际重启 Nginx 服务。 1234567891011121314151617181920212223242526272829# Nginx 配置文件## 全局块worker_processes 1;# Events 块events &#123; # 定义事件处理模型&#125;# HTTP 块http &#123; # 可以在这里定义全局的 HTTP 设置，例如 MIME 类型映射、默认错误页面等。 server &#123; # Server 址块 listen 80; # 示例: 监听 80 端口 server_name localhost; # 示例: 指定服务器名称 # Location 块 location / &#123; # 这里可以指定如何处理请求到根目录 &quot;/&quot; 的所有请求 root html; # 示例: 指定根目录 index index.html index.htm; # 示例: 指定索引文件 &#125; # 更多 location 块可以根据需要添加 &#125;&#125; 全局块 全局块是配置文件的第一个块，也是配置文件的主体部分。它主要用来设置一些影响 Nginx 服务器整体运行的配置指令，包括但不限于配置运行 Nginx 服务器的用户（组）、允许生成的 worker process 数量、进程 PID 存放路径、日志存放路径和类型以及配置文件的引入等。 1234567891011121314# 指定运行 Nginx 服务器的用户，只能在全局块配置# 将 user 指令注释掉，或者配置成 nobody 的话所有用户都可以运行# user [user] [group];# user nobody nobody;user nginx;# 指定生成的worker进程的数量，也可使用自动模式，只能在全局块配置worker_processes 1;# 错误日志存放路径和类型error_log /var/log/nginx/error.log warn;# 进程PID存放路径pid /var/run/nginx.pid; events 块 1234567events &#123; # 指定使用哪种网络IO模型，只能在events块中进行配置 # use epoll; # 每个worker process允许的最大连接数 worker_connections 1024;&#125; http 块 http 块是配置文件的主要部分，包括 http 全局块和 server 块 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657http &#123; # 引入其他配置文件 include /etc/nginx/mime.types; # 默认类型，如果请求的URL没有包含文件类型，则使用默认类型 default_type application/octet-stream; # 开启高效文件传输模式 sendfile on; # 连接超时时间 keepalive_timeout 65; # Access log 日志存放路径和类型 # 格式为：access_log &lt;path&gt; [format [buffer=size] [gzip[=level]] [flush=time] [if=condition]]; access_log /var/log/nginx/access.log main; # 定义日志格式 log_format main &#x27;$remote_addr - $remote_user [$time_local] &#x27; &#x27;&quot;$request&quot; $status $body_bytes_sent &quot;$http_referer&quot; &#x27; &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;; # 设置sendfile最大传输片段大小，默认为0，表示不限制 # sendfile_max_chunk 1m; # 每个连接的请求次数 # keepalive_requests 100; # 开启gzip压缩 # gzip on; # 开启gzip压缩的最小文件大小 # gzip_min_length 1k; # gzip压缩级别，1-9，级别越高压缩率越高，但是消耗CPU资源也越多 # gzip_comp_level 2; # gzip压缩文件类型 # gzip_types text/plain application/javascript application/x-javascript text/css application/xml text/javascript application/x-httpd-php image/jpeg image/gif image/png; # upstream指令用于定义一组服务器，一般用来配置反向代理和负载均衡 upstream www.example.com &#123; # ip_hash指令用于设置负载均衡的方式，ip_hash表示使用客户端的IP进行hash， # 这样可以保证同一个客户端的请求每次都会分配到同一个服务器，解决了session共享的问题 ip_hash; # weight 用于设置权重，权重越高被分配到的几率越大 server 192.168.50.11:80 weight=3; server 192.168.50.12:80; server 192.168.50.13:80; &#125; # server 块 server &#123; # 参考server块的配置 &#125;&#125; server 块 server 块是配置虚拟主机的，⼀个 http 块可以包含多个 server 块，每个 server 块就是⼀个虚拟主机 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061server &#123; # 监听IP和端口 # listen的格式为： # listen [ip]:port [default_server] [ssl] [http2] [spdy] # [proxy_protocol] [setfib=number] [fastopen=number] [backlog=number]; # listen指令非常灵活，可以指定多个IP和端口，也可以使用通配符 # 下面是一些实际的例子： # listen 127.0.0.1:80; # 监听来自127.0.0.1的80端口的请求 # listen 80; # 监听来自所有IP的80端口的请求 # listen *:80; # 监听来自所有IP的80端口的请求，同上 # listen 127.0.0.1; # 监听来自127.0.0.1的80端口，默认端口为80 listen 80; # server_name 用来指定虚拟主机的域名，可以使用精确匹配、通配符匹配和正则匹配等方式 # server_name example.org www.example.org; # 精确匹配 # server_name *.example.org; # 通配符匹配 # server_name ~^www\\d+\\.example\\.net$; # 正则匹配 server_name localhost; # location块用来配置请求的路由，一个server块可以包含多个location块，每个 # location块就是一个请求路由 # location块的格式是： # location [=|~|~*|^~] /uri/ &#123; ... &#125; # = 表示精确匹配，只有完全匹配上才能生效 # ~ 表示区分大小写的正则匹配 # ~* 表示不区分大小写的正则匹配 # ^~ 表示普通字符匹配，如果匹配成功，则不再匹配其他location # /uri/ 表示请求的URI，可以是字符串，也可以是正则表达式 # &#123; ... &#125; 表示location块的配置内容 location / &#123; # root指令用于指定请求的根目录，可以是绝对路径，也可以是相对路径 root /usr/share/nginx/html; # 根目录 # index指令用于指定默认文件，如果请求的是目录，则会在目录下查找默认文件 index index.html index.htm; # 默认文件 &#125; # 下面是一些location的示例： location = / &#123; # 精确匹配请求 root /usr/share/nginx/html; index index.html index.htm; &#125; location ^~ /images/ &#123; # 匹配以/images/开头的请求 root /usr/share/nginx/html; &#125; location ~* \\.(gif|jpg|jpeg)$ &#123; # 匹配以gif、jpg或者jpeg结尾的请求 root /usr/share/nginx/html; &#125; location !~ \\.(gif|jpg|jpeg)$ &#123; # 不匹配以gif、jpg或者jpeg结尾的请求 root /usr/share/nginx/html; &#125; location !~* \\.(gif|jpg|jpeg)$ &#123; # 不匹配以gif、jpg或者jpeg结尾的请求 root /usr/share/nginx/html; &#125; # error_page 用于指定错误页面，可以指定多个，按照优先级从高到低依次查找 error_page 500 502 503 504 /50x.html; # 错误页面 location = /50x.html &#123; root /usr/share/nginx/html; &#125;&#125; 常用命令12345678nginx # 启动Nginxnginx -c filename # 指定配置文件nginx -V # 查看Nginx的版本和编译参数等信息nginx -t # 检查配置文件是否正确，也可用来定位配置文件的位置nginx -s quit # 优雅停止Nginxnginx -s stop # 快速停止Nginxnginx -s reload # 热启动，重新加载配置文件nginx -s reopen # 重新打开日志文件 常用模块123456# nginx -Vnginx version: nginx/1.25.5built by gcc 12.2.0 (Debian 12.2.0-14) built with OpenSSL 3.0.9 30 May 2023 (running with OpenSSL 3.0.11 19 Sep 2023)TLS SNI support enabledconfigure arguments: --prefix=/etc/nginx --sbin-path=/usr/sbin/nginx --modules-path=/usr/lib/nginx/modules --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --pid-path=/var/run/nginx.pid --lock-path=/var/run/nginx.lock --http-client-body-temp-path=/var/cache/nginx/client_temp --http-proxy-temp-path=/var/cache/nginx/proxy_temp --http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp --http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp --http-scgi-temp-path=/var/cache/nginx/scgi_temp --user=nginx --group=nginx --with-compat --with-file-aio --with-threads --with-http_addition_module --with-http_auth_request_module --with-http_dav_module --with-http_flv_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_mp4_module --with-http_random_index_module --with-http_realip_module --with-http_secure_link_module --with-http_slice_module --with-http_ssl_module --with-http_stub_status_module --with-http_sub_module --with-http_v2_module --with-http_v3_module --with-mail --with-mail_ssl_module --with-stream --with-stream_realip_module --with-stream_ssl_module --with-stream_ssl_preread_module --with-cc-opt=&#x27;-g -O2 -ffile-prefix-map=/data/builder/debuild/nginx-1.25.5/debian/debuild-base/nginx-1.25.5=. -fstack-protector-strong -Wformat -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -fPIC&#x27; --with-ld-opt=&#x27;-Wl,-z,relro -Wl,-z,now -Wl,--as-needed -pie&#x27; 模块名（Module Name） 描述（Description） http_access_module 接受或拒绝特定的客户端请求 http_auth_request_module 根据子请求的结果实现客户端授权 http_auth_basic_module 使用用户名和密码进行 HTTP 基本认证，限制对资源的访问 http_autoindex_module 自动生成目录列表 http_browser_module 从 User-Agent 请求头中识别客户端浏览器 http_charset_module 为 Content-Type 响应头添加特定字符集 http_empty_gif_module 返回一个 1 像素的透明 GIF 图片 http_fastcgi_module 提供 FastCGI 支持 http_geo_module 根据 IP 地址获取地理位置信息 http_gzip_module 支持 Gzip 压缩 http_limit_conn_module 限制并发连接数 http_limit_req_module 限制请求速率 http_map_module 基于变量映射获取值 http_memcached_module 提供 Memcached 支持 http_proxy_module 提供反向代理支持 http_referer_module 防止盗链 http_rewrite_module 支持 URL 重写 http_scgi_module 将请求转发到 SCGI 服务器 http_ssi_module 处理和支持 SSI（服务器端包含） http_split_clients_module 根据客户端 IP 地址或其他变量将客户端分组，通常用于 A&#x2F;B 测试 http_upstream_hash_module 提供一致性哈希负载均衡 http_upstream_ip_hash_module 提供 IP 哈希负载均衡 http_upstream_keepalive_module 支持长连接负载均衡 http_upstream_least_conn_module 提供最少连接负载均衡 http_upstream_zone_module 提供共享内存负载均衡 http_userid_module 为客户端设置唯一的 ID（UID、cookie） http_uwsgi_module 将请求转发到 uWSGI 服务器，通常用于 Python 应用 统一鉴权 鉴权服务地址：http://127.0.0.1:7777/api/auth （部署在本地的 Docker 容器） 后端应用服务：http://127.0.0.1:8888 （直接本地运行的后端应用） 转发和鉴权配置： 12345678910111213141516171819202122232425262728293031323334server &#123; listen 80; server_name localhost; # 内部鉴权位置，不要对外暴露 location = /auth-internal &#123; internal; proxy_pass http://host.docker.internal:7777/api/auth; proxy_intercept_errors on; # 确保拦截错误 &#125; # 自定义 401 错误响应 error_page 401 = @auth_error; location @auth_error &#123; return 401 Unauthorize; &#125; # 需要鉴权的请求 location /api/payment/ &#123; # 使用 http_auth_request_module 鉴权 auth_request /auth-internal; # 如果鉴权通过，设置请求头 auth_request_set $user_role $upstream_http_x_user_role; auth_request_set $user_id $upstream_http_x_user_id; # 设置鉴权通过后的自定义头部 proxy_set_header X-User-Role $user_role; proxy_set_header X-User-ID $user_id; # 转发到后端服务 proxy_pass http://host.docker.internal:8888; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; &#125;&#125; 效果： Ingress Ingress 是对集群中服务的外部访问进行管理的 API 对象，Ingress可以提供统一的入口控制、HTTP&#x2F;HTTPS路由、SSL终止和负载均衡等功能。如通过 Ingress 资源来配置不同的转发规则，从而达到根据不同的规则设置访问集群内不同的 Service 所对应的后端 Pod。 API对象（Application Programming Interface Object）通常指的是在软件系统中定义的一组接口和协议，它们允许不同的软件应用程序之间进行交互。API对象可以是数据结构、函数、类或服务，它们提供了一种标准化的方法来访问一个应用程序或服务的功能或数据。 Nginx Ingress Controller 是 Kubernetes 生态系统中广泛使用的 Ingress 控制器之一，上文统一鉴权是用 Nginx 的 auth_request 模块，部署在 K8s 的后需要使用 Nginx Ingress Controller 的 auth-url 注解（ External Authentication ）或插入自定义 Nginx 配置（Configuration snippet）来实现。 Nginx Ingress 安装 heml 安装 Kubectl kubectl 连接集群 helm 安装 ingress-nginx 版本与升级 Supported Versions table 新建 Ingress Ingress 的 annotations 主要用于配置全局的行为和特性，如超时、重写规则等，但不能直接修改或插入复杂的 location 配置 使用 nginx.ingress.kubernetes.io/server-snippet 可以添加全局的自定义 location 块，但不能针对单个路径 使用 nginx.ingress.kubernetes.io/location-snippet 可以针对特定路径添加自定义的 location 配置 相关扩展Kubernetes 资源对象 定义: Kubernetes 资源对象是 Kubernetes 集群中用于描述和管理各种资源的 API 对象。它们定义了集群中需要运行和管理的服务、应用程序、网络、存储等。 种类: 包括多种类型，如 Pod、Service、Deployment、Ingress、ConfigMap、Secret、PersistentVolume 等。 功能: 它们用于声明和管理集群中的资源状态。例如，Deployment 资源用于管理应用的副本和滚动更新，Service 资源用于定义服务的访问方式。 运行方式: 资源对象本身不直接运行在 Pod 中，它们是 Kubernetes 集群的配置和管理单位。它们通过 Kubernetes 控制平面（控制器）和调度器来管理集群中的实际工作负载。 Pod 定义: Pod 是 Kubernetes 中最基本的部署单元，是运行在集群节点上的一个或多个容器的集合。Pod 提供了容器运行时所需的网络和存储资源。 功能: Pod 是实际运行应用程序代码的地方。每个 Pod 包含一个或多个容器，这些容器共享网络和存储。Pod 还可以包括 Init 容器、存储卷等。 运行方式: Pod 是 Kubernetes 集群中的实际工作负载，它们被 Kubernetes 调度器分配到节点上，并由容器运行时（如 Docker、containerd）执行容器。Pod 通过 Deployment、DaemonSet 或 StatefulSet 等控制器进行管理和调度。 关系 资源对象 vs Pod: Pod 是一种 Kubernetes 资源对象（kind: Pod），它用于定义和运行容器。其他资源对象（如 Deployment）用于管理 Pod 的生命周期。资源对象提供了集群的配置和管理功能，而 Pod 是实际运行应用程序的实体。 管理: Kubernetes 控制平面和调度器使用资源对象来管理和调度 Pod。通过创建和更新资源对象，用户可以控制 Pod 的部署、扩展、更新等操作。 Ingress 资源 定义: Ingress 是 Kubernetes 的一个标准 API 资源，用于管理集群外部访问服务的路由规则。 功能: 它定义了如何将 HTTP 和 HTTPS 请求路由到集群内部的服务。通过 Ingress 资源，可以指定路径、主机、证书等信息。 实现: Ingress 可以由不同的控制器来实现，包括 Nginx、Traefik、HAProxy、Istio 等。具体的功能和配置会依赖于你使用的 Ingress 控制器。 运行: Ingress 本身不是一个运行中的组件，它只是一个 Kubernetes 资源对象。它定义了路由规则、主机、路径等，控制如何将请求转发到服务。 部署: 你通过 kubectl apply 命令创建或更新 Ingress 资源，它会被 Kubernetes 控制平面管理，并与相应的 Ingress 控制器一起工作。 NginxIngress 控制器 定义: NginxIngress 控制器（即 Ingress-Nginx 控制器）是实现 Ingress 资源的具体方案之一。 功能: 它使用 Nginx 作为反向代理服务器，将外部请求根据 Ingress 规则转发到集群内部的服务。它提供了许多高级功能，如自定义 Nginx 配置、TLS 终止、路径重写等。 配置: Ingress-Nginx 控制器通常通过 ConfigMap、Ingress 注解等方式进行配置。它还允许使用注解来修改或扩展 Nginx 的行为。 运行: NginxIngress 控制器运行在 Kubernetes 集群中的 Pod 中。它通常是一个或多个 Pod 的集合，这些 Pod 运行着 Nginx 实例，负责根据 Ingress 资源的规则处理和路由流量。 部署: Ingress-Nginx 控制器作为 Kubernetes 的 Deployment 或 DaemonSet 部署，通常会在 kube-system 命名空间中或其他指定的命名空间中运行。 关系 Ingress Controller 是一个运行在 Kubernetes 集群中的应用程序，它负责实现 Ingress 资源定义的规则。它监听 Ingress 资源的变化，并根据这些变化来配置自己的负载均衡和服务路由规则。你提供的 Service 配置是 NGINX Ingress Controller 的一部分，它作为服务运行在集群中，并被 Kubernetes API 管理。 Ingress 资源 是 Kubernetes 的 API 对象，它定义了如何将外部请求路由到集群内的服务。Ingress 资源包含了路由规则，例如基于域名或路径的路由。 首先，你需要部署一个 Ingress Controller（比如 NGINX Ingress Controller）到你的 Kubernetes 集群中。这个 Controller 会作为一个服务运行，并且监听 API Server 以获取 Ingress 资源的变化。 然后，你创建 Ingress 资源，定义了路由规则。这些规则告诉 Ingress Controller 如何将进入的请求转发到集群内的特定服务。 当外部请求到达时，它们首先会被 Ingress Controller 接收，然后根据 Ingress 资源中定义的规则，将请求路由到正确的服务。 Ingress Controller 是实现 Ingress 规则的组件，而 Ingress 资源定义了这些规则","tags":["Nginx","Kubernetes","JWT"],"categories":["Internship"]},{"title":"基于 Redis 实现分布式锁 🔒 - Golang","path":"/2024/07/04/redis-lock/","content":"基于 Redis 的分布式锁，确保计划任务只由一个实例执行 分布式锁分布式锁是一种在分布式系统中使用的锁机制，用来确保多个节点在执行关键代码或访问共享资源时互斥，避免并发冲突。分布式锁的目的是保证在一个多节点的分布式环境中，某个共享资源（如数据库记录、缓存对象、任务队列等）在同一时刻只能由一个节点操作。 普通锁的 作用对象是线程或进程，而分布式锁的作用对象是 跨节点的实例。 分布式锁使用案例 领导者选举：在分布式系统中，经常需要选举一个领导节点来协调行动或管理资源。分布式锁可用于确保在任何给定时间内只有一个节点成为领导者。 任务调度：在分布式任务调度器中，分布式锁可确保计划任务只由一个工作节点执行，防止重复执行。 资源分配：在管理共享资源（如文件系统、网络套接字或硬件设备）时，分布式锁可确保每次只有一个进程能访问资源，从而防止冲突并确保妥善的资源管理。 微服务协调：当多个微服务需要执行协调操作（如更新不同数据库中的相关数据）时，分布式锁可确保这些操作以受控和有序的方式执行。 库存管理：在电子商务平台中，分布式锁可以管理库存更新，确保在多个用户同时尝试购买同一商品时，库存水平得到准确维护。 会话管理：在分布式环境中处理用户会话时，分布式锁可确保用户会话一次只被一台服务器修改，防止出现不一致的情况。 分布式锁的实现 分布式锁可以使用各种工具和框架来实现，如： ZooKeeper：主要用于提供分布式协调服务，包括配置管理、分布式锁、领导者选举等 Redis：广泛用于缓存、会话管理等场景，通过 SETNX 或 Redlock 算法支持分布式锁 Consul：用于服务发现、配置管理和服务网格的工具，除了服务网格功能，Consul 也提供分布式锁机制 Etcd：分布式键值存储系统，主要用于存储配置数据、提供分布式协调等功能 基于 Redis 实现Lua 脚本使用 Lua 脚本是为了确保在 Redis 中的操作 原子性，特别是在分布式锁场景中，Lua 脚本可以确保多个 Redis 命令在同一个执行周期内被原子地执行，避免并发问题（被其他客户端的操作打断）。 原子性保证：Lua 脚本内部的多个操作会在一个事务中完成，保证不会有其他客户端插入的命令破坏执行顺序。 操作灵活性：Lua 脚本中可以包含复杂的逻辑，如条件判断、循环、计算等，因此可以实现比单独使用 Redis 命令更复杂的操作。 高效性：由于脚本中的命令是直接在 Redis 服务器上执行的，减少了客户端与 Redis 之间的通信开销。 Redis 的 pipeline 是一种在客户端一次性发送多条命令给 Redis，然后批量执行和返回结果的模式。它的主要目的是减少客户端与 Redis 之间的通信次数，提高执行效率。Pipeline 模式无原子性保证，每条命令依旧是独立执行的，其他客户端可以在 pipeline 执行过程中插入命令，因此如果涉及多个操作的状态依赖，就可能导致不一致性。 特性 Pipeline Lua 脚本 原子性 无法保证原子性，操作可能被其他命令打断 保证原子性，所有操作在同一事务中执行 执行方式 批量发送命令，但 Redis 逐个顺序执行 将多个命令封装在一个脚本中，原子执行 并发操作 支持高效批量并发操作 适合需要多个命令组合原子操作的场景 复杂逻辑 只能执行单个命令，无条件判断、循环等复杂逻辑 支持复杂的逻辑，如条件判断、循环等 使用场景 批量执行独立的、无依赖的操作 原子操作、多步骤逻辑的复杂操作 性能 减少了客户端与 Redis 的网络通信开销 减少了网络开销，同时避免了操作间的并发问题 常见应用 批量写入、批量获取、批量修改 分布式锁、事务性操作、多步条件逻辑 在 Lua 脚本中，KEYS 和 ARGV 是由外部传入的参数： KEYS 用于传递键名，通常用于指定需要操作的 Redis 键 ARGV 用于传递附加参数，如锁的值和过期时间等 在客户端（例如 Go 代码）调用 Redis 的 EVAL 命令时，可以将键名和参数以列表形式传入，KEYS 和 ARGV 会相应地映射为脚本中的输入 SETNX不直接使用 SETNX 指令，而是通过 Lua 脚本完成锁的获取与过期设置，因为 Lua 脚本保证多个操作的原子性，可以提供更复杂的控制逻辑，包括锁的可重入和延长过期时间，避免 SETNX 和 EXPIRE 分开执行导致的死锁风险。使用 Lua 脚本的优势： 原子性检查与更新：Lua 脚本可以在同一个执行流中完成检查锁的持有者和更新锁的操作，避免了分布式环境下的竞态问题 可重入锁：代码中的 Lua 脚本实现了锁的可重入逻辑。如果当前客户端已经持有锁，那么它可以通过脚本延长锁的过期时间，这对于某些需要长时间运行并延长锁持有时间的场景是非常有用的 在 Redis 2.6.12 及以上版本，SET 命令可以通过带多个参数实现和 SETNX 类似的功能，同时设置过期时间 加锁Lua 脚本解析 12345678910111213local val = redis.call(&#x27;get&#x27;, KEYS[1])-- 获取当前锁的持有者if val == false then -- key 不存在，表示锁没有被持有，进行加锁 return redis.call(&#x27;set&#x27;, KEYS[1], ARGV[1], &#x27;EX&#x27;, ARGV[2])elseif val == ARGV[1] then -- 锁的持有者是当前客户端，刷新过期时间，支持可重入 redis.call(&#x27;expire&#x27;, KEYS[1], ARGV[2]) return &quot;OK&quot;else -- 锁被其他客户端持有，返回空字符串 return &quot;&quot;end **KEYS[1]**：传入的锁的键名，表示锁的唯一标识 **ARGV[1]**：表示锁的值，用于标识持有锁的客户端，通常是一个唯一的字符串 **ARGV[2]**：锁的过期时间，单位是秒，用于防止死锁的发生 Go 代码解析 Client 和 Lock 结构体 12345678910111213type Client struct &#123;\tclient redis.Cmdable // Redis 客户端接口\tg singleflight.Group // 用于防止缓存击穿的工具，可以让并发请求变成单个请求\tvaluer func() string // 用于生成唯一的值，确保锁的持有者唯一（通常是 UUID）&#125;type Lock struct &#123;\tclient redis.Cmdable // 持有的 Redis 客户端，用于操作锁\tkey string // 锁的键，用于标识锁\tvalue string // 锁的值，用于标识持有者，避免误释放其他客户端的锁\texpiration time.Duration // 锁的过期时间\tunlock chan struct&#123;&#125; // 用于信号化锁的释放操作，退出自动续约逻辑\tsignalUnlockOnce sync.Once // 确保解锁操作只执行一次，防止重复释放&#125; Lock 方法实现 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162type RetryStrategy interface &#123;\t// Next 返回下一次重试的间隔，如果不需要继续重试，那么第二参数发挥 false\tNext() (time.Duration, bool)&#125;type FixIntervalRetry struct &#123;\t// 重试间隔\tInterval time.Duration\t// 最大次数\tMax int\tcnt int&#125;func (f *FixIntervalRetry) Next() (time.Duration, bool) &#123;\tf.cnt++\treturn f.Interval, f.cnt &lt;= f.Max&#125;func (c *Client) Lock(ctx context.Context, key string, expiration time.Duration, retry RetryStrategy, timeout time.Duration) (*Lock, error) &#123; val := c.valuer() // 生成唯一的锁值，标识当前客户端 var timer *time.Timer defer func() &#123; if timer != nil &#123; timer.Stop() // 在退出之前停止定时器，避免资源泄露 &#125; &#125;() for &#123; lctx, cancel := context.WithTimeout(ctx, timeout) // 为每次获取锁尝试设置超时 res, err := c.client.Eval(lctx, luaLock, []string&#123;key&#125;, val, expiration.Seconds()).Result() cancel() if err != nil &amp;&amp; !errors.Is(err, context.DeadlineExceeded) &#123; // 非超时错误，比如 Redis server 崩溃、网络异常等，不再继续尝试 return nil, err &#125; if res == &quot;OK&quot; &#123; // 锁获取成功，返回锁对象 return newLock(c.client, key, val, expiration), nil &#125; interval, ok := retry.Next() if !ok &#123; // 如果重试次数耗尽，返回错误 if err != nil &#123; err = fmt.Errorf(&quot;最后一次重试错误: %w&quot;, err) &#125; else &#123; err = fmt.Errorf(&quot;锁被人持有: %w&quot;, ErrFailedToPreemptLock) &#125; return nil, fmt.Errorf(&quot;rlock: 重试机会耗尽，%w&quot;, err) &#125; // 设置重试的等待时间 if timer == nil &#123; timer = time.NewTimer(interval) &#125; else &#123; timer.Reset(interval) &#125; // 等待重试或者上下文结束 select &#123; case &lt;-timer.C: // 定时器到达，表示重试间隔已过，可以再次尝试获取锁 case &lt;-ctx.Done(): // 上下文 ctx 被取消 return nil, ctx.Err() &#125; &#125;&#125; 解锁 Lua 脚本解析 1234567if redis.call(&quot;get&quot;, KEYS[1]) == ARGV[1]then -- 如果锁的值与传入的值一致，表示当前客户端持有该锁 return redis.call(&quot;del&quot;, KEYS[1]) -- 删除键，释放锁else return 0 -- 锁未被当前客户端持有，返回 0end Go 代码解析 1234567891011121314151617181920212223242526func (l *Lock) Unlock(ctx context.Context) error &#123;\t// 使用 Lua 脚本进行解锁操作，保证原子性\tres, err := l.client.Eval(ctx, luaUnlock, []string&#123;l.key&#125;, l.value).Int64()\tdefer func() &#123; // 确保只进行一次解锁信号操作，防止重复解锁引起 panic l.signalUnlockOnce.Do(func() &#123; l.unlock &lt;- struct&#123;&#125;&#123;&#125; // 向 unlock 通道发送信号 close(l.unlock) // 关闭 unlock 通道 &#125;)\t&#125;()\tif err == redis.Nil &#123; // 锁不存在或者锁的值与预期不符，表示当前锁不属于调用者 return ErrLockNotHold\t&#125;\tif err != nil &#123; // Redis 操作出错，返回错误 return err\t&#125;\tif res != 1 &#123; // Lua 脚本执行结果不是 1，表示锁未被成功释放 return ErrLockNotHold\t&#125;\treturn nil // 成功释放锁&#125; 续约约操作对于长时间运行的任务非常重要，以确保在任务未完成时锁不会意外过期导致其他客户端获得锁，从而引起竞态条件。 1234567if redis.call(&quot;get&quot;, KEYS[1]) == ARGV[1]then -- 如果锁的值与传入的值一致，表示当前客户端持有该锁 return redis.call(&quot;expire&quot;, KEYS[1], ARGV[2]) -- 更新锁的过期时间else return 0 -- 锁未被当前客户端持有，返回 0 表示续约失败end 123456789101112131415func (l *Lock) Refresh(ctx context.Context) error &#123; // 使用 Lua 脚本执行锁续约操作，保证续约的原子性 res, err := l.client.Eval(ctx, luaRefresh, []string&#123;l.key&#125;, l.value, l.expiration.Seconds()).Int64() if err != nil &#123; // Redis 操作出错，返回错误 return err &#125; if res != 1 &#123; // Lua 脚本执行结果不是 1，表示锁续约失败，可能是锁不存在或者锁的值不匹配 return ErrLockNotHold &#125; return nil // 成功续约锁&#125; 自动续约机制 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061func (l *Lock) AutoRefresh(interval time.Duration, timeout time.Duration) error &#123; // 创建一个定时器，每隔 interval 时间触发一次 ticker := time.NewTicker(interval) // 刷新超时 channel，用于通知在发生超时时重试 ch := make(chan struct&#123;&#125;, 1) defer func() &#123; // 确保在函数退出时停止定时器并关闭通道 ticker.Stop() close(ch) &#125;() for &#123; select &#123; case &lt;-ticker.C: // 定时器触发时创建一个带有超时时间的上下文，用于刷新锁 ctx, cancel := context.WithTimeout(context.Background(), timeout) err := l.Refresh(ctx) cancel() // 如果刷新操作超时，则继续尝试 if err == context.DeadlineExceeded &#123; // 因为有两个地方可能要写入数据到 ch，而 ch 容量只有 1 // 如果写入不成功，则说明前一次调用超时且尚未被处理 select &#123; case ch &lt;- struct&#123;&#125;&#123;&#125;: default: &#125; continue &#125; // 如果刷新过程中出现了其他错误，则返回错误 if err != nil &#123; return err &#125; case &lt;-ch: // 超时处理，重新尝试刷新锁 ctx, cancel := context.WithTimeout(context.Background(), timeout) err := l.Refresh(ctx) cancel() // 如果仍然超时，则继续重试 if err == context.DeadlineExceeded &#123; select &#123; case ch &lt;- struct&#123;&#125;&#123;&#125;: default: &#125; continue &#125; // 处理其他错误 if err != nil &#123; return err &#125; case &lt;-l.unlock: // 当检测到 unlock 信号时，退出续约逻辑，说明锁已经被释放 return nil &#125; &#125;&#125; RedlockRedlock 是一种 Redis 分布式锁实现方案，旨在提供比单实例 Redis 锁更高的 容错性和可靠性。Redlock 是由 Redis 的创造者提出的一种分布式锁算法，它通过在多个 Redis 节点（通常为 5 个）上进行锁的操作来实现分布式锁的可靠性。Redlock 的核心思想是将锁保存在多个独立的 Redis 实例中，以实现容错性： 客户端需要在多数（即超过一半） Redis 实例上成功获取锁，才能认为锁获取成功。 通过多实例的方案来避免单点故障的问题，如果部分 Redis 实例不可用，只要多数节点仍可用，系统依然可以正常工作。 在单实例实现中，通过 SET key value NX PX ttl 或通过 GET + DEL 来实现分布式锁的获取和释放，同时还使用了自动续约机制，保证锁在任务长时间运行期间不会过期。 锁的获取是一个单实例上的简单原子操作 锁的释放和续约使用了 Lua 脚本，确保在 Redis 服务器端以原子操作方式执行 自动续约机制 用于延长锁的过期时间，确保在任务执行较长时间时不会因为锁的自然过期导致其他客户端意外获取到锁 Redlock 在设计时使用了一组步骤来确保锁的获取过程既高效又一致： 客户端按照顺序对每个 Redis 实例尝试加锁（通过 SET NX PX 操作），并设置一个较短的超时时间，确保获取锁操作不会阻塞 客户端必须在所有节点上尝试加锁的时间内成功获取到大多数节点的锁，才能认为获取锁成功 锁的超时时间应该比客户端操作的预计完成时间更长，以确保操作能够在锁过期之前完成 在所有操作完成后，客户端会尝试对所有节点释放锁 定时任务本地time **time.Tick**：用于创建一个周期性的定时器，返回一个在固定时间间隔发送信号的通道。适用于需要周期性执行的任务，但需注意内存泄漏风险，建议使用 time.NewTicker 以确保资源的可管理性 **time.After**：用于创建一个延迟执行的定时器，在经过指定的时间后向通道发送信号，适用于一次性延迟或超时控制 cron robfig&#x2F;cron 基于时间调度器、时间解析器、Ticker 和 Goroutine 实现了类似 Unix cron 的功能。通过 Cron 表达式灵活地定义任务的执行时间，并使用 Go 的并发特性（Goroutine）来确保任务可以高效并发执行，广泛用于 Go 程序中需要定时任务调度的场景。 使用 在线工具 可以帮助验证 Cron 表达式是否符合预期 分布式本地定时任务加上分布式锁可以实现分布式定时任务的效果。通过使用分布式锁机制，能够有效避免多个节点同时执行同一任务的问题，从而实现协调多个节点的执行，确保任务在集群环境下只执行一次。","tags":["Golang","Redis"],"categories":["Internship"]},{"title":"Hypertext Transfer Protocol (HTTP) 🌐","path":"/2024/06/29/ahttp/","content":"“鱼总是最后看见水的” - 理解 HTTP 协议本质与应用 基本概念网络分层模型TCP&#x2F;IP 网络分层模型 “分层”的概念，把复杂的网络通信划分出多个层次，再给每一个层次分配不同的职责，层次内只专心做自己的事情就好，用“分而治之”的思想把一个“大麻烦”拆分成了数个“小麻烦”，从而解决了网络通信的难题。 graph TB link_layer[\"link layer/MAC\"] internet_layer[\"internet layer/IP\"] transport_layer[\"transport Layer/TCP/UDP\"] application_layer[\"application layer/HTTP\"] 链接层（link layer）负责在以太网、WiFi 这样的底层网络上发送原始数据包，工作在网卡这个层次，使用 MAC 地址来标记网络上的设备，所以有时候也叫 MAC 层 网际层或网络互连层（internet layer）在“链接层”的基础上，用 IP 地址取代 MAC 地址，把许许多多的局域网、广域网连接成一个虚拟的巨大网络，在这个网络里找设备时只要把 IP 地址再“翻译”成 MAC 地址就可以了 传输层（transport layer）的职责是保证数据在 IP 地址标记的两点之间“可靠”地传输，是 TCP （Transmission Control Protocol）协议工作的层次，另外还有 UDP（User Datagram Protocol） TCP 是一个有状态的协议，需要先与对方建立连接然后才能发送数据，而且保证数据不丢失不重复 UDP 则比较简单，它无状态，不用事先建立连接就可以任意发送数据，但不保证数据一定会发到对方 TCP 的数据是连续的“字节流”，有先后顺序，而 UDP 则是分散的小数据包，是顺序发，乱序收 应用层（application layer）“百花齐放”，有各种面向具体应用的协议，例如 Telnet、SSH、FTP、SMTP 等 MAC 层的传输单位是帧（frame），IP 层的传输单位是包（packet），TCP 层的传输单位是段（segment），HTTP 的传输单位则是消息或报文（message），但这些名词并没有什么本质的区分，可以统称为数据包 OSI 网络分层模型 OSI 全称是“开放式系统互联通信参考模型”（Open System Interconnection Reference Model）。TCP&#x2F;IP 发明于 1970 年代，当时除了它还有很多其他的网络协议，整个网络世界比较混乱，后来国际标准组织（ISO）设计出了一个新的网络分层模型，想用这个新框架来统一既存的各种网络协议 graph LR L7[\"L7 Application Layer\"] L6[\"L6 Presentation Layer\"] L5[\"L5 Session Layer\"] L4[\"L4 Transport Layer\"] L3[\"L3 Network Layer\"] L2[\"L2 Data Link Layer\"] L1[\"L1 Physical Layer\"] 第一层：物理层，网络的物理形式，例如电缆、光纤、网卡、集线器等等； 第二层：数据链路层，它基本相当于 TCP&#x2F;IP 的 链接层； 第三层：网络层，相当于 TCP&#x2F;IP 里的 网际层； 第四层：传输层，相当于 TCP&#x2F;IP 里的 传输层； 第五层：会话层，维护网络中的连接状态，即保持会话和同步； 第六层：表示层，把数据转换为合适、可理解的语法和语义； 第七层：应用层，面向具体的应用传输数据。 OSI 分层模型在发布的时候就明确地表明是一个“参考”，不是强制标准 TCP&#x2F;IP 是一个纯软件的栈，没有网络应有的最根基的电缆、网卡等物理设备的位置。而 OSI 则补足了这个缺失，在理论层面上描述网络更加完整，OSI 的分层模型在四层以上分的太细，而 TCP&#x2F;IP 实际应用时的会话管理、编码转换、压缩等和具体应用经常联系的很紧密，很难分开 “四层负载均衡”：工作在传输层上，基于 TCP&#x2F;IP 协议的特性，例如 IP 地址、端口号等实现对后端服务器的负载均衡 “七层负载均衡”：工作在应用层上，看到的是 HTTP 协议，解析 HTTP 报文里的 URI、主机名、资源类型等数据，再用适当的策略转发给后端服务器 凡是由操作系统负责处理的就是四层或四层以下，凡是需要由应用程序（也就是自己写代码）负责处理的就是七层 HTTP 是什么HTTP 协议的发展过程 HTTP 协议始于三十年前蒂姆·伯纳斯 - 李的一篇论文（1989 年）； HTTP&#x2F;0.9 是个简单的文本协议，只能获取文本资源； HTTP&#x2F;1.0 确立了大部分现在使用的技术，但它不是正式标准（1993 年）； HTTP&#x2F;1.1 是目前互联网上使用最广泛的协议，功能也非常完善（1999 年）； HTTP&#x2F;2 基于 Google 的 SPDY 协议，注重性能改善，但还未普及（2015 年）； HTTP&#x2F;3 基于 Google 的 QUIC 协议，是将来的发展方向（2018 年）。 graph LR subgraph 协议 subgraph 传输 超文本 end end Hypertext Transfer Protocol 超文本传输协议 协议 协议必须要有两个或多个参与者，也就是“协” 协议是对参与者的一种行为约定和规范，也就是“议” 传输 HTTP 协议是一个“双向协议”，但允许中间有“中转”或者“接力” 超文本 文字、图片、音频和视频等的混合体，含有“超链接” HTTP 是一个在计算机世界里专门在两点之间传输文字、图片、音频、视频等超文本数据的约定和规范。 在互联网上 HTTP 传输最多的可能就是 HTML（HyperText Markup Language），但要是论数据量，HTML 可能要往后排了，图片、音频、视频这些类型的资源显然更大。 HTTP 通常跑在 TCP&#x2F;IP 协议栈之上，依靠 IP 协议实现寻址和路由、TCP 协议实现可靠数据传输、DNS 协议实现域名查找、SSL&#x2F;TLS 协议实现安全通信。此外，还有一些协议依赖于 HTTP，例如 WebSocket、HTTPDNS 等。 HTTP 相关概念 Web 浏览器 Web Browser 是检索、查看互联网上网页资源的应用程序，Web 指的是“World Wide Web”（万维网） 浏览器本质上是一个 HTTP 协议中的请求方，使用 HTTP 协议获取网络上的各种资源 HTTP 协议里，浏览器的角色被称为“User Agent”即“用户代理 “，通常都简单地称之为“客户端” Web 服务器 硬件含义：物理形式或“云”形式的机器，在大多数情况下它可能不是一台服务器，而是利用反向代理、负载均衡等技术组成的庞大集群 软件含义： 提供 Web 服务的应用程序，通常会运行在硬件含义的服务器上，利用强大的硬件能力响应海量的客户端 HTTP 请求，处理磁盘上的网页、图片等静态文件，或者把请求转发给后面的 Tomcat、Node.js 等业务应用，返回动态信息 CDN 内容分发网络（Content Delivery Network）应用 HTTP 协议里的缓存和代理技术，代替源站响应客户端的请求 CDN 一项重要基础设施，除了基本的网络加速外，还提供负载均衡、安全防护、边缘计算、跨运营商网络等功能 爬虫 “爬虫”（Crawler）是一种可以自动访问 Web 资源的应用程序 爬虫绝大多数是各大搜索引擎抓取网页存入庞大的数据库，再建立关键字索引 HTML&#x2F;WebService&#x2F;WAF HTML 描述了超文本页面，用各种“标签”定义文字、图片等资源和排版布局，最终由浏览器“渲染”出可视化页面 广义上的 HTML 通常是指 HTML、JavaScript、CSS 等前端技术的组合，能够实现比传统静态页面更丰富的动态页面 Web Service 是一个基于 Web（HTTP）的服务架构技术，具有跨平台跨语言的优点 WAF（Web Application Firewall） 是专门检测 HTTP 流量，是防护 Web 应用的安全技术，通常位于 Web 服务器之前，可以阻止如 SQL 注入、跨站脚本等攻击 TCP&#x2F;IP TCP&#x2F;IP 协议是一系列网络通信协议的统称，其中最核心的两个协议是 TCP 和 IP，其他的还有 UDP、ICMP、ARP 等等，共同构成了一个复杂但有层次的协议栈 IP 协议是“Internet Protocol”的缩写，主要目的是解决寻址和路由问题，以及如何在两点间传送数据包 TCP 协议是“Transmission Control Protocol”的缩写，意思是“传输控制协议”，它位于 IP 协议之上，基于 IP 协议提供可靠的、字节流形式的通信，是 HTTP 协议得以实现的基础 “可靠”是指保证数据不丢失，“字节流”是指保证数据完整，在 TCP 协议的两端可以如同操作文件一样访问传输的数据，就像是读写在一个密闭的管道里“流动”的字节 HTTP 协议就运行在了 TCP&#x2F;IP 上，HTTP 也就可以更准确地称为“HTTP over TCP&#x2F;IP” DNS “域名系统”（Domain Name System）用有意义的名字来作为 IP 地址的等价替代 “域名”（Domain Name）被设计成了一个有层次的结构 用 “.” 分隔成多个单词，级别从左到右逐级升高，最右边的被称为“顶级域名”，然后是“二级域名”，层级关系向左依次降低 最左边的是主机名，可以用来表明主机的用途，比如“www”表示提供万维网服务、“mail”表示提供邮件服务 在 Apache、Nginx 这样的 Web 服务器里，域名可以用来标识虚拟主机，决定由哪个虚拟主机来对外提供服务 域名本质上还是个名字空间系统 就像 IP 地址必须转换成 MAC 地址才能访问主机一样，域名也必须要转换成 IP 地址，这个过程就是“域名解析” 域名的其他用途 重定向：当主机有情况需要下线、迁移时，可以更改 DNS 记录，让域名指向其他的机器 内部使用：域名是一个名字空间，可以使用 bind9 等开源软件搭建一个在内部使用的 DNS，作为名字服务器 负载均衡：域名解析可以返回多个 IP 地址，所以一个域名可以对应多台主机 URI&#x2F;URL 使用 URI（Uniform Resource Identifier），统一资源标识符能够唯一地标记互联网上资源 URI 另一个更常用的表现形式是 URL（Uniform Resource Locator）， 统一资源定位符（俗称的“网址”） URI 不完全等同于网址，它包含有 URL 和 URN（Uniform Resource Name） 两个部分，因为 URL 太普及，常常把这两者简单地视为相等 客户端看到的必须是完整的 URI，使用特定的协议去连接特定的主机，而服务器看到的只是报文请求行里被删除了协议名和主机名的 URI sequenceDiagram participant Client as 客户端 participant Server as 服务器 Client->>+Server: 请求 (scheme://host:port/path?query) activate Server Server-->>-Client: 响应 deactivate Server HTTPS HTTPS 全称是“HTTP over SSL&#x2F;TLS”，SSL&#x2F;TLS 它是一个负责加密通信的安全协议，建立在 TCP&#x2F;IP 之上 SSL 的全称是“Secure Socket Layer”，由网景公司发明，当发展到 3.0 时被标准化，改名为 TLS 即 “Transport Layer Security” 但由于历史的原因还是有很多人称之为 SSL&#x2F;TLS，或者直接简称为 SSL，SSL 综合了对称加密、非对称加密、摘要算法、数字签名、数字证书等技术，能够在不安全的环境中为通信的双方创建出一个秘密的、安全的传输通道 代理 代理（Proxy）是 HTTP 协议中请求方和应答方中间的一个环节，作为“中转站”，既可以转发客户端的请求，也可以转发服务器的应答 代理有很多的种类，常见的有： 匿名代理：完全“隐匿”了被代理的机器，外界看到的只是代理服务器； 透明代理：顾名思义，它在传输过程中是“透明开放”的，外界既知道代理，也知道客户端； 正向代理：靠近客户端，代表客户端 向服务器发送请求； 反向代理：靠近服务器端，代表服务器 响应客户端的请求； CDN 实际上就是一种代理，它代替源站服务器响应客户端的请求，通常扮演着透明代理和反向代理的角色 由于代理在传输过程中插入了一个“中间层”，所以可以在这个环节做很多有意思的事情，比如： 负载均衡：把访问请求均匀分散到多台机器，实现访问集群化； 内容缓存：暂存上下行的数据，减轻后端的压力； 安全防护：隐匿 IP, 使用 WAF 等工具抵御网络攻击，保护被代理的机器； 数据处理：提供压缩、加密等额外的功能 HTTP 报文结构HTTP 报文 HTTP 协议是一个“纯文本”的协议，可读性好，其请求报文和响应报文的结构基本相同，由三大部分组成： 起始行（start line）：描述请求或响应的基本信息； 头部字段集合（header）：使用 key-value 形式更详细地说明报文； 消息正文（entity）：实际传输的数据，它不一定是纯文本，可以是图片、视频等二进制数据。 前两部分起始行和头部字段经常又合称为“请求头”或“响应头”，消息正文又称为“实体”，但与“header”对应，很多时候就直接称为“body” 请求行 请求行（request line），它简要地描述了客户端想要如何操作服务器端的资源，由三部分构成： 请求方法：是一个动词，如 GET&#x2F;POST，表示对资源的操作； 请求目标：通常是一个 URI，标记了请求方法要操作的资源； 版本号：表示报文使用的 HTTP 协议版本。 1GET / HTTP/1.1 状态行 响应报文里的起始行不叫“响应行”，而是叫“状态行”（status line），意思是服务器响应的状态，同样也是由三部分构成： 版本号：表示报文使用的 HTTP 协议版本； 状态码：一个三位数，用代码的形式表示处理的结果，比如 200 是成功，500 是服务器错误； 原因：是状态码的简短文字描述，但它只是为了兼容早期的文本客户端而存在，目前的大多数客户端都会忽略它。 12HTTP/1.1 200 OKHTTP/1.1 404 Not Found 头部字段 请求行或状态行再加上头部字段集合就构成了 HTTP 报文里完整的请求头或响应头，头部字段是 key-value 的形式，key 和 value 之间用“:”分隔，最后用 CRLF 换行表示字段结束。 HTTP 头字段非常灵活，不仅可以使用标准里的 Host、Connection 等已有头，也可以任意添加自定义头，用头字段需要注意下面几点： 字段名里不允许出现空格，可以使用连字符“-”，但不能使用下划线“_”。例如，“test-name”是合法的字段名，而“test name”、“test_name”是不正确的字段名； 字段名后面必须紧接着“:”，不能有空格，而“:”后的字段值前可以有多个空格； 字段的顺序是没有意义的，可以任意排列不影响语义； 字段原则上不能重复，除非这个字段本身的语义允许，例如 Set-Cookie。 常用头字段 HTTP 协议规定了非常多的头部字段，基本上可以分为四大类： 通用字段：在请求头和响应头里都可以出现； 请求字段：仅能出现在请求头里，进一步说明请求信息或者额外的附加条件； 响应字段：仅能出现在响应头里，补充说明响应报文的信息； 实体字段：它实际上属于通用字段，但专门描述 body 的额外信息。 常见字段： Host 字段，它属于请求字段，只能出现在请求头里，它同时也是唯一一个 HTTP&#x2F;1.1 规范里要求必须出现的字段，Host 字段告诉服务器这个请求应该由哪个主机来处理，当一台计算机上托管了多个虚拟主机的时候，服务器端就需要用 Host 字段来选择，有点像是一个简单的“路由重定向” User-Agent 是请求字段，只出现在请求头里。它使用一个字符串来描述发起 HTTP 请求的客户端，服务器可以依据它来返回最合适此浏览器显示的页面。 Date 字段是一个通用字段，但通常出现在响应头里，表示 HTTP 报文创建的时间，客户端可以使用这个时间再搭配其他字段决定缓存策略。 Server 字段是响应字段，只能出现在响应头里。它告诉客户端当前正在提供 Web 服务的软件名称和版本号，Server 字段也不是必须要出现的，因为这会把服务器的一部分信息暴露给外界。 Content-Length 是实体字段，它表示报文里 body 的长度，也就是请求头或响应头空行后面数据的长度 请求方法请求方法的实际含义就是客户端发出了一个“动作指令”，要求服务器端对 URI 定位的资源执行这个动作，目前 HTTP&#x2F;1.1 规定了八种方法，单词都必须是大写的形式：GET、HEAD、POST、PUT、DELETE、CONNECT、OPTIONS、TRACE GET&#x2F;HEAD GET 方法的含义是请求从服务器获取资源，这个资源既可以是静态的文本、页面、图片、视频，也可以是由 PHP、Java 动态生成的页面或者其他格式的数据 HEAD 方法可以看做是 GET 方法的一个“简化版”或者“轻量版”，但服务器不会返回请求的实体数据，只会传回响应头，也就是资源的“元信息”，比如，想要检查一个文件是否存在，只要发个 HEAD 请求就可以了，没有必要用 GET 把整个文件都取下来 POST&#x2F;PUT GET 和 HEAD 方法是从服务器获取数据，而 POST 和 PUT 方法则是相反操作，向 URI 指定的资源提交数据，数据就放在报文的 body 里，通常 POST 表示的是“新建”“create”的含义，而 PUT 则是“修改”“update”的含义 在实际应用中，PUT 用到的比较少，它与 POST 的语义、功能太过近似，有的服务器甚至就直接禁止使用 PUT 方法，只用 POST 方法上传数据 其他方法 DELETE 方法指示服务器删除资源，因为这个动作危险性太大，所以通常服务器不会执行真正的删除操作，而是对资源做一个删除标记 CONNECT 是一个比较特殊的方法，要求服务器为客户端和另一台远程服务器建立一条特殊的连接隧道，这时 Web 服务器在中间充当了代理的角色 OPTIONS 方法要求服务器列出可对资源实行的操作方法，在响应头的 Allow 字段里返回，它的功能很有限，用处也不大，有的服务器（例如 Nginx）干脆就没有实现对它的支持 TRACE 方法多用于对 HTTP 链路的测试或诊断，可以显示出请求 - 响应的传输路径。它的本意是好的，但存在漏洞，会泄漏网站的信息，所以 Web 服务器通常也是禁止使用 常用状态码RFC 标准把状态码分成了五类： 1××：提示信息，表示目前是协议处理的中间状态，还需要后续的操作； 偶尔能够见到的是“101 Switching Protocols”，它的意思是客户端使用 Upgrade 头字段，要求在 HTTP 协议的基础上改成其他的协议继续通信，比如 WebSocket。而如果服务器也同意变更协议，就会发送状态码 101，但这之后的数据传输就不会再使用 HTTP 了 2××：成功，报文已经收到并被正确处理； “200 OK”是最常见的成功状态码，表示一切正常，服务器如客户端所期望的那样返回了处理结果，如果是非 HEAD 请求，通常在响应头后都会有 body 数据。 “204 No Content”是另一个很常见的成功状态码，它的含义与“200 OK”基本相同，但响应头后没有 body 数据。所以对于 Web 服务器来说，正确地区分 200 和 204 是很必要的。 “206 Partial Content”是 HTTP 分块下载或断点续传的基础，在客户端发送“范围请求”、要求获取资源的部分数据时出现，它与 200 一样，也是服务器成功处理了请求，但 body 里的数据不是资源的全部，而是其中的一部分。 状态码 206 通常还会伴随着头字段“Content-Range”，表示响应报文里 body 数据的具体范围，供客户端确认，例如“Content-Range: bytes 0-99&#x2F;2000”，意思是此次获取的是总计 2000 个字节的前 100 个字节 3××：重定向，资源位置发生变动，需要客户端重新发送请求； “301 Moved Permanently”俗称“永久重定向”，含义是此次请求的资源已经不存在了，需要改用改用新的 URI 再次访问。 与它类似的是“302 Found”，曾经的描述短语是“Moved Temporarily”，俗称“临时重定向”，意思是请求的资源还在，但需要暂时用另一个 URI 来访问。 301 和 302 都会在响应头里使用字段 Location 指明后续要跳转的 URI，最终的效果很相似，浏览器都会重定向到新的 URI “304 Not Modified” 用于 If-Modified-Since 等条件请求，表示资源未修改，用于缓存控制。它不具有通常的跳转含义，但可以理解成“重定向已到缓存的文件”（即“缓存重定向”） 4××：客户端错误，请求报文有误，服务器无法处理； “400 Bad Request”是一个通用的错误码，表示请求报文有错误，但具体是数据格式错误、缺少请求头还是 URI 超长它没有明确说，只是一个笼统的错误 “403 Forbidden”实际上不是客户端的请求出错，而是表示服务器禁止访问资源。原因可能多种多样，例如信息敏感、法律禁止等，如果服务器友好一点，可以在 body 里详细说明拒绝请求的原因 “404 Not Found”可能是我们最常看见也是最不愿意看到的一个状态码，它的原意是资源在本服务器上未找到，所以无法提供给客户端，但现在已经被“用滥了”，只要服务器“不高兴”就可以给出个 404 开发中常用的还有： 405 Method Not Allowed：不允许使用某些方法操作资源，例如不允许 POST 只能 GET； 406 Not Acceptable：资源无法满足客户端请求的条件，例如请求中文但只有英文； 408 Request Timeout：请求超时，服务器等待了过长的时间； 409 Conflict：多个请求发生了冲突，可以理解为多线程并发时的竞态； 413 Request Entity Too Large：请求报文里的 body 太大； 414 Request-URI Too Long：请求行里的 URI 太大； 429 Too Many Requests：客户端发送了太多的请求，通常是由于服务器的限连策略； 431 Request Header Fields Too Large：请求头某个字段或总体太大； 5××：服务器错误，服务器在处理请求时内部发生了错误。 “500 Internal Server Error”与 400 类似，也是一个通用的错误码，服务器究竟发生了什么错误我们是不知道的。不过对于服务器来说这应该算是好事，通常不应该把服务器内部的详细信息，例如出错的函数调用栈告诉外界。虽然不利于调试，但能够防止黑客的窥探或者分析 “501 Not Implemented”表示客户端请求的功能还不支持，这个错误码比 500 要“温和”一些，和“即将开业，敬请期待”的意思差不多，不过具体什么时候“开业”就不好说了。 “502 Bad Gateway”通常是服务器作为网关或者代理时返回的错误码，表示服务器自身工作正常，访问后端服务器时发生了错误，但具体的错误原因也是不知道的。 “503 Service Unavailable”表示服务器当前很忙，暂时无法响应服务，我们上网时有时候遇到的“网络服务正忙，请稍后重试”的提示信息就是状态码 503。 503 是一个“临时”的状态，很可能过几秒钟后服务器就不那么忙了，可以继续提供服务，所以 503 响应报文里通常还会有一个“Retry-After”字段，指示客户端可以在多久以后再次尝试发送请求 HTTP 的特点特点 灵活可扩展：HTTP 协议只规定了报文的基本格式，比如用空格分隔单词，用换行分隔字段，“header+body”等，各个组成部分都没有做严格的语法语义限制 可靠传输：HTTP 协议是基于 TCP&#x2F;IP 的，而 TCP 本身是一个“可靠”的传输协议，所以 HTTP 自然也就继承了这个特性，能够在请求方和应答方之间“可靠”地传输数据，“可靠”只是向使用者提供了一个“承诺”，会在下层用多种手段“尽量”保证数据的完整送达 应用层协议：FTP 用于传输文件、SMTP 用于发送邮件、SSH 用于远程登录；HTTP 几乎可以传递一切东西，满足各种需求，称得上是一个“万能”的协议 请求-应答： HTTP 的请求-应答模式恰好契合了传统的 C&#x2F;S（Client&#x2F;Server）系统架构，也完全符合 RPC（Remote Procedure Call）的工作模式，可以把 HTTP 请求处理封装成远程函数调用，导致了 WebService、RESTful 和 gPRC 等的出现 无状态：“状态”其实就是客户端或者服务器里保存的一些数据或者标志，记录了通信过程中的一些变化信息，HTTP 可以通过“补丁”增加这个特性 优点&#x2F;缺点 HTTP 最大的优点是简单、灵活和易于扩展； HTTP 拥有成熟的软硬件环境，应用的非常广泛，是互联网的基础设施； HTTP 是无状态的，可以轻松实现集群化，扩展性能，但有时也需要用 Cookie 等技术来实现“有状态”； HTTP 是明文传输，数据完全肉眼可见，能够方便地研究分析，但也容易被窃听； HTTP 是不安全的，无法验证通信双方的身份，也不能判断报文是否被窜改； HTTP 1.1 的性能不算差，但不完全适应现在的互联网，还有很大的提升空间（HTTP&#x2F;2 和 HTTP&#x2F;3）。 HTTP 的实体数据HTTP 协议作为应用层的协议，数据到达之后工作只能说是完成了一半，还必须要告诉上层应用这是什么数据才行，早在 HTTP 协议诞生之前，在电子邮件系统里让电子邮件可以发送 ASCII 码以外的任意数据，方案的名字叫做“多用途互联网邮件扩展”（Multipurpose Internet Mail Extensions），简称为 MIME MIME 是一个很大的标准规范，HTTP 取了其中的一部分，用来标记 body 的数据类型（MIME type），MIME 把数据分成了八大类，每个大类下再细分出多个子类，形式是“type&#x2F;subtype”的字符串，所以能够很容易地纳入 HTTP 头字段里 HTTP 里经常遇到的几个类别： text：即文本格式的可读数据，如超文本文档 text&#x2F;html ，纯文本 text&#x2F;plain、样式表 text&#x2F;css 等 image：即图像文件，有 image&#x2F;gif、image&#x2F;jpeg、image&#x2F;png 等 audio&#x2F;video：音频和视频数据，例如 audio&#x2F;mpeg、video&#x2F;mp4 等 application：数据格式不固定，可能是文本也可能是二进制，必须由上层应用程序来解释，常见的有 application&#x2F;json，application&#x2F;javascript、application&#x2F;pdf 和 application&#x2F;octet-stream 二进制数据等 HTTP 在传输时为了节约带宽，有时候还会压缩数据，还需要有一个“Encoding type”，告诉数据是用的什么编码格式，这样对方才能正确解压缩，还原出原始的数据，常用的 Encoding type 只有下面三种： gzip：GNU zip 压缩格式，也是互联网上最流行的压缩格式； deflate：zlib（deflate）压缩格式，流行程度仅次于 gzip br：一种专门为 HTTP 优化的新压缩算法（Brotli） 有了 MIME type 和 Encoding type，无论是浏览器还是服务器就都可以轻松识别出 body 的类型，也就能够正确处理数据了 Accept 字段标记的是客户端可理解的 MIME type，可以用“,”做分隔符列出多个类型，服务器会在响应报文里用头字段 Content-Type 告诉实体数据的真实类型： 1234567# 客户端Accept: text/html,application/xml,image/webp,image/pngAccept-Encoding: gzip, deflate, brContent-Encoding: gzip# 服务器Content-Type: text/html# 如果响应报文里没有 Content-Encoding 字段，就表示响应数据没有被压缩 此外还有语言类型使用的头字段、内容协商的质量值等字段 graph LR A[Accept] --> B(Content-Type) C[Acept-Encoding] --> D(Content-Encoding) E[Acept-Language] --> F(Content-Language) G[Acept-Charset] --> B HTTP 的应用传输大文件 数据压缩：gzip 等压缩算法通常只对文本文件有较好的压缩率，而图片、音频视频等多媒体数据本身就已经是高度压缩的，再用 gzip 处理效果不好 分块传输 “化整为零”的思路在 HTTP 协议里就是“chunked”分块传输编码，在响应报文里用头字段“Transfer-Encoding: chunked”来表示，意思是报文里的 body 部分不是一次性发过来的，而是分成了许多的块（chunk）逐个发送 “Transfer-Encoding: chunked”和“Content-Length”这两个字段是互斥的，也就是说响应报文里这两个字段不能同时出现，一个响应报文的传输要么是长度已知，要么是长度未知（chunked） 范围请求&#x2F;多段数据 HTTP 协议为了满足这样的需求，提出了“范围请求”（range requests）的概念，允许客户端在请求头里使用专用字段来表示只获取文件的一部分，相当于是客户端的“化整为零” 不仅看视频的拖拽进度需要范围请求，常用的下载工具里的多段下载、断点续传也是基于它实现的，要点是： 先发个 HEAD，看服务器是否支持范围请求，同时获取文件的大小； 开 N 个线程，每个线程使用 Range 字段划分出各自负责下载的片段，发请求传输数据； 下载意外中断也不怕，不必重头再来一遍，只要根据上次的下载记录，用 Range 请求剩下的那一部分就可以了。 这些方法不是互斥的，而是可以混合起来使用，例如压缩后再分块传输，或者分段后再分块 连接管理短连接和长连接 HTTP 协议最初（0.9⁄1.0）是个非常简单的协议，通信过程也采用了简单的“请求 - 应答”方式，它底层的数据传输基于 TCP&#x2F;IP，每次发送请求前需要先与服务器建立连接，收到响应报文后会立即关闭连接。因为客户端与服务器的整个连接过程很短暂，不会与服务器保持长时间的连接状态，所以就被称为“短连接”（short-lived connections）。早期的 HTTP 协议也被称为是“无连接”的协议。 HTTP 协议就提出了“长连接”的通信方式，也叫“持久连接”（persistent connections）、“连接保活”（keep alive）、“连接复用”（connection reuse） 用的就是“成本均摊”的思路，既然 TCP 的连接和关闭非常耗时间，那么就把这个时间成本由原来的一个“请求 - 应答”均摊到多个“请求 - 应答”上 连接相关的头字段 由于长连接对性能的改善效果非常显著，所以在 HTTP&#x2F;1.1 中的连接都会默认启用长连接。不需要用什么特殊的头字段指定，只要向服务器发送了第一次请求，后续的请求都会重复利用第一次打开的 TCP 连接，也就是长连接。 在请求头里明确地要求使用长连接机制，使用的字段是 Connection，值是“keep-alive” 如果服务器支持长连接，它总会在响应报文里放一个“Connection: keep-alive”字段 因为 TCP 连接长时间不关闭，服务器必须在内存里保存它的状态，这就占用了服务器的资源。如果有大量的空闲长连接只连不发，就会很快耗尽服务器的资源，导致服务器无法为真正有需要的用户提供服务。 客户端可以在请求头里加上“Connection: close”字段，告诉服务器：“这次通信后就关闭连接”。 服务器端通常不会主动关闭连接，但也可以使用一些策略。拿 Nginx 来举例，它有两种方式： 使用“keepalive_timeout”指令，设置长连接的超时时间，如果在一段时间内连接上没有任何数据收发就主动断开连接，避免空闲连接占用系统资源。 使用“keepalive_requests”指令，设置长连接上可发送的最大请求次数。比如设置成 1000，那么当 Nginx 在这个连接上处理了 1000 个请求后，也会主动断开连接。 队头阻塞 “队头阻塞”与短连接和长连接无关，而是由 HTTP 基本的“请求 - 应答”模型所导致的。因为“请求 - 应答”模型不能变，所以“队头阻塞”问题在 HTTP&#x2F;1.1 里无法解决，只能缓解。 “并发连接”（concurrent connections），是同时对一个域名发起多个长连接，用数量来解决质量的问题 “域名分片”（domain sharding）技术还是用数量来解决质量的思路，多开几个域名都指向同一台服务器这样实际长连接的数量就又上去了 重定向和跳转“Location”字段属于响应字段，必须出现在响应报文里。但只有配合 301⁄302 状态码才有意义，它 标记了服务器要求重定向的 URI 301 俗称“永久重定向”（Moved Permanently），意思是原 URI 已经“永久”性地不存在了，今后的所有请求都必须改用新的 URI。 浏览器看到 301，就知道原来的 URI“过时”了，就会做适当的优化。比如历史记录、更新书签，下次可能就会直接用新的 URI 访问，省去了再次跳转的成本。搜索引擎的爬虫看到 301，也会更新索引库，不再使用老的 URI。 302 俗称“临时重定向”（“Moved Temporarily”），意思是原 URI 处于“临时维护”状态，新的 URI 是起“顶包”作用的“临时工”。 浏览器或者爬虫看到 302，会认为原来的 URI 仍然有效，但暂时不可用，所以只会执行简单的跳转页面，不记录新的 URI，也不会有其他的多余动作，下次访问还是用原 URI。 重定向的应用场景 资源不可用时用另一个新的 URI 来代替 避免重复，让多个网址都跳转到一个 URI，增加访问入口的同时还不会增加额外的工作量 重定向的相关问题 性能损耗，定向的机制决定了一个跳转会有两次请求 - 应答，比正常的访问多了一次，站内重定向可以长连接复用，站外重定向就要开两个连接 循环跳转，HTTP 协议特别规定，浏览器必须具有检测“循环跳转”的能力，在发现这种情况时应当停止发送请求并给出错误提示 Cookie 机制Cookie 机制需要用到响应头字段 Set-Cookie 和请求头字段 Cookie： 服务器有时会在响应头里添加多个 Set-Cookie，存储多个“key &#x3D; value” 浏览器这边发送时不需要用多个 Cookie 字段，只要在一行里用“;”隔开就行 Cookie 是由浏览器负责存储的，而不是操作系统 Cookie 的有效期可以使用 Expires 和 Max-Age 两个属性来设置： “Expires”俗称“过期时间”，用的是绝对时间点，可以理解为“截止日期”（deadline） “Max-Age”用的是相对时间，单位是秒，浏览器用收到报文的时间点再加上 Max-Age，就可以得到失效的绝对时间 设置 Cookie 的作用域，让浏览器仅发送给特定的服务器和 URI，避免被其他网站盗用： “Domain”和“Path”指定了 Cookie 所属的域名和路径 浏览器在发送 Cookie 前会从 URI 中提取出 host 和 path 部分，对比 Cookie 的属性。如果不满足条件，就不会在请求头里发送 Cookie，现实中为了省事，通常 Path 就用一个“&#x2F;”或者直接省略，表示域名下的任意路径都允许使用 Cookie，让服务器自己去挑 Cookie 的安全性： 属性“HttpOnly”会告诉浏览器，此 Cookie 只能通过浏览器 HTTP 协议传输，禁止其他方式访问，浏览器的 JS 引擎就会禁用 document.cookie 等一切相关的 API 属性“SameSite”可以防范“跨站请求伪造”（XSRF）攻击，设置成“SameSite &#x3D; Strict”可以严格限定 Cookie 不能随着跳转链接跨站发送，而“SameSite &#x3D; Lax”则略宽松一点，允许 GET&#x2F;HEAD 等安全方法，但禁止 POST 跨站发送 “Secure”属性表示这个 Cookie 仅能用 HTTPS 协议加密传输，明文的 HTTP 协议会禁止发送，但 Cookie 本身不是加密的，浏览器里还是以明文的形式存在 Cookie 的应用有身份识别、广告跟踪等，为了防止滥用 Cookie 搜集用户隐私，互联网组织相继提出了 DNT（Do Not Track）和 P3P（Platform for Privacy Preferences Project），但实际作用不大 因为 Cookie 并不属于 HTTP 标准（RFC6265，而不是 RFC2616&#x2F;7230），所以语法上与其他字段不太一致，使用的分隔符是“;”，与 Accept 等字段的“,”不同 缓存控制服务器的缓存控制 服务器标记资源有效期使用的头字段是“Cache-Control”，里面的值“max-age &#x3D; 30”就是资源的有效时间，相当于告诉浏览器，“这个页面只能缓存 30 秒，之后就算是过期，不能用。” “max-age”是 HTTP 缓存控制最常用的属性，此外在响应报文里还可以用其他的属性来更精确地指示浏览器应该如何使用缓存： no_store：不允许缓存，用于某些变化非常频繁的数据，例如秒杀页面； no_cache：它的字面含义容易与 no_store 搞混，实际的意思并不是不允许缓存，而是可以缓存，但在使用之前必须要去服务器验证是否过期，是否有最新的版本； must-revalidate：又是一个和 no_cache 相似的词，它的意思是如果缓存不过期就可以继续使用，但过期了如果还想用就必须去服务器验证。 客户端的缓存控制 客户端也可以发“Cache-Control”，请求 - 应答的双方都可以用这个字段进行缓存控制，互相协商缓存的使用策略 当点“刷新”按钮的时候，浏览器会在请求头里加一个“Cache-Control: max-age &#x3D; 0”，服务器看到 max-age &#x3D; 0，也就会用一个最新生成的报文回应浏览器 Ctrl+F5 的“强制刷新”是发了一个“Cache-Control: no-cache”，含义和“max-age &#x3D; 0”基本一样，就看后台的服务器怎么理解，通常两者的效果是相同的 在“前进”“后退”“跳转”这些重定向动作中浏览器不会“夹带私货”，只用最基本的请求头，没有“Cache-Control”，所以就会检查缓存，直接利用之前的资源，不再进行网络通信 条件请求 条件请求一共有 5 个头字段，最常用的是“if-Modified-Since”和“If-None-Match”这两个 需要第一次的响应报文预先提供“Last-modified”和“ETag”，然后第二次请求时就可以带上缓存里的原值，验证资源是否是最新的 如果资源没有变，服务器就回应一个“304 Not Modified”，表示缓存依然有效，浏览器就可以更新一下有效期 ETag 是“实体标签”（Entity Tag）的缩写，是资源的一个唯一标识，主要是用来解决修改时间无法准确区分文件变化的问题： 一个文件在一秒内修改了多次，但因为修改时间是秒级，所以这一秒内的新版本无法区分。 一个文件定期更新，但有时会是同样的内容，实际上没有变化，用修改时间就会误以为发生了变化，传送给浏览器就会浪费带宽。 代理服务graph LR A[浏览器] -- \"请求\" --> B(代理服务器) B -- \"请求\" --> C(源服务器) C -- \"响应\" --> B B -- \"响应\" --> A 代理的作用 “计算机科学领域里的任何问题，都可以通过引入一个中间层来解决”（在这句话后面还可以再加上一句“如果一个中间层解决不了问题，那就再加一个中间层”） 代理最基本的一个功能是负载均衡，在负载均衡的同时，代理服务还可以执行更多的功能，比如： 健康检查：使用“心跳”等机制监控后端服务器，发现有故障就及时“踢出”集群，保证服务高可用； 安全防护：保护被代理的后端服务器，限制 IP 地址或流量，抵御网络攻击和过载； 加密卸载：对外网使用 SSL&#x2F;TLS 加密通信认证，而在安全的内网不加密，消除加解密成本； 数据过滤：拦截上下行的数据，任意指定策略修改请求或者响应； 内容缓存：暂存、复用服务器响应。 代理相关头字段 Via 是一个通用字段，请求头或响应头里都可以出现。每当报文经过一个代理节点，代理服务器就会把自身的信息追加到字段的末尾，它只解决了客户端和源服务器判断是否存在代理的问题，还不能知道对方的真实信息 服务器的 IP 地址应该是保密的，关系到企业的内网安全，所以一般不会让客户端知道；通常服务器又需要知道客户端的真实 IP 地址，方便做访问控制、用户画像、统计分析 HTTP 标准里并没有为此定义头字段，但已经出现了很多“事实上的标准”，最常用的两个头字段是“X-Forwarded-For”和“X-Real-IP” “X-Forwarded-For”的字面意思是“为谁而转发”，形式上和“Via”差不多，Via”追加的是代理主机名（或者域名），而“X-Forwarded-For”追加的是请求方的 IP 地址 “X-Real-IP”是另一种获取客户端真实 IP 的手段，它的作用很简单，就是记录客户端 IP 地址，没有中间的代理信息，相当于是“X-Forwarded-For”的简化版 代理协议 因为通过“X-Forwarded-For”操作代理信息必须要解析 HTTP 报文头，这对于代理来说成本比较高，原本只需要简单地转发消息就好，而现在却必须要费力解析数据再修改数据，会降低代理的转发性能。所以就出现了一个专门的“代理协议”（The PROXY protocol），它由知名的代理软件 HAProxy 所定义，也是一个“事实标准”，被广泛采用（注意并不是 RFC）。 “代理协议”v1 是在 HTTP 报文前增加了一行 ASCII 码文本，相当于又多了一个头，这一行文本其实非常简单，开头必须是“PROXY”五个大写字母，然后是“TCP4”或者“TCP6”，表示客户端的 IP 地址类型，再后面是请求方地址、应答方地址、请求方端口号、应答方端口号，最后用一个回车换行（\\r ）结束。 服务器看到这样的报文，只要解析第一行就可以拿到客户端地址，不需要再去理会后面的 HTTP 数据，省了很多事情。 不过代理协议并不支持“X-Forwarded-For”的链式地址形式，所以拿到客户端地址后再如何处理就需要代理服务器与后端自行约定。 HTTPS如果通信过程具备了四个特性，就可以认为是“安全”的，这四个特性是：机密性、完整性，身份认证和不可否认： 机密性（Secrecy&#x2F;Confidentiality）是指对数据的“保密”，只能由可信的人访问，对其他人是不可见的“秘密”，简单来说就是不能让不相关的人看到不该看的东西。 完整性（Integrity，也叫一致性）是指数据在传输过程中没有被 窜改，不多也不少，“完完整整”地保持着原状。 身份认证（Authentication）是指确认对方的真实身份，也就是“证明你真的是你”，保证消息只能发送给可信的人。 不可否认（Non-repudiation&#x2F;Undeniable），也叫不可抵赖，意思是不能否认已经发生过的行为，不能“说话不算数”“耍赖皮” 只有同时具备了机密性、完整性、身份认证、不可否认这四个特性，通信双方的利益才能有保障，才能算得上是真正的安全 HTTPS 名字里的“S”，是把 HTTP 下层的传输协议由 TCP&#x2F;IP 换成了 SSL&#x2F;TLS，由“HTTP over TCP&#x2F;IP”变成了“HTTP over SSL&#x2F;TLS”，让 HTTP 运行在了安全的 SSL&#x2F;TLS 协议上 SSL&#x2F;TLSSSL 即安全套接层（Secure Sockets Layer），在 OSI 模型中处于第 5 层（会话层），由网景公司于 1994 年发明，SSL 发展到 v3 时已经证明了它自身是一个非常好的安全通信协议，于是互联网工程组 IETF 在 1999 年把它改名为 TLS（传输层安全，Transport Layer Security），正式标准化，版本号从 1.0 重新算起，所以 TLS1.0 实际上就是 SSLv3.1。 到今天 TLS 已经发展出了三个版本，分别是 2006 年的 1.1、2008 年的 1.2 和去年 2018 的 1.3，目前应用的最广泛的 TLS 是 1.2，而之前的协议（TLS1.1⁄1.0、SSLv3&#x2F;v2）都已经被认为是不安全的，各大浏览器在 2020 年左右停止支持。 浏览器和服务器在使用 TLS 建立连接时需要选择 一组恰当的加密算法 来实现安全通信，这些算法的组合被称为“密码套件”（cipher suite，也叫 加密套件），TLS 的密码套件命名非常规范，基本的形式是“密钥交换算法 + 签名算法 + 对称加密算法 + 摘要算法”，如： “ECDHE-RSA-AES256-GCM-SHA384” - “握手时使用 ECDHE 算法进行密钥交换，用 RSA 签名和身份认证，握手后的通信使用 AES 对称算法，密钥长度 256 位，分组模式是 GCM，摘要算法 SHA384 用于消息认证和产生随机数。” OpenSSL 是一个著名的开源密码学程序库和工具包，几乎支持所有公开的加密算法和协议，已经成为了事实上的标准，许多应用软件都会使用它作为底层库来实现 TLS 功能，包括常用的 Web 服务器 Apache、Nginx 等。 对称与非对称加密实现机密性最常用的手段是“加密”（encrypt），就是把消息用某种方式转换成谁也看不懂的乱码，只有掌握特殊“钥匙”的人才能再转换出原始文本。 这里的“钥匙”就叫做“密钥”（key），加密前的消息叫“明文”（plain text&#x2F;clear text），加密后的乱码叫“密文”（cipher text），使用密钥还原明文的过程叫“解密”（decrypt），是加密的反操作，加密解密的操作过程就是“加密算法”。 按照密钥的使用方式，加密可以分为两大类：对称加密和非对称加密。 对称加密 “对称加密”就是指加密和解密时使用的密钥都是同一个，是“对称”的，只要保证了密钥的安全，那整个通信过程就可以说具有了机密性。 TLS 里有非常多的对称加密算法可供选择，比如 RC4、DES、3DES、AES、ChaCha20 等，但前三种算法都被认为是不安全的，通常都禁止使用，目前常用的只有 AES 和 ChaCha20。 AES 的意思是“高级加密标准”（Advanced Encryption Standard），密钥长度可以是 128、192 或 256。它是 DES 算法的替代者，安全强度很高，性能也很好，而且有的硬件还会做特殊优化，所以非常流行，是应用最广泛的对称加密算法 ChaCha20 是 Google 设计的另一种加密算法，密钥长度固定为 256 位，纯软件运行性能要超过 AES，曾经在移动客户端上比较流行，但 ARMv8 之后也加入了 AES 硬件优化，所以现在不再具有明显的优势，但仍然算得上是一个不错算法 非对称加密 对称加密看上去好像完美地实现了机密性，但其中有一个很大的问题：如何把密钥安全地传递给对方，术语叫“密钥交换”。 非对称加密（也叫公钥加密算法）有两个密钥，一个叫“公钥”（public key），一个叫“私钥”（private key）。两个密钥是不同的，“不对称”，公钥可以公开给任何人使用，而私钥必须严格保密。 公钥和私钥有个特别的“单向”性，虽然都可以用来加密解密，但公钥加密后只能用私钥解密，反过来，私钥加密后也只能用公钥解密。 非对称加密可以解决“密钥交换”的问题。网站秘密保管私钥，在网上任意分发公钥，你想要登录网站只要用公钥加密就行了，密文只能由私钥持有者才能解密。而黑客因为没有私钥，所以就无法破解密文。 非对称加密算法的设计要比对称算法难得多，在 TLS 里只有很少的几种，比如 DH、DSA、RSA、ECC 等 RSA 可能是其中最著名的一个，几乎可以说是非对称加密的代名词，它的安全性基于“整数分解”的数学难题，使用两个超大素数的乘积作为生成密钥的材料，想要从公钥推算出私钥是非常困难的。 ECC（Elliptic Curve Cryptography）是非对称加密里的“后起之秀”，它基于“椭圆曲线离散对数”的数学难题，使用特定的曲线方程和基点生成公钥和私钥，子算法 ECDHE 用于密钥交换，ECDSA 用于数字签名。 混合加密 然非对称加密没有“密钥交换”的问题，但因为它们都是基于复杂的数学难题，运算速度很慢，即使是 ECC 也要比 AES 差上好几个数量级。如果仅用非对称加密，虽然保证了安全，但通信速度有如乌龟、蜗牛，实用性就变成了零。 RSA 的运算速度是非常慢的，2048 位的加解密大约是 15KB&#x2F;S（微秒或毫秒级），而 AES128 则是 13MB&#x2F;S（纳秒级），差了几百倍。 TLS 里使用的混合加密方式，解决了对称加密算法的密钥交换问题，而且 安全和性能兼顾，完美地实现了 机密性。 数字签名与证书仅有机密性，离安全还差的很远，黑客虽然拿不到会话密钥，无法破解密文，但可以通过窃听收集到足够多的密文，再尝试着修改、重组后发给网站，另外，黑客也可以伪造身份发布公钥。如果你拿到了假的公钥，混合加密就完全失效了。你以为自己是在和“某宝”通信，实际上网线的另一端却是黑客，银行卡号、密码等敏感信息就在“安全”的通信过程中被窃取了 摘要算法 实现完整性的手段主要是摘要算法（Digest Algorithm），也就是常说的散列函数、哈希函数（Hash Function） 可以把摘要算法近似地理解成一种特殊的压缩算法，它能够把任意长度的数据“压缩”成固定长度、而且独一无二的“摘要”字符串，就好像是给这段数据生成了一个数字“指纹” 也可以把摘要算法理解成特殊的“单向”加密算法，它只有算法，没有密钥，加密后的数据无法解密，不能从摘要逆推出原文 MD5（Message-Digest 5）和 SHA-1（Secure Hash Algorithm 1），是最常用的两个摘要算法，能够生成 16 字节和 20 字节长度的数字摘要，但这两个算法的安全强度比较低，不够安全，在 TLS 里已经被禁止使用了，目前 TLS 推荐使用的是 SHA-1 的后继者：SHA-2 SHA-2 实际上是一系列摘要算法的统称，总共有 6 种，常用的有 SHA224、SHA256、SHA384，分别能够生成 28 字节、32 字节、48 字节的摘要 完整性 摘要算法保证了“数字摘要”和原文是完全等价的。所以，我们只要在原文后附上它的摘要，就能够保证数据的完整性 不过摘要算法不具有机密性，如果明文传输，那么黑客可以修改消息后把摘要也一起改了，网站还是鉴别不出完整性，所以真正的完整性必须要建立在机密性之上，在混合加密系统里用会话密钥加密消息和摘要，这样黑客无法得知明文，也就没有办法动手脚了 数字签名 加密算法结合摘要算法，我们的通信过程可以说是比较安全了。但这里还有漏洞，就是通信的两个端点（endpoint） 使用 非对称加密+摘要算法，就能够实现“数字签名”，同时实现“身份认证”和“不可否认” 签名：使用私钥对数据（通常是数据的哈希值）进行加密的过程，这个过程产生一个数字签名，该签名是唯一的，并且只能由持有相应公钥的人来解密 验签：使用与签名私钥对应的公钥来解密签名，并验证其有效性 数字证书和 CA CA（Certificate Authority，证书认证机构）像网络世界里的公安局、教育部、公证中心，具有极高的可信度，由它来给各个 公钥 签名，用自身的信誉来保证公钥无法伪造，是可信的，解决“公钥的信任”问题 CA 对公钥的签名认证也是有格式的，不是简单地把公钥绑定在持有者身份上就完事了，还要包含序列号、用途、颁发者、有效时间等等，把这些打成一个包再签名，完整地证明公钥关联的各种信息，形成“数字证书”（Certificate） 知名的 CA 全世界就那么几家，比如 DigiCert、VeriSign、Entrust、Let’s Encrypt 等，它们签发的证书分 DV、OV、EV 三种，区别在于可信程度。 小一点的 CA 可以让大 CA 签名认证，但链条的最后，也就是 Root CA，就只能自己证明自己了，这个就叫“自签名证书”（Self-Signed Certificate）或者“根证书”（Root Certificate）。你必须相信，否则整个证书信任链就走不下去了 操作系统和浏览器都内置了各大 CA 的根证书，上网的时候只要服务器发过来它的证书，就可以验证证书里的签名，顺着证书链（Certificate Chain）一层层地验证，直到找到根证书，就能够确定证书是可信的，从而里面的公钥也是可信的 TLS 1.2 连接过程TLS 包含几个子协议，比较常用的有记录协议、警报协议、握手协议、变更密码规范协议等 记录协议（Record Protocol）规定了 TLS 收发数据的基本单位：记录（record）。它有点像是 TCP 里的 segment，所有的其他子协议都需要通过记录协议发出。但多个记录数据可以在一个 TCP 包里一次性发出，也并不需要像 TCP 那样返回 ACK 警报协议（Alert Protocol）的职责是向对方发出警报信息，有点像是 HTTP 协议里的状态码。比如，protocol_version 就是不支持旧版本，bad_certificate 就是证书有问题，收到警报后另一方可以选择继续，也可以立即终止连接 握手协议（Handshake Protocol）是 TLS 里最复杂的子协议，要比 TCP 的 SYN&#x2F;ACK 复杂的多，浏览器和服务器会在握手过程中协商 TLS 版本号、随机数、密码套件等信息，然后交换证书和密钥参数，最终双方协商得到会话密钥，用于后续的混合加密系统 变更密码规范协议（Change Cipher Spec Protocol），是一个“通知”，告诉对方，后续的数据都将使用加密保护。那么反过来，在它之前，数据都是明文的 ECDHE 握手过程 在 TCP 建立连接之后，客户端会首先发一个“Client Hello”消息，也就是跟服务器“打招呼”。里面有客户端的版本号、支持的密码套件，还有一个 随机数（Client Random），用于后续生成会话密钥。 服务器收到“Client Hello”后，会返回一个“Server Hello”消息。把版本号对一下，也给出一个 随机数（Server Random），然后从客户端的列表里选一个作为本次通信使用的密码套件 服务器为了证明自己的身份，就把 证书 也发给了客户端（Server Certificate） 因为服务器选择了 ECDHE 算法，所以它会在证书后发送“Server Key Exchange”消息，里面是 椭圆曲线的公钥（Server Params），用来实现密钥交换算法，再加上自己的私钥签名认证 客户端和服务器通过明文共享了三个信息：Client Random、Server Random 和 Server Params 客户端按照密码套件的要求，也生成一个 椭圆曲线的公钥（Client Params），用“Client Key Exchange”消息发给服务器 客户端和服务器手里都拿到了密钥交换算法的两个参数（Client Params、Server Params），就用 ECDHE 算法一阵算，算出了一个新的东西，叫“Pre-Master”，其实也是一个随机数 现在客户端和服务器手里有了三个随机数：Client Random、Server Random 和 Pre-Master。用这三个作为原始材料，就可以生成用于加密会 话的主密钥，叫“Master Secret”。而黑客因为拿不到“Pre-Master”，所以也就得不到主密钥 有了主密钥和派生的会话密钥，握手就快结束了。客户端发一个“Change Cipher Spec”，然后再发一个“Finished”消息，把之前所有发送的数据做个摘要，再加密一下，让服务器做个验证 服务器也是同样的操作，发“Change Cipher Spec”和“Finished”消息，双方都验证加密解密 OK，握手正式结束，后面就收发被加密的 HTTP 请求和响应了 双向认证 上面说的是“单向认证”握手过程，只认证了服务器的身份，而没有认证客户端的身份。这是因为通常单向认证通过后已经建立了安全通信，用账号、密码等简单的手段就能够确认用户的真实身份。 但为了防止账号、密码被盗，有的时候（比如网上银行）还会使用 U 盾给用户颁发客户端证书，实现“双向认证”，这样会更加安全。 双向认证的流程也没有太多变化，只是在“Server Hello Done”之后，“Client Key Exchange”之前，客户端要发送“Client Certificate”消息，服务器收到后也把证书链走一遍，验证客户端的身份。 TLS 1.3 特性解析 TLS1.3 的三个主要改进目标：兼容、安全与性能 最大化兼容性 强化安全 提升性能 Other PointsHTTP 2HTTP 有两个主要的缺点：安全不足和性能不高。 HTTPS，通过引入 SSL&#x2F;TLS 在安全上达到了“极致”，但在性能提升方面却是乏善可陈，只优化了握手加密的环节，对于整体的数据传输没有提出更好的改进方案，还只能依赖于“长连接”这种“落后”的技术。 在 HTTPS 逐渐成熟之后，HTTP 就向着性能方面开始“发力”，走出了另一条进化的道路。 与 HTTPS 不同，HTTP&#x2F;2 没有在 URI 里引入新的协议名，仍然用“http”表示明文协议，用“https”表示加密协议 兼容 HTTP&#x2F;1 头部压缩 二进制格式 虚拟的“流” 强化安全 协议栈 HTTP 3 NGINXWeb 服务器就那么几款，目前市面上主流的只有两个：Apache 和 Nginx，两者合计占据了近 90% 的市场份额。Nginx，它是 Web 服务器的“后起之秀”，虽然比 Apache 小了 10 岁，但增长速度十分迅猛。 Nginx 应该读成“Engine X”，但“X”念起来太“拗口”，倾向于读做“Engine ks”，这也与 UNIX、Linux 的发音一致 进程池 Nginx 作为“轻量级”的服务器，它的 CPU、内存占用都非常少，同样的资源配置下就能够为更多的用户提供服务，其奥秘在于它独特的工作模式。 在 Nginx 之前，Web 服务器的工作模式大多是“Per-Process”或者“Per-Thread”，对每一个请求使用单独的进程或者线程处理。这就存在创建进程或线程的成本，还会有进程、线程“上下文切换”的额外开销。如果请求数量很多，CPU 就会在多个进程、线程之间切换时“疲于奔命”，平白地浪费了计算时间。 Nginx 使用了“进程池 + 单线程”的工作模式，在启动的时候会预先创建好固定数量的 worker 进程，在之后的运行过程中不会再 fork 出新进程，这就是进程池，而且可以自动把进程“绑定”到独立的 CPU 上，这样就完全消除了进程创建和切换的成本，能够充分利用多核 CPU 的计算能力。 在进程池之上，还有一个“master”进程，用来监控进程，自动恢复发生异常的 worker，保持进程池的稳定和服务能力。 I&#x2F;O 多路复用 Nginx 就选择了单线程的方式，带来的好处就是开发简单，没有互斥锁的成本，减少系统消耗。单线程的 Nginx，处理能力却能够超越其他多线程的服务器要归功于 Nginx 利用了 Linux 内核里的一件“神兵利器”，I&#x2F;O 多路复用接口，“大名鼎鼎”的 epoll。 Web 服务器从根本上来说是“I&#x2F;O 密集型”而不是“CPU 密集型”，处理能力的关键在于网络收发而不是 CPU 计算（这里暂时不考虑 HTTPS 的加解密），而网络 I&#x2F;O 会因为各式各样的原因不得不等待，比如数据还没到达、对端没有响应、缓冲区满发不出去等等。 对于一般的单线程来说 CPU 就会“停下来”，造成浪费 多线程的解决思路有点类似“并发连接”，虽然有的线程可能阻塞，但由于多个线程并行，总体上看阻塞的情况就不会太严重了。 Nginx 里使用的 epoll，就好像是 HTTP&#x2F;2 里的“多路复用”技术，它把多个 HTTP 请求处理打散成碎片，都“复用”到一个单线程里，不按照先来后到的顺序处理，而是只当连接上真正可读、可写的时候才处理，如果可能发生阻塞就立刻切换出去，处理其他的请求。 通过这种方式，Nginx 就完全消除了 I&#x2F;O 阻塞，把 CPU 利用得“满满当当”，又因为网络收发并不会消耗太多 CPU 计算能力，也不需要切换进程、线程，所以整体的 CPU 负载是相当低的。 epoll 还有一个特点，大量的连接管理工作都是在操作系统内核里做的，这就减轻了应用程序的负担，所以 Nginx 可以为每个连接只分配很小的内存维护状态，即使有几万、几十万的并发连接也只会消耗几百 M 内存，而其他的 Web 服务器这个时候早就“Memory not enough”了。 多阶段处理 Nginx 在内部也采用的是“化整为零”的思路，把整个 Web 服务器分解成了多个“功能模块”，Nginx 的 HTTP 处理有四大类模块： handler 模块：直接处理 HTTP 请求； filter 模块：不直接处理请求，而是加工过滤响应报文； upstream 模块：实现反向代理功能，转发请求到其他服务器； balance 模块：实现反向代理时的负载均衡算法。 Nginx 里的 handler 模块和 filter 模块就是按照“职责链”模式设计和组织的，HTTP 请求报文就是“原材料”，各种模块就是工厂里的工人，走完模块构成的“流水线”，出来的就是处理完成的响应报文。 Nginx 的“流水线”，在 Nginx 里的术语叫“阶段式处理”（Phases），一共有 11 个阶段，每个阶段里又有许多各司其职的模块。 WAFHTTPS 只是网络安全中很小的一部分，仅仅保证了“通信链路安全”，让第三方无法得知传输的内容。在通信链路的两端，也就是客户端和服务器，它是无法提供保护的。 Web 服务遇到的威胁 DDoS（distributed denial-of-service attack），耗尽带宽、CPU 和内存，导致网站完全无法提供正常服务 SQL 注入（SQL injection），利用了服务器字符串拼接形成 SQL 语句的漏洞，构造出非正常的 SQL 语句；HTTP 头注入攻击的方式也是类似的原理，服务端程序如果解析不当，就会执行预设的恶意代码 网络应用防火墙 传统“防火墙”工作在三层或者四层，隔离了外网和内网，使用预设的规则，只允许某些特定 IP 地址和端口号的数据包通过，拒绝不符合条件的数据流入或流出内网，实质上是一种网络数据过滤设备。 WAF （Web Application Firewall）也是一种“防火墙”，但它工作在七层，看到的不仅是 IP 地址和端口号，还能看到整个 HTTP 报文，所以就能够对报文内容做更深入细致的审核，使用更复杂的条件、规则来过滤数据。 WAF 就是一种“HTTP 入侵检测和防御系统”，通常一款产品能够称为 WAF，要具备下面的一些功能： IP 黑名单和白名单，拒绝黑名单上地址的访问，或者只允许白名单上的用户访问； URI 黑名单和白名单，与 IP 黑白名单类似，允许或禁止对某些 URI 的访问； 防护 DDoS 攻击，对特定的 IP 地址限连限速； 过滤请求报文，防御“代码注入”攻击； 过滤响应报文，防御敏感信息外泄； 审计日志，记录所有检测到的入侵操作。 WAF 就像是平时编写程序时必须要做的函数入口参数检查，拿到 HTTP 请求、响应报文，用字符串处理函数看看有没有关键字、敏感词，或者用正则表达式做一下模式匹配，命中了规则就执行对应的动作，比如返回 403&#x2F;404。 网络安全领域必须时刻记得“木桶效应”（也叫“短板效应”），网站的整体安全不在于你加固的最强的那个方向，而是在于你可能都没有意识到的“短板”，使用 WAF 最好“不要重新发明轮子”，而是使用现有的、比较成熟的、经过实际考验的 WAF 产品。 CDN光速是有限的，虽然每秒 30 万公里，但这只是真空中的上限，在实际的电缆、光缆中的速度会下降到原本的三分之二左右，也就是 20 万公里 &#x2F; 秒，这样一来，地理位置的距离导致的传输延迟就会变得比较明显了。 此外，互联网从逻辑上看是一张大网，但实际上是由许多小网络组成的，网络内部的沟通很顺畅，但网络之间却只有很少的联通点。 还有，网络中还存在许多的路由器、网关，数据每经过一个节点，都要停顿一下，在二层、三层解析转发，这也会消耗一定的时间，带来延迟。把这些因素再放到全球来看，地理距离、运营商网络、路由转发的影响就会成倍增加。 什么是 CDN CDN 的最核心原则是“就近访问”，如果用户能够在本地几十公里的距离之内获取到数据，那么时延就基本上变成 0 了，所以 CDN 投入了大笔资金，在全国、乃至全球的各个大枢纽城市都建立了机房，部署了大量拥有高存储高带宽的节点，构建了一个专用网络。 用户在上网的时候就不直接访问源站，而是访问离他“最近的”一个 CDN 节点，术语叫“边缘节点”（edge node），其实就是缓存了源站内容的代理服务器，这样一来就省去了“长途跋涉”的时间成本，实现了“网络加速”。 在 CDN 领域里，“内容”其实就是 HTTP 协议里的“资源”，比如超文本、图片、视频、应用程序安装包等等。很显然，只有静态资源才能够被缓存加速、就近访问，而动态资源只能由源站实时生成，即使缓存了也没有意义。 不过，如果动态资源指定了“Cache-Control”，允许缓存短暂的时间，那它在这段时间里也就变成了“静态资源”，可以被 CDN 缓存加速。 CDN 的负载均衡 全局负载均衡（Global Sever Load Balance）一般简称为 GSLB，它是 CDN 的“大脑”，主要的职责是当用户接入网络的时候在 CDN 专网中挑选出一个“最佳”节点提供服务，解决的是用户如何找到“最近的”边缘节点，对整个 CDN 网络进行“负载均衡”。 GSLB 最常见的实现方式是“DNS 负载均衡”，原来没有 CDN 的时候，权威 DNS 返回的是网站自己服务器的实际 IP 地址，浏览器收到 DNS 解析结果后直连网站。 加入 CDN 后，权威 DNS 返回的不是 IP 地址，而是一个 CNAME( Canonical Name ) 别名记录，指向的就是 CDN 的 GSLB，因为没拿到 IP 地址，于是本地 DNS 就会向 GSLB 再发起请求，这样就进入了 CDN 的全局负载均衡系统，开始“智能调度”，主要的依据有这么几个： 看用户的 IP 地址，查表得知地理位置，找相对最近的边缘节点； 看用户所在的运营商网络，找相同网络的边缘节点； 检查边缘节点的负载情况，找负载较轻的节点； 其他，比如节点的“健康状况”、服务能力、带宽、响应时间等。 GSLB 把这些因素综合起来，用一个复杂的算法，最后找出一台“最合适”的边缘节点，把这个节点的 IP 地址返回给用户，用户就可以“就近”访问 CDN 的缓存代理了。 CDN 的缓存代理 缓存系统是 CDN 的另一个关键组成部分，相当于 CDN 的“心脏”。如果缓存系统的服务能力不够，不能很好地满足用户的需求，那 GSLB 调度算法再优秀也没有用。 两个 CDN 的关键概念：“命中”和“回源”： “命中”就是指用户访问的资源恰好在缓存系统里，可以直接返回给用户 “回源”则正相反，缓存里没有，必须用代理的方式回源站取。 相应地，也就有了两个衡量 CDN 服务质量的指标：“命中率”和“回源率”，好的 CDN 应该是命中率越高越好，回源率越低越好。现在的商业 CDN 命中率都在 90% 以上，相当于把源站的服务能力放大了 10 倍以上。 怎么样才能尽可能地提高命中率、降低回源率： 硬件方面：在存储系统上下功夫，硬件用高速 CPU、大内存、万兆网卡，再搭配 TB 级别的硬盘和快速的 SSD 软件方面：不断“求新求变”，各种新的存储软件，比如 Memcache、Redis、Ceph，尽可能地高效利用存储，存下更多的内容 缓存系统：划分出层次，分成一级缓存节点和二级缓存节点。一级缓存配置高一些，直连源站，二级缓存配置低一些，直连用户 高性能的缓存服务：国内的 CDN 厂商内部都是基于开源软件定制，最常用的是专门的缓存代理软件 Squid、Varnish 和 ATS（Apache Traffic Server），Nginx 和 OpenResty 作为 Web 服务器领域的“多面手”，凭借着强大的反向代理能力和模块化、易于扩展的优点，也在 CDN 里占据了不少的份额 WebSocketTCP Socket 是一种功能接口，通过这些接口就可以使用 TCP&#x2F;IP 协议栈在传输层收发数据，TCP 连接是全双工的。 WebSocket 就是运行在 Web，也就是 HTTP 上的 Socket 通信规范，提供与 TCP Socket 类似的功能，使用它可以像 TCP Socket 一样调用下层协议栈，任意地收发数据。更准确地说，WebSocket 是一种基于 TCP 的轻量级网络通信协议，在地位上是与 HTTP“平级”的。 WebSocket 与 HTTP&#x2F;2 一样，都是为了解决 HTTP 某方面的缺陷而诞生的，HTTP&#x2F;2 针对的是“队头阻塞”，而 WebSocket 针对的是“请求 - 应答”通信模式。 “请求 - 应答”是一种“半双工”的通信模式，虽然可以双向收发数据，但同一时刻只能一个方向上有动作，传输效率低。更关键的一点，它是一种“被动”通信模式，服务器只能“被动”响应客户端的请求，无法主动向客户端发送数据。 HTTP 难以应用在动态页面、即时消息、网络游戏等要求“实时通信”的领域 浏览器是一个“受限的沙盒”，不能用 TCP，只有 HTTP 协议可用，在 WebSocket 出现之前，在浏览器环境里用 JavaScript 开发实时 Web 应用很麻烦，就出现了很多“变通”的技术，“轮询”（polling）就是比较常用的的一种。 如果轮询的频率比较高，那么就可以近似地实现“实时通信”的效果。轮询的缺点也很明显，反复发送无效查询请求耗费了大量的带宽和 CPU 资源，非常不经济。 WebSocket 的特点 WebSocket 是一个真正“全双工”的通信协议，与 TCP 一样，客户端和服务器都可以随时向对方发送数据。服务器就可以变得更加“主动”了，一旦后台有新的数据，就可以立即“推送”给客户端，不需要客户端轮询，“实时通信”的效率也就提高了。 WebSocket 采用了二进制帧结构，语法、语义与 HTTP 完全不兼容，但因为它的主要运行环境是浏览器，为了便于推广和应用，在使用习惯上尽量向 HTTP 靠拢，这就是它名字里“Web”的含义。 服务发现方面，WebSocket 没有使用 TCP 的“IP 地址 + 端口号”，而是延用了 HTTP 的 URI 格式，但开头的协议名不是“http”，引入的是两个新的名字：“ws”和“wss”，分别表示明文和加密的 WebSocket 协议。 WebSocket 的默认端口也选择了 80 和 443，因为现在互联网上的防火墙屏蔽了绝大多数的端口，只对 HTTP 的 80、443 端口“放行”，所以 WebSocket 就可以“伪装”成 HTTP 协议，比较容易地“穿透”防火墙，与服务器建立连接。 虽然大多数情况下会在浏览器里调用 API 来使用 WebSocket，但它不是一个“调用接口的集合”，而是一个通信协议，把它理解成“TCP over Web”会更恰当一些。 WebSocket 的帧结构 WebSocket 的握手 总结 浏览器是一个“沙盒”环境，有很多的限制，不允许建立 TCP 连接收发数据，而有了 WebSocket，我们就可以在浏览器里与服务器直接建立“TCP 连接”，获得更多的自由。 不过自由也是有代价的，WebSocket 虽然是在应用层，但使用方式却与“TCP Socket”差不多，过于“原始”，用户必须自己管理连接、缓存、状态，开发上比 HTTP 复杂的多，所以是否要在项目中引入 WebSocket 必须慎重考虑。 HTTP 的“请求 - 应答”模式不适合开发“实时通信”应用，效率低，难以实现动态页面，所以出现了 WebSocket； WebSocket 是一个“全双工”的通信协议，相当于对 TCP 做了一层“薄薄的包装”，让它运行在浏览器环境里； WebSocket 使用兼容 HTTP 的 URI 来发现服务，但定义了新的协议名“ws”和“wss”，端口号也沿用了 80 和 443； WebSocket 使用二进制帧，结构比较简单，特殊的地方是有个“掩码”操作，客户端发数据必须掩码，服务器则不用； WebSocket 利用 HTTP 协议实现连接握手，发送 GET 请求要求“协议升级”，握手过程中有个非常简单的认证机制，目的是防止误连接。 HTTP 性能优化参考资料 透视 HTTP 协议 趣谈网络协议","tags":["HTTP"],"categories":["Network"]},{"title":"MySQL /maɪ ˈsiːkwəl/ 原理与实践 💽","path":"/2024/06/28/mysql/","content":"梳理 MySQL 知识体系 SQL 执行graph LR 客户端-->连接器 连接器-->查询缓存 连接器-->分析器 查询缓存--命中则 直接返回结果-->客户端 分析器-->优化器 优化器-->执行器 执行器-->存储引擎 存储引擎 Server 层：连接器、查询缓存、分析器、优化器、执行器等（包括内置函数、存储过程、触发器、视图等） 连接器：负责跟客户端建立连接、获取权限、维持和管理连接，客户端如果太长时间没动静，连接器就会自动将它断开 查询缓存：key 是查询的语句，value 是查询的结果（查询缓存命中率通常很低），8.0 版本将查询缓存的整块功能删除 分析器：根据词法分析的结果，语法分析器会根据语法规则，判断输入的这个 SQL 语句是否满足 MySQL 语法 优化器：在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序 执行器：开始执行的时候，要先判断一下你对这个表 T 有没有执行的权限，然后使用引擎提供的接口 存储引擎层：负责数据的存储和提取，插件式支持 InnoDB（5.5.5 后默认）、MyISAM、Memory 等存储引擎 日志与查询流程不一样的是，更新流程还涉及两个重要的日志模块：redo log（重做日志）和 binlog（归档日志）。 redo logMySQL 中的 WAL（Write-Ahead Logging）关键点就是先写日志，再写磁盘。当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 redo log 里面，并更新内存，这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做。 InnoDB 的 redo log 是固定大小的文件，从头开始写，写到末尾就又回到开头循环写。有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为 crash-safe。 binlogredo log 是 InnoDB 引擎特有的日志，而 Server 层也有自己的日志，称为 binlog（归档日志），这两种日志有以下三点不同： redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。 redo log 是 物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是 逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID &#x3D; 2 这一行的 c 字段加 1 ”。 redo log 是 循环写 的，空间固定会用完；binlog 是可以 追加写 入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。 执行器和 InnoDB 引擎在执行这个简单的 update 语句时的内部流程： graph A[取 ID=2 这一行] --> B(数据页在内存中?) B --> |是| C[返回行数据] B --> |否| D[磁盘中读入内存] D --> C C --> E[将这行的 C 值加 1] E --> F[写入新行] F --> G[新行更新到内存] G --> H[写入 redo log 处于 prepare 阶段] H --> I[写 binlog] I --> J[提交事务 redo log 处于 commit 状态] 两阶段提交为了 让两份日志之间的逻辑一致，将 redo log 的写入拆成了两个步骤：prepare 和 commit，这就是”两阶段提交”。 如果不使用“两阶段提交”，那么数据库的状态就有可能和用它的日志恢复出来的库的状态不一致。 binlog 会记录所有的逻辑操作，并且是采用“追加写”的形式。如果 DBA 承诺说半个月内可以恢复，那么备份系统中一定会保存最近半个月的所有 binlog，同时系统会定期做整库备份。 redo log 用于保证 crash-safe 能力。innodb_flush_log_at_trx_commit 这个参数设置成 1 的时候，表示每次事务的 redo log 都直接持久化到磁盘，这样可以保证 MySQL 异常重启之后数据不丢失。 sync_binlog 这个参数设置成 1 的时候，表示每次事务的 binlog 都持久化到磁盘，这样可以保证 MySQL 异常重启之后 binlog 不丢失。 事务简单来说，事务就是要保证一组数据库操作，要么全部成功，要么全部失败。在 MySQL 中，事务支持是在引擎层实现的。事务的 ACID（Atomicity、Consistency、Isolation、Durability） 即原子性、一致性、隔离性、持久性。 隔离级别当数据库上有 多个事务同时执行 的时候，就可能出现 脏读（dirty read）、不可重复读（non-repeatable read）、幻读（phantom read） 的问题，为了解决这些问题，就有了“隔离级别”的概念。 隔离得越严实，效率就会越低，SQL 标准的事务隔离级别包括读未提交（read uncommitted）、读提交（read committed）、可重复读（repeatable read） 和 串行化（serializable ）： 读未提交：一个事务还没提交时，它做的变更就能被别的事务看到。 读提交：一个事务提交之后，它做的变更才会被其他事务看到。 可重复读：一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然，在可重复读隔离级别下，未提交变更对其他事务也是不可见的。 串行化：对于同一行记录，“写”会加“写锁”，“读”会加“读锁”，当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。 在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准： 读未提交：直接返回记录上的最新值，没有视图概念 读提交：视图是 在每个 SQL 语句开始执行的时候 创建的 可重复读：视图是 在事务启动时 创建的，整个事务存在期间都用这个视图 串行化：直接用加锁的方式 来避免并行访问 什么时候需要“可重复读”的场景呢？ 假设管理一个个人银行账户表，一个表存了每个月月底的余额，一个表存了账单明细。这时候要做数据校对，也就是判断上个月的余额和当前余额的差额，是否与 本月的账单明细 一致。一定希望 在校对过程中，即使有用户发生了一笔新的交易，也不影响你的校对结果。 这时候使用“可重复读”隔离级别就很方便。事务启动时的视图可以认为是静态的，不受其他事务更新的影响。 启动方式MySQL 的事务启动方式有以下几种： 显式启动事务语句， begin 或 start transaction。配套的提交语句是 commit，回滚语句是 rollback。 set autocommit=0，这个命令会将这个线程的 自动提交 关掉。意味着如果你只执行一个 select 语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你 主动 执行 commit 或 rollback 语句，或者断开连接。 隔离的实现在 MySQL 中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值，当没有事务再需要用到这些回滚日志时（就是当系统里没有比这个回滚日志更早的 read-view 的时候），回滚日志会被删除。 假设一个值从 1 被按顺序改成了 2、3、4，不同时刻启动的事务查询这条记录会有不同的 read-view，即同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC）。 为什么尽量不要使用长事务？ 长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致 大量占用存储空间。除了对回滚段的影响，长事务还 占用锁资源，也可能拖垮整个库。 如何避免长事务对业务的影响？ 从应用开发端来看： 确认是否使用了 set autocommit &#x3D; 0。这个确认工作可以在测试环境中开展，把 MySQL 的 general_log 开起来，然后随便跑一个业务逻辑，通过 general_log 的日志来确认。一般框架如果会设置这个值，也就会提供参数来控制行为，目标就是把它改成 1。 确认是否有不必要的 只读事务。有些框架会习惯不管什么语句先用 begin&#x2F;commit 框起来。有些是业务并没有这个需要，但是也 把好几个 select 语句放到了事务中。这种只读事务可以去掉。 业务连接数据库的时候，根据业务本身的预估，通过 SET MAX_EXECUTION_TIME 命令，来 控制每个语句执行的最长时间，避免单个语句意外执行太长时间。 从数据库端来看： 监控 information_schema.Innodb_trx 表，设置长事务阈值，超过就报警 &#x2F; 或者 kill； Percona 的 pt-kill 工具； 在业务功能测试阶段要求输出所有的 general_log，分析日志行为提前发现问题； 如果使用的是 MySQL 5.6 或者更新版本，把 innodb_undo_tablespaces 设置成 2（或更大的值）。如果真的出现大事务导致回滚段过大，这样设置后清理起来更方便。 事务到底是隔离的还是不隔离的？ begin/start transaction 命令并不是一个事务的起点，在执行到它们之后的第一个操作 InnoDB 表的语句，事务才真正启动。如果想要马上启动一个事务，可以使用 start transaction with consistent snapshot 这个命令。 第一种启动方式，一致性视图是在第执行第一个快照读语句时创建的； 第二种启动方式，一致性视图是在执行 start transaction with consistent snapshot时创建的。 在 MySQL 里，有两个“视图”的概念： 一个是 view。它是一个用查询语句定义的虚拟表，在调用的时候执行查询语句并生成结果。创建视图的语法是 create view … ，而它的查询方法与表一样。 另一个是 InnoDB 在实现 MVCC 时用到的一致性读视图，即 consistent read view，用于支持 RC（Read Committed，读提交）和 RR（Repeatable Read，可重复读）隔离级别的实现。 它没有物理结构，作用是事务执行期间用来定义“我能看到什么数据”。 “快照”在 MVCC 里是怎么工作的？ 在可重复读隔离级别下，事务在启动的时候就“拍了个快照”。注意，这个快照是 基于整库 的（但并不需要拷贝整库数据）。 InnoDB 里面每个事务有一个唯一的事务 ID，叫作 transaction id。它是在事务开始的时候向 InnoDB 的事务系统申请的，是按申请顺序严格递增的。 而每行数据也都是有多个版本的。每次事务更新数据的时候，都会生成一个新的数据版本，并且把 transaction id 赋值给这个数据版本的事务 ID，记为 row trx_id。 数据表中的一行记录，其实可能有多个版本 (row)，每个版本有自己的 row trx_id。 graph LR V1[\"V1 (k=1)row trx-id=10\"] V2[\"V2 (k=10)row trx-id=15\"] V3[\"V3 (k=11)row trx-id=17\"] V4[\"V4 (k=22)row trx-id=25\"] V1 -->|U1: set k=10transaction id=15| V2 V2 -->|U2: set k=k+1transaction id=17| V3 V3 -->|U3: set k=k*2transaction id=25| V4 按照可重复读的定义，一个事务启动的时候，能够看到所有已经提交的事务结果。但是之后，这个事务执行期间，其他事务的更新对它不可见。即一个事务以启动的时刻为准，如果一个数据版本是在启动之前生成的就认；如果是启动以后才生成的就不认，如果是这个事务自己更新的数据，还是要认的。 在实现上， InnoDB 为每个事务构造了一个数组，用来保存这个事务启动瞬间，当前正在“活跃”的所有事务 ID。“活跃”指的就是，启动了但还没提交。数组里面事务 ID 的最小值记为低水位，当前系统里面已经创建过的事务 ID 的最大值加 1 记为高水位。这个视图数组和高水位，就组成了当前事务的一致性视图（read-view）。而数据版本的可见性规则，就是基于数据的 row trx_id 和这个一致性视图的对比结果得到的。 graph LR A[\"已提交事务\"] B[\"未提交事务集合\"] C[\"未开始事务\"] D[\"当前事务\"] A |低水位| B B |高水位| C D --> B 对于当前事务的启动瞬间来说，一个数据版本的 row trx_id，有以下几种可能： 如果落在绿色部分，表示这个版本是已提交的事务或者是当前事务自己生成的，这个数据是可见的； 如果落在红色部分，表示这个版本是由将来启动的事务生成的，是肯定不可见的； 如果落在黄色部分，那就包括两种情况 若 row trx_id 在数组中，表示这个版本是由还没提交的事务生成的，不可见； 若 row trx_id 不在数组中，表示这个版本是已经提交了的事务生成的，可见。 InnoDB 利用了“所有数据都有多个版本”的这个特性，实现了“秒级创建快照”的能力。 一个数据版本，对于一个事务视图来说，除了自己的更新总是可见以外，有三种情况： 版本未提交，不可见； 版本已提交，但是是在视图创建后提交的，不可见； 版本已提交，而且是在视图创建前提交的，可见。 更新逻辑 当要去更新数据的时候，就不能再在历史版本上更新了，否则其他事务的更新就丢失了，这里就用到了这样一条规则：更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）。 除了 update 语句外，select 语句如果加锁，也是当前读。 select * from t where id=1 改为修改一下，加上 lock in share mode 或 for update，下面这两个 select 语句，就是分别加了读锁（S 锁，共享锁）和写锁（X 锁，排他锁）。 12mysql&gt; select k from t where id=1 lock in share mode;mysql&gt; select k from t where id=1 for update; 如果事务 C 没有提交，在同一行的写锁还没释放，事务 B 是当前读必须要读最新版本，而且必须加锁，因此就被锁住了，必须等到事务 C 释放这个锁，才能继续它的当前读。 可重复读的核心就是一致性读（consistent read）；而事务更新数据的时候，只能用当前读。如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待。 而读提交的逻辑和可重复读的逻辑类似，它们最主要的区别是： 在可重复读隔离级别下，只需要在事务开始的时候创建一致性视图，之后事务里的其他查询都共用这个一致性视图； 在读提交隔离级别下，每一个语句执行前都会重新算出一个新的视图。 为什么表结构不支持“可重复读”？这是因为表结构没有对应的行数据，也没有 row trx_id，因此只能遵循当前读的逻辑，MySQL 8.0 已经可以把表结构放在 InnoDB 字典里了，也许以后会支持表结构的可重复读。 索引常见索引模型索引的常见模型有哈希表、有序数组、搜索树： 哈希表 是一种以键 - 值（key-value）存储数据的结构，拉链法解决哈希冲突的问题，区间需要全部扫描，哈希表这种结构适用于只有等值查询的场景。 有序数组 在等值查询和范围查询场景中的性能就都非常优秀，但是往中间插入一个记录就必须得挪动后面所有的记录，有序数组索引只适用于静态数据存储引擎。 二叉搜索树 为了维持 O(log(N)) 的查询复杂度，就需要保持这棵树是平衡二叉树，为了做这个保证，更新的时间复杂度也是 O(log(N))。 N 叉树 树可以有二叉，也可以有多叉，二叉树是搜索效率最高的，但是实际上大多数的数据库存储却并不使用二叉树，因为索引不止存在内存中，还要写到磁盘上 100 万节点的平衡二叉树，树高 20。一次查询可能需要访问 20 个数据块，在机械硬盘时代，从磁盘随机读一个数据块需要 10 ms 左右的寻址时间 为了让一个查询尽量少地读磁盘，就必须让查询过程访问尽量少的数据块则使用“N 叉”树，“N”取决于数据块的大小 以 InnoDB 的一个整数字段索引为例，这个 N 差不多是 1200。这棵树高是 4 的时候，就可以存 1200 的 3 次方个值，这已经 17 亿了 树根的数据块总是在内存中的（第二层也有很大概率在），一个 10 亿行的表上一个整数字段的索引，查找一个值最多只需要访问 2-3 次磁盘 N 叉树由于在读写上的性能优点，以及适配磁盘的访问模式，已经被广泛应用在数据库引擎中了 在 MySQL 中，索引是在存储引擎层实现的，所以并没有统一的索引标准，即不同存储引擎的索引的工作方式并不一样，而即使多个存储引擎支持同一种类型的索引，其底层的实现也可能不同。 InnoDB 索引模型在 InnoDB 中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表。InnoDB 使用了 B+ 树索引模型，所以数据都是存储在 B+ 树中的。 根据叶子节点的内容，索引类型分为 主键索引 和 非主键索引： 主键索引的叶子节点存的是整行数据，主键索引也被称为聚簇索引（clustered index） 非主键索引的叶子节点内容是主键的值，非主键索引也被称为二级索引（secondary index） 基于主键索引和普通索引的查询有什么区别？ 如果语句是 select * from T where ID &#x3D; 500，即主键查询方式，则只需要搜索 ID 这棵 B+ 树； 如果语句是 select * from T where k &#x3D; 5，即普通索引查询方式，则需要先搜索 k 索引树，得到 ID 的值为 500，再到 ID 索引树搜索一次。这个过程称为回表。 即基于非主键索引的查询需要多扫描一棵索引树 索引维护 页分裂：如果插入数据所在的数据页已经满了，根据 B+ 树的算法，这时候需要申请一个新的数据页，然后挪动部分数据过去 页合并：当相邻两个页由于删除了数据，利用率很低之后，会将数据页做合并（分裂过程的逆过程） 哪些场景下应该使用自增主键，而哪些场景下不应该？ 自增主键： NOT NULL PRIMARY KEY AUTO_INCREMENT，每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂，而有业务逻辑的字段做主键，则往往不容易保证有序插入，这样写数据成本相对较高。此外，主键长度越小，二级索引的叶子节点就越小，普通索引占用的空间也就越小。 如果业务的场景需求是只有一个索引且该索引必须是唯一索引（典型的 KV 场景），这时候就要优先考虑“尽量使用主键查询”原则，直接将这个索引设置为主键，可以避免每次查询需要搜索两棵树（避免回表）。 覆盖索引 select * from T where k between 3 and 5 的查找过程（k 上有索引）： 在 k 索引树上找到 k &#x3D; 3 的记录，取得 ID &#x3D; 300； 再到 ID 索引树查到 ID &#x3D; 300 对应的 R3； 在 k 索引树取下一个值 k &#x3D; 5，取得 ID &#x3D; 500； 再回到 ID 索引树查到 ID &#x3D; 500 对应的 R4； 在 k 索引树取下一个值 k &#x3D; 6，不满足条件，循环结束。 这个查询过程读了 k 索引树的 3 条记录（步骤 1、3 和 5），回表了两次（步骤 2 和 4），由于查询结果所需要的数据只在主键索引上有，所以 不得不回表。 如果执行的语句是 select ID from T where k between 3 and 5 ，这时只需要查 ID 的值，而 ID 的值已经在 k 索引树上了，因此可以直接提供查询结果，不需要回表。 需要注意的是，在引擎内部使用覆盖索引在索引 k 上其实读了三个记录，但是对于 MySQL 的 Server 层来说，它就是找引擎拿到了两条记录，因此 MySQL 认为扫描行数是 2。 由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。 是否有必要将身份证号和名字建立联合索引？ 如果有根据身份证号查询市民信息的需求，只要在身份证号字段上建立索引就够了。而再建立一个（身份证号、姓名）的联合索引，是不是浪费空间？如果有一个高频请求，要 根据市民的身份证号查询他的姓名，用到了覆盖索引，不再需要回表查整行记录，减少语句的执行时间。 索引字段的维护总是有代价的，在建立冗余索引来支持覆盖索引时就需要权衡考虑了。 最左前缀原则 建立（name，age）联合索引，where name like ‘张%’，能够用上这个索引，查找到第一个符合条件的记录然后向后遍历，直到不满足条件为止。 只要满足最左前缀，就可以利用索引来加速检索。这个最左前缀可以是联合索引的 最左 N 个字段，也可以是字符串索引的 最左 M 个字符。 建立联合索引的时候，索引内的字段顺序安排的评估标准是 索引的复用能力，因为可以支持最左前缀，所以当已经有了 (a, b) 这个联合索引后，一般就不需要单独在 a 上建立索引了。第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。 但是如果查询条件里面只有 b 的语句，是无法使用 (a, b) 这个联合索引的，这时候你不得不维护另外一个索引，也就是说你需要同时维护 (a, b)、(b) 这两个索引，这时候要考虑的原则就是空间了，比如 name 字段是比 age 字段大的，则创建一个（name, age) 的联合索引和一个 (age) 的单字段索引。 索引下推 建立（name，age）联合索引 1mysql&gt; select * from user where name like &#x27;张 %&#x27; and age=10 and ismale=1; 这个语句在搜索索引树的时候，只能用 “张”，找到第一个满足条件的记录，在 MySQL 5.6 之前需要回表到主键索引上找出数据行，再对比字段值。 而 MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。InnoDB 在 (name, age) 索引内部就判断了 age 是否等于 10，对于不等于 10 的记录，直接判断并跳过 唯一索引 OR 普通索引查询过程 对于普通索引来说，查找到满足条件的第一个记录后，需要查找下一个记录，直到碰到第一个不满足条件的记录。 对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。 那么，这个不同带来的性能差距会有多少呢？答案是，微乎其微。 InnoDB 的数据是按数据页为单位来读写的。也就是说，当需要读一条记录的时候，并不是将这个记录本身从磁盘读出来，而是以页为单位，将其整体读入内存。在 InnoDB 中，每个数据页的大小默认是 16KB。 因为引擎是按页读写的，当找到满足条件的记录的时候，它所在的数据页就都在内存里了，对于普通索引来说，要多做的那一次“查找和判断下一条记录”的操作，就只需要一次指针寻找和一次计算。如果满足条件的记录刚好是这个数据页的最后一个记录，那么要取下一个记录，必须读取下一个数据页，这种情况的概率会很低，计算平均性能差异时，仍可以认为这个操作成本对于现在的 CPU 来说可以忽略不计。 更新过程 当需要更新一个数据页时： 如果数据页在内存中就直接更新 如果数据页还没有在内存中，在不影响数据一致性的前提下，InooDB 会将这些更新操作缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了，在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作（保证数据逻辑的正确性） change buffer 是可以持久化的数据，其在内存中有拷贝，也会被写入到磁盘上，将 change buffer 中的操作应用到原数据页，得到最新结果的过程称为 merge 除了访问这个数据页会触发 merge 外，系统有后台线程会定期 merge。在数据库正常关闭（shutdown）的过程中，也会执行 merge 操作 change buffer 用的是 buffer pool 里的内存，因此不能无限增大。change buffer 的大小，可以通过参数 innodb_change_buffer_max_size 来动态设置。这个参数设置为 50 的时候，表示 change buffer 的大小最多只能占用 buffer pool 的 50%。 什么条件下可以使用 change buffer 呢？ 对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束，而这必须要将数据页读入内存才能查找判断，如果都已经读入到内存了，那直接更新内存会更快，就没必要使用 change buffer 了。因此，唯一索引的更新就不能使用 change buffer，实际上也只有普通索引可以使用。 如果要在一张表中插入一个新记录，InnoDB 的处理流程： 第一种情况是，这个记录要更新的目标页在内存中。这时，InnoDB 的处理流程如下： 对于唯一索引来说，找到 3 和 5 之间的位置，判断到没有冲突，插入这个值，语句执行结束； 对于普通索引来说，找到 3 和 5 之间的位置，插入这个值，语句执行结束。 普通索引和唯一索引对更新语句性能影响的差别，只是一个判断，只会耗费微小的 CPU 时间。 第二种情况是，这个记录要更新的目标页不在内存中。这时，InnoDB 的处理流程如下： 对于唯一索引来说，需要将数据页读入内存，判断到没有冲突，插入这个值，语句执行结束； 对于普通索引来说，则是将更新记录在 change buffer，语句执行就结束了。 将数据从磁盘读入内存涉及随机 IO 的访问，是数据库里面成本最高的操作之一。 change buffer 因为减少了随机磁盘访问，所以对更新性能的提升是会很明显的。 change buffer 的使用场景 change buffer 只限于用在普通索引的场景下，而不适用于唯一索引。 因为 merge 的时候是真正进行数据更新的时刻，而 change buffer 的主要目的就是将记录的变更动作缓存下来，所以在一个数据页做 merge 之前，change buffer 记录的变更越多（也就是这个页面上要更新的次数越多），收益就越大。 对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时 change buffer 的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。 假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在 change buffer，但之后由于马上要访问这个数据页，会立即触发 merge 过程。这样随机访问 IO 的次数不会减少，反而增加了 change buffer 的维护代价。所以，对于这种业务模式来说，change buffer 反而起到了副作用。 索引选择和实践 普通索引和唯一索引在查询能力上是没差别的，主要考虑的是对更新性能的影响，所以建议尽量选择普通索引。如果所有的更新后面，都马上伴随着对这个记录的查询，那么你应该关闭 change buffer。而在其他情况下，change buffer 都能提升更新性能。 普通索引和 change buffer 的配合使用，对于数据量大的表的更新优化还是很明显的。当有一个类似“历史数据”的库，并且出于成本考虑用的是机械硬盘时，应该特别关注这些表里的索引，尽量使用普通索引，然后把 change buffer 尽量开大，以确保这个“历史数据”表的数据写入速度。 change buffer 和 redo log change buffer 是占用 InnoDB buffer pool 的空间，同时也会持久化到硬盘 1mysql&gt; insert into t(id,k) values(id1,k1),(id2,k2); 分析这条更新语句，它涉及了四个部分：InnoDB buffer pool、redo log（ib_log_fileX）、 数据表空间（t.ibd）、系统表空间（ibdata1） 这条更新语句做了如下的操作： Page 1（k1 所在的页） 在内存中，直接更新内存； Page 2（k2 所在的页）没有在内存中，就在内存的 change buffer 区域，记录下“往 Page 2 插入一行”这个信息； 将上述两个动作记入 redo log 中（写入磁盘）。 做完上面这些，事务就可以完成了，执行这条更新语句的成本很低，就是写了两处内存，然后写了一处磁盘（两次操作合在一起写了一次磁盘），而且还是顺序写的。 1mysql&gt; select * from t where k in (k1, k2) 如果读语句发生在更新语句后不久，内存中的数据都还在，那么此时的这两个读操作（k1，k2）就与系统表空间（ibdata1）和 redo log（ib_log_fileX）无关了 读 Page 1 的时候，直接从内存返回。WAL 之后如果读数据，是不是一定要读盘，是不是一定要从 redo log 里面把数据更新以后才可以返回？其实是不用，虽然磁盘上还是之前的数据，但直接从内存返回结果，结果是正确的。 要读 Page 2 的时候，需要把 Page 2 从磁盘读入内存中，然后应用 change buffer 里面的操作日志，生成一个正确的版本并返回结果，所以直到需要读 Page 2 的时候，这个数据页才会被读入内存。 redo log 主要节省的是随机写磁盘的 IO 消耗（转成顺序写），而 change buffer 主要节省的则是随机读磁盘的 IO 消耗。 索引的选择选择索引是优化器的工作，而优化器选择索引的目的，是找到一个最优的执行方案，并用最小的代价去执行语句。在数据库里面，扫描行数是影响执行代价的因素之一。扫描的行数越少，意味着访问磁盘数据的次数越少，消耗的 CPU 资源越少。 扫描行数并不是唯一的判断标准，优化器还会结合是否使用临时表、是否排序等因素进行综合判断。 锁 🔒数据库锁设计的初衷是处理 并发问题。作为多用户共享的资源，当出现并发访问的时候，数据库需要合理地控制资源的访问规则，而锁就是用来实现这些访问规则的重要数据结构。根据加锁的范围，MySQL 里面的锁大致可以分成 全局锁、表级锁和行锁 三类。 全局锁全局锁就是对整个数据库实例加锁，MySQL 提供了一个加全局读锁的方法，命令是 Flush tables with read lock(FTWRL)，使用这个命令之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。 全局锁的典型使用场景是，做 全库逻辑备份。也就是把整库每个表都 select 出来存成文本，但是业务就得停摆。 官方自带的逻辑备份工具是 mysqldump。当 mysqldump 使用参数 –single-transaction 的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于 MVCC 的支持，这个过程中数据是可以正常更新的，single-transaction 方法只适用于所有的表使用事务引擎的库。 既然要全库只读，为什么不使用 set global readonly &#x3D; true 的方式呢？ 在有些系统中，readonly 的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。因此，修改 global 变量的方式影响面更大。 在异常处理机制上有差异。如果执行 FTWRL 命令之后由于客户端发生异常断开，那么 MySQL 会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为 readonly 之后，如果客户端发生异常，则数据库就会一直保持 readonly 状态，这样会导致整个库长时间处于不可写状态，风险较高。 表级锁表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL) 表锁的语法是 lock tables … read/write。与 FTWRL 类似，可以用 unlock tables 主动释放锁，也可以在客户端断开的时候自动释放，lock tables 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。 如果在某个线程 A 中执行 lock tables t1 read, t2 write; 这个语句，则其他线程写 t1、读写 t2 的语句都会被阻塞。同时，线程 A 在执行 unlock tables 之前，也只能执行读 t1、读写 t2 的操作。 对于 InnoDB 这种支持行锁的引擎，一般不使用 lock tables 命令来控制并发，毕竟锁住整个表的影响面还是太大。 另一类表级的锁是 MDL（metadata lock)。MDL 不需要显式使用，在访问一个表的时候会被自动加上。MDL 的作用是，保证读写的正确性。在 MySQL 5.5 版本中引入了 MDL，当对一个表做增删改查操作的时候，加 MDL 读锁；当要对表做结构变更操作的时候，加 MDL 写锁。 读锁之间不互斥，因此可以有多个线程同时对一张表增删改查。 读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。 如何安全地给小表加字段？ 要小心不要导致锁住线上查询和更新，如：读（未提交）写（被阻塞）读（被阻塞）… 解决长事务，事务不提交，就会一直占着 MDL 锁，在 MySQL 的 information_schema 库的 innodb_trx 表中，可以查到当前执行中的事务。如果你要做 DDL 变更的表刚好有长事务在执行，要考虑先暂停 DDL，或者 kill 掉这个长事务。 在 alter table 语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到 MDL 写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。 MariaDB 已经合并了 AliSQL 的这个功能，所以这两个开源分支目前都支持 DDL NOWAIT&#x2F;WAIT n 这个语法。 12ALTER TABLE tbl_name NOWAIT add column ...ALTER TABLE tbl_name WAIT N add column ... 行锁行锁是在引擎层由各个引擎自己实现的，并不是所有的引擎都支持行锁，比如 MyISAM 引擎就不支持行锁，这也是 MyISAM 被 InnoDB 替代的重要原因之一。 行锁就是针对数据表中行记录的锁，比如事务 A 更新了一行，而这时候事务 B 也要更新同一行，则必须等事务 A 的操作完成后才能进行更新。 在 InnoDB 事务中，行锁是在需要的时候才加上的，但 并不是不需要了就立刻释放，而是要 等到事务结束时才释放。这个就是两阶段锁协议。 如果事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放，比如电影票在线交易业务，这个业务需要涉及到以下操作： 从顾客 A 账户余额中扣除电影票价； 给影院 B 的账户余额增加这张电影票价； 记录一条交易日志。 要完成这个交易，需要 update 两条记录，并 insert 一条记录。为了保证交易的原子性，要把这三个操作放在一个事务中。那么，要怎样安排这三个语句在事务中的顺序呢？ 如果同时有另外一个顾客 C 要在影院 B 买票，那么这两个事务冲突的部分就是语句 2 了。因为它们要更新同一个影院账户的余额，需要修改同一行数据。 如果你把语句 2 安排在最后，比如按照 3、1、2 这样的顺序，那么影院 账户余额这一行的锁时间就最少。这就最大程度地 减少了事务之间的锁等待，提升了并发度。 死锁检测当出现死锁以后，有两种策略： 一种策略是，直接进入等待，直到超时。这个 超时时间 可以通过参数 innodb_lock_wait_timeout 来设置。 另一种策略是，发起 死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑。 在 InnoDB 中，innodb_lock_wait_timeout 的默认值是 50s，意味着如果采用第一个策略，当出现死锁以后，第一个被锁住的线程要过 50s 才会超时退出，然后其他线程才有可能继续执行。 超时退出容易误伤： 对于在线服务来说，这个等待时间往往是无法接受的。但是，我们又不可能直接把这个时间设置成一个很小的值，比如 1s。这样当出现死锁的时候，确实很快就可以解开，但如果不是死锁，而是简单的锁等待呢？所以，超时时间设置太短的话，会出现很多误伤。 所以，正常情况下我们还是要采用第二种策略，即：主动死锁检测，而且 innodb_deadlock_detect 的默认值本身就是 on。主动死锁检测在发生死锁的时候，是能够快速发现并进行处理的，但是它也是有额外负担的。 死锁检测要耗费大量的 CPU 资源： 每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，这是一个时间复杂度是 O(n) 的操作。假设有 1000 个并发线程要同时更新同一行，那么死锁检测操作就是 100 万这个量级的。虽然最终检测的结果是没有死锁，但是这期间要消耗大量的 CPU 资源。因此，你就会看到 CPU 利用率很高，但是每秒却执行不了几个事务。 解决办法： 头痛医头：就是如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉。但是这种操作本身带有一定的风险，因为业务设计的时候一般不会把死锁当做一个严重错误，毕竟出现死锁了，就回滚，然后通过业务重试一般就没问题了，这是业务无损的。而关掉死锁检测意味着可能会出现大量的超时，这是 业务有损 的。 控制并发度：在客户端做并发控制汇总到数据库服务端以后峰值并发数也很高，如果有中间件，可以考虑在中间件实现，基本思路就是，对于相同行的更新，在进入引擎之前排队，这样在 InnoDB 内部就不会有大量的死锁检测工作了。 业务设计上：通过将一行改成逻辑上的多行来减少锁冲突，可以考虑放在多条记录上，比如 10 个记录，影院的 账户总额等于这 10 个记录的值的总和（和记录表不一样的），这样每次要给影院账户加金额的时候，随机选其中一条记录来加。这样每次冲突概率变成原来的 1&#x2F;10，可以减少锁等待个数，也就减少了死锁检测的 CPU 消耗。 自增 id表定义自增值 id InnoDB 系统自增 row_id Xid Innodb trx_id thread_id 参考资料 MySQL 实战 45 讲","tags":["MySQL"],"categories":["MySQL"]},{"title":"「云计算」背景知识概览 ☁️","path":"/2024/06/15/cc/","content":"梳理云上最具代表性的各项能力，帮助全面了解云计算，也为云上实践打下基础 云计算云计算的演进总结： 工作负载的变化：从早期的物理服务器，通过虚拟化技术演进为虚拟机，再通过容器化技术演进为目前的 容器。 隔离单元：无论是启动时间还是单元大小，物理机、虚拟机、容器一路走来，实现了 从重量级到轻量级 的转变。 供应商：从闭源到开源（从 VMware 到 KVM，到 OpenStack，再到 Kubernetes），从单一供应商到跨越多个供应商（从公有云到自建云，再到混合云）。 XaaS 的简单归纳： IaaS（Infrastructure as a Service，基础设施即服务），指云计算所提供的计算、存储、网络等基本底层能力，客户不用关注物理机器，只需关注基础架构及应用程序； PaaS（Platform as a Service，平台即服务），指基于云底层能力而构建的面向领域或场景的高层服务，如数据库、应用服务等，客户不用关注基础架构，只需关注应用程序； SaaS（Software as a Service，软件即服务），指基于云构建可开箱即用的各种业务应用，此外还有 FaaS（Function as a Service）、CaaS（Container as a Service），客户只需关注功能和数据。 在过去的二十年间，云计算几乎重新定义了整个行业的格局，越来越多的企业开始降低对 IT 基础设施的直接资本投入，不再倾向于维护自建的数据中心，而是开始通过上云的方式来获取更强大的计算、存储能力，并实现按时按需付费。 这不仅仅降低 IT 支出，同时也降低了整个行业的技术壁垒，使得更多的公司 尤其是初创公司可以更快地实践业务想法并迅速推送到市场。（正是在初创公司实习才开始使用到容器服务 ☁️） IaaS [aɪæs]IaaS 的本质，是对云数据中心和各类 IT 基础设施的抽象，是基于软件技术对物理硬件进行的封装和虚拟。 区域在云计算行业中，区域对应的则是云计算厂商在某个地理位置提供的所有云服务的组合，是厂商对外提供云服务的基本单位和容器。区域的设立和分布，相当程度地体现了云厂商的业务重点和地区倾向。云厂商在选址时一般会有两种思路： 一种是考虑放在 人口稠密的中心城市，离用户和商业更近，以提供较快的接入体验； 另一种则是在 相对偏远的地区，当地往往能够提供良好的气候条件、充足的建设空间，以及较低的电力、带宽等运营维护成本。 如何选择合适的区域 区域的地理位置本身。 如果场景中需要本地数据中心与云端进行互联，也就是混合云架构，其专线接入一般以同城或短距离接入为主，这样能够较好地控制费用，同时提高线路的稳定性。 区域之间云服务的差别。 换句话说，同一个云在不同的区域，所能提供的服务和规模可能是不同的。新旧区域哪个更好，需要根据服务需求和待选区域的实际情况来综合衡量。 成本因素。 即便是同一种服务的价格，在不同区域也往往是不相同的。区域的流量费用也需要注意，如果把区域作为一个有边界范围的实体圈起来，这个流量可以分为三类：入站流量、出站流量和内部流量。 多区域架构 多区域架构指的是部分关键应用，为了追求最佳的用户体验和高可用性，需要把多个区域的资源和能力结合起来进行构建。主流云厂商在跨区域方面也进行了大量建设和投资，主要体现为： 物理上，各区域之间建设有网络互联专线，一般称为骨干网（Backbone）。骨干网的存在使得同一个云在不同区域间的通信，能够有较高的带宽和较低的延时。 软件层面，允许位于不同区域的虚拟网络跨区域进行互联，使得多区域的私有内网能够借助自有骨干网无缝高速打通。 DNS 解析层面，通常会提供就近解析和智能路由能力，将分布广泛的 C 端流量引流到最近的数据中心，以获得最快的响应速度。 公有云的基础设施（尤其是骨干网的存在）能够极大地方便我们构建多区域的应用程序。通过合理架构完全可以让多个区域的云服务融为一体。借助云的力量，小厂也能轻松拥有巨头的分布式部署能力。 在应用架构层面，多区域并不意味着需要把某区域的资源复制到其他区域，而是可以根据实际情况各司其职，让不同区域担任不同的角色，联动起来达到业务目的。 比如，可以将面向消费者服务的触点部署到多个区域，就近服务各地区的互联网流量，而偏后台的数据分析和 BI（Business Intelligence） 服务，则可以安置在性价比较高的非一线城市区域，业务数据可通过骨干网不断回传。这是一种经典的分工模式。 当然，也不应当走向另一个极端：轻率、随意地拓展区域。每一个区域的增加，都会相应增加应用架构的复杂性和流量费用，也给我们的维护工作带来负担，这些额外的成本可能会抵消多区域架构带来的好处。 可用区 可用区是区域的下级概念，是指一个具备完整而独立的电力供应、冷却系统、网络设施的数据中心单元。 高可用性 拓展性 尽管数据中心内部有着非常精密的运作系统和冗余机制，但地震、火灾、雷击等极端情况下，仍有可能造成数据中心级别的故障。为了避免单个数据中心故障让整个区域不可用，那自然就有必要建设多个相对独立的数据中心，也就是多个可用区了。 区域本身也有扩展的需求。一些区域由于早期的容量规划和成本控制原因，很可能在若干年的运营后就会变得资源紧张、后劲不足。这时得益于可用区的机制，区域可以通过新建可用区，不断扩展自身容量，补充新鲜血液；而老旧的可用区，则可不对新用户开放，逐步封存甚至淘汰，这让区域形成了良好的新陈代谢机制。 可用区的数量也可以成为一个衡量区域规模的重要指标。数量越多，意味着这个区域规模越大。 云虚拟机云虚拟机即在云端虚拟出的服务器，虚拟化技术是云虚拟机服务的核心，它本身是一个非常宏大的技术领域。比如 Xen、KVM、VMWare、HyperV 等等虚拟化产品和技术。云计算中所使用的虚拟化技术，也大都是从这些虚拟化实现方式演化而来的。云端的虚拟化技术在不断进步和发展，使得云端虚拟化的性能损耗在不断减少、资源利用率不断提升。 云虚拟机与传统虚拟机的不同 云虚拟机的体系结构是全面解耦的 计算存储分离 的设计思想。传统的虚拟化，往往是对单一物理机器资源的纵向切割，计算、存储、网络等各方面的能力都是一台物理机的子集，从 可伸缩性 的角度来说，传统虚拟机存在较大的局限，当物理机的局部出现故障时，也很容易影响到里面的虚拟机。以下是简化的示意图： 这样虚拟出来的机器，我们在使用感受上其实与传统服务器并无不同，但在可扩展性和故障隔离方面，它就具有很大的优势了。各家厂商的云虚拟机服务的名称会略有不同，阿里云称为云服务器 ECS（Elastic Compute Service），AWS 称为 EC2（Elastic Compute Cloud），Azure 就叫 Virtual Machine，腾讯云则叫做云服务器 CVM（Cloud Virtual Machine）等等。 网络安全组（Network Security Group, NSG） 网络安全组可以理解为一层覆盖在虚拟机之外的网络防火墙。它能够控制虚拟机入站、出站的流量，并能根据协议、端口、流向等所设定的规则，来决定是否允许流量通过。 网络安全组并不工作在操作系统层面，而是在操作系统层之外，是额外的一层防护。非法流量在尚未到达 OS 的网络堆栈之前，就已经被它阻断了。所以 NSG 的一个优点在于，它不会影响 VM 的性能。 网络安全组是一种可复用的配置。如果有大量虚拟机适用于同样的网络控制规则，就能够很方便地让它们使用同一个网络安全组，它体现了云计算中 软件定义网络 的特点。 虚拟机类型 决定虚拟机配置的最重要的三个要素，即 类型、代别和实例大小。 云厂商会提供通用均衡型、计算密集型、内存优化型、图形计算型等常见的虚拟机类型，CPU 数和内存大小（按 GB 计算）的比例，是决定和区分虚拟机类型的重要指征之一。 通用均衡型 的比例通常是 1:4，如 2 核 8G，这是一个经典的搭配，可用于建站、应用服务等各种常见负载，比如作为官网和企业应用程序的后端服务器等。 如果 vCPU（Virtual CPU）和内存比是 1:2 甚至 1:1，那就是 计算密集型 的范畴，它可以用于进行科学计算、视频编码、代码编译等计算密集型负载。 比例为 1:8 及以上，一般就会被归入 内存优化型 了，比如 8 核 64G 的搭配，它在数据库、缓存服务、大数据分析等应用场景较为常见。 图形计算型 就是带有 GPU 能力的虚拟机，一般用于机器学习和深度学习模型的训练和推理。 本地存储型 是指带有高性能或大容量的本地存储的机型。 同类型虚拟机的更新换代，往往首先会带来相应 硬件 CPU 的换代提升。随着一代新机型的推出，云厂商一般都会详细说明背后支撑的硬件详细信息。很多时候也伴随着底层软硬件架构的更新和提升，尤其是 虚拟化技术 的改进。 实例大小（Size），也就是硬件计算资源的规模。业界常常使用 medium、large、xlarge 等字眼来进行命名区分，标准 large 对应的是 2vCPU 的配备，xlarge 则代表 4 个 vCPU，而更高的配置一般用 _n_xlarge 来表达，其中 n 与 xlarge 代表的 4vCPU 是乘法关系。 因为超线程（HyperThreading）技术的普遍存在，常常一个核心能够虚拟出两个 vCPU 的算力，但也有些处理器不支持超线程 在某些场景下，可能还会看到“metal”或者“bare metal”这样的描述规格的字眼，中文称为“裸金属”。它们就是云服务商尽最大可能 将物理裸机以云产品方式暴露出来 的实例，主要用于一些追求极致性能，或是需要在非虚拟化环境下运行软件的场景。 云硬盘云硬盘，又叫做“云盘”或者“云磁盘”，就是云虚拟机上可以挂载和使用的硬盘。这里，它既包含了用于承载操作系统的系统盘，也包括了承载数据的数据盘。有时还会把云端磁盘服务叫做块存储（Block Storage），因为它们与 Linux 操作系统中的块设备相对应，是云上提供的“裸盘”，可以格式化并且施加文件系统。 云硬盘与传统磁盘的真正差异在于，绝大多数的云硬盘都是远程的。在经典计算机的体系结构中，硬盘是通过本地机器内部主板的高速总线，与 CPU、内存等部件相连接；而在云端，硬盘则很可能并不在宿主机上，而是在专用的磁盘服务器阵列中，两者是通过数据中心内部的特有 IO 线路进行连接。这也正是 计算存储分离架构 的一种体现。 当下的云硬盘经过了多次的软硬件迭代，尤其是 SSD 的迅速发展，吞吐量和随机读写能力等各项性能指标都已经不再是问题了。云硬盘的性能等级的分为 HDD、SSD&#x2F;HDD、SSD、高性能 SSD： 基于传统 HDD 硬盘构建而成的，性能一般，成本低，在不注重性能的测试环境，或者是个人自用的服务器； 基于混合硬盘，也就是结合 HDD 和 SSD 硬盘构建的云硬盘，比较适合像是操作系统启动盘这样的常规负载； 纯 SSD 硬盘，可以用它来承载生产环境中重要的关键业务应用，或是各类数据库等 IO 密集型应用； 进一步优化增强的 SSD 云盘，采用更新一代的企业级闪存硬件，配合改进后的底层传输协议和虚拟化技术栈的优化来提供服务。 同等的性能等级下，云硬盘的容量越大，一般来说它的性能就越高，直到达到这个等级的上限，这是由云上磁盘能力共享的底层设计所决定的，所以在某些时候，可能需要刻意地增大所申请的云硬盘的容量，以获取更高的性能，即便这些额外的空间不一定能被用上。 云盘的热挂载特性让它使用起来特别灵活方便，而且大小性能可以调度，挂载后和本地硬盘操作没有什么两样。当一些应用软件系统本身考虑到了硬件的不可靠性，设计了上层的存储冗余机制时，也可以考虑采用云虚拟机的本地磁盘，当机器关机或删除，以及出现硬件故障时，本地磁盘上的数据就可能损坏或丢失。 虚拟网络虚拟私有网络 虚拟私有网络（Virtual Private Cloud，简称 VPC），是云计算网络端最重要的概念之一，它是指构建在云上的、相互隔离的、用户可以自主控制的私有网络环境，虚拟私有网络有时也称为专有网络或虚拟网络。 私有网络就是一张内网，内网之内的服务器和设备可以比较自由地互相通信，与外界默认是隔离的。如果外部互联网，或者其他虚拟网络需要连接，则需要额外的配置。 在传统数据中心里，经典网络架构中的概念和组件，在虚拟网络中几乎都能找到对应。比较重要的一些概念包括： 网段，私有网络的内部 IP 区段，通常用无类别域间路由（Classless Inter-Domain Routing， CIDR） 形式来表达，如 192.168.0.0&#x2F;16。 子网，私有网络的下级网络结构，一个私有网络可以划分多个子网，这和通常意义上的子网也是对应和一致的； 路由表，用于定义私有网络内流量的路由规则，决定着数据包的“下一跳”去向何方。每个子网都必须有一张关联的路由表，通常情况下，系统会自动创建一个默认的路由表； 网关，是对进出私有网络的流量进行把守和分发的重要节点，根据用途的不同，有多种类型； 安全组，私有网络里虚拟机进出流量的通行或拦截规则，可以起到虚拟机网络防火墙的作用。 VPC 属于局域网，按照 RFC （Request for Comments，互联网技术发展和标准化的核心资料） 规范，能够使用的 IPv4 区段必须为 192.168.0.0&#x2F;16、172.16.0.0&#x2F;12、10.0.0.0&#x2F;8 这三个或它们的子集。 如果在没有 VPC 的情况下直接创建虚拟机，公有云一般都会自动生成 VPC。 可以建立跨可用区，也就是跨同区域内不同数据中心的私有网络，这是 VPC 的一个强大的特性，能够为我们私有网络的高可用性提供保障。比如，可以让主力集群在一个可用区工作，备用集群在另一个可用区随时待命，需要时迅速切换，也可以把流量同时分发到不同的可用区，动态控制分发策略。 私有网络中的虚拟机 一个虚拟网络已经存在时，就可以 将新创建的虚拟机放置在这个虚拟网络中，虚拟机和专有网络的连接点是虚拟机的网卡，又称 弹性网卡（Elastic Network Interface， 简称 ENI）。虚拟机的网卡一方面是和虚拟机的本体进行绑定，另一方面则嵌入某个私有网络的子网，也会拥有至少一个私网 IP。云上的网卡，之所以被称为“弹性”网卡，是因为它具备以下特征： 一个虚拟机可以绑定多块网卡，有主网卡和辅助网卡之分； 一块网卡隶属于一个子网，可以配置同一子网内的多个私有 IP； 辅助网卡可以动态解绑，还能够绑定到另一台虚拟机上。 当在创建虚拟机的时候，向导会询问这台虚拟机属于哪个 VPC，以及 VPC 下的哪个子网。这个选项的实质性结果，就是新虚拟机自动生成的主网卡，接入了所选 VPC 的所选子网。 对于生产环境尽量不要使用和依赖自动生成的 公有 IP，因为它本质上是一个从公有云的 IP 池中临时租用的 IP，如果机器关闭或重启，下次获得的 IP 可能就完全不同了。这时，应该用到的是弹性 IP（Elastic IP），弹性 IP 一旦生成，它所对应的 IP 是固定、不会变化的，非常适合需要稳定 IP 的生产环境，它所谓的弹性，其实是指可以非常自由地解绑和再次绑定到任意目标。 私有网络对外的出入口 如果一台云虚拟机没有被赋予公有 IP，为了安全控制，默认情况下它就失去了访问外网的能力，只能进行内网通信。但也有一些情况，希望内网的机器和外界并不完全隔离，一些互联网流量需要有序地引进来，一些内网机器也需要访问外网。 如果需要访问外网的虚拟机数量有很多，这种办法就需要很多弹性 IP，管理上就太麻烦了，成本也不划算 还有一个问题是，弹性 IP 带来的是双向的开放，有时我们只想允许单向的连接 这就是 网关 可以大显身手的场景了，它正是用来统一协调管理私有网络与外部通信的组件，网关有很多种类型，比如 NAT（Network Address Translation）网关，用于在私有网络与公共网络之间进行通信： 目标网络地址转换（Destination Network Address Translation，DNAT）是 NAT 的一种形式，它主要用于将外部请求的目标 IP 地址转换为内部网络中的特定 IP 地址。 源网络地址转换（Source Network Address Translation，SNAT）是 NAT 的另一种形式，它用于将内部网络中的源 IP 地址转换为公共网络可路由的 IP 地址。 还有一种网关被称为 VPN 网关，也可以帮助外界连接到 VPC，它本质上是基于 VPN 技术。由于 VPN 能够基于互联网提供私有加密的通信，因此非常适合用来从任意其他私有设施安全地连接到 VPC。这些私有设施可以小到一台个人电脑或手机终端，也可以大到是本地的数据中心，还可以是另一个 VPC。 VPN 主要用于创建安全的远程连接和加密数据传输，而 SNAT 则是一种网络地址转换技术。 当想要科学上网访问境外服务器时，需要使用 VPN 服务来连接到位于另一个国家的服务器，用户的网络流量就会通过这个远程服务器路由，从而绕过地理限制或审查制度。 使用 VPN 时，数据传输会被加密，这意味着即使数据在传输过程中被截获，第三方也无法轻易解读内容。此外，VPN 还可以隐藏用户的真实 IP 地址，只显示 VPN 服务器的 IP 地址，从而保护用户的隐私和安全 API 网关 是一个独立的 PaaS 服务，它的作用是为外界访问提供一个端点，并引流到我们的后台计算服务。有点类似传输层的负载均衡，但 API 网关是工作在网络的 应用层，它的后端可以连接指向云函数等多种服务。 另外，API 网关还能够提供不少应用层的实用功能，比如 访问鉴权、限流熔断、版本控制 等等。 多网连接的方式 公有云上是允许同时使用多个 VPC 的，这样可以构建更加复杂的网络架构，实现模块隔离和跨区域扩展等高级需求。 云端 VPC 和 VPC 的互联可以采用 对等连接（VPC Peering）的方式，能够在不添加额外设备的情况下，让两个 VPC 无缝地互联起来，对等连接甚至还能够支持跨区域的私有网络互联，但是它 不具备传递性； 如果需要多个 VPC 间任意路径的互联互通，可以考虑使用 专用网络设施，允许进行更精细的路由设置； 公有云中的私有网络，还可以和企业本地数据中心进行互联，形成 混合云架构，可以先考虑使用 VPN 这种轻量的方式，通过公网线路为两边建立连接渠道，如果应用场景要求保证延迟和带宽就需要 专线 进行连接，一般专线还会和 VPN 一起组合使用，来保证通道的高可用性。 混合云的构建是一项较为复杂的工程，通常需要由本地机房、云厂商、电信运营商三方配合进行，也牵涉到本地数据中心端的网络规划和路由设备适配。 故障与伸缩服务等级协议（Service Level Agreement，SLA）主要是用来对服务的可靠性作出一个预期和保证。SLA 的可用性等级可能是 99.9%，也可能是 99.99%，再好的服务也不能达到理论上的 100%。 从架构思维的角度上来说，需要假定故障就是可能会发生，对于它的影响事先就要做好准备，事先就进行推演并设置相关的冗余和预案，AWS 有一个非常著名的架构原则，叫做 Design For Failure。 云上故障分类： 第一种故障是在宿主机的级别，这也是从概率上来说最常见的一种故障。 第二种规模更大的故障，是在数据中心，也就是可用区的层面。（火灾、雷击等物理破坏） 第三种更严重的故障，就是整个区域级别的事故了。 应对的基本思想是化单点为多点，形成不同层面、不同粒度的冗余。 弹性伸缩 弹性伸缩既可以提高工作负载洪峰来临时的吞吐和消化能力，提高业务稳定性，又能够在低谷期帮我们显著地节约成本。 在 IaaS 端，能够弹性伸缩的最实用的产品形态，莫过于 虚拟机编组 了，也就是功能相同的多个虚拟机的集合。把它们作为一个单位来创建、管理和伸缩，是一种普遍应用的最佳实践。把多个虚拟机以弹性伸缩组的方式进行统一管理，能够极大地提高效率，减轻负担。因为弹性伸缩服务，会帮我们动态地创建和销毁虚拟机实例，自动根据我们指定的数量和扩缩容规则，来协调虚拟机的生命周期。 弹性伸缩服务，在云端还有一个最佳拍档，就是 负载均衡器。将流量均匀地，或者按照一定权重或规则，分发到多台虚拟机上，正好可以和提供计算资源的弹性伸缩服务形成配合。当负载增大、虚拟机增加时，负载均衡也能够自动动态识别，将流量分发到新创建的虚拟机上。 使用弹性伸缩服务来实现云端弹性架构，用它来管理一组虚拟机，并与负载均衡一起配合。这特别适合处理无状态类的计算需求，因为它会代劳底层计算资源的管理。 云上运维云的引入能够让我们在更高的层面去思考和解决问题，比如说， 云端基础设施的存在，可以让运维从偏硬件服务器、偏物理机房的日常繁琐工作中解脱出来，更多地基于云在软件的层面，进行部署、监控、调整。 而云上的高质量、高可用的服务，也能避免我们重复建设，不用自己造轮子，也大大减轻了运维负担。 底层的机房运维、基础架构运维仍然会继续存在，但会向头部的云供应商大规模集中，这属于云厂商的运维视角 云其实是提高了运维的效率，改变了运维的形态，与此同时，由于云上运维的软件属性显著增强了，它就自然地和研发会有更强的融合。近期 DevOps 理念和云原生热潮的兴起，就说明了这一点。许多工作慢慢地会分不清它究竟是属于运维还是研发，因为 两者的界限正在模糊。 云时代的运维利器 几乎每个云都推出了自己的命令行工具，比如 AWS CLI、Azure CLI、阿里云 CLI 等，除了命令行工具，各云还都提供了开发者工具包（SDK）。如果资源调度逻辑相当复杂，或者需要与自己的程序集成，那么可以考虑使用相应语言的 SDK，来进行云上的一些资源管理操作。 如果要频繁地在云上部署一套包含众多资源项的复杂系统，还有另外一个得力的帮手：资源编排类云服务。属于这个领域的服务包括有 AWS CloudFormation、 Azure 的 ARM Template、阿里云资源编排服务（ROS）等，它们都可以通过使用一个 JSON 格式的文本文件，来描述和定义一个系统中所有的组件，以及它们互相之间的关系。 云运维由哪些工作组成 在云端，传统的运维工作仍然存在，其中包括所熟知的 监控、部署、升级、备份 等 监控 一直是运维最核心的工作之一。几乎所有的云端服务都自带有一定的监控功能，默认提供了不少内置的维度指标和可视化图表，这些开箱即用的图表要充分利用好，它们能够很好地帮助了解相关服务的状态。 备份 是一个简单但又很容易被我们忽视的事项。在云上需要创造多层次的冗余，而备份在创造冗余方面也承担着重要的角色，有的时候它会是最后保障。 迁移 是带有云端特色的运维任务，因为只要不是在云上创建的全新业务，传统业务在逐步上云的过程中一定会面临迁移工作。 云上的运维会包含和云厂商进行 对接 的工作，运维团队中需要有相应的角色对云的工单机制，以及技术支持侧的对接方式了然于胸，以备不时之需。 具有管理属性，比如对于云资源的命名、开通、清理等日常操作的规范，各类云上安全的控制和最佳实践，所有云资源的负责人、所属资源组和权限体系等，还有一项重要事务就是 成本管理。 当前业界的一个重要趋势是，运维和开发的边界正在模糊。所以我在前面提到的诸多运维工作，可能是由开发者来负责，也可能是运维人员来承担。 作为开发者，应该学习和掌握一些运维的知识和技巧，让自己变得更加全面和综合； 作为运维人员，也应该学习了解现代软件构建和系统架构方面的知识，尤其是学习云、掌握云，为云端架构的全面到来做好准备。 PaaS [pæs]虚拟机、云磁盘、云网络等服务的特点是，和传统 IT 基础设施往往有一个对应关系，所以被称为基础设施即服务（Infrastructure-as-a-Service）。PaaS （Platform-as-a-Service），则是指云计算提供的平台类服务，在这些平台的基础上，用户可以直接开发、运行、管理应用程序，而无需构建和维护底层的基础设施。 PaaS 是在 IaaS 的基础上又做了许多工作，构建了很多关键抽象和可复用的单元，让我们用户能够在更上层进行应用的构建，把更多精力放在业务逻辑上。 PaaS 服务的优势，就在于生产力，在于效率，尤其是在搭建和运维层面。 对象存储对象存储（Object Storage）就是在云端可以存放任意对象的存储服务。这里的“对象”指的是任意的二进制对象，保存到云上通常是以二进制文件的形式。 对象存储不但注重打造存储的核心能力，还建立了一整套成熟的管理控制机制，更能够方便地与各种应用程序集成。 对象存储和云硬盘的区别 访问的接口与形式 云硬盘是挂载到虚拟机的虚拟硬盘，它是通过实现操作系统级别的底层接口，作为虚拟机的 块存储设备 而存在，所以也必须连接到相关的虚拟机，才能访问它里面的数据。 对象存储本质是一个网络化的服务，调用方主要通过高层的 API 和 SDK 来和它进行交互。不管是面向外部公开互联网服务，还是和内部应用程序对接，对象存储都是通过提供像 HTTP 这样的网络接口来实现的。独立性很强，不需要依赖其他组件就可以运作。 对象存储内本身不存在一个真正的文件系统，而是更接近一个键值（Key-Value）形式的存储服务 键就是对象的路径（路径中包含斜杠符号“&#x2F;”），这里的值就是存储对象的二进制文件 键值系统和云硬盘上经典文件系统的核心差异，就在于文件系统保存了更多的元数据，尤其是实现了目录结构和目录操作 键值系统中所谓的目录其实是多个对象共享的路径前缀（模拟出的目录），这样的设计也使得对象存储中的“目录”操作代价变高了，比如说目录的删除和重命名 可扩展性（Scalability）：对象存储的巨大容量 对象存储能够轻松地容纳上 PB 的超大容量数据，这是任何的云硬盘所不能企及的 对象存储本身也是非常擅长和适合处理小文件的，即便是海量的小文件，对象存储也不会像 HDFS 那样处理起来捉襟见肘 得益于冗余机制，一般都有高达 99.999999999%（11 个 9）的数据可靠 对象存储的高级特性 存储分层 可以按照访问热度，设置 从热到冷 不同的存储级别（或者叫存储类型） 这些存储级别其实是一种在访问效率和存储成本之间的平衡 很多用户上云的一个应用场景就是，把原本占用大量传统磁盘的备份文件，利用对象存储的归档能力长期保存 生命周期管理 生命周期管理功能允许设置一定的过期规则，当对象满足规则时，可以自动地执行一些清理操作 比如，要求最后修改时间超过 60 天的文件自动切换到低频访问层，超过 180 天的文件则进行归档或删除 对象的版本管理 对象存储系统就能够自动地记录这个对象之前的多个版本，可以按需进行回滚和恢复，避免不必要的损失 跨区域同步、访问日志分析等 自动对数据进行跨区域同步，常用于重要数据备份或热点数据分发 对已经存放了海量数据的对象存储进行管理分析 对象存储的应用场景 一切需要保存数据的地方，不论是原始数据的保留备份、中间结果的临时落地，还是处理结果数据的永久保存，都可以考虑对象存储是否适用。 对象存储可以直接面向公开互联网，作为文件服务器对外提供服务，通过妥善设置对象的 HTTP 响应头，甚至还能支撑起静态网站，免去我们创建虚拟机的麻烦。 如果下载量比较大，且对带宽延时有更高要求的话，它又能无缝地与云上的 CDN 服务进行集成，作为 CDN 的回源站点 应用托管在云计算发展的早期，就已经出现了“建站类服务”，这正是应用托管服务的雏形。当时的建站类服务，会自动分配好服务器，安装好相应语言的 Web 环境以供使用。在部署层面，服务通常会开放 FTP 端口，以便上传服务器端的代码、脚本和资源。这是应用服务的一种轻量形式。更现代的应用托管服务，不但在细节选项、自动化程度上进步了许多，还包含了大量的增值服务。 应用服务的本质就是为应用提供一个隔离的独立运行环境，作为用户来讲，可以只专注于业务逻辑，不需要来手动创建这个环境，更不需要运维这个环境。 应用托管服务背后采用的隔离技术对用户一般是不可见的，它可能是虚拟机，可能是 Docker，或者是自研的其他容器类技术。 应用托管服务背后采用的隔离技术对用户一般是不可见的，它可能是虚拟机，可能是 Docker，或者是自研的其他容器类技术。 应用托管的增值服务 监控，针对 Web 应用的特点而进行的 HTTP 层面的应用监控 不仅能看到计算资源的占用率，如 CPU、内存使用率等 还能看到许多应用层指标，比如总请求数、错误响应数、并发连接数、响应时间等 基于这些监控的指标，还能够在云上制定相应的报警规则 扩展，既包含了底层机器配置的垂直扩展，也包含了机器数量层面的水平扩展 应用托管服务不是只能对应一台机器，而是能够创建多台机器来承接请求，并会在前端均衡地分发到多个实例上去 集成，与其他 PaaS 的集成 在监控数据方面，可以和云监控系统进行衔接；有些云允许 Web 应用以目录的形式，挂载对象存储中的文件 还可以与云上 DevOps 组件和流程无缝对接； 此外还有远程调试和诊断、运行环境自动补丁升级、私有网络内的部署、Web 防火墙防护等 云数据库云上的关系型数据库 RDS（Relational Database Service）和传统关系型数据库 云数据库在外部交互的层面上，保持了和传统“原版”数据库几乎完全一致的编程接口和使用体验 早期比较简单的云数据库实现原理，是充分利用云上已经提供的虚拟机、云磁盘等 IaaS 层面的资源，在隔离的环境下进行数据库镜像的安装 后来技术实力比较强大的厂商，还能够做到对数据库源码和模块的深度定制，在保证兼容性的前提下，进行许多对用户透明的云端适配和优化 云数据库尽管是一个受限的 PaaS 环境（比如它通常无法直接访问底层的服务器），但在使用体验上和传统数据库是相当一致的 云数据库和传统数据库有很大的区别，指在搭建、运维、管理层面 比如灵活的性能等级调整、详尽的监控体系、攻击防护机制等 两个最具代表性的云上关系型数据库的高级特性 支持读写分离，从创建从库到建立同步，再到读写流量分发，云数据库都能自动完成 支持自动调优，自带的性能分析与改进模块，能够自动地发现性能热点，甚至还能够智能地给出调整建议 自研云原生数据库 云厂商们不满足于封装现有的数据库，而是极具野心地开始构建完全为云设计、能够充分发挥云的特点和优势的数据库。 出于生态发展和降低学习难度的需要，绝大多数的云原生数据库仍然保留了 SQL 等常见接口，除此以外，云原生数据库大都进行了全面革新和重新设计，有的云会大刀阔斧地改造开源代码，有的甚至脱离了现有包袱，完全重新构建。 更强的可扩展性 得益于原生设计的计算存储分离架构，云原生数据库可以支撑更大规模的数据量 云原生数据库可以利用云快速地进行水平扩展，迅速调整、提升数据库的处理能力 更高的可用性和可靠性 云原生数据库往往默认就是多副本高可用的，数据同步、读写分离等高级特性是作为原生机制的一部分天生存在的 得益于原生数据同步机制的底层设计，云原生数据库还能很方便地支持跨区域的实例复制，在进一步增强冗余的同时，还能便于就近服务全球用户 更好的弹性 在存储上不需要预先设置容量大小，而是会随着存储占用自动扩 在计算上，不需要使用固定的计算资源，这在面对间歇偶发或者难以预测的工作负载时，非常经济实用 云数据库之于传统数据库，是用完全不同的研发模式、商业模式和产品形态，从另一个层面发起了挑战，从而具备了竞争优势 大数据云计算以存储、计算规模和弹性著称，而大数据方面的业务需求，恰恰需要大量的存储，和呼之即来的澎湃算力。云可以说是最适合运行大数据工作负载的平台了，大数据也成为了云上最需要解决的重要场景之一。 大数据主要是 技术手段，是一系列处理海量数据的方法论和技术实现的总称；而云是一种 资源和能力的载体，也是一种商业存在，是可以运行大数据负载和应用的平台。云上的大数据 PaaS 产品是云对大数据技术进行了封装和产品化的成果。 云上大数据的特点 保证兼容性（技术栈） 解耦计算和存储（不仅仅是开源大数据技术的移植和搬运） 按需启停（集群可以动态地创建，做完工作后立刻将集群删除） 增值服务（性能监控、集群交互工具） 容器服务容器上云：从 Docker 到 Kubernetes 容器对于运行环境的极强适应性和快速启动的能力，配合云上动态扩展的庞大资源规模，让云端的容器应用可以在短时间内拓展到成千上万个实例。云可以说是容器应用的最佳载体，容器应用也非常适合在云上运行和扩展。 在 Docker 技术家喻户晓之前，云厂商已经在研究和使用类似容器的技术了，因为云本身是多租户的，需要运行环境的隔离性，所以云本身也是容器技术的用户和受益者。 随着容器应用的复杂化，编排逐渐成为了用户最急迫的需求，所以各厂商又纷纷推出和加强容器编排方面的解决方案，容器编排框架大战的结果是 Kubernetes “一统天下”，成为了事实标准。就现在最新的形势而言，如果要容器上云，直接选择各大云上最新的针对 Kubernetes 的服务即可。 相对于自建 Kubernetes 集群，云上 Kubernetes 服务的几个独有特点： 由于云端的多租户特性，可以免除在 Master 节点方面的开销，只需要创建 Worker 节点，并为之付费就行了 K8s 虽然复杂性较高，但抽象设计出色，能够支持大量灵活的扩展，云厂商能够让很多云平台上的 IaaS 或 PaaS 功能组件，渗透到 K8s 的体系中 引导外部流量的 Ingress Controller（入口控制器）方面，就有基于云上负载均衡器的控制器实现，它们会创建相应的 PaaS 服务实例，来为 K8s 集群服务 可以在 Kubernetes 中定义动态存储卷分配策略的 StorageClass 层面，指定使用云端的块存储服务，来按需创建和挂载持久化存储 云和 K8s 集成的方面还有很多，权限认证、日志集成、私有网络等 从架构灵活性的角度来看，云上 Kubernetes 服务还带来了另一个好处：多集群 容器镜像服务 容器的镜像是容器化程序封装后的基本单位，在云上也需要一个可以存储和管理自己程序镜像的地方，就像 Docker Hub 管理了很多公开镜像一样。在大多数云上都提供了自己的容器镜像服务，可以建立私有的镜像仓库，支持镜像的推送和拉取，还可以进行版本管理等操作。 全托管的容器实例服务 如果只是有一个容器镜像，想要尽快地在云上跑起来，那么这类服务很可能就是最佳选择。因为它简便易行，成本低、速度快，而且不需要操心底层的虚机和集群，也可以绕开复杂的编排系统，只需要关注 Pod 运行层面的目标就可以了。这是容器实例类云服务很大的卖点，尤其对于 无状态 的应用非常适合。 无服务器计算“无服务器”是云计算中资源抽象的极致体现。所谓“无服务器”就是想让用户感觉不到服务器的存在，这是因为有一朵巨大的云在底层进行着支撑。这样可以完全专注于业务逻辑的编写，而不再关心任何基础设施。 无服务器查询服务、无服务器容器服务和对象存储服务理论上来说也是符合无服务器特征的，因为不用关心究竟是什么样的机器和多少机器在背后支撑它。 无服务器计算服务（Serverless Computing） 在粒度上，无服务器会允许用户拆分得更细致、更轻量，甚至可以把每一个具有独立功能的函数，来作为一个单独的服务进行部署和运行。这也是在有些云计算的分类方法下，无服务器计算被称为 函数即服务（Function-as-a-Service，FaaS） 的原因。 也正因为底层没有固化的资源，无服务器计算的计费机制是与众不同的。它一般会按照调用次数和调用时长这两个指标来计费。从成本上来看尤其适合那些偶尔触发、短时间运行的工作。这会比专门设立一台虚拟机来做同样的事情要划算很多。 无服务器计算是多面手 事件模型 是无服务器的核心编程模型和运行逻辑，所以它非常适合相当广泛的事件驱动开发场景。事件的起始，要依靠 触发器。 云上 Serverless 服务一般都配套提供了多种多样的触发器，包括 API 触发器、对象存储触发器、队列触发器 等。 较为常用的还有对象存储触发器。比如当用户上传了一个文件，后台程序把它保存到对象存储中，这时相应的无服务器函数会被这个新对象触发，就能对这个新上传的文件进行必要的处理了。 无服务器计算本身是无状态的，所有的持久化需求都要借助外部存储来实现，所以经常需要和数据库、对象存储等服务配合，这既是常用手法，也是必然选择。 在云端，一个常见的场景和架构范式是，云函数可以和消息队列服务形成一对黄金搭档：当队列中有新的消息进入，队列触发器就会触发云函数，并将消息作为事件参数传递给云函数；然后云函数进行及时处理，处理结果还能够再写入另外一个队列；队列又可以触发下一个云函数。如此层层传递，就可以形成一个 流式数据的处理管道，实现数据的实时处理和分发。 现在无服务器业界发展的又一个热点：即允许按照业务逻辑的控制处理流程，以工作流的方式，进行云函数等事件处理单元的组合和编排。 这里云函数工作流服务，和前面基于队列的流式处理的区别。工作流服务构建的是 控制流，定义事件发生的先后次序和条件依赖；而队列流式处理是 数据流，是数据的传递和流向。 在 事件机制 和 工作流服务 的加持下，无服务器计算就成为了一个真正的多面手。它在很多环节都能够扮演恰当的角色，除了自己承担的计算任务之外，它还擅长串联很多云端组件，成为系统组件间的胶水层。 AI 服务AI 相关的 PaaS 服务。它们其实也大致分为两类： 一类是各种成熟能力的开放，是 云厂商已经构建好的现有模型和 API； 另一类则是机器学习的 全生命周期管理支撑平台，可以帮助构建属于自己的机器学习模型。 开箱即用的 AI 服务 这类服务的特点，一般是将非结构化数据处理分析的通用需求场景，进行了封装和开放。可以通过云端标准的 API 和 SDK 来进行调用，一般会按调用次数进行收费。 非结构化数据，指的是 图像、视频、语音、文本 等包含丰富信息的常见数字化内容。对于这些内容的理解，用传统的程序逻辑很难解决，但这恰好是人工智能的强项，它可以深入分析这些内容，并进行信息提取和转换。不同的非结构化数据类型，对应着不同的人工智能研究领域，也对应着相关的各种云上 AI 服务。 构建自己的 AI 模型 无论你想要构建哪种模型，包括经典机器学习和深度学习，它们共性的地方在于，都有一个类似的流程和步骤，包括数据准备和标注、模型训练、模型部署等。云上机器学习服务，它的目标就是非常精准地支撑和赋能这些重要环节，帮助你进行贯穿全生命周期的模型构建和管理。 云上还有 IoT 服务、区块链服务、DevOps 服务 等 云计算和云原生云计算已经成为一个无所不包的信息技术服务平台，它抽象了多个大型数据中心内的海量计算存储资源，对外提供了从基础设施到托管平台不同层次、不同粒度的在线服务和组件，同时也是各个领域最新前沿技术和架构理念的最佳载体。 云计算还是一种行之有效的商业模式，是一门好的生意，能够持续有效地获得巨大营收和利润。这也是云计算行业得以聚拢人才、持续发展的原因。 云计算 其实是一个 载体 和 平台。这个平台之上承载着从 IaaS 到 PaaS 林林总总的能力，每项能力中既包含了 资源，也体现了 技术，并且以 产品 和 服务 的形态开放。云的 承载性 是云得以包罗万象，并且与时俱进的根本原因。 云原生 的本质是用于构建现代云端应用的一系列架构理念，以及帮助这些理念落地的技术支撑和最佳实践。云原生的核心理念包括 无状态、分布式、服务化、弹性扩展 等等。 常见的一种 狭义 的云原生定义，特指的是容器化、容器编排和微服务架构，从更广义的视角来看，只要是适合在云上运行，具备和符合云上架构特点的应用，都可以说是属于“云原生”范畴。 如果通过优雅地结合使用对象存储、云数据库、无服务器计算等云端组件，开发了一个弹性可扩展的应用程序，那它当然也完全称得上是“云原生”应用。 相关资料 深入浅出云计算 深入高可用架构原理与实践","tags":["IaaS","Paas","cloud computing"],"categories":["Cloud"]},{"title":"Efficient Programmers' Way of Working","path":"/2024/06/11/programmer/","content":"10x 程序员工作法 - 郑晔 大部分程序员忙碌解决的问题，都不是程序问题，而是由偶然复杂度导致的问题。如何减少偶然复杂度引发的问题，让软件开发工作有序、高效地进行？ 本质复杂度（Essential Complexity） 指解决问题或实现功能时，不可避免存在的复杂性 是由问题本身的复杂性所导致的，无法通过简化设计或改变方法来消除 例如：处理大规模数据时所面对的复杂性，即使采用最佳算法和数据结构，也无法避免 偶然复杂度（Accident Complexity） 指在软件开发过程中，由于设计、工具或技术选择等外部因素引入的额外复杂性 是可以通过改变设计、优化工具选择或改进工作流程等方式来减少或消除的复杂性 例如：由于技术栈选择不当或设计不良引入的额外代码复杂性，例如过多的依赖或复杂的类继承结构 思考框架 一个思考框架 Where are we?（现状） Where are we going?（目标） How can we get there?（路径） 开发一个功能特性时，通常需要思考 为什么要做这个特性，它会给用户带来怎样的价值？ 什么样的用户会用到这个特性，他们在什么场景下使用，他们又会怎样使用它？ 达成这个目的是否有其它手段？是不是一定要开发一个系统？ 这个特性上线之后，怎么衡量它的有效性？ 四个思考原则 以终为始：在工作的一开始就确定好自己的目标 任务分解：将大目标拆分成一个一个可行的执行任务，工作分解得越细致，越能更好地掌控工作 沟通反馈：疏通与其他人交互的渠道（解决与人打交道出现的问题） 保证信息能够传达出去，减少因为理解偏差造成的工作疏漏 保证我们能够准确接收外部信息，以免因为自我感觉良好，阻碍了进步 自动化：将繁琐的工作通过自动化的方式交给机器执行（解决与机器打交道出现的问题） 现在在哪？（现状） 要到哪去？（目标） 如何到达那里？（路径） 你很清楚 以终为始 任务分解、沟通反馈、自动化 以终为始 以终为始：如何让你的努力不白费 把目光放长远是需要额外消耗能量的，“以终为始”是一种反直觉的思维方式 任何事物都要经过两次创造： 一次是在头脑中的创造，也就是智力上的或者第一次创造（Mental&#x2F;First Creation） 然后才是付诸实践，也就是实际的构建或第二次创造（Physical&#x2F;Second Creation） 在今天的软件开发实践中，已经有很多采用了“以终为始”原则的实践 测试驱动开发 持续集成 践行“以终为始”就是在做事之前，先考虑结果，根据结果来确定要做的事情（遇到事情，倒着想） DoD的价值：你完成了工作，为什么他们还不满意 DoD（Definition of Done，完成的定义）为了解决软件开发中常见的“完成”问题（理解鸿沟）而生的 例如：特性开发完成，表示开发人员经过了需求澄清、功能设计、编写代码、单元测试，通过了测试人员的验收，确保代码处于一个可部署的状态，相关文档已经编写完毕 开发完成，表示开发人员编写好功能代码，编写好单元测试代码，编写好集成测试代码，测试可以通过，代码通过了代码风格检查、测试覆盖率检查 DoD 是一个清单，清单是由一个个实际可检查的检查项组成，用来检查我们的工作完成情况 DoD 是团队成员间彼此汇报的一种机制，在团队层面，也可以定义 DoD： 某个功能的 DoD，比如：这个功能特性已经开发完成，经过产品负责人的验收，处于一个可部署的状态 一个迭代的 DoD，比如：这个迭代规划的所有功能已经完成 一次发布的 DoD，比如：整个软件处于可发布的状态，上线计划已经明确 DoD 不仅局限在团队内部协作上，在工作中用途非常广泛 例如“定义接口”的 DoD，需要检查： 服务方提供的接口是不是和这个可运行的接口返回值是一样的 调用方是否可以和这个可运行的接口配合使用 DoD 是一个思维模式，是一种尽可能消除不确定性，达成共识的方式 本着“以终为始”的方式做事情，DoD 让我们能够在一开始就把“终”清晰地定义出来 接到需求任务，你要先做哪件事 用户故事（User Story）是站在用户的角度来描述了一个用户希望得到的功能，关注用户在系统中完成一个动作需要经过怎样的路径 一个完整的用户故事大致包含以下几个部分 标题，简要地说明这个用户故事的主要内容 概述，简要地介绍这个用户故事的主要内容，一般会用这样的格式：- As a (Role), I want to (Activity), so that (Business Value) 验收标准，这个部分会描述一个正常使用的流程是怎样的，以及各种异常流程系统是如何给出响应的，把详述中很多叙述的部分变成一个具体的测试用例 验收标准给出了这个需求最基本的测试用例，它保证了开发人员完成需求最基本的质量，其非常重要的一环是异常流程的描述 BDD（Behavior-Driven Development，“行为驱动开发”） 验收标准所给出实现细节应该是业务上的，程序员的发挥空间应该是在技术实现上 虽然你名义上是程序员，但当拿到一个需求的时候，你要做的事不是立即动手写代码，而是扮演产品经理的角色，分析需求，圈定任务范围 “最好维护的代码是没有写出来的代码” 持续集成：集成本身就是写代码的一个环节 当我们在一个团队中工作的时候，把不同人的代码放在一起，使之成为一个可工作软件的过程就是集成 持续集成（Continuous Integration）一个关键的思维破局是，将原来分成两个阶段的开发与集成合二为一了，也就是一边开发一边集成 每日构建作为早期的一种“最佳实践”被提了出来，当人们进一步“调小”参数后，诞生了一个更极致的实践：持续集成，也就是每次提交代码都进行集成 一个好的做法是尽早把代码和已有代码集成到一起，而不应该等着所有代码都开发完了，再去做提交 精益创业：产品经理不靠谱，你该怎么办 我们必须要有自己的独立思考，多问几个为什么，尽可能减少掉到“坑”里之后再求救的次数 软件开发的主流由面向确定性问题，逐渐变成了面向不确定性问题 一旦一个问题变成通用问题，就有人尝试总结各种最佳实践，一旦最佳实践积累多了，就会形成一套新的方法论 最早成型的面向不确定性创造新事物的方法论是精益创业（Lean Startup） 精益创业是在尽可能少浪费的前提下，面向不确定性创造新事物，既然是不确定的，那你唯一能做的事情就是“试” 最小可行产品 MVP（Minimum Viable Product）是精益创业提出的一个非常重要的概念（少花钱，多办事） “把软件完整地做出来是最大的浪费” 默认所有需求都不做，直到弄清楚为什么要做这件事 解决了很多技术问题，为什么你依然在“坑”里 花大力气去解决一个可能并不是问题的问题，常常是很多程序员的盲区（被自己的思考局限住） 不同角色工作真正的差异在于上下文的差异，在一个局部上下文难以解决的问题，换到另外一个上下文甚至是可以不解决的 当你对软件开发的全生命周期都有了认识之后，你看到的就不再是一个点了，而是一条线 扩大自己工作的上下文，别把自己局限在一个“程序员”的角色上 为什么说做事之前要先进行推演 一件事 → 工作列表（模糊 → 清晰）比如： 先从结果的角度入手，看看最终上线要考虑哪些因素 推演出一个可以一步一步执行的上线方案，用前面考虑到的因素作为衡量指标 根据推演出来的上线方案，总结要做的任务 “最后一公里”：完成一件事，在最后也是最关键的步骤；结果是重要的。然而，通向结果的路径才是更重要的 一种是前期其乐融融，后期手忙脚乱；一种是前面思前想后，后面四平八稳 即便已经确定了自己的工作目标，我们依然要在具体动手之前，把实施步骤推演一番，完成一次头脑中的创造，也就是第一次创造或智力上的创造 这种思想在军事上称之为沙盘推演，在很多领域都有广泛地应用 你的工作可以用数字衡量吗 直觉通常是一种洞见（Insight），洞见很大程度上依赖于一个人在一个领域长期的沉淀和积累，而这其实是某种意义上的大数据 主观 → 客观（测量指标） 很少把数字化的思维带到工作范围内是工作中很多“空对空”对话的根源所在 出现波动尤其是大幅度波动，又不能给出一个合理解释的话，就说明系统存在着隐患 迭代0: 启动开发之前，你应该准备什么 需求方面 细化过的迭代1需求 用户界面和用户交互 技术方面 基本技术准备（技术选型、系统架构、数据库表结构、持续集成、测试） 发布准备（数据库迁移、发布） 任务分解 向埃隆·马斯克学习任务分解 不同的可执行定义差别在于，你是否能清楚地知道这个问题该如何解决 大多数人都高估了自己可执行粒度，低估任务分解的程度（分解出来的任务粒度偏大） 软件行业都在提倡拥抱变化，而任务分解是我们拥抱变化的前提 测试也是程序员的事吗 尽可能早地发现问题，修正问题，这样所消耗的成本才是最低的 “以终为始”，就是在强调尽早发现问题，能从需求上解决的问题，就不要到开发阶段，在开发阶段能解决的问题，就不要留到测试阶段 测试框架把自动化测试作为一种最佳实践引入到开发过程中，使得测试动作可以通过标准化的手段固定下来 单元测试框架只是一个自动化测试的工具而已，并不是用来定义测试类型 关注最小程序模块的单元测试、将多个模块组合在一起的集成测试、将整个系统组合在一起的系统测试 根据不同测试的配比，也就有了不同的测试模型 冰淇淋蛋卷测试模型的人并不多，它是一种费时费力的模型，要准备高层测试实在是太麻烦了 行业里的最佳实践：测试金字塔（越在底层测试，成本越低，执行越快；越在高层测试，成本越高，执行越慢） 虽然冰淇淋蛋卷更符合直觉，但测试金字塔才是行业的最佳实践 在本地运行单元测试和集成测试，在持续集成服务器上运行系统测试 先写测试，就是测试驱动开发吗 先写测试，后写代码的实践指的是测试先行开发（Test First Development），而非测试驱动开发（Test Driven Development） 二者的差别在于，TDD 还有一个更重要的环节：重构（refactoring），不能忽略了新增代码可能带来的“坏味道（Code Smell） 重构与测试是相辅相成的：没有测试，你只能是提心吊胆地重构；没有重构，代码的混乱程度是逐步增加的，测试也会变得越来越不好写 先测试后写代码的方式，会让你看待代码的角度完全改变，甚至要调整你的设计，才能够更好地去测试（写代码前，先想怎么测） 懂 TDD 的人会把 TDD 解释为测试驱动设计（Test Driven Design） 大师级程序员的工作秘笈 极限编程对于行业最大的贡献在于，它引入了大量的实践，比如持续集成、TDD、结对编程、现场客户等等 极限编程之所以叫“极限”，它背后的理念就是把好的实践推向极限 如果集成是好的，我们就尽早集成，推向极限每一次修改都集成，这就是持续集成 如果开发者测试是好的，我们就尽早测试，推向极限就是先写测试，再根据测试调整代码，这就是测试驱动开发 如果代码评审是好的，我们就多做评审，推向极限就是随时随地地代码评审，这就是结对编程 如果客户交流是好的，我们就和客户多交流，推向极限就是客户与开发团队时时刻刻在一起，这就是现场客户 能把任务分解到很小，其实是证明你已经想清楚了；而大多数程序员之所以开发效率低，很多时候是没想清楚就动手了 TDD 实践起来却不知道如何下手，中间就是缺了任务分解的环节（或是任务分解的粒度不够“小”） 一起练习分解任务 按照一个需求、一个需求的过程走，这样，任务是可以随时停下来的 需求：用户通过输入用户名和密码登录，按照完整实现一个需求的顺序去安排分解出来的任务 分解前： 分解后： 检验每个任务项是否拆分到位，就是看你是否知道它应该怎么做了 所有分解出来的任务，都是独立的，每做完一个任务，代码都是可以提交的（小步提交） 为什么你的测试不够好 测试的作用是保证代码的正确性，如何保证测试的正确性？把测试写简单，简单到一目了然，不需要证明它的正确性 一般测试要具备的四段：前置准备、执行、断言（预期判断）和清理；没有断言的测试，是没有意义的 测试不好写，往往是设计的问题，应该调整的是设计，而不是在测试这里做妥协 当测试代码里出现各种判断和循环语句，基本上这个测试就有问题了，应该多写几个测试，每个测试覆盖一种场景 怎么样的测试算是好的测试呢？一段旅程（A-TRIP） Automatic，自动化 - 测试一定要有断言 Thorough，全面的 - 测试覆盖率工具 Repeatable，可重复的 - 不应依赖任何不在控制之下的环境 Independent，独立的 - 试和测试之间不应该有任何依赖 Professional，专业的 - 测试代码，也是代码 程序员也可以“砍”需求吗 “主题”只是帮你记住大方向，需要进一步分解；“用户故事”是需求管理的基本单位 评价用户故事有一个 “INVEST 原则”，这是六个单词的缩写，分别是： Independent，独立的。一个用户故事应该完成一个独立的功能，尽可能不依赖于其它用户故事，因为彼此依赖的用户故事会让管理优先级、预估工作量都变得更加困难。如果真的有依赖，一种好的做法是，将依赖部分拆出来，重新调整。 Negotiable，可协商的。有事大家商量是一起工作的前提，我们无法保证所有的细节都能100%落实到用户故事里，这个时候最好的办法是大家商量。它也是满足其它评判标准的前提，就像前面提到的，一个用户故事不独立，需要分解，这也需要大家一起商量的。 Valuable，有价值的。一个用户故事都应该有其自身价值，这一项应该最容易理解，没有价值的事不做。但正如我们一直在说的那样，做任何一个事情之前，先问问价值所在。 Estimatable，可估算的。我们会利用用户故事估算的结果安排后续的工作计划。不能估算的用户故事，要么是因为有很多不确定的因素，要么是因为需求还是太大，这样的故事还没有到一个能开发的状态，还需要产品经理进一步分析。 Small，小。步子大了，不行。不能在一定时间内完成的用户故事只应该有一个结果，拆分。小的用户故事才方便调度，才好安排工作。 Testable，可测试的。不能测试谁知道你做得对不对。这个是我们在前面已经强调过的内容，也就是验收标准，你得知道怎样才算是工作完成。 度量用户故事大小的方式有很多种，有人用 T 恤大小的方式，也就是S、M、L、XL、XXL。也有人用费波纳契数列，也就是1、2、3、5、8等等 任务分解是基础中的基础，不学会分解，工作就只能依赖于感觉，很难成为一个靠谱的程序员（估算的结果是相对的，不是绝对精确的） 这时候再说需求调整，调整的就不再是一个大主题，而是一个个具体的用户故事了 需求管理：太多人给你安排任务，怎么办 如果不了解需求是怎么管理的，即便是进行了需求分解，最终的结果很有可能依然是深陷泥潭 一个有效的时间管理策略是艾森豪威尔矩阵（Eisenhower Matrix） 如果不把精力放在重要的事情上，到最后可能都变成紧急的事情 当有多个需求来源时，如何确认哪个需求是最重要的呢？当员工想不明白的事，换成老板的视角就全明白了 很多所谓的人生难题不过是因为见识有限造成的。比如，如果你觉得公司内总有人跟你比技术，莫不如把眼光放得长远一些，把自己放在全行业的水平上去比较，因为你是为自己的职业生涯在工作，而不是一个公司 如何用最小的代价做产品 精益创业就是通过不断地尝试在真实世界中验证产品想法，其中一个重要的实践是最小可行产品（Minimum Viable Product，MVP） “最小”：能不做的事情就不做，能简化的事情就简化 “可行”：找到一条路径，给用户一个完整的体验 当时间有限时，需要学会找到一条可行的路径，在完整用户体验和完整系统之间，找到一个平衡（”刚刚好”满足客户需求） 沟通反馈 为什么世界和你的理解不一样 学习各种知识，是为更好地理解这个世界的运作方式，而沟通反馈，就是与真实世界互动的最好方式 每个人经历见识的差异，造成了各自编解码器的差异，世界是同一个世界，每个人看到的却是千姿百态 通过沟通反馈，不断升级自己的编解码能力，改善编解码，需要从几个角度着手 编码器，让信息能输出更准确 解码器，减少信号过滤，改善解码能力 编解码算法，也就是各种来自行业的“最佳实践”，协调沟通的双方 你的代码为谁而写 一个专业程序员，追求的不仅是实现功能，还要追求代码可维护 任何人都能写出计算机能够理解的代码，只有好程序员才能写出人能够理解的代码。- —— Martin Fowler 人要负责将业务问题和机器执行连接起来，缺少了业务背景是不可能写出好代码的 一个好的命名需要你对业务知识有一个深入的理解，需要额外地学习，这也是我们想写好代码的前提 轻量级沟通：你总是在开会吗 改善会议的第一个行动项是，减少参与讨论的人数，如果你要讨论，找人面对面沟通 开会的目的不再是讨论，而是信息同步 一种特殊的会议：站会 “做了什么” ，是为了与其他人同步进展，看事情是否在计划上，这会涉及到是否要调整项目计划 “要做什么” ，是同步你接下来的工作安排。如果涉及到与其他人协作，也就是告诉大家，让他们有个配合的心理准备 “问题和求助”， 就是与其他人的协作，表示：我遇到不懂的问题，你们有信息的话，可以给我提供一下 多面对面沟通，少开会 可视化：一种更为直观的沟通方式 ThoughtWorks 技术雷达是由 ThoughtWorks 技术咨询委员会（Technology Advisory Board）编写的一份技术趋势报告 技术雷达用来追踪技术，在雷达图的术语里，每一项技术表示为一个 blip，也就是雷达上的一个光点 用两个分类元素组织这些 blip：象限（quadrant）和圆环（ring） 象限表示一个 blip 的种类，目前有四个种类：技术、平台、工具，还有语言与框架 圆环表示一个 blip 在技术采纳生命周期中所处的阶段：采用（Adopt）、试验（Trial）、评估（Assess）和暂缓（Hold） 雷达图是一种很好的将知识分类组织的形式，它可以让你一目了然地看到并了解所有知识点，并根据自己的需要，决定是否深入了解 看板，是一种项目管理工具，它将我们正在进行的工作变得可视化，这个实践来自精益生产 将工作分成几个不同的阶段，然后，把分解出来的工作做成一张卡片，根据当前状态放置到不同的阶段中 看板可以帮助你一眼看出许多问题，比如，当前进展是否合适，是否有人同时在做很多的事，发现当前工作的瓶颈等 多尝试用可视化的方式进行沟通 快速反馈：为什么你们公司总是做不好持续集成 持续集成的两个重要目标：怎样快速地得到反馈，以及什么样的反馈是有效的 “快速”：不能把检查只放到 CI 服务器上执行，在本地开发环境上执行 用好本地构建脚本（build script），保证各种各样的检查都可以在本地环境执行 一旦有了构建脚本，你在 CI 服务器上的动作也简单了，就是调用这个脚本（动作一致） “反馈”，也就是怎么得到即时的、有效的反馈，持续集成监视器，也是 CI 监视器 CI 监视器的原理很简单，CI 服务器在构建完之后，会把结果以 API 的方式暴露出来 只有 CI 服务器处于绿色的状态才能提交代码，CI 服务器一旦检查出错，要立即修复 开发中的问题一再出现，应该怎么办 把过程还原，进行研讨与分析的方式，就是复盘（客体化） 用别人的视角看问题，这就是客体化，由一个主观的视角，变成了一个客观的视角 回顾会议 —— 一种复盘的实践 回顾会议是一个常见的复盘实践，定期回顾是一个团队自我改善的前提 主题分类 比如：做得好的、做得欠佳的、问题或建议 或者海星图，分成了五大类：“继续保持、开始做、停止做、多做一些、少做一些” 写事实，不写感受，针对性地讨论 5个为什么（5 Whys）—— 一个常用的找到根因的方式 比如服务器经常返回504，那我们可以采用“5个为什么”的方式来问一下 为什么会出现504呢？因为服务器处理时间比较长，超时了 为什么会超时呢？因为服务器查询后面的 Redis 卡住了 为什么访问 Redis 会卡住呢？因为另外一个更新 Redis 的服务删除了大批量的数据，然后，重新插入，服务器阻塞了 为什么它要大批量的删除数据重新插入呢？因为更新算法设计得不合理 为什么一个设计得不合理的算法就能上线呢？因为这个设计没有按照流程进行评审 解决之道自然就浮出水面了：一个核心算法一定要经过相关人员的评审 “5个为什么”中的“5”只是一个参考数字，不是目标 不要用这些方法责备某个人，目标是想要解决问题，不断地改进，而不是针对某个人发起情感批判 作为程序员，你也应该聆听用户声音 “Eat your own dog food” —— “提高自家产品在内部使用的比例” 我们要做一个有价值的产品，这个“价值”，不是对产品经理有价值，而是要对用户有价值 谁离用户近，谁就有发言权，无论你的角色是什么 尽早暴露问题：为什么被指责的总是你 不是所有的问题，都是值得解决的技术难题，遇到问题，最好的解决方案是尽早把问题暴露出来 写程序有一个重要的原则叫 Fail Fast，如果遇到问题，尽早报错 在程序中尽早暴露问题是很容易接受的，但在工作中暴露自己的问题，却是很大的挑战 比起尽早暴露问题，还有更进一步的工作方式，那就是把自己的工作透明化 结构化：写文档也是一种学习方式 你发现矛盾了吗？一方面，我们讨厌写文档，另一方面，文档却对我们的工作学习有着不可忽视的作用 很多人回避写文档的真正原因是，他掌握的内容不能很好地结构化 当你的知识都是零散的，任何新技术的出现，都是新东西，当你建立起自己的知识结构，任何新东西都只是在原有知识上的增量叠加 将零散的知识结构化，有很多种方式，但输出是非常关键的一环；输出的过程，本质上就是把知识连接起来的过程 输出的方式有很多，对于程序员来说，最常接触到的两种应该是写作与演讲，软件行业的很多大师级程序员都是对外输出的高手 把事情说清楚，把自己的知识清晰地呈现出来，金字塔原理： 即便强如乔布斯，他的演讲也是经过大量练习的，本质上，对演讲的惧怕只是因为练习不足 无他，唯手熟尔！ 自动化 “懒惰”应该是所有程序员的骄傲 Perl 语言的发明人 Larry Wall 一个经典叙述：优秀程序员应该有三大美德：懒惰、急躁和傲慢（Laziness, Impatience and hubris） 懒惰，是一种品质，它会使你花很大力气去规避过度的精力消耗，敦促你写出节省体力的程序，别人也能很好地利用，你还会为此写出完善的文档，以免别人来问问题 急躁，是计算机偷懒时，你会感到的一种愤怒，它会促使你写出超越预期的程序，而不只是响应需求。 傲慢，极度自信，写出（或维护）别人挑不出毛病的程序 做有价值的事是重要的，这里面的有价值，不仅仅是“做”了什么，通过“不做”节省时间和成本也是有价值的 可以从需求的角度判断哪些工作是可以不做的，但我们也要防止程序员自己“加戏” NIH 综合症（Not Invented Here Syndrome），人特别看不上别人做的东西，非要自己做出一套来，原因只是因为那个东西不是我做的，可能存在各种问题 写代码之前，先问问自己真的要做吗？能不做就不做，直到你有了足够的理由去做 在软件开发中，其它的东西都是易变的，唯有设计的可变性是你可以控制的 不懂软件设计，只专注各种工具，其结果一定是被新技术遗弃，这也是很多人经常抱怨 IT 行业变化快的重要原因 一个好的项目自动化应该是什么样子的 将工作过程自动化 生成 IDE 工程、编译、打包、运行测试、代码风格检查、测试覆盖率、数据库迁移、运行应用 程序员怎么学习运维知识 每个程序员都应该学习运维知识，保证我们对软件的运行有更清楚地认识，而且部署工作是非常适合自动化的 但是，对运维工具的学习是非常困难的，因为我们遇到的很多工具是非常零散的，需要有体系地学习运维知识 持续交付：有持续集成就够了吗 一般来说，在构建持续交付的基础设施时，会有下面几个不同的环境 持续集成环境，持续集成是持续交付的前提，这个过程主要是执行基本的检查，打出一个可以发布的包 测试环境（Test），这个环境往往是单机的，主要负责功能验证，这里运行的测试基本上都是验收测试级别的，而一般把单元测试和集成测试等执行比较快的测试放到持续集成环境中执行 预生产环境（Staging），这个环境通常与生产环境配置是相同的，比如，负载均衡，集群之类的都要有，只是机器数量上会少一些，主要负责验证部署环境，比如，可以用来发现由多机并发带来的一些问题 生产环境（Production），这就是真实的线上环境了 通常会用几个不同的环境验证，每一个环境都是一个单独的阶段，一个阶段不通过，是不能进入下一阶段的，这种按照不同阶段组织构建的方式，称之为构建流水线（Build Pipeline） 在准备好发布包和部署的基础设施之后，我们顺着持续集成的思路，将部署过程也加了进来，这就是持续交付 持续交付，是一种让软件随时处于可以部署到生产环境的能力，让软件具备部署到生产环境的能力，这里面有两个关键点：验证发布包和部署 DevOps 包含了很多方面，对程序员最直接的影响是各种工具的发展，这些工具推动着另一个理念的发展：基础设施即代码（Infrastructure as code） 今天定义交付，就不再是一个发布包，而是一个可以部署的镜像 如何做好验收测试 验收测试（Acceptance Testing），是确认应用是否满足设计规范的测试，这种测试往往是站在用户的角度，看整个应用能否满足业务需求 让验收测试从各自为战的混乱中逐渐有了体系的是行为驱动开发（Behavior Driven Development）这个概念的诞生 行为驱动开发中的行为，指的是业务行为，想写好 BDD 的测试用例，关键点在用业务视角描述 基本格式为“Given…When…Then”，要编写步骤定义（Step Definition）将测试用例与实现连接起来 （怎么看起来的感觉像形式化语言、形式化规格说明之类的 你的代码是怎么变混乱的 Robert Martin 提出的面向对象设计原则：SOLID，这其实是五个设计原则的缩写，分别是 单一职责原则（Single responsibility principle，SRP） 开放封闭原则（Open–closed principle，OCP） Liskov 替换原则（Liskov substitution principle，LSP） 接口隔离原则（Interface segregation principle，ISP） 依赖倒置原则（Dependency inversion principle，DIP） 如果说设计模式是“术”，设计原则才是“道”，设计模式并不能帮你建立起知识体系，而设计原则可以 很多代码的问题就是因为对设计思考得不足导致的，如果只能记住一件事，那请记住：把函数写短 总是在说MVC分层架构，但你真的理解分层吗 分层架构，实际上，就是一种在设计上的分解，因为好的分层往往需要有好的抽象 网络模型的分层架构好到你作为上层的使用者几乎可以忽略底层，这正是分层的价值：构建一个良好的抽象 为数不少的团队都在自己的业务代码中直接使用了第三方代码中的对象，第三方的任何修改都会让你的代码跟着改，你的团队就只能疲于奔命 解决这个问题最好的办法就是把它们分开，你的领域层只依赖于你的领域对象，第三方发过来的内容先做一次转换，转换成你的领域对象，这种做法称为防腐层 把领域模型看成了整个设计的核心，看待其他层的视角也会随之转变，它们只不过是适配到不同地方的一种方式而已 这种理念的推广，就是一些人在说的六边形架构 在日常工作中，我们应该把精力重点放在构建自己的领域模型上，因为它才是工作最核心、不易变的东西 为什么总有人觉得5万块钱可以做一个淘宝 作为程序员，我们需要知道自己面对的到底是一个什么样的系统，不同业务量级的系统本质上就不是一个系统 淘宝的工程师之所以要改进系统，真实的驱动力不是技术，而是不断攀升的业务量带来的问题复杂度 评估系统当前所处的阶段，采用恰当的技术解决，是我们最应该考虑的问题 一方面，有人会因为对业务量级理解不足，盲目低估其他人系统的复杂度 另一方面，也有人会盲目应用技术，给系统引入不必要的复杂度，让自己陷入泥潭 用简单技术解决问题，直到问题变复杂 先做好DDD再谈微服务吧，那只是一种部署形式 服务划分不好，等待团队的就是无穷无尽的偶然复杂度泥潭 领域驱动设计（Domain Driven Design，DDD）是 Eric Evans 提出的从系统分析到软件建模的一套方法论 DDD 把你的思考起点，从技术的角度拉到了业务上 将业务概念和业务规则转换成软件系统中概念和规则，从而降低或隐藏业务复杂性，使系统具有更好的扩展性 许多团队一提起建模，第一反应依然是建数据库表。这种做法是典型的面向技术实现的做法，一旦业务发生变化，团队通常都是措手不及 DDD 分为战略设计（Strategic Design）和战术设计（Tactical Design） 战略设计是高层设计，它帮我们将系统切分成不同的领域，并处理不同领域的关系 战术设计，通常是指在一个领域内，在技术层面上如何组织好不同的领域对象 微服务真正的难点并非在于技术实现，而是业务划分，而这刚好是 DDD 战略设计中限界上下文（Bounded Context）的强项 困扰很多人的微服务之间大量相互调用，本身就是一个没有划分好边界而带来的伪命题，靠技术解决业务问题，事倍功半 即便你学了 DDD，知道了限界上下文，也别轻易使用微服，先用分模块的方式在一个工程内，让服务先演化一段时间，等到真的觉得某个模块可以“毕业”了，再去开启微服务之旅 综合运用 新入职一家公司，怎么快速进入工作状态 业务 如果你了解了业务，你自己就可以推演出基本的代码结构，反之几乎不可能 了解业务时，一定要打起精神，告诉自己，这个阶段，我要了解的只是业务，千万别给我讲技术 技术 系统的技术栈、业务架构、模块划分、项目分层结构、接口的形式（REST&#x2F;RPC&#x2F;MQ） 这个系统对外提供哪些接口，这对应着系统提供的能力 这个系统需要集成哪些外部系统，对应着它需要哪些支持 团队运作 需求是从哪来的，产品最终会由谁使用，团队需要向谁汇报，如果有外部客户，日常沟通是怎么安排的 定期的活动，比如，站会、回顾会议、周会，这些不同活动的时间安排是怎样的 团队的日常活动，比如，是否有每天的代码评审、是否有内部的分享机制等 如果有人很清楚团队现状的话，你可以去请教，也许一天就够了 大多数程序员习惯的工作方式，往往是从细节入手，很难建立起一个完整的图景，常常是“只见树木不见森林” 需要从大到小、由外而内，将要了解的内容层层分解，有了大图景之后，知道自己做的事情到底在整体上处于什么样的位置 在交流的过程中，学习一点”行话“，这会让人觉得你懂行，让你很快得到信任，尽早融入团队 面对遗留系统，你应该这样做 构建测试防护网，保证新老模块功能一致；分成小块，逐步替换 要想代码腐化的速度不那么快，一定要在软件设计上多下功夫 一方面，建立好领域模型，有不少行业已经形成了自己在领域模型上的最佳实践，比如，电商领域 另一方面，寻找行业对于系统构建的最新理解，即我们需要知道现在行业已经发展到什么水平了 既然选择重写代码，至少新的代码应该按照“最佳实践”来做，才能够尽可能减缓代码腐化的速度 改造遗留系统，一个关键点就是，不要回到老路上 我们应该如何保持竞争力 我们的焦虑来自于对未来的不确定性，而这种不确定性是一个特定时代加上特定行业的产物 有了“一专”，“多能”才是有意义的，这里的“专”不是熟练，而是深入 当你有了“一专”，拓展“多能”，就会拥有更宽广的职业道路。比如，我拥有了深厚的技术功底，通晓怎么做软件： 如果还能够带着其他人一起做好，就成了技术领导者 如果能够分享技术的理解，就有机会成为培训师 如果能够在实战中帮助别人解决问题，就可以成为咨询师 怎么才能让自己的水平不断提高呢？我的答案是，找一个好问题去解决 如果你还什么都不会，那有一份编程的工作就好 如果你已经能够写好普通的代码，就应该尝试去编写程序库 如果实现一个具体功能都没问题了，那就去做设计，让程序有更好的组织 如果你已经能完成一个普通的系统设计，那就应该去设计业务量更大的系 在学习区工作和成长 结束语 怎么才能有效工作呢 拓展自己的上下文，看到真正的目标，更好地对准靶子，比如，多了解用户，才不至于做错了方向；站在公司的层面上，才知道哪个任务优先级更高；站在行业的角度，而不局限于只在公司内成为高手，等等 去掉不必要的内容，减少浪费，比如，花时间分析需求，不做非必要的功能；花时间做好领域设计，别围着特定技术打转；花时间做好自动化，把精力集中在编码上，等等 一方面，意识上要注意自己工作中无效的部分 另一方面，要构建自己关于软件开发的知识体系，这是要花时间积累的","tags":["programmer"],"categories":["Reading"]},{"title":"Redis 核心原理与实践 🚀","path":"/2024/05/22/redis/","content":"梳理 Redis 知识体系 持久化Redis 持久化拥有以下三种方式： 快照方式（RDB, Redis Data Base）将某一个时刻的内存数据，以二进制的方式写入磁盘； 文件追加方式（AOF, Append Only File），记录所有的操作命令，并以文本的形式追加到文件中； 混合持久化方式，Redis 4.0 之后新增的方式，混合持久化是结合了 RDB 和 AOF 的优点，在写入的时候，先把当前的数据以 RDB 的形式写入文件的开头，再将后续的操作命令以 AOF 的格式存入文件，这样既能保证 Redis 重启时的速度，又能减低数据丢失的风险。 RDB 优点 RDB 的内容为二进制的数据，占用内存更小，更紧凑，更适合做为备份文件； RDB 对灾难恢复非常有用，它是一个紧凑的文件，可以更快的传输到远程服务器进行 Redis 服务恢复； RDB 可以更大程度的提高 Redis 的运行速度，因为每次持久化时 Redis 主进程都会 fork() 一个子进程，进行数据持久化到磁盘，Redis 主进程并不会执行磁盘 I&#x2F;O 等操作； 与 AOF 格式的文件相比，RDB 文件可以更快的重启。 RDB 缺点 因为 RDB 只能保存某个时间间隔的数据，如果中途 Redis 服务被意外终止了，则会丢失一段时间内的 Redis 数据； RDB 需要经常 fork() 才能使用子进程将其持久化在磁盘上。如果数据集很大，fork() 可能很耗时，并且如果数据集很大且 CPU 性能不佳，则可能导致 Redis 停止为客户端服务几毫秒甚至一秒钟。 AOF 优点 AOF 持久化保存的数据更加完整，AOF 提供了三种保存策略：每次操作保存、每秒钟保存一次、跟随系统的持久化策略保存，其中每秒保存一次，从数据的安全性和性能两方面考虑是一个不错的选择，也是 AOF 默认的策略，即使发生了意外情况，最多只会丢失 1s 钟的数据； AOF 采用的是命令追加的写入方式，所以不会出现文件损坏的问题，即使由于某些意外原因，导致了最后操作的持久化数据写入了一半，也可以通过 redis-check-aof 工具轻松的修复； AOF 持久化文件，非常容易理解和解析，它是把所有 Redis 键值操作命令，以文件的方式存入了磁盘。即使不小心使用 flushall 命令删除了所有键值信息，只要使用 AOF 文件，删除最后的 flushall 命令，重启 Redis 即可恢复之前误删的数据。 AOF 缺点 对于相同的数据集来说，AOF 文件要大于 RDB 文件； 在 Redis 负载比较高的情况下，RDB 比 AOF 性能更好； RDB 使用快照的形式来持久化整个 Redis 数据，而 AOF 只是将每次执行的命令追加到 AOF 文件中，因此从理论上说，RDB 比 AOF 更健壮。 graph subgraph 混合持久化 A[Redis 启动] --> B{开启AOF} B -- 是 --> C{文件开头为RDB格式} C -- 是 --> D[加载RDB] D --> E[加载AOF] E --> F[正常启动] C -- 否 --> E B -- 否 --> G{开启RDB} G -- 是 --> H{有RDB文件} H -- 是 --> I[加载RDB] I --> F H -- 否 --> F G -- 否 --> F end 混合持久化优点： 混合持久化结合了 RDB 和 AOF 持久化的优点，开头为 RDB 的格式，使得 Redis 可以更快的启动，同时结合 AOF 的优点，有减低了大量数据丢失的风险。 混合持久化缺点： AOF 文件中添加了 RDB 格式的内容，使得 AOF 文件的可读性变得很差； 兼容性差，如果开启混合持久化，那么此混合持久化 AOF 文件，就不能用在 Redis 4.0 之前版本了。 事务multi 命令可以让客户端从非事务模式状态，变为事务模式状态，如果客户端已经是事务状态，再执行 multi 命令会报错，但不会终止客户端为事务的状态。 graph LR A[非事务状态] -->|multi 返回ok| C(事务状态) C -->|multi 返回 error| C 客户端进入事务状态之后，执行的所有常规 Redis 操作命令（非触发事务执行或放弃和导致入列异常的命令）会依次入列，命令入列成功后会返回 QUEUED，命令会按照先进先出（FIFO）的顺序出入列，也就是说事务会按照命令的入列顺序，从前往后依次执行。 graph LR A[客户端命令] --> B(事务状态) B --> |是| C(命令人列) C --> D(返回入列结果) B --> |否| E(执行命令) E --> F(返回执行结果) 执行事务的命令是 exec，放弃事务的命令是 discard graph LR A[客户端命令] --> B(事务状态) B --> |是| C(exec、discard) B --> |否| F C --> |否| D(命令人列) D --> E(返回入列结果) C --> |是| F(执行命令) F --> G(返回执行结果) 错误&amp;回滚 执行时错误： 即使事务队列中某个命令在执行期间发生了错误，事务也会继续执行，直到事务队列中所有命令执行完成 入列错误不会导致事务结束： 重复执行 multi 会导致入列错误，但不会终止事务，最终查询的结果是事务执行成功了 入列错误导致事务结束： exec 时候不会运行事务 不支持事务回滚的原因有以下两个： 他认为 Redis 事务的执行时，错误通常都是编程错误造成的，这种错误通常只会出现在开发环境中，而 很少会在实际的生产环境中出现，所以他认为没有必要为 Redis 开发事务回滚功能； 不支持事务回滚是因为这种复杂的功能和 Redis 追求的简单高效的设计主旨不符合。 这里不支持事务回滚，指的是 不支持运行时错误的事务回滚。 监控 watch 命令用于客户端并发情况下，为事务提供一个乐观锁（CAS，Check And Set），也就是可以用 watch 命令来监控一个或多个变量，如果在事务的过程中，某个 监控项被修改 了，那么 整个事务 就会 终止执行。 graph LR A[watch 命令] --> B(multi 开启事务) B --> C(命令入列) C --> D(exec 执行事务) D --> E(监控值发生改变) E --> |是| F(退出事务) E --> |否| G(执行并返回结果) watch 命令只能在客户端开启事务之前执行，在事务中执行 watch 命令会引发错误，但不会造成整个事务失败，即使在事务的执行过程中，k 值被修改了，因为调用了 unwatch 命令，整个事务依然会顺利执行。 正常情况下 Redis 事务分为三个阶段：开启事务、命令入列、执行事务。Redis 事务并不支持运行时错误的事务回滚，但在某些入列错误，如 set key 或者是 watch 监控项被修改时，提供整个事务回滚的功能。 Pipeline管道技术（Pipeline）是 客户端 提供的一种 批处理技术，用于一次处理多个 Redis 命令，从而提高整个交互的性能。 管道技术解决了多个命令集中请求时造成网络资源浪费的问题，加快了 Redis 的响应速度，让 Redis 拥有更高的运行速度。但要注意的一点是，管道技术本质上是客户端提供的功能，而非 Redis 服务器端的功能。 graph subgraph 普通命令模式 B -->|结果一| A A[客户端] -->|命令一| B(服务器端) end graph subgraph 管道模式 B -->|结果一+结果二...| A A[客户端] -->|命令一+命令二...| B(服务器端) end 管道技术在使用时还需注意以下几个细节： 发送的命令数量不会被限制，但输入缓存区也就是命令的最大存储体积为 1GB，当发送的命令超过此限制时，命令不会被执行，并且会被 Redis 服务器端断开此连接； 如果管道的数据过多可能会导致客户端的等待时间过长，导致网络阻塞； 部分客户端自己本身也有缓存区大小的设置，如果管道命令没有没执行或者是执行不完整，可以排查此情况或减少管道内的命令重新尝试执行。 过期策略Redis 中设置过期时间主要通过以下四种方式： expire key seconds：设置 key 在 n 秒后过期； pexpire key milliseconds：设置 key 在 n 毫秒后过期； expireat key timestamp：设置 key 在某个时间戳（精确到秒）之后过期； pexpireat key millisecondsTimestamp：设置 key 在某个时间戳（精确到毫秒）之后过期； 字符串中的过期操作 字符串中几个直接操作过期时间的方法，如下列表： set key value ex seconds：设置键值对的同时指定过期时间（精确到秒）； set key value px milliseconds：设置键值对的同时指定过期时间（精确到毫秒）； setex key seconds valule：设置键值对的同时指定过期时间（精确到秒）。 移除过期时间 使用命令： persist key 可以移除键值的过期时间 Redis 中维护了一个字典，存储了所有设置了过期时间的键值（过期字典） graph LR A(客户端) --请求--> C{在缓存字典中} C -->|是| D{当前时间小于过期时间} C -->|否| E(正常键值) D -->|是| E(正常键值) D -->|否| F(结束) E --> F(结束) Redis 会删除已过期的键值，以此来减少 Redis 的空间占用，但因为 Redis 本身是单线的，如果因为删除操作而影响主业务的执行就得不偿失了，为此 Redis 需要制定多个（过期）删除策，常见的过期策略有以下三种： 定时删除 惰性删除 定期删除 定时删除 在设置键值过期时间时，创建一个定时事件，当过期时间到达时，由事件处理器自动执行键的删除操作。 优点：保证内存可以被尽快地释放。 缺点：在 Redis 高负载的情况下或有大量过期键需要同时处理时，会造成 Redis 服务器卡顿，影响主业务执行。 惰性删除 不主动删除过期键，每次从数据库获取键值时判断是否过期，如果过期则删除键值，并返回 null。 优点：因为每次访问时，才会判断过期键，所以此策略只会使用很少的系统资源。 缺点：系统占用空间删除不及时，导致空间利用率降低，造成了一定的空间浪费。 graph LR A[客户端] --请求--> B{检测是否过期} B -- 是 --> C[删除键值并返回 null] B -- 否 --> D[正常返回数据] 定期删除 每隔一段时间检查一次数据库，随机删除一些过期键。Redis 默认每秒进行 10 次过期扫描，此配置可通过 Redis 的配置文件 redis.conf 进行配置，配置键为 hz 它的默认值是 hz 10。 需要注意的是：Redis 每次扫描并不是遍历过期字典中的所有键，而是采用随机抽取判断并删除过期键的形式执行的。 优点： 通过限制删除操作的时长和频率，来减少删除操作对 Redis 主业务的影响，同时也能删除一部分过期的数据减少了过期键对空间的无效占用。 缺点： 内存清理方面没有定时删除效果好，同时没有惰性删除使用的系统资源少。 graph LR A[开始扫描] --> B[从过期字典中获取20元素] B --> C[删除过期键] C --> D{判断过期键是否超过25%} D -- 否 --> E[结束] D -- 是 --> B Redis 使用的是 惰性删除 加 定期删除 的过期策略。 内存淘汰 Redis 过期策略指的是 Redis 使用哪种策略，来删除已经过期的键值对 Redis 内存淘汰机制是指当 Redis 运行内存已经超过 Redis 设置的最大内存之后，采用什么策略来删除符合条件的键值对 graph LR A[客户端] -->|发送命令| B{服务器端检查 maxmemory 是否大于0} B -- 是 --> D{检查运行内存 是否大于 maxmemory} D -- 是 --> E[执行淘汰策略] B -- 否 --> F[结束] D -- 否 --> F[结束] E --> F 策略分类 早期版本的 Redis 有以下 6 种淘汰策略： noeviction：不淘汰任何数据，当内存不足时，新增操作会报错，Redis 默认内存淘汰策略； **allkeys-lru**：淘汰整个键值中最久未使用的键值； **allkeys-random**：随机淘汰任意键值； **volatile-lru**：淘汰所有设置了过期时间的键值中最久未使用的键值； **volatile-random**：随机淘汰设置了过期时间的任意键值； **volatile-ttl**：优先淘汰更早过期的键值。 在 Redis 4.0 版本中又新增了 2 种淘汰策略： **volatile-lfu**：淘汰所有设置了过期时间的键值中，最少使用的键值； **allkeys-lfu**：淘汰整个键值中最少使用的键值。 其中 allkeys-xxx 表示从所有的键值中淘汰数据，而 volatile-xxx 表示从设置了过期键的键值中淘汰数据。 策略修改 设置内存淘汰策略有两种方法，这两种方法各有利弊，需要使用者自己去权衡。 方式一：通过 config set maxmemory-policy 命令设置。它的优点是设置之后立即生效，不需要重启 Redis 服务，缺点是重启 Redis 之后，设置就会失效。 方式二：通过修改 Redis 配置文件修改，设置 maxmemory-policy 策略，它的优点是重启 Redis 服务后配置不会丢失，缺点是必须重启 Redis 服务，设置才能生效。 淘汰算法 从内存淘汰策略分类上，可以得知，除了随机删除和不删除之外，主要有两种淘汰算法：LRU 算法 和 LFU 算法。LRU 算法LRU 全称是 Least Recently Used 译为最近最少使用，是一种常用的页面置换算法，选择最近最久未使用的页面予以淘汰。 LRU 算法需要基于链表结构，链表中的元素按照操作顺序从前往后排列，最新操作的键会被移动到表头，当需要内存淘汰时，只需要删除链表尾部的元素即可。 Redis 使用的是一种近似 LRU 算法，目的是为了更好的节约内存，它的实现方式是给现有的数据结构添加一个额外的字段，用于记录此键值的最后一次访问时间，Redis 内存淘汰时，会使用随机采样的方式来淘汰数据，它是随机取 5 个值（此值可配置），然后淘汰最久没有使用的那个。 LRU 算法有一个缺点，比如说很久没有使用的一个键值，如果最近被访问了一次，那么它就不会被淘汰，即使它是使用次数最少的缓存，那它也不会被淘汰，因此在 Redis 4.0 之后引入了 LFU 算法。 LFU 算法LFU 全称是 Least Frequently Used 翻译为最不常用的，最不常用的算法是根据总访问次数来淘汰数据的，它的核心思想是“如果数据过去被访问多次，那么将来被访问的频率也更高”。 LFU 解决了偶尔被访问一次之后，数据就不会被淘汰的问题，相比于 LRU 算法也更合理一些。 在 Redis 中 LFU 存储分为两部分，16 bit 的 ldt（last decrement time）和 8 bit 的 logc（logistic counter）。 logc 是用来存储 访问频次，8 bit 能表示的最大整数值为 255，它的值越小表示使用频率越低，越容易淘汰； ldt 是用来存储上一次 logc 的 更新时间。 消息队列发布订阅模式 发布订阅模式的三个命令： subscribe channel 普通订阅 publish channel message 消息推送 psubscribe pattern 主题订阅 发布订阅模式存在以下两个缺点： 无法持久化保存消息，如果 Redis 服务器宕机或重启，那么所有的消息将会丢失； 发布订阅模式是“发后既忘”的工作模式，如果有订阅者离线重连之后不能消费之前的历史消息。 然而这些缺点在 Redis 5.0 添加了 Stream 类型之后会被彻底的解决。除了以上缺点外，发布订阅模式还有另一个需要注意问题：当消费端有一定的 消息积压 时，也就是 生产者发送的消息，消费者消费不过来 时，如果超过 32M 或者是 60s 内持续保持在 8M 以上，消费端会被强行断开，这个参数是在配置文件中设置的，默认值是 client-output-buffer-limit pubsub 32mb 8mb 60。 List 和 ZSet 的实现 List 方式是实现消息队列最简单和最直接的方式，它主要是通过 lpush 和 rpop 存入和读取实现消息队列 graph LR;A[生产者]-->|发送数据 lpush|C[List];E[消费者]-->|拉取数据 rpop|C; 当队列中如果没有数据的情况下，无限循环会一直消耗系统的资源，SDK 中可以使用 brpop 替代 rpop 来解决这个问题，b 是 blocking 的缩写，表示阻塞读，也就是当队列没有数据时，它会进入休眠状态，当有数据进入队列之后，它才会“苏醒”过来执行读取任务，brpop() 方法的第一个参数是设置超时时间的，设置 0 表示一直阻塞。 List 优点： 消息可以被 持久化，借助 Redis 本身的持久化（AOF、RDB 或者是混合持久化），可以有效的保存数据； 消费者可以 积压消息，不会因为客户端的消息过多而被强行断开。 List 缺点： 消息 不能被重复消费，一个消息消费完就会被删除； 没有主题订阅 的功能。 ZSet 版消息队列相比于之前的两种方式，List 和发布订阅方式在实现上要复杂一些，但 ZSet 因为多了一个 score（分值）属性，从而使它具备更多的功能，例如可以用它来存储时间戳，以此来实现延迟消息队列等。它的实现思路和 List 相同也是利用 zadd 和 zrangebyscore 来实现存入和读取。 ZSet 优点： 支持消息持久化； 相比于 List 查询更方便，ZSet 可以利用 score 属性很方便的完成检索，而 List 则需要遍历整个元素才能检索到某个值。 ZSet 缺点： ZSet 不能存储相同元素的值，也就是如果有消息是重复的，那么只能插入一条信息在有序集合中； ZSet 是根据 score 值排序的，不能像 List 一样，按照插入顺序来排序； ZSet 没有向 List 的 brpop 那样的阻塞弹出的功能。 终极方案 - Stream 在 Redis 5.0 Stream 没出来之前，消息队列的实现方式都有着各自的缺陷，例如： 发布订阅模式 PubSub，不能持久化也就无法可靠的保存消息，并且对于离线重连的客户端不能读取历史消息的缺陷； 列表实现消息队列的方式不能重复消费，一个消息消费完就会被删除； 有序集合消息队列的实现方式不能存储相同 value 的消息，并且不能阻塞读取消息。 并且以上三种方式在实现消息队列时，只能存储单 value 值，也就是如果你要存储一个对象的情况下，必须先序列化成 JSON 字符串，在读取之后还要反序列化成对象才行，这也给用户的使用带来的不便。 Redis 5.0 推出了 Stream 类型用于实现消息队列，它借鉴了 Kafka 的设计思路，它支持消息的持久化和消息轨迹的消费，支持 ack 确认消息的模式，让消息队列更加的稳定和可靠。 基本使用 xadd 添加消息； xlen 查询消息长度； xdel 根据消息 ID 删除消息； del 删除整个 Stream； xrange 读取区间消息； xread 读取某个消息之后的消息； xgroup 创建消费者群组； 分布式锁锁是一种常用的并发控制机制，用于保证一项资源在任何时候只能被一个线程使用，如果其他线程也要使用同样的资源，必须排队等待上一个线程使用完。 graph LR A[线程 1] -->|使用| B(锁🔒) B D(资源) C[线程 2] -->|排队等待| B 上面说的锁指的是程序级别的锁，放到分布式环境下就不适用了，这个时候就要使用分布式锁。分布式锁比较好理解就是用于分布式环境下并发控制的一种机制，用于控制某个资源在同一时刻只能被一个应用所使用。 graph LR A[用户] -->|请求| D C[用户] -->|请求| B subgraph 分布式系统 B[应用 1] D[应用 2] end B -->|使用| E(分布式锁🔒) D -->|排队等待| E E F(资源) 分布式锁的实现 分布式锁比较常见的实现方式有三种： Memcached 实现的分布式锁：使用 add 命令，添加成功的情况下，表示创建分布式锁成功。 ZooKeeper 实现的分布式锁：使用 ZooKeeper 顺序临时节点来实现分布式锁。 Redis 实现的分布式锁。 Redis 分布式锁的实现思路是使用 setnx（set if not exists），如果创建成功则表明此锁创建成功，否则代表这个锁已经被占用创建失败，释放锁使用 del 即可，如果在锁未被删除之前，其他程序再来执行 setnx 是不会创建成功的。 死锁的问题 可以使用 expire key seconds 设置超时时间，即使出现程序中途崩溃的情况，超过超时时间之后，这个锁也会解除，不会出现死锁的情况了。 1234567127.0.0.1:6379&gt; setnx lock true(integer) 1127.0.0.1:6379&gt; expire lock 30(integer) 1#逻辑业务处理...127.0.0.1:6379&gt; del lock(integer) 1 #释放锁 但这样依然会有问题，因为命令 setnx 和 expire 处理是一前一后非原子性的，因此如果在它们执行之间，出现断电和 Redis 异常退出的情况，因为超时时间未设置，依然会造成死锁。 可以使用带参数的 set 命令来设置分布式锁，并设置超时时间了，而且 set 命令可以保证原子性 1234127.0.0.1:6379&gt; set lock true ex 30 nxOK #创建锁成功127.0.0.1:6379&gt; set lock true ex 30 nx(nil) #在锁被占用的时候，企图获取锁失败 其中， ex n 为设置超时时间，nx 为元素非空判断，用来判断是否能正常使用锁。 执行超时问题 如果设置锁的最大超时时间是 30s，但业务处理使用了 35s，这就会导致原有的业务还未执行完成，锁就被释放了，新的程序和旧程序一起操作就会带来线程安全的问题。 graph LR A[应用 1] -->|同时拥有锁 使用锁超过 30s| B[分布式锁] C[应用 2] -->|30s 后锁自动释放 此锁被应用2获得| B 执行超时的问题处理带来线程安全问题之外，还引发了另一个问题：锁被误删。 graph LR subgraph 30s 时 A[应用 1] -->|使用锁超过 30s| B[分布式锁] C[应用 2] -->|30s 后成功创建锁| B end subgraph 35s 时 X[应用 1] -->|35s 删除锁| Y[分布式锁] Z[应用 2] --> Y end 锁被误删的解决方案是在使用 set 命令创建锁时，给 value 值设置一个归属人标识，例如给应用关联一个 UUID，每次在删除之前先要判断 UUID 是不是属于当前的线程，如果属于在删除，这样就避免了锁被误删的问题。 如果是在代码中执行删除，不能使用先判断再删除的方法，因为判断代码和删除代码不具备原子性，因此也不能这样使用，这个时候可以使用 Lua 脚本 来执行判断和删除的操作，因为多条 Lua 命令可以保证 原子性。 执行超时问题的解决： 把执行比较耗时的任务不要放到加锁的方法内，锁内的方法尽量控制执行时长； 把最大超时时间可以适当的设置长一点，正常情况下锁用完之后会被手动的删除掉，因此适当的把最大超时时间设置的长一点，也是可行的。 续约机制。 延迟队列延迟队列是指把当前要做的事情，往后推迟一段时间再做。 使用场景 延迟队列的常见使用场景有以下几种： 超过 30 分钟未支付的订单，将会被取消 外卖商家超过 5 分钟未接单的订单，将会被取消 在平台注册但 30 天内未登录的用户，发短信提醒 等类似的应用场景，都可以使用延迟队列来实现。 实现方式 目前市面上延迟队列的实现方式基本分为三类 第一类是通过程序的方式实现，例如 JDK 自带的延迟队列 DelayQueue 优点：开发比较方便，可以直接在代码中使用，代码实现比较简单 缺点：不支持持久化保存，不支持分布式系统 第二类是通过 MQ 框架来实现，例如 RabbitMQ 可以通过 rabbitmq-delayed-message-exchange 插件来实现延迟队列 优点：支持分布式，支持持久化 缺点：框架比较重，需要搭建和配置 MQ 第三类就是通过 Redis 的方式来实现延迟队列 Redis 是通过有序集合（ZSet）的方式来实现延迟消息队列的，ZSet 有一个 Score 属性可以用来存储延迟执行的时间。 实现 第一种是利用 zrangebyscore 查询符合条件的所有待处理任务，循环执行队列任务。 第二种实现方式是每次查询最早的一条消息，判断这条信息的执行时间是否小于等于此刻的时间，如果是则执行此任务，否则继续循环检测。 优点 灵活方便，Redis 是互联网公司的标配，无序额外搭建相关环境； 可进行消息持久化，大大提高了延迟队列的可靠性； 分布式支持，不像 JDK 自身的 DelayQueue； 高可用性，利用 Redis 本身高可用方案，增加了系统健壮性。 缺点 需要使用 无限循环的方式 来执行任务检查，会消耗少量的系统资源。 定时任务键空间通知 默认情况下 Redis 服务器端是不开启键空间通知的，需要手动开启，其中 Ex 表示 开启键事件通知里面的 key 过期事件。 redis-cli：config set notify-keyspace-events Ex redis.conf：notify-keyspace-events Ex 更多配置项说明如下： K：键空间通知，所有通知以 __keyspace@&lt;db&gt;__ 为前缀 E：键事件通知，所有通知以 __keyevent@&lt;db&gt;__ 为前缀 g：DEL、EXPIRE、RENAME 等类型无关的通用命令的通知 $：字符串命令的通知 l：列表命令的通知 s：集合命令的通知 h：哈希命令的通知 z：有序集合命令的通知 x：过期事件，每当有过期键被删除时发送 e：驱逐（evict）事件，每当有键因为 maxmemory 政策而被删除时发送 A：参数 g$lshzxe 的别名 以上配置项可以自由组合，例如订阅列表事件就是 El，但需要注意的是，如果 notify-keyspace-event 的值设置为空，则表示不开启任何通知，有值则表示开启通知。 功能实现 要实现定时任务需要使用 Pub&#x2F;Sub 订阅者和发布者的功能，使用订阅者订阅元素的过期事件，然后再执行固定的任务，这就是定时任务的实现思路。 使用 redis-cli 开启一个客户端，监听 __keyevent@0__:expired 键过期事件，此监听值 __keyevent@0__:expired 为固定的写法，其中 0 表示第一个数据库，Redis 中一共有 16 个数据，默认使用的是第 0 个，建议新开一个非 0 的数据库专门用来实现定时任务，这样就可以避免很多无效的事件监听。 命令监听如下： 1234127.0.0.1:6379&gt; psubscribe __keyevent@0__:expired1) &quot;psubscribe&quot;2) &quot;__keyevent@0__:expired&quot;3) (integer) 1 此时开启另一个客户端，添加两条测试数据试试，命令如下： 1234127.0.0.1:6379&gt; set key value ex 3OK127.0.0.1:6379&gt; set user xiaoming ex 3OK 等过去 3 秒钟之后，监听结果如下： 123456789101112127.0.0.1:6379&gt; psubscribe __keyevent@0__:expired1) &quot;psubscribe&quot;2) &quot;__keyevent@0__:expired&quot;3) (integer) 11) &quot;pmessage&quot; 2) &quot;__keyevent@0__:expired&quot;3) &quot;__keyevent@0__:expired&quot;4) &quot;key&quot; #接收到过期信息 key1) &quot;pmessage&quot;2) &quot;__keyevent@0__:expired&quot;3) &quot;__keyevent@0__:expired&quot;4) &quot;user&quot; #接收到过期信息 user 已经成功的接收到两条过期信息了 通过开启 Keyspace Notifications 和 Pub&#x2F;Sub 消息订阅的方式，可以拿到每个键值过期的事件，利用这个机制实现了给每个人开启一个定时任务的功能，过期事件中可以获取到过期键的 key 值，在 key 值中可以存储每个用户的 id，例如“user_1001”的方式，其中数字部分表示用户的编号，通过此编号就可以完成给对应人发送消息通知的功能。 主从同步主从同步（主从复制）是 Redis 高可用服务的基石，也是多机运行中最基础的一个。把主要存储数据的节点叫做主节点 (master），把其他通过复制主节点数据的副本节点叫做从节点 (slave）。 graph TD A[主节点] -->|复制| B[从节点] A -->|复制| C[从节点] A -->|复制| D[从节点] 在 Redis 中一个主节点可以拥有多个从节点，一个从节点也可以是其他服务器的主节点。 graph TD A[主节点] -->|复制| B[从节点] A -->|复制| C[从节点] A -->|复制| D[从节点] D -->|复制| F[从节点] D -->|复制| G[从节点] 主从同步的优点 性能方面：有了主从同步之后，可以把查询任务分配给从服务器，用主服务器来执行写操作，这样极大的提高了程序运行的效率，把所有压力分摊到各个服务器了； 高可用：当有了主从同步之后，当主服务器节点宕机之后，可以很迅速的把从节点提升为主节点，为 Redis 服务器的宕机恢复节省了宝贵的时间； 防止数据丢失：当主服务器磁盘坏掉之后，其他从服务器还保留着相关的数据，不至于数据全部丢失。 开启主从同步 使用 replicaof host port 命令，把自己设置为目标 IP 的从服务器 如果主服务设置了密码，需要在从服务器输入主服务器的密码，使用 config set masterauth 主服务密码 命令的方式 在执行完 replicaof 命令之后，从服务器的数据会被清空，主服务会把它的数据副本同步给从服务器 启动时可以使用命令 redis-server --port 6380 --replicaof 127.0.0.1 6379 将自己设置成目标服务器的从服务器 数据同步 完整数据同步 当有新的从服务器连接时，为了保障多个数据库的一致性，主服务器会执行一次 bgsave 命令生成一个 RDB 文件，然后再以 Socket 的方式发送给从服务器，从服务器收到 RDB 文件之后再把所有的数据加载到自己的程序中，就完成了一次全量的数据同步。 部分数据同步 Redis 2.8 的优化方法是当从服务离线之后，主服务器会把离线之后的写入命令，存储在一个特定大小的队列中，队列是可以保证先进先出的执行顺序的，当从服务器重写恢复上线之后，主服务会判断离线这段时间内的命令是否还在队列中，如果在就直接把队列中的数据发送给从服务器，这样就避免了完整同步的资源浪费。 存储离线命令的队列大小默认是 1MB，使用者可以自行修改队列大小的配置项 repl-backlog-size。 无盘数据同步 如果主服务器是非固态硬盘的时候，系统的 I&#x2F;O 操作是非常高的，为了缓解这个问题，Redis 2.8.18 新增了无盘复制功能，无盘复制功能不会在本地创建 RDB 文件，而是会派生出一个子进程，然后由子进程通过 Socket 的方式，直接将 RDB 文件写入到从服务器，这样主服务器就可以在不创建 RDB 文件的情况下，完成与从服务器的数据同步。 要使用无盘复制功能，只需把配置项 repl-diskless-sync 的值设置为 yes 即可，它默认配置值为 no。 关闭主从同步 可以使用 replicaof no one 命令来停止从服务器的复制： 123456789101112127.0.0.1:6379&gt; role #查询当前角色1) &quot;slave&quot; #从服务器2) &quot;192.168.1.71&quot;3) (integer) 63804) &quot;connected&quot;5) (integer) 14127.0.0.1:6379&gt; replicaof no one #关闭同步OK127.0.0.1:6379&gt; role #查询当前角色1) &quot;master&quot; #主服务器2) (integer) 10973) (empty list or set) 执行了 replicaof no one 命令之后，自己就从服务器变成主服务器了，服务器类型的转换并不会影响数据，这台服务器的数据将会被保留。 注意事项 数据一致性问题 当从服务器已经完成和主服务的数据同步之后，再新增的命令会以异步的方式发送至从服务器，在这个过程中主从同步会有短暂的数据不一致，如在这个异步同步发生之前主服务器宕机了，会造成数据不一致。 从服务器只读性 默认在情况下，处于复制模式的主服务器既可以执行写操作也可以执行读操作，而从服务器则只能执行读操作。 可以在从服务器上执行 config set replica-read-only no 命令，使从服务器开启写模式，但需要注意以下几点： 在从服务器上写的数据不会同步到主服务器； 当键值相同时主服务器上的数据可以覆盖从服务器； 在进行完整数据同步时，从服务器数据会被清空。 复制命令的变化 Redis 5.0 之前使用的复制命令是 slaveof，在 Redis 5.0 之后复制命令才被改为 replicaof，在高版本（Redis 5+）中应该尽量使用 replicaof，因为 slaveof 命令可能会被随时废弃掉。 哨兵模式主从复制模式，它是属于 Redis 多机运行的基础，但这种模式本身存在一个致命的问题，当主节点奔溃之后，需要人工干预才能恢复 Redis 的正常使用。需要一个自动的工具——Redis Sentinel（哨兵模式）来把手动的过程变成自动的，让 Redis 拥有自动容灾恢复（failover）的能力。 graph TD A[哨兵] -->|监视| B[主节点] subgraph B -->|复制| C[从节点] B -->|复制| D[从节点] B -->|复制| E[从节点] end Redis Sentinel 搭建 edis Sentinel 的最小分配单位是一主一从，需要使用命令 ./src/redis-sentinel sentinel.conf 来启动 Sentinel，可以看出在启动它时必须设置一个 sentinel.conf 文件，这个配置文件中必须包含监听的 主节点信息： 12sentinel monitor mymaster 127.0.0.1 6379 1sentinel auth-pass mymaster pwd654321 其中： master-name 表示给监视的主节点起一个名称； ip 表示主节点的 IP； port 表示主节点的端口； quorum 表示确认主节点下线的 Sentinel 数量，如果 quorum 设置为 1 表示只要有一台 Sentinel 判断它下线了，就可以确认它真的下线了。 如果主节点 Redis 服务器有密码，还必须在 sentinel.conf 中添加主节点的密码 Sentinel 只需配置监听主节点的信息，它会自动监听对应的从节点。 启动 Sentinel 集群 生产环境不会只启动一台 Sentinel，因为如果启动一台 Sentinel 假如它不幸宕机的话，就不能提供自动容灾的服务了，不符高可用的宗旨，所以会在不同的物理机上启动多个 Sentinel 来组成 Sentinel 集群，来保证 Redis 服务的高可用。 启动 Sentinel 集群的方法和上面启动单台的方式一样，只需要把多个 Sentinel 监听到一个主服务器节点，那么多个 Sentinel 就会自动发现彼此，并组成一个 Sentinel 集群。 graph TD subgraph A[哨兵] -->|监视| B[主节点] F[哨兵] -->|监视| B[主节点] G[哨兵] -->|监视| B[主节点] end subgraph B -->|复制| C[从节点] B -->|复制| D[从节点] B -->|复制| E[从节点] end Sentinel 可以监视多台主节点，而不是只能监视一台服务器。 想要监视多台主节点只需要在配置文件中设置多个 sentinel monitor master-name ip port quorum 即可，通过 master-name 来区分不同的主节点 一般情况下 Sentinel 集群的数量取大于 1 的奇数，例如 3、5、7、9，而 quorum 的配置要根据 Sentinel 的数量来发生变化，例如 Sentinel 是 3 台，那么对应的 quorum 最好是 2，如果 Sentinel 是 5 台，那么 quorum 最好是 3，它表示当有 3 台 Sentinel 都确认主节点下线了，就可以确定主节点真的下线了。 与 quorum 参数相关的有两个概念：主观下线 和 客观下线。 当 Sentinel 集群中，有一个 Sentinel 认为主服务器已经下线时，它会将这个主服务器标记为主观下线（Subjectively Down，SDOWN），然后询问集群中的其他 Sentinel，是否也认为该服务器已下线，当同意主服务器已下线的 Sentinel 数量达到 quorum 参数所指定的数量时，Sentinel 就会将相应的主服务器标记为客观下线（Objectively down，ODOWN），然后开始对其进行故障转移。 主服务竞选规则 新主节点竞选优先级设置 redis.conf 中的 replica-priority 选项来设置竞选新主节点的优先级，它的默认值是 100，它的最大值也是 100，这个值越小它的权重就越高，例如从节点 A 的 replica-priority 值为 100，从节点 B 的值为 50，从节点 C 的值为 5，那么在竞选时从节点 C 会作为新的主节点。 新主节点竞选规则 新主节点的竞选会排除不符合条件的从节点，然后再剩余的从节点按照优先级来挑选 存在以下条件的从节点会被排除： 排除所有已经下线以及长时间没有回复心跳检测的疑似已下线从服务器； 排除所有长时间没有与主服务器通信，数据状态过时的从服务器； 排除所有优先级（replica-priority）为 0 的服务器。 符合条件的从节点竞选顺序： 优先级最高的从节点将会作为新主节点； 优先级相等则判断复制偏移量，偏移量最大的从节点获胜； 如果以上两个条件都相同，选择 Redis 运行时随机生成 ID 最小那个为新的主服务器。 旧主节点恢复上线 如果之前的旧主节点恢复上线，会作为从节点运行在主从服务器模式中 哨兵工作原理 首先每个 Sentinel 会以 每秒钟 1 次的频率，向已知的 主服务器、从服务器和以及其他 Sentinel 实例，发送一个 PING 命令。 如果最后一次有效回复 PING 命令的时间超过 down-after-milliseconds 所配置的值（默认 30s），那么这个实例会被 Sentinel 标记为主观下线。 如果一个主服务器被标记为主观下线，那么正在监视这个主服务器的所有 Sentinel 节点，要以每秒 1 次的频率确认主服务器的确进入了主观下线状态。 如果有足够数量（quorum 配置值）的 Sentinel 在指定的时间范围内同意这一判断，那么这个主服务器被标记为客观下线。此时所有的 Sentinel 会按照规则协商自动选出新的主节点。 一个有效的 PING 回复可以是：+PONG、-LOADING 或者 -MASTERDOWN。如果返回值非以上三种回复，或者在指定时间内没有回复 PING 命令， 那么 Sentinel 认为服务器返回的回复无效（non-valid)。 Sentinel 命令操作 连接到 Sentinel 服务器，和连接 Redis 服务相同，我们可以使用 redis-cli 来连接 Sentinel。 通过 Sentinel 连接信息获取相关 Redis 客户端，再进行相关 Redis 操作，这样 Sentinel 就会帮我们做容灾恢复，就不用担心操作某一个 Redis 服务器端，因为服务器挂了之后就会导致程序不可用了。 集群模式Redis Cluster 是 Redis 3.0 版本推出的 Redis 集群方案，它将数据分布在不同的服务区上，以此来降低系统对单主节点的依赖，并且可以大大的提高 Redis 服务的读写性能。 Redis 将所有的数据分为 16384 个 slots（槽），每个节点负责其中的一部分槽位，当有 Redis 客户端连接集群时，会得到一份集群的槽位配置信息，这样它就可以直接把请求命令发送给对应的节点进行处理。 Redis Cluster 是 无代理去中心化的运行模式，客户端发送的绝大数命令会直接交给相关节点执行，这样大部分情况请求命令无需转发，或仅转发一次的情况下就能完成请求与响应，所以集群单个节点的性能与单机 Redis 服务器的性能是非常接近的，因此在理论情况下，当水平扩展一倍的主节点就相当于请求处理的性能也提高了一倍，所以 Redis Cluster 的性能是非常高的。 graph LR subgraph 集群 A[主节点] --> B(从节点) A --> C(从节点) A --> D(从节点) E[主节点] --> F(从节点) E --> G(从节点) E --> H(从节点) end 搭建 Redis Cluster Redis Cluster 的搭建方式有两种： 一种是使用 Redis 源码中提供的 create-cluster 工具快速的搭建 Redis 集群环境 另一种是配置文件的方式手动创建 Redis 集群环境 create-cluster 搭建的方式虽然速度很快，但是该方式搭建的集群主从节点数量固定以及槽位分配模式固定，并且安装在同一台服务器上，所以只能用于测试环境。 在实际生产环境中需要使用手动添加配置的方式搭建 Redis 集群，需要修改每个节点内的 redis.conf 文件，设置 cluster-enabled yes 表示开启集群模式，redis.conf 配置好之后，就可以启动所有的节点。 但这些节点都在各自的集群之内并未互联互通，因此接下来需要把这些节点串连成一个集群，并为它们指定对应的槽位，执行命令如下： 1redis-cli --cluster create 127.0.0.1:30001 127.0.0.1:30002 127.0.0.1:30003 127.0.0.1:30004 127.0.0.1:30005 127.0.0.1:30006 --cluster-replicas 1 其中 create 后面跟多个节点，表示把这些节点作为整个集群的节点，而 cluster-replicas 表示给集群中的主节点指定从节点的数量，1 表示为每个主节点设置一个从节点。在执行了 create 命令之后，系统会为我们指定节点的角色和槽位分配计划。 使用 redis-cli 连接并测试一下集群的运行状态： 123456789101112131415161718$ redis-cli -c -p 30001 # 连接到集群127.0.0.1:30001&gt; cluster info # 查看集群信息cluster_state:ok # 状态正常cluster_slots_assigned:16384 # 槽位数cluster_slots_ok:16384 # 正常的槽位数cluster_slots_pfail:0 cluster_slots_fail:0cluster_known_nodes:6 # 集群的节点数cluster_size:3 # 集群主节点数cluster_current_epoch:6cluster_my_epoch:1cluster_stats_messages_ping_sent:130cluster_stats_messages_pong_sent:127cluster_stats_messages_sent:257cluster_stats_messages_ping_received:122cluster_stats_messages_pong_received:130cluster_stats_messages_meet_received:5cluster_stats_messages_received:257 动态增删节点 增加主节点 cluster meet [ip:port]&#x2F;redis-cli --cluster add-node [添加节点ip:port] [集群某节点ip:port] 添加从节点 cluster replicate [nodeId] 删除节点 cluster forget [nodeId] 重新分片，对槽位（slots）进行重新分配 redis-cli --cluster reshard [ip:port] 槽位定位算法 Redis 集群总共的槽位数是 16384 个，每一个主节点负责维护一部分槽以及槽所映射的键值数据，Redis 集群默认会对要存储的 key 值使用 CRC16 算法进行 hash 得到一个整数值，然后用这个整数值对 16384 进行取模来得到具体槽位，公式为： slot &#x3D; CRC16(key) % 16383 在 Redis 集群负载不均衡的情况下，我们可以使用 rebalance 命令重新分配各个节点负责的槽数量，从而使得各个节点的负载压力趋于平衡，从而提高 Redis 集群的整体运行效率。 故障故障发现 故障发现里面有两个重要的概念：疑似下线（PFAIL-Possibly Fail）和确定下线（Fail），和哨兵模式里面的主观下线和客观下线的概念比较类似。 集群中的健康监测是通过定期向集群中的其他节点发送 PING 信息来确认的，如果发送 PING 消息的节点在规定时间内，没有收到返回的 PONG 消息，那么对方节点就会被标记为疑似下线。 一个节点发现某个节点疑似下线，它会将这条信息 向整个集群广播，其它节点就会收到这个消息，并且通过 PING 的方式监测某节点是否真的下线了。如果一个节点收到某个节点疑似下线的数量超过集群数量的一半以上，就可以标记该节点为确定下线状态，然后向整个集群广播，强迫其它节点也接收该节点已经下线的事实，并立即对该失联节点进行主从切换。 故障转移 当一个节点被集群标识为确认下线之后就可以执行故障转移了，故障转移的执行流程如下： 从下线的主节点的所有从节点中，选择一个从节点； 从节点会执行 SLAVEOF NO ONE 命令，关闭这个从节点的复制功能，并从从节点转变回主节点，原来同步所得的数据集不会被丢弃； 新的主节点会撤销所有对已下线主节点的槽指派，并将这些槽全部指派给自己； 新的主节点向集群广播一条 PONG 消息，这条 PONG 消息是让集群中的其他节点知道此节点已经由从节点变成了主节点，并且这个主节点已经接管了原本由已下线节点负责处理的槽位信息； 新的主节点开始处理相关的命令请求，此故障转移过程完成。 新主节点选举原则 新主节点选举的方法是这样的： 集群的纪元（epoch）是一个自增计数器，初始值为 0； 而每个主节点都有一次投票的机会，主节点会把这一票投给第一个要求投票的从节点； 当从节点发现自己正在复制的主节点确认下线之后，就会向集群广播一条消息，要求所有有投票权的主节点给此从节点投票； 如果有投票权的主节点还没有给其他人投票的情况下，它会向第一个要求投票的从节点发送一条消息，表示把这一票投给这个从节点； 当从节点收到投票数量大于集群数量的半数以上时，这个从节点就会当选为新的主节点。 布隆过滤器HyperLogLog 可以用来做基数统计，但它没提供判断一个值是否存在的查询方法，如果使用传统的方式，例如 SQL 中的传统查询，因为数据量太多，查询效率又低有占用系统的资源，因此需要一个优秀的算法和功能来实现这个需求 —— 布隆过滤器。 使用 在 Redis 中不能直接使用布隆过滤器，但可以通过 Redis 4.0 版本之后提供的 modules（扩展模块）的方式引入。 布隆过滤器的命令主要包含以下几个： bf.add：添加元素 bf.exists：判断某个元素是否存在 bf.madd：添加多个元素 bf.mexists：判断多个元素是否存在 bf.reserve：设置布隆过滤器的准确率 准确率 bf.reserve 的使用必须在元素刚开始执行，否则会报错，它有三个参数：key、error_rate 和 initial_size error_rate：允许布隆过滤器的错误率，这个 值越低过滤器占用空间也就越大，以为此值决定了 位数组的大小，位数组是用来存储结果的，它的空间占用的越大（存储的信息越多），错误率就越低，它的默认值是 0.01。 initial_size：布隆过滤器存储的元素大小，实际存储的值大于此值，准确率就会降低，它的默认值是 100。 原理 Redis 布隆过滤器的实现，依靠的是它数据结构中的一个位数组，每次存储键值的时候，不是直接把数据存储在数据结构中，因为这样太占空间了，它是利用几个不同的无偏哈希函数，把此元素的 hash 值均匀的存储在位数组中，也就是说，每次添加时会通过几个无偏哈希函数算出它的位置，把这些位置设置成 1 就完成了添加操作。 当进行元素判断时，查询此元素的几个哈希位置上的值是否为 1，如果全部为 1，则表示此值存在，如果有一个值为 0，则表示不存在。因为此位置是通过 hash 计算得来的，所以即使这个位置是 1，并不能确定是那个元素把它标识为 1 的，因此 布隆过滤器查询此值存在时，此值不一定存在，但查询此值不存在时，此值一定不存在。 并且当位数组存储值比较稀疏的时候，查询的准确率越高，而当位数组存储的值越来越多时，误差也会增大。 graph LR subgraph 数据存储 A0[0] ----> A1[1] --> A2[0] ----> A3[1] ----> A4[1] ----> A5[0] --> A6[0] ----> A7[1] --> A8[0] end key(Key) --> A1 key --> A3 key --> A4 key2(Key2) --> A4 key2 --> A5 key2 --> A7 使用场景 它的经典使用场景包括以下几个： 垃圾邮件过滤 爬虫里的 URL 去重 判断一个元素在亿级数据中是否存在 布隆过滤器在数据库领域的使用也比较广泛，例如：HBase、Cassandra、LevelDB、RocksDB 内部都有使用布隆过滤器。 RediSearchRediSearch 是一个高性能的全文搜索引擎，它可以作为一个 Redis Module（扩展模块）运行在 Redis 服务器上。 RediSearch 主要特性如下： 基于文档的多个字段全文索引 高性能增量索引 文档排序（由用户在索引时手动提供） 在子查询之间使用 AND 或 NOT 操作符的复杂布尔查询 可选的查询子句 基于前缀的搜索 支持字段权重设置 自动完成建议（带有模糊前缀建议） 精确的短语搜索 在许多语言中基于词干分析的查询扩展 支持用于查询扩展和评分的自定义函数 将搜索限制到特定的文档字段 数字过滤器和范围 使用 Redis 自己的地理命令进行地理过滤 Unicode 支持（需要 UTF-8 字符集） 检索完整的文档内容或只是 ID 的检索 支持文档删除和更新与索引垃圾收集 支持部分更新和条件文档更新 性能测试为什么需要性能测试 性能测试的使用场景有很多，例如以下几个： 技术选型，比如测试 Memcached 和 Redis； 对比单机 Redis 和集群 Redis 的吞吐量； 评估不同类型的存储性能，例如集合和有序集合； 对比开启持久化和关闭持久化的吞吐量； 对比调优和未调优的吞吐量； 对比不同 Redis 版本的吞吐量，作为是否升级的一个参考标准。 等等，诸如此类的情况，都需要进行性能测试。 性能测试的几种方式 目前比较主流的性能测试分为两种： 编写代码模拟并发进行性能测试； 使用 redis-benchmark 进行测试。 因为自己编写代码进行性能测试的方式不够灵活，且很难短时间内模拟大量的并发数，所有作者并不建议使用这种方式。幸运的是 Redis 本身给提供了性能测试工具 redis-benchmark（Redis 基准测试）。 慢查询Redis 慢查询作用和 MySQL 慢查询作用类似，都是为了查询出不合理的执行命令，然后让开发人员和运维人员一起来规避这些耗时的命令，从而让服务器更加高效和健康的运行。 如何进行慢查询 Redis 慢查询重要的配置项： slowlog-log-slower-than：用于设置慢查询的评定时间，也就是说超过此配置项的命令，将会被当成慢操作记录在慢查询日志中，它执行单位是微秒（1 秒等于 1000000 微秒）； slowlog-max-len：用来配置慢查询日志的最大记录数。 slowlog-log-slower-than 和 slowlog-max-len 可以通过 config set xxx 的模式来修改，例如 config set slowlog-max-len 200 设置慢查询最大记录数为 200 条。 使用 slowlog show 来查询慢日志，当慢查询日志超过设定的最大存储条数之后，会把最早的执行命令依次舍弃。 慢查询其他相关命令 查询指定条数慢日志 slowlog get n 获取慢查询队列长度 slowlog len 清空慢查询日志 slowlog reset 性能优化缩短键值对的存储长度 键值对的长度是和性能成反比的，做一组写入数据的性能测试，执行结果如下： 数据量 key 大小 value 大小 string: set 平均耗时 hash: hset 平均耗时 100w 20byte 512byte 1.13 微秒 10.28 微秒 100w 20byte 200byte 0.74 微秒 8.08 微秒 100w 20byte 100byte 0.65 微秒 7.92 微秒 100w 20byte 50byte 0.59 微秒 6.74 微秒 100w 20byte 20byte 0.55 微秒 6.60 微秒 100w 20byte 5byte 0.53 微秒 6.53 微秒 使用 lazy free 特性 在删除的时候提供异步延时释放键值的功能，把键值释放操作放在 BIO（Background I&#x2F;O）单独的子线程处理中，以减少删除对 Redis 主线程的阻塞，可以有效地避免删除 big key 时带来的性能和可用性问题。 lazy free 对应了 4 种场景，默认都是关闭的： 1234lazyfree-lazy-eviction nolazyfree-lazy-expire nolazyfree-lazy-server-del noslave-lazy-flush no 它们代表的含义如下： lazyfree-lazy-eviction：表示当 Redis 运行内存超过 maxmeory 时，是否开启 lazy free 机制删除； lazyfree-lazy-expire：表示设置了过期时间的键值，当过期之后是否开启 lazy free 机制删除； lazyfree-lazy-server-del：有些指令在处理已存在的键时，会带有一个隐式的 del 键的操作，比如 rename 命令，当目标键已存在，Redis 会先删除目标键，如果这些目标键是一个 big key，就会造成阻塞删除的问题，此配置表示在这种场景中是否开启 lazy free 机制删除； slave-lazy-flush：针对 slave（从节点）进行全量数据同步，slave 在加载 master 的 RDB 文件前，会运行 flushall 来清理自己的数据，它表示此时是否开启 lazy free 机制删除。 建议开启其中的 lazyfree-lazy-eviction、lazyfree-lazy-expire、lazyfree-lazy-server-del 等配置，这样就可以有效的提高主线程的执行效率。 设置键值的过期时间 应该根据实际的业务情况，对键值设置合理的过期时间，这样 Redis 会自动清除过期的键值对，以节约对内存的占用，以避免键值过多的堆积，频繁的触发内存淘汰策略。 禁用耗时长的查询命令 其中 O(1) 表示可以安全使用的，而 O(N) 就应该当心了，N 表示不确定，数据越大查询的速度可能会越慢。因为 Redis 只用一个线程来做数据查询，如果这些指令耗时很长，就会阻塞 Redis，造成大量延时。 https://redis.io/docs/latest/commands/ 要避免 O(N) 命令对 Redis 造成的影响，可以从以下几个方面入手改造： 决定禁止使用 keys 命令； 避免一次查询所有的成员，要使用 scan 命令进行分批的，游标式的遍历； 通过机制严格控制 Hash、Set、Sorted Set 等结构的数据大小； 将排序、并集、交集等操作放在客户端执行，以减少 Redis 服务器运行压力； 删除（del）一个大数据的时候，可能会需要很长时间，所以建议用异步删除的方式 unlink，它会启动一个新的线程来删除目标数据，而不阻塞 Redis 的主线程。 使用 slowlog 优化耗时命令 可以根据实际的业务情况进行相应的配置，其中慢日志是按照插入的顺序倒序存入慢查询日志中，使用 slowlog get n 来获取相关的慢查询日志，再找到这些慢查询对应的业务进行相关的优化。 使用 Pipeline 批量操作数据 Pipeline（管道技术）是客户端提供的一种批处理技术，用于一次处理多个 Redis 命令，从而提高整个交互的性能。 避免大量数据同时失效 如果在大型系统中有大量缓存在同一时间同时过期，那么会导致 Redis 循环多次持续扫描删除过期字典，直到过期字典中过期键值被删除的比较稀疏为止，而在整个执行过程会导致 Redis 的读写出现明显的卡顿，卡顿的另一种原因是内存管理器需要频繁回收内存页，因此也会消耗一定的 CPU。 需要预防大量的缓存在同一时刻一起过期，最简单的解决方案就是在过期时间的基础上添加一个指定范围的随机数。 客户端使用优化 在客户端的使用上除了要尽量使用 Pipeline 的技术外，还需要注意要尽量使用 Redis 连接池，而不是频繁创建销毁 Redis 连接，这样就可以减少网络传输次数和减少了非必要调用指令。 限制 Redis 内存大小 在 64 位操作系统中 Redis 的内存大小是没有限制的，也就是配置项 maxmemory &lt;bytes&gt; 是被注释掉的，这样就会导致在物理内存不足时，使用 swap 空间既交换空间，而当操心系统将 Redis 所用的内存分页移至 swap 空间时，将会阻塞 Redis 进程，导致 Redis 出现延迟，从而影响 Redis 的整体性能。因此需要限制 Redis 的内存大小为一个固定的值，当 Redis 的运行到达此值时会触发内存淘汰策略。 使用物理机而非虚拟机 在虚拟机中运行 Redis 服务器，因为和物理机共享一个物理网口，并且一台物理机可能有多个虚拟机在运行，因此在内存占用上和网络延迟方面都会有很糟糕的表现，可以通过 ./redis-cli --intrinsic-latency 100 命令查看延迟时间，如果对 Redis 的性能有较高要求的话，应尽可能在物理机上直接部署 Redis 服务器。 检查数据持久化策略 Redis 4.0 之后新增了混合持久化的方式，因此在必须要进行持久化操作时，应该选择混合持久化的方式。查询是否开启混合持久化可以使用 config get aof-use-rdb-preamble 命令。 使用分布式架构来增加读写速度 Redis 分布式架构有三个重要的手段： 主从同步 哨兵模式 Redis Cluster 集群 使用主从同步功能可以把写入放到主库上执行，把读功能转移到从服务上，因此就可以在单位时间内处理更多的请求，从而提升的 Redis 整体的运行速度。而哨兵模式是对于主从功能的升级，但当主节点奔溃之后，无需人工干预就能自动恢复 Redis 的正常使用。 Redis Cluster 是 Redis 3.0 正式推出的，Redis 集群是通过将数据分散存储到多个节点上，来平衡各个节点的负载压力，因此性能会有很大的提升。 缓存问题缓存雪崩 缓存雪崩是指在短时间内，有大量缓存同时过期，导致大量的请求直接查询数据库，从而对数据库造成了巨大的压力，严重情况下可能会导致数据库宕机的情况叫做缓存雪崩。 graph LR A[用户] --> B(应用程序) B -->|缓存过期| C(Redis) C -->|直接查询| D(DB) 常用解决方案： 加锁排队：加锁排队可以起到缓冲的作用，防止大量的请求同时操作数据库，但它的缺点是增加了系统的响应时间，降低了系统的吞吐量，牺牲了一部分用户体验。 随机化过期时间：为了避免缓存同时过期，可在设置缓存时添加随机时间，这样就可以极大的避免大量的缓存同时失效。 设置二级缓存：二级缓存指的是除了 Redis 本身的缓存，再设置一层缓存（例如本地缓存），当 Redis 失效之后，先去查询二级缓存。 缓存击穿 缓存击穿指的是某个热点缓存，在某一时刻恰好失效了，然后此时刚好有大量的并发请求，此时这些请求将会给数据库造成巨大的压力。 graph LR A[用户] --> B(应用程序) B -->|缓存失效| C(Redis) C -->|直接查询| D(DB) 常用解决方案： 加锁排队：此处理方式和缓存雪崩加锁排队的方法类似，都是在查询数据库时加锁排队，缓冲操作请求以此来减少服务器的运行压力。 设置永不过期：对于某些热点缓存，可以设置永不过期，这样就能保证缓存的稳定性，注意在数据更改之后，要及时更新此热点缓存，不然就会造成查询结果的误差。 缓存穿透 graph LR A[用户] --> B(查询) B --> C(Redis) C --> |无数据|E(DB) C -->|有数据| D(完成) E -->|有数据| C E -->|无数据| D 缓存穿透是指查询数据库和缓存都无数据，因为 数据库查询无数据，出于容错考虑，不会将结果保存到缓存中，因此每次请求都会去查询数据库，这种情况就叫做缓存穿透。 常用解决方案： 使用过滤器：使用过滤器来减少对数据库的请求，例如每次查询之前，先使用布隆过滤器过滤掉一定不存在的无效请求，从而避免了无效请求给数据库带来的查询压力。 缓存空结果：把每次从数据库查询的数据都保存到缓存中，为了提高前台用户的使用体验 (解决长时间内查询不到任何信息的情况)，我们可以将空结果的缓存时间设置得短一些，例如 3~5 分钟。 缓存预热 缓存预热并不是一个问题，而是使用缓存时的一个优化方案，它可以提高前台用户的使用体验。缓存预热指的是在系统启动的时候，先把查询结果预存到缓存中，以便用户后面查询时可以直接从缓存中读取，以节约用户的等待时间。 缓存预热的实现思路有以下三种： 把需要缓存的方法写在系统初始化的方法中，这样系统在启动的时候就会自动的加载数据并缓存数据； 把需要缓存的方法挂载到某个页面或后端接口上，手动触发缓存预热； 设置定时任务，定时自动进行缓存预热。 参考资料 Redis 仓库 Redis 官网 Redis 核心技术与实战","tags":["Redis"],"categories":["Redis"]},{"title":"Go SDK：context、sync、reflect、errors","path":"/2024/05/05/gosdk/","content":"Go 语言类库要点整理 📄 context协程如何退出 一个协程启动后，大部分情况需要等待里面的代码执行完毕，协程才会自行退出，如何让协程提前退出？ 12345678910111213141516171819202122232425262728293031323334package mainimport (\t&quot;fmt&quot;\t&quot;sync&quot;\t&quot;time&quot;)func main() &#123;\tvar wg sync.WaitGroup\twg.Add(1)\tstopCh := make(chan bool) //用来停止监控狗\tgo func() &#123; defer wg.Done() watchDog(stopCh, &quot;【监控狗1】&quot;)\t&#125;()\ttime.Sleep(5 * time.Second) //先让监控狗监控5秒\tstopCh &lt;- true //发停止指令\twg.Wait()&#125;func watchDog(stopCh chan bool, name string) &#123;\t//开启 for select 循环，一直后台监控\tfor &#123; select &#123; case &lt;-stopCh: fmt.Println(name, &quot;停止指令已收到，马上停止&quot;) return default: fmt.Println(name, &quot;正在监控……&quot;) &#125; time.Sleep(1 * time.Second)\t&#125;&#125; 实现了通过 select + channel 发送指令让监控狗停止，进而达到协程退出的目的。 初识 Context如果希望做到同时取消很多个协程或定时取消协程又该怎么办？这时候 select + channel 的局限性就凸现出来了，即使定义了多个 channel 解决问题，代码逻辑也会非常复杂、难以维护。 通过 Context 重写上面的示例，实现让监控狗停止的功能： 123456789101112131415161718192021222324252627func main() &#123;\tvar wg sync.WaitGroup\twg.Add(1)\tctx, stop := context.WithCancel(context.Background())\tgo func() &#123; defer wg.Done() watchDog(ctx, &quot;【监控狗1】&quot;)\t&#125;()\ttime.Sleep(5 * time.Second) //先让监控狗监控5秒\tstop() //发停止指令\twg.Wait()&#125;func watchDog(ctx context.Context, name string) &#123;\t//开启for select循环，一直后台监控\tfor &#123; select &#123; case &lt;-ctx.Done(): fmt.Println(name, &quot;停止指令已收到，马上停止&quot;) return default: fmt.Println(name, &quot;正在监控……&quot;) &#125; time.Sleep(1 * time.Second)\t&#125;&#125; 相比 select+channel 的方案，Context 方案主要有 4 个改动点： watchDog 的 stopCh 参数换成了 ctx，类型为 context.Context。 原来的 case &lt;-stopCh 改为 case &lt;-ctx.Done()，用于判断是否停止。 使用 context.WithCancel(context.Background()) 函数生成一个可以取消的 Context，用于发送停止指令。这里的 context.Background() 用于生成一个空 Context，一般作为整个 Context 树的根节点。 原来的 stopCh &lt;- true 停止指令，改为 context.WithCancel 函数返回的取消函数 stop()。 这和修改前的整体代码结构一样，只不过从 channel 换成了 Context。 什么是 Context 一个任务会有很多个协程协作完成，一次 HTTP 请求也会触发很多个协程的启动，而这些协程有可能会启动更多的子协程，并且无法预知有多少层协程、每一层有多少个协程。 如果因为某些原因导致任务终止了，HTTP 请求取消了，那么它们启动的协程怎么办？该如何取消呢？因为取消这些协程可以节约内存，提升性能，同时避免不可预料的 Bug。 Context 就是用来简化解决这些问题的，并且是并发安全的。Context 是一个接口，它具备手动、定时、超时发出取消信号、传值等功能，主要用于控制多个协程之间的协作，尤其是取消操作。一旦取消指令下达，那么被 Context 跟踪的这些协程都会收到取消信号，就可以做清理和退出操作。 Context 接口只有四个方法： 123456type Context interface &#123; Deadline() (deadline time.Time, ok bool) Done() &lt;-chan struct&#123;&#125; Err() error Value(key interface&#123;&#125;) interface&#123;&#125;&#125; Deadline 方法可以获取设置的截止时间，第一个返回值 deadline 是截止时间，到了这个时间点，Context 会自动发起取消请求，第二个返回值 ok 代表是否设置了截止时间。 Done 方法返回一个只读的 channel，类型为 struct{}。在协程中，如果该方法返回的 chan 可以读取，则意味着 Context 已经发起了取消信号。通过 Done 方法收到这个信号后，就可以做清理操作，然后退出协程，释放资源。 Err 方法返回取消的错误原因，即因为什么原因 Context 被取消。 Value 方法获取该 Context 上绑定的值，是一个键值对，所以要通过一个 key 才可以获取对应的值。 Context 接口的四个方法中最常用的就是 Done 方法，它返回一个只读的 channel，用于接收取消信号。当 Context 取消的时候，会关闭这个只读 channel，也就等于发出了取消信号。 Context 树Go 语言提供了函数可以帮助生成不同的 Context，通过这些函数可以生成一颗 Context 树，这样 Context 才可以关联起来，父 Context 发出取消信号的时候，子 Context 也会发出，这样就可以控制不同层级的协程退出。 从使用功能上分，有四种实现好的 Context。 空 Context：不可取消，没有截止时间，主要用于 Context 树的根节点。 可取消的 Context：用于发出取消信号，当取消的时候，它的子 Context 也会取消。 可定时取消的 Context：多了一个定时的功能。 值 Context：用于存储一个 key-value 键值对。 在 Go 语言中，可以通过 context.Background() 获取一个根节点 Context，有了根节点 Context 后，使用 Go 语言提供的四个函数生成这棵 Context 树： **WithCancel(parent Context)**：生成一个可取消的 Context。 **WithDeadline(parent Context, d time.Time)**：生成一个可定时取消的 Context，参数 d 为定时取消的具体时间。 **WithTimeout(parent Context, timeout time.Duration)**：生成一个可超时取消的 Context，参数 timeout 用于设置多久后取消 **WithValue(parent Context, key, val interface{})**：生成一个可携带 key-value 键值对的 Context。 以上四个生成 Context 的函数中，前三个都属于可取消的 Context，它们是一类函数，最后一个是值 Context，用于存储一个 key-value 键值对。 取消多个协程要取消多个协程，把 Context 作为参数传递给协程即可，还是以监控狗为例，如下所示： 12345678910111213141516171819202122232425262728293031323334func main() &#123;\tvar wg sync.WaitGroup\twg.Add(3)\tctx, stop := context.WithCancel(context.Background())\tgo func() &#123; defer wg.Done() watchDog(ctx, &quot;【监控狗1】&quot;)\t&#125;()\tgo func() &#123; defer wg.Done() watchDog(ctx, &quot;【监控狗2】&quot;)\t&#125;()\tgo func() &#123; defer wg.Done() watchDog(ctx, &quot;【监控狗3】&quot;)\t&#125;()\ttime.Sleep(5 * time.Second) // 发出取消信号，这三个协程都会退出，他们的根节点都是 main 中的 ctx\tstop() wg.Wait()&#125;func watchDog(ctx context.Context, name string) &#123;\tfor &#123; select &#123; case &lt;-ctx.Done(): fmt.Println(name, &quot;停止指令已收到，马上停止&quot;) return default: fmt.Println(name, &quot;正在监控……&quot;) &#125; time.Sleep(1 * time.Second)\t&#125;&#125; Context 传值Context 不仅可以取消，还可以传值，通过这个能力，可以把 Context 存储的值供其他协程使用。 123456789101112131415161718192021222324252627func main() &#123;\tvar wg sync.WaitGroup\twg.Add(1)\tctx, cancelFunc := context.WithCancel(context.Background())\tvalCtx := context.WithValue(ctx, &quot;userId&quot;, 2)\tgo func() &#123; defer wg.Done() getUser(valCtx)\t&#125;()\ttime.Sleep(5 * time.Second)\tcancelFunc()\twg.Wait()&#125;func getUser(ctx context.Context) &#123;\tfor &#123; select &#123; case &lt;-ctx.Done(): fmt.Println(&quot;【获取用户】&quot;, &quot;协程退出&quot;) return default: userId := ctx.Value(&quot;userId&quot;) fmt.Println(&quot;【获取用户】&quot;, &quot;用户ID为：&quot;, userId) time.Sleep(1 * time.Second) &#125;\t&#125;&#125; 通过 context.WithValue() 函数存储一个 userId 为 2 的键值对，就可以在 getUser 函数中通过 ctx.Value(&quot;userId&quot;) 方法把对应的值取出来，达到传值的目的。 Context 使用原则Context 是一种非常好的工具，使用它可以很方便地控制取消多个协程。在 Go 语言标准库中也使用了它们，比如 net&#x2F;http 中使用 Context 取消网络的请求。 要更好地使用 Context，有一些使用原则需要尽可能地遵守。 Context 不要放在结构体中，要以参数的方式传递。 Context 作为函数的参数时，要放在第一位，也就是第一个参数。 要使用 context.Background() 函数生成根节点的 Context，也就是最顶层的 Context。 Context 传值要传递必须的值，而且要尽可能地少，不要什么都传。 Context 多协程安全，可以在多个协程中放心使用。 以上原则是规范类的，Go 语言的编译器并不会做这些检查，要靠自己遵守。 syncchannel 为什么是并发安全的呢？是因为 channel 内部使用了互斥锁 来保证并发的安全。在 Go 语言中，不仅有 channel 这类比较易用且高级的同步机制，还有 sync.Mutex、sync.WaitGroup 等比较原始的同步机制。通过它们可以更加灵活地 控制数据的同步和多协程的并发。 资源竞争1234567891011121314151617//共享的资源var sum = 0func main() &#123; //开启100个协程让sum+10 for i := 0; i &lt; 100; i++ &#123; go add(10) &#125; //防止提前退出 time.Sleep(2 * time.Second) fmt.Println(&quot;和为:&quot;,sum)&#125;func add(i int) &#123; sum += i&#125; 小技巧：使用 go build、go run、go test 这些 Go 语言工具链提供的命令时，添加 -race 标识可以帮检查 Go 语言代码是否存在资源竞争。 同步原语sync.Mutex 互斥锁 指的是在同一时刻只有一个协程执行某段代码，其他协程都要等待该协程执行完毕后才能继续执行。 1234567891011var( sum int mutex sync.Mutex)func add(i int) &#123; mutex.Lock() defer mutex.Unlock() sum += i // mutex.Unlock()&#125; 以上被加锁保护的 sum+&#x3D; i 代码片段又称为 临界区。在同步的程序设计中，临界区段指的是一个访问共享资源的程序片段，而这些共享资源又有无法同时被多个协程访问的特性。当有协程进入临界区段时，其他协程必须等待，这样就保证了临界区的并发安全。 sync.RWMutex 123456789101112131415161718func main() &#123; for i := 0; i &lt; 100; i++ &#123; go add(10) &#125; for i:=0; i&lt;10;i++ &#123; go fmt.Println(&quot;和为:&quot;,readSum()) &#125; time.Sleep(2 * time.Second)&#125;//增加了一个读取sum的函数，便演示并发func readSum() int &#123; mutex.Lock() defer mutex.Unlock() b:=sum return b&#125; 解决了多个 goroutine 同时读写的资源竞争问题，但是又遇到另外一个问题——性能。因为每次读写共享资源都要加锁，所以性能低下，有以下几种情况： 写的时候不能同时读，因为这个时候读取的话可能读到脏数据（不正确的数据）； 读的时候不能同时写，因为也可能产生不可预料的结果； 读的时候可以同时读，因为数据不会改变，所以不管多少个 goroutine 读都是并发安全的。 通过读写锁 sync.RWMutex 来优化这段代码，提升性能： 12345678var mutex sync.RWMutexfunc readSum() int &#123; //只获取读锁 mutex.RLock() defer mutex.RUnlock() b:=sum return b&#125; 把锁的声明换成读写锁 sync.RWMutex，把函数 readSum 读取数据的代码换成读锁，也就是 RLock 和 RUnlock，这样性能就会有很大的提升，因为多个 goroutine 可以同时读数据，不再相互等待。 sync.WaitGroup 上面代码的 time.Sleep(2 * time.Second)，这是为了防止主函数 main 返回使用，一旦 main 函数返回了，程序也就退出了，因为不知道 100 个执行 add 的协程和 10 个执行 readSum 的协程什么时候完全执行完毕，所以设置了一个比较长的等待时间，也就是两秒。 有没有办法监听所有协程的执行，一旦全部执行完毕，程序马上退出，这样既可保证所有协程执行完毕，又可以及时退出节省时间，提升性能。 12345678910111213141516171819202122232425func main() &#123; run()&#125;func run()&#123; var wg sync.WaitGroup //因为要监控110个协程，所以设置计数器为110 wg.Add(110) for i := 0; i &lt; 100; i++ &#123; go func() &#123; //计数器值减1 defer wg.Done() add(10) &#125;() &#125; for i:=0; i&lt;10;i++ &#123; go func() &#123; //计数器值减1 defer wg.Done() fmt.Println(&quot;和为:&quot;,readSum()) &#125;() &#125; //一直等待，只要计数器值为0 wg.Wait()&#125; 通过 sync.WaitGroup 可以很好地跟踪协程。在协程执行完毕后，整个 run 函数才能执行完毕，时间不多不少，正好是协程执行的时间。 sync.Once 让代码只执行一次，哪怕是在高并发的情况下，比如创建一个单例。针对这种情形，Go 语言为提供了 sync.Once 来保证代码只执行一次 1234567891011121314151617181920212223242526func main() &#123; doOnce()&#125;func doOnce() &#123; var once sync.Once onceBody := func() &#123; fmt.Println(&quot;Only once&quot;) &#125; //用于等待协程执行完毕 done := make(chan bool) //启动10个协程执行once.Do(onceBody) for i := 0; i &lt; 10; i++ &#123; go func() &#123; //把要执行的函数(方法)作为参数传给once.Do方法即可 once.Do(onceBody) done &lt;- true &#125;() &#125; for i := 0; i &lt; 10; i++ &#123; &lt;-done &#125;&#125; sync.Cond sync.WaitGroup 用于最终完成的场景，关键点在于一定要等待所有协程都执行完毕；而 sync.Cond 可以用于发号施令，一声令下所有协程都可以开始执行，关键点在于协程开始的时候是等待的，要等待 sync.Cond 唤醒才能执行。 sync.Cond 从字面意思看是条件变量，它具有阻塞协程和唤醒协程的功能，所以可以在满足一定条件的情况下唤醒协程，但条件变量只是它的一种使用场景。 123456789101112131415161718192021222324252627282930//10个人赛跑，1个裁判发号施令func race()&#123; cond :=sync.NewCond(&amp;sync.Mutex&#123;&#125;) var wg sync.WaitGroup wg.Add(11) for i:=0;i&lt;10; i++ &#123; go func(num int) &#123; defer wg.Done() fmt.Println(num,&quot;号已经就位&quot;) cond.L.Lock() cond.Wait()//等待发令枪响 fmt.Println(num,&quot;号开始跑……&quot;) cond.L.Unlock() &#125;(i) &#125; //等待所有goroutine都进入wait状态 time.Sleep(2*time.Second) go func() &#123; defer wg.Done() fmt.Println(&quot;裁判已经就位，准备发令枪&quot;) fmt.Println(&quot;比赛开始，大家准备跑&quot;) cond.Broadcast()//发令枪响 &#125;() //防止函数提前返回退出 wg.Wait()&#125; sync.Cond 有三个方法，它们分别是： Wait，阻塞当前协程，直到被其他协程调用 Broadcast 或者 Signal 方法唤醒，使用的时候需要加锁，使用 sync.Cond 中的锁即可，也就是 L 字段。 Signal，唤醒一个等待时间最长的协程。 Broadcast，唤醒所有等待的协程。 在调用 Signal 或者 Broadcast 之前，要确保目标协程处于 Wait 阻塞状态，不然会出现死锁问题。 reflect反射提供了一种可以在运行时操作任意类型对象的能力，比如查看一个接口变量的具体类型、看看一个结构体有多少字段、修改某个字段的值等。 Go 语言是静态编译类语言，比如在定义一个变量的时候，已经知道了它是什么类型，那么为什么还需要反射呢？比如定义了一个函数，它有一个 interface{} （any）类型的参数，这也就意味着调用者可以传递任何类型的参数给这个函数。在这种情况下，如果想知道调用者传递的是什么类型的参数，就需要用到反射。如果想知道 一个结构体有哪些字段和方法，也需要反射。 在 Go 语言的反射定义中，任何接口都由两部分组成：接口的具体类型，以及具体类型对应的值。 interface{} 是空接口，可以表示任何类型，也就是说可以把任何类型转换为空接口，它通常用于 反射、类型断言，以减少重复代码，简化编程。 123456func main() &#123; i:=3 iv:=reflect.ValueOf(i) it:=reflect.TypeOf(i) fmt.Println(iv,it) // 3 int&#125; reflect.Value在 Go 语言中，reflect.Value 被定义为一个 struct 结构体： 12345type Value struct &#123; typ *rtype ptr unsafe.Pointer flag&#125; 它的常用方法有三类： 一类用于获取和修改对应的 值； 一类和 struct 类型的 字段 有关，用于获取对应的字段； 一类和类型上的 方法集 有关，用于获取对应的方法。 获取原始类型 reflect.Value 和 int 类型互转 12345678func main() &#123; i:=3 //int to reflect.Value iv:=reflect.ValueOf(i) //reflect.Value to int i1:=iv.Interface().(int) fmt.Println(i1)&#125; 修改对应的值 因为 reflect.ValueOf 函数返回的是一份值的拷贝，所以要传入变量的指针，因为传递的是一个指针，所以需要调用 Elem 方法找到这个指针指向的值，这样才能修改。 1234567// 修改一个变量的值func main() &#123; i:=3 ipv:=reflect.ValueOf(&amp;i) ipv.Elem().SetInt(4) fmt.Println(i)&#125; 修改 struct 结构体字段的值，可总结出以下步骤： 传递一个 struct 结构体的指针，获取对应的 reflect.Value； 通过 Elem 方法获取指针指向的值； 通过 Field 方法获取要修改的字段； 通过 Set 系列方法修改成对应的值。 1234567891011// 修改 struct 结构体字段的值func main() &#123; p:=person&#123;Name: &quot;hcjjj&quot;, Age: 26&#125; ppv:=reflect.ValueOf(&amp;p) ppv.Elem().Field(0).SetString(&quot;HCJ&quot;) fmt.Println(p)&#125;type person struct &#123; Name string Age int&#125; 在程序运行时通过反射修改一个变量或字段的值的规则： 可被寻址，通俗地讲就是要向 reflect.ValueOf 函数传递一个指针作为参数。 如果要修改 struct 结构体字段值的话，该字段需要是可导出的，而不是私有的，也就是该字段的首字母为大写。 记得使用 Elem 方法获得指针指向的值，这样才能调用 Set 系列方法进行修改。 获取对应的底层类型 底层类型对应的主要是基础类型，比如接口、结构体、指针……因为可以通过 type 关键字声明很多新的类型。变量 p 的实际类型是 person，但是 person 对应的底层类型是 struct 这个结构体类型，而 &amp;p 对应的则是指针类型。 1234567func main() &#123; p:=person&#123;Name: &quot;hcjjj&quot;,Age: 26&#125; ppv:=reflect.ValueOf(&amp;p) fmt.Println(ppv.Kind()) // ptr pv:=reflect.ValueOf(p) fmt.Println(pv.Kind()) // struct&#125; reflect.Typereflect.Value 可以用于与值有关的操作中，而如果是和变量类型本身有关的操作，则最好使用 reflect.Type，比如要获取结构体对应的字段名称或方法。 接口定义 和 reflect.Value 不同，reflect.Type 是一个接口，而不是一个结构体，所以也只能使用它的方法。对比 reflect.Value 的方法功能， reflect.Type 几个特有的方法如下： Implements 方法用于判断是否实现了接口 u； AssignableTo 方法用于判断是否可以赋值给类型 u，其实就是是否可以使用 &#x3D;，即赋值运算符； ConvertibleTo 方法用于判断是否可以转换成类型 u，其实就是是否可以进行类型转换； Comparable 方法用于判断该类型是否是可比较的，其实就是是否可以使用关系运算符进行比较。 遍历结构体的字段和方法 123456789101112func main() &#123; p:=person&#123;Name: &quot;hcjjj&quot;,Age: 26&#125; pt:=reflect.TypeOf(p) //遍历person的字段 for i:=0;i&lt;pt.NumField();i++&#123; fmt.Println(&quot;字段：&quot;,pt.Field(i).Name) &#125; //遍历person的方法 for i:=0;i&lt;pt.NumMethod();i++&#123; fmt.Println(&quot;方法：&quot;,pt.Method(i).Name) &#125;&#125; 可以通过 FieldByName 方法获取指定的字段，也可以通过 MethodByName 方法获取指定的方法，这在需要获取某个特定的字段或者方法时非常高效，而不是使用遍历。 是否实现某接口 12345678func main() &#123; p:=person&#123;Name: &quot;hcjjj&quot;,Age: 26&#125; pt:=reflect.TypeOf(p) stringerType:=reflect.TypeOf((*fmt.Stringer)(nil)).Elem() writerType:=reflect.TypeOf((*io.Writer)(nil)).Elem() fmt.Println(&quot;是否实现了fmt.Stringer：&quot;,pt.Implements(stringerType)) fmt.Println(&quot;是否实现了io.Writer：&quot;,pt.Implements(writerType))&#125; 尽可能通过类型断言的方式判断是否实现了某接口，而不是通过反射。 string ↔️ struct字符串和结构体互转的场景中，使用最多的就是 JSON 和 struct 互转，还有配置文件和 struct 的转换 JSON 和 Struct 互转 Go 语言的标准库有一个 json 包，通过 json.Marshal 函数，可以把一个 struct 转为 JSON 字符串。通过 json.Unmarshal 函数，可以把一个 JSON 字符串转为 struct。 123456789101112func main() &#123; p:=person&#123;Name: &quot;hcjjj&quot;,Age: 26&#125; //struct to json jsonB,err:=json.Marshal(p) if err==nil &#123; fmt.Println(string(jsonB)) &#125; //json to struct respJSON:=&quot;&#123;\\&quot;Name\\&quot;:\\&quot;hcjjj\\&quot;,\\&quot;Age\\&quot;:26&#125;&quot; json.Unmarshal([]byte(respJSON),&amp;p) fmt.Println(p)&#125; JSON 字符串的 Key 和 struct 结构体的字段名称一样 Struct Tag struct tag 是一个添加在 struct 字段上的标记，使用它进行辅助，可以完成一些额外的操作，比如 json 和 struct 互转。如果想把输出的 json 字符串的 Key 改为小写的 name 和 age，可以通过为 struct 字段添加 tag 的方式。 1234type person struct &#123; Name string `json:&quot;name&quot;` Age int `json:&quot;age&quot;`&#125; json 作为 Key，是 Go 语言自带的 json 包解析 JSON 的一种约定，它会通过 json 这个 Key 找到对应的值，用于 JSON 的 Key 值。 这个 tag 就像是为 struct 字段起的别名，那么 json 包是如何获得这个 tag 的呢？这就需要反射了。 123456//遍历person字段中key为json的tag// pt:=reflect.TypeOf(p)for i:=0;i&lt;pt.NumField();i++&#123; sf:=pt.Field(i) fmt.Printf(&quot;字段%s上,json tag为%s &quot;,sf.Name,sf.Tag.Get(&quot;json&quot;))&#125; 结构体的字段可以有多个 tag，用于不同的场景，比如 json 转换、bson 转换、orm 解析等。如果有多个 tag，要使用空格分隔。采用不同的 Key 可以获得不同的 tag： 123456789101112//遍历person字段中key为json、bson的tag// pt:=reflect.TypeOf(p)for i:=0;i&lt;pt.NumField();i++&#123; sf:=pt.Field(i) fmt.Printf(&quot;字段%s上,json tag为%s &quot;,sf.Name,sf.Tag.Get(&quot;json&quot;)) fmt.Printf(&quot;字段%s上,bson tag为%s &quot;,sf.Name,sf.Tag.Get(&quot;bson&quot;))&#125;type person struct &#123; Name string `json:&quot;name&quot; bson:&quot;b_name&quot;` Age int `json:&quot;age&quot; bson:&quot;b_name&quot;`&#125; 1234字段Name上,key为json的tag为name字段Name上,key为bson的tag为b_name字段Age上,key为json的tag为age字段Age上,key为bson的tag为b_name 通过不同的 Key，使用 Get 方法就可以获得自定义的不同的 tag。 实现 Struct 转 JSON 自定义的 jsonBuilder 负责 json 字符串的拼接，通过 for 循环把每一个字段拼接成 json 字符串。 123456789101112131415161718192021222324func main() &#123; p:=person&#123;Name: &quot;hcjjj&quot;,Age: 26&#125; pv:=reflect.ValueOf(p) pt:=reflect.TypeOf(p) //自己实现的struct to json jsonBuilder:=strings.Builder&#123;&#125; jsonBuilder.WriteString(&quot;&#123;&quot;) num:=pt.NumField() for i:=0;i&lt;num;i++&#123; jsonTag:=pt.Field(i).Tag.Get(&quot;json&quot;) //获取json tag jsonBuilder.WriteString(&quot;\\&quot;&quot;+jsonTag+&quot;\\&quot;&quot;) jsonBuilder.WriteString(&quot;:&quot;) //获取字段的值 jsonBuilder.WriteString(fmt.Sprintf(&quot;\\&quot;%v\\&quot;&quot;,pv.Field(i))) if i&lt;num-1&#123; jsonBuilder.WriteString(&quot;,&quot;) &#125; &#125; jsonBuilder.WriteString(&quot;&#125;&quot;) fmt.Println(jsonBuilder.String())//打印json字符串&#125; json 字符串的转换只是 struct tag 的一个应用场景，完全可以把 struct tag 当成结构体中字段的元数据配置，使用它来做想做的任何事情，比如 orm 映射、xml 转换、生成 swagger 文档等。 反射定律 反射是计算机语言中程序 检视其自身结构 的一种方法，它属于元编程的一种形式。反射灵活、强大，但也存在不安全。它可以绕过编译器的很多静态检查，如果过多使用便会造成混乱。Go 语言的作者在博客上总结了 反射的三大定律。 任何接口值 interface{} 都可以反射出反射对象，也就是 reflect.Value 和 reflect.Type，通过函数 reflect.ValueOf 和 reflect.TypeOf 获得。 反射对象也可以还原为 interface{} 变量，也就是第 1 条定律的可逆性，通过 reflect.Value 结构体的 Interface 方法获得。 要修改反射的对象，该值必须可设置，也就是 可寻址。 errors错误是通过内置的 error 接口表示，它只有一个 Error 方法用来返回具体的错误信息： 123type error interface &#123; Error() string&#125; 一般而言，error 接口用于当方法或者函数执行遇到错误时进行返回，而且是第二个返回值。通过这种方式，可以让调用者自己根据错误信息决定如何进行下一步处理。 12345678func main() &#123; i,err:=strconv.Atoi(&quot;a&quot;) if err!=nil &#123; fmt.Println(err) &#125; else &#123; fmt.Println(i) &#125;&#125; 1func Atoi(s string) (int, error) error 工厂函数 自己定义的函数也可以返回错误信息给调用者： 1234567func add(a, b int) (int, error)&#123; if a&lt;0 || b&lt;0 &#123; return 0, errors.New(&quot;a 或者 b 不能为负数&quot;) &#125;else &#123; return a+b,nil &#125;&#125; 123456sum,err := add(-1,2)if err != nil &#123; fmt.Println(err)&#125; else &#123; fmt.Println(sum)&#125; 自定义 error 采用工厂返回错误信息的方式只能传递一个字符串，也就是携带的信息只有字符串，如果想要携带更多信息（比如错误码信息）就需要自定义 error 。 12345678type commonError struct &#123; errorCode int //错误码 errorMsg string //错误信息&#125;func (ce *commonError) Error() string&#123; return ce.errorMsg&#125; 123return 0, &amp;commonError &#123; errorCode: 1, errorMsg: &quot;a 或者 b 不能为负数&quot;&#125; error 断言 需要先把返回的 error 接口转换为自定义的错误类型 123456sum, err := add(-1, 2)if cm,ok := err.(*commonError); ok &#123; fmt.Println(&quot;错误代码为:&quot;, cm.errorCode, &quot;，错误信息为：&quot;, cm.errorMsg)&#125; else &#123; fmt.Println(sum)&#125; 错误嵌套 调用一个函数，返回了一个错误信息 error，在不想丢失这个 error 的情况下，又想添加一些额外信息返回新的 error。 1234type MyError struct &#123; err error msg string&#125; 让 MyError 这个 struct 实现 error 接口，然后在初始化 MyError 的时候传递存在的 error 和新的错误信息： 12345678func (e *MyError) Error() string &#123; return e.err.Error() + e.msg&#125;func main() &#123; //err是一个存在的错误，可以从另外一个函数返回 newErr := MyError&#123;err, &quot;数据上传问题&quot;&#125;&#125; Error Wrapping 这种方式可以满足的需求，但是非常烦琐，因为既要定义新的类型还要实现 error 接口。所以从 Go 语言 1.13 版本开始，Go 标准库新增了 Error Wrapping 功能，可以基于一个存在的 error 生成新的 error，并且可以保留原 error 信息： 123e := errors.New(&quot;原始错误e&quot;)w := fmt.Errorf(&quot;Wrap 了一个错误: %w&quot;, e)fmt.Println(w) Go 语言没有提供 Wrap 函数，而是扩展了 fmt.Errorf 函数，然后加了一个 %w，通过这种方式，便可以生成 wrapping error。 errors.Unwrap 函数 Go 语言提供了 errors.Unwrap 用于获取被嵌套的 error，比如以上例子中的错误变量 w ，就可以对它进行 unwrap，获取被嵌套的原始错误 e。 1fmt.Println(errors.Unwrap(w)) errors.Is 函数 有了 Error Wrapping 后，会发现原来用的判断两个 error 是不是同一个 error 的方法失效了，比如 Go 语言标准库经常用到的如下代码中的方式： 1if err == os.ErrExist 于是 Go 语言为提供了 errors.Is 函数，用来判断两个 error 是否是同一个： 1func Is(err, target error) bool 以上就是 errors.Is 函数的定义，可以解释为： 如果 err 和 target 是同一个，那么返回 true。 如果 err 是一个 wrapping error，target 也包含在这个嵌套 error 链中的话，也返回 true。 1fmt.Println(errors.Is(w,e)) errors.As 函数 有了 error 嵌套后，error 断言也不能用了，因为不知道一个 error 是否被嵌套，又嵌套了几层。所以 Go 语言为解决这个问题提供了 errors.As 函数，比如前面 error 断言的例子，可以使用 errors.As 函数重写，效果是一样的： 123456var cm *commonErrorif errors.As(err, &amp;cm) &#123; fmt.Println(&quot;错误代码为:&quot;, cm.errorCode,&quot;，错误信息为：&quot;, cm.errorMsg)&#125; else &#123; fmt.Println(sum)&#125; 所以在 Go 语言提供的 Error Wrapping 能力下，写的代码要尽可能地使用 Is、As 这些函数做判断和转换。 defer defer 调用栈 return x 不是一个原子语句 Go 语言为提供了 defer 函数，可以保证文件关闭（资源的释放）后一定会被执行，不管自定义的函数出现异常还是错误。 下面的代码是 Go 语言标准包 ioutil 中的 ReadFile 函数，它需要打开一个文件，然后通过 defer 关键字确保在 ReadFile 函数执行结束后，f.Close() 方法被执行，这样文件的资源才一定会释放。 123456789func ReadFile(filename string) ([]byte, error) &#123; f, err := os.Open(filename) if err != nil &#123; return nil, err &#125; defer f.Close() //省略无关代码 return readAll(f, n)&#125; defer 关键字用于修饰一个函数或者方法，使得该函数或者方法在返回前才会执行，也就说被延迟，但又可以保证一定会执行。 以上面的 ReadFile 函数为例，被 defer 修饰的 f.Close 方法延迟执行，也就是说会先执行 readAll(f, n)，然后在整个 ReadFile 函数 return 之前执行 f.Close 方法。 defer 语句常被用于成对的操作，如文件的打开和关闭，加锁和释放锁，连接的建立和断开等。不管多么复杂的操作，都可以保证资源被正确地释放。 panicGo 语言是一门静态的强类型语言，很多问题都尽可能地在编译时捕获，但是有一些只能在运行时检查，比如数组越界访问、不相同的类型强制转换等，这类运行时的问题会引起 panic 异常。 除了运行时可以产生 panic 外，自己也可以抛出 panic 异常。假设需要连接 MySQL 数据库，可以写一个连接 MySQL 的函数 connectMySQL，如下面的代码所示： 123456func connectMySQL(ip,username,password string)&#123; if ip ==&quot;&quot; &#123; panic(&quot;ip不能为空&quot;) &#125; //省略其他代码&#125; 在 connectMySQL 函数中，如果 ip 为空会直接抛出 panic 异常。这种逻辑是正确的，因为数据库无法连接成功的话，整个程序运行起来也没有意义，所以就抛出 panic 终止程序的运行。 panic 是 Go 语言内置的函数，可以接受 interface{} 类型的参数，也就是任何类型的值都可以传递给 panic 函数，如下所示： 1func panic(v interface&#123;&#125;) 小提示：interface{} 是空接口的意思，在 Go 语言中代表任意类型。 panic 异常是一种非常严重的情况，会让程序中断运行，使程序崩溃，所以 如果是不影响程序运行的错误，不要使用 panic，使用普通错误 error 即可。 recover通常情况下，不对 panic 异常做任何处理，因为既然它是影响程序运行的异常，就让它直接崩溃即可。但是也的确有一些特例，比如在程序崩溃前做一些资源释放的处理，这时候就需要从 panic 异常中恢复，才能完成处理。 在 Go 语言中，可以通过内置的 recover 函数恢复 panic 异常。因为在程序 panic 异常崩溃的时候，只有被 defer 修饰的函数才能被执行，所以 recover 函数要结合 defer 关键字使用才能生效。 下面的示例是通过 defer 关键字 + 匿名函数 + recover 函数 从 panic 异常中恢复的方式。 12345678func main() &#123; defer func() &#123; if p:=recover();p!=nil&#123; fmt.Println(p) &#125; &#125;() connectMySQL(&quot;&quot;,&quot;root&quot;,&quot;123456&quot;)&#125; 运行这个代码，可以看到如下的打印输出，这证明 recover 函数成功捕获了 panic 异常。 1ip 不能为空 通过这个输出的结果也可以发现，recover 函数返回的值就是通过 panic 函数传递的参数值。 unsafeGo 将其定义为这个包名，也是为了让尽可能地不使用它。不过虽然不安全，它也有优势，那就是可以绕过 Go 的内存安全机制，直接对内存进行读写。所以有时候出于性能需要，还是会冒险使用它来对内存进行操作。 指针类型转换 Go 是强类型的静态语言，强类型意味着一旦定义了，类型就不能改变；静态意味着类型检查在运行前就做了。同时出于安全考虑，Go 语言是不允许两个指针类型进行转换的。 123456func main() &#123; i := 10 ip := &amp;i var fp *float64 = (*float64)(ip) fmt.Println(fp)&#125; 在编译的时候，会提示 cannot convert ip (type * int) to type * float64，也就是不能进行强制转型。那如果还是需要转换呢？这就需要使用 unsafe 包里的 Pointer 了。 unsafe.Pointer unsafe.Pointer 是一种特殊意义的指针，可以表示任意类型的地址，类似 C 语言里的 void * 指针，是全能型的。正常情况下，* int 无法转换为 *float64，但是通过 unsafe.Pointer 做中转就可以了。 1234567func main() &#123; i:= 10 ip:=&amp;i var fp *float64 = (*float64)(unsafe.Pointer(ip)) *fp = *fp * 3 fmt.Println(i)&#125; 按 Go 语言官方的注释，ArbitraryType 可以表示任何类型，而 unsafe.Pointer 又是 *ArbitraryType，也就是说 unsafe.Pointer 是任何类型的指针，也就是一个通用型的指针，足以表示任何内存地址。 uintptr 指针类型 uintptr 也是一种指针类型，它足够大，可以表示任何指针。unsafe.Pointer 不能进行运算，比如不支持 +（加号）运算符操作，但是 uintptr 可以对指针偏移进行计算，这样就可以访问特定的内存，达到对特定内存读写的目的，这是真正内存级别的操作。 1234567891011121314func main() &#123; p := new(person) //Name是person的第一个字段不用偏移，即可通过指针修改 pName := (*string)(unsafe.Pointer(p)) *pName = &quot;gogogo&quot; //Age 并不是 person 的第一个字段，所以需要进行偏移，这样才能正确定位到 Age 字段这块内存，才可以正确的修改 pAge := (*int)(unsafe.Pointer(uintptr(unsafe.Pointer(p))+unsafe.Offsetof(p.Age))) *pAge = 20 fmt.Println(*p)&#125;type person struct &#123; Name string Age int&#125; 指针转换规则 graph LR A[*T] B(unsafe.Pointer) B C(uintptr) Go 语言中存在三种类型的指针，它们分别是常用的 *T、unsafe.Pointer 及 uintptr，这三者的转换规则： 任何类型的 *T 都可以转换为 unsafe.Pointer； unsafe.Pointer 也可以转换为任何类型的 *T； unsafe.Pointer 可以转换为 uintptr； uintptr 也可以转换为 unsafe.Pointer。 unsafe.Pointer 主要用于指针类型的转换，而且是各个指针类型转换的桥梁。uintptr 主要用于指针运算，尤其是通过偏移量定位不同的内存。 othersString 和 [] byte字符串 string 也是一个不可变的字节序列，所以可以直接转为字节切片 [] byte： 12s:=&quot;Hello 世界&quot;bs:=[]byte(s) string 不止可以直接转为 [] byte，还可以使用 [] 操作符获取指定索引的字节值： 123456789101112s:=&quot;Hello 世界&quot;bs:=[]byte(s)fmt.Println(bs)fmt.Println(s[0],s[1],s[6])// 字节长度 12 (6 + 3*2)fmt.Println(len(s))// 字符长度 8fmt.Println(utf8.RuneCountInString(s))// 逐个遍历字符for i, r := range s &#123;\tfmt.Printf(&quot;%d %c &quot;, i, r)&#125; new 和 makeGo 语言程序所管理的虚拟内存空间会被分为两部分：堆内存和栈内存。栈内存主要由 Go 语言来管理，开发者无法干涉太多，堆内存才是开发者发挥能力的舞台，因为程序的数据大部分分配在堆内存上，一个程序的大部分内存占用也是在堆内存上。常说的 Go 语言的内存垃圾回收是针对 堆内存 的垃圾回收。 变量的声明 12var s string // 声明并未初始化，string 的零值：&quot;&quot;（空字符串）var sp *string // 指针类型变量的零值：nil，它没有指向的内存，无法使用 变量的赋值 如果在声明一个变量的时候就给这个变量赋值，这种操作就称为变量的初始化。指针类型的变量 如果没有分配内存，就默认是零值 nil，它没有指向的内存，所以无法使用，强行使用就会得到 nil 指针错误。而对于 值类型的变量 来说，即使只声明一个变量，没有对其初始化，该变量也会有分配好的内存。 struct 结构体，是一个值类型，Go 语言自动分配了内存，所以可以直接使用，不会报 nil 异常。 12345var s1 string = &quot;Go&quot;s2 := &quot;Go&quot;s3 = &quot;Go&quot; // 假设已经声明变量 svar sp *string*sp = &quot;Go&quot; // runtime error: invalid memory address or nil pointer dereference 如果要对一个变量赋值，这个变量必须有对应的分配好的内存，这样才可以对这块内存操作，完成赋值的目的。所以一个变量必须要经过 声明、内存分配 才能 赋值，才可以在声明的时候进行 初始化。指针类型在声明的时候，Go 语言并没有自动分配内存，所以不能对其进行赋值操作，这和值类型不一样。 map 和 chan 也一样，因为它们本质上也是指针类型。 new 函数 1234// The new built-in function allocates memory. The first argument is a type,// not a value, and the value returned is a pointer to a newly// allocated zero value of that type.func new(Type) *Type new 函数的作用是根据传入的类型申请一块内存，然后返回指向这块内存的指针，指针指向的数据就是该类型的 零值。 123var sp *stringsp = new(string) // *sp = &quot;&quot;*sp = &quot;Go&quot; // ok 变量的初始化 当声明了一些类型的变量时，这些变量的零值并不能满足要求，这时就需要在变量声明的同时进行赋值（修改变量的值），这个过程称为变量的初始化。 12345678var s string = &quot;Go&quot;s1 := &quot;Go&quot;type person struct &#123; name string age int&#125;p := person&#123;name: &quot;Go&quot;, age: 15&#125; 指针变量初始化 new 函数可以申请内存并返回一个指向该内存的指针，但是这块内存中数据的值默认是该类型的零值，在一些情况下并不满足业务需求。可以自定义一个函数，对指针变量进行初始化： 123456func NewPerson(name string, age int) *person&#123; p := new(person) p.name = name p.age = age return p&#125; NewPerson 函数就是工厂函数，除了使用 new 函数创建一个 person 指针外，还对它进行了赋值，也就是初始化。 make 函数 在使用 make 函数创建 map 的时候，其实调用的是 makemap 函数： 1234// makemap implements Go map creation for make(map[k]v, hint).func makemap(t *maptype, hint int, h *hmap) *hmap&#123;\t// ...&#125; makemap 函数返回的是 *hmap 类型，而 hmap 是一个结构体，它的定义如下面的代码所示： 1234567891011121314// A header for a Go map.type hmap struct &#123; // Note: the format of the hmap is also encoded in cmd/compile/internal/gc/reflect.go. // Make sure this stays in sync with the compiler&#x27;s definition. count int // # live cells == size of map. Must be first (used by len() builtin) flags uint8 B uint8 // log_2 of # of buckets (can hold up to loadFactor * 2^B items) noverflow uint16 // approximate number of overflow buckets; see incrnoverflow for details hash0 uint32 // hash seed buckets unsafe.Pointer // array of 2^B Buckets. may be nil if count==0. oldbuckets unsafe.Pointer // previous bucket array of half the size, non-nil only when growing nevacuate uintptr // progress counter for evacuation (buckets less than this have been evacuated) extra *mapextra // optional fields&#125; 要想使用这样的 hmap，不是简单地通过 new 函数返回一个 *hmap 就可以，还需要对其进行初始化，这就是 make 函数要做的事情，如下所示： 1m := make(map[string]int, 10) 其实 make 函数就是 map 类型的工厂函数，它可以根据传递它的 K-V 键值对类型，创建不同类型的 map，同时可以初始化 map 的大小。 make 函数不只是 map 类型的工厂函数，还是 chan、slice 的工厂函数。它同时可以用于 slice、chan 和 map 这三种类型的初始化。 new 函数只用于分配内存，并且把内存清零，也就是返回一个指向对应类型零值的指针。new 函数一般用于需要显式地返回指针的情况，不是太常用。 make 函数只用于 slice、chan 和 map 这三种内置类型的创建和初始化，因为这三种类型的结构比较复杂，比如 slice 要提前初始化好内部元素的类型，slice 的长度和容量等，这样才可以更好地使用它们。 闭包（匿名函数）1234567891011121314func main() &#123; cl:=colsure() fmt.Println(cl()) // 1 fmt.Println(cl()) // 2 fmt.Println(cl()) // 3&#125;// 注意这个返回值是一个闭包func colsure() func() int &#123; i := 0 return func() int &#123; i++ return i &#125;&#125; 闭包对其作用域内变量的 捕获和持有。闭包捕获并持有了变量 i 的引用，而不是其值，因此每次调用闭包时，它都操作同一个 i 变量，而 不是每次重新初始化 i。 loopvar12345678910111213141516171819// go1.22func main() &#123; done := make(chan bool) values := []string&#123;&quot;a&quot;, &quot;b&quot;, &quot;c&quot;&#125; for _, v := range values &#123; go func() &#123; fmt.Println(v) done &lt;- true &#125;() &#125; // wait for all goroutines to complete before exiting for _ = range values &#123; &lt;-done &#125;&#125;// 1.21 可能输出一样的值，也可能不一样// 1.22 每个值都会输出，但是顺序有可能随机 1234567891011121314151617func rightLoop() &#123; done := make(chan bool) values := []string&#123;&quot;a&quot;, &quot;b&quot;, &quot;c&quot;&#125; for _, v := range values &#123; go func(str string) &#123; fmt.Println(str) done &lt;- true &#125;(v) &#125; // wait for all goroutines to complete before exiting for range values &#123; &lt;-done &#125;&#125;// a b c go1.22 版本之后解决了 for 循环变量共享的问题，注意必须 go 版本和 gomod 版本都 &gt;&#x3D; 1.22 才会使用新的 loopvar 虽然之前版本的变量共享，但在协程里可能会输出不同的值，不该想当然以为值永远是最后一个。","tags":["Golang"],"categories":["Golang"]},{"title":"攻击树/图技术总结 😈⃤","path":"/2024/03/18/attack/","content":"感知和理解网络攻击是一项困难的任务，需要借助有效的技术手段来加以辅助 攻击建模技术攻击建模技术（AMT）用于建模和可视化一系列事件和&#x2F;或事件组合，这些事件使得对计算机或网络的网络攻击能够成功实施。 AMT 大致可以分为三类：基于用例框架的方法、基于时间维度呈现的方法、基于图形的建模方法 AMT 不仅能够帮助观察者分析网络攻击场景，还减轻了安全专家在评估攻击和制定缓解措施时的认知负担。通过简化复杂信息的表达，它使决策者更快掌握安全问题，更好地感知风险，并直观理解复杂概念。AMT 提供了高效的工具和工作空间，促进了更清晰的讨论和辩论，同时在较少依赖逻辑模型的情况下支持对网络攻击的感知和理解。 攻击建模中的术语分类 前提条件（Precondition）用于描述网络攻击成功所需的先决条件 相关术语包括：Exploit、Prerequisite、Precondition、Predicate、Requires 等 后置条件（Postcondition）描述网络攻击完成后产生的后果或效果 相关术语包括：Postcondition、Effect、Provides、Consequence、Impact 等 实施者（Perpetrator）表示进行网络攻击的主体 相关术语包括：Perpetrator、Attacker、Adversary、Hacker、Misuser、Bad guy 等 攻击模型的可视化 攻击模型通常通过组合二维形状（如正方形、矩形和椭圆）、一维形状（如线条）以及文本语法来构建，用以表示网络攻击的结构。这种表达方式被称为视觉语法、视觉修辞或视觉符号体系。 故障树和 Petri 网等建模系统的视觉语法已经实现标准化，它们在模拟网络攻击时能够形成一致的理解框架。然而，攻击图和攻击树在视觉语法上缺乏标准化、规范化方法以及通用的建模框架。许多研究者使用自创且未经验证的视觉语法来模拟攻击，这种方法被亚历山大称为“无意识设计方法”。 目前，有超过 75 种攻击图可视化语法配置和超过 20 种攻击树配置，这些配置涵盖了 180 多种不同的可视化语法。这些可视化语法在用于表示网络攻击中关键构造（如先决条件和漏洞）的形状和形式上存在显著差异。如此多的相互冲突的提案不仅容易让研究人员和从业者在选择时感到困惑，也反映出该领域的“不成熟”，并导致研究工作的“分散化”。 网络攻击网络攻击相关术语 术语 解释 漏洞 (Vulnerability) 一种可被利用的、意外存在的系统弱点，由一个或多个前提条件的存在而导致 前提条件 (Precondition) 系统中为了成功利用漏洞而必须满足的状态 初始前提条件 (Initial precondition) 网络攻击中需要满足的第一个前提条件 攻击者能力 (Perpetrator capability) 攻击者运行漏洞利用所需的工具、知识和&#x2F;或访问权限级别 后置条件 (Postcondition) 成功利用漏洞后产生的条件或状态 目标 (Goal) 网络攻击的最终目标 利用 (Exploit) 一系列步骤 —— 包括执行代码或手动操作，利用目标系统中的一个或多个漏洞，并为攻击者提供特定的能力 非侵入性事件 (Non-intrusive event) 支持和辅助网络攻击的事件，但不会改变目标系统的状态 脆弱性、前提条件和后置条件 脆弱性 脆弱性是指系统设计、实施或管理中存在的可被利用的弱点 脆弱性通常由多个系统状态的组合构成，这些状态被称为前提条件 前提条件 前提条件是指一组系统属性，漏洞的利用必须具备这些属性才能成功执行 初始前提条件是系统固有的属性，并非由于漏洞利用而产生 通过解决这些前提条件，可能会使攻击中的所有后续步骤失效，至少有 三种类型的前提条件： 状态&#x2F;服务：目标系统持有或宣称特定版本的操作系统、系统软件&#x2F;应用程序、服务，或处于特定的硬件&#x2F;软件状态 可达性：目标是可访问的 攻击者能力：攻击者具备某些特定能力，例如能够在目标系统上运行进程、使用工具、拥有特权级别，或具备攻击工具和必要的技能 在上述前提条件类型中，状态&#x2F;服务 通常在 AMTs 中表示，如攻击图和攻击树，可达性和攻击者能力的表示则较为少见 实施者能力是攻击分析中的关键因素之一，对于 安全分析师 而言，了解哪些漏洞需要较高的实施者能力，哪些漏洞对实施者的能力要求较低，至关重要。例如，在 RPC（远程过程调用） 漏洞中，实施者能力的要求如下： rcp 服务必须对攻击者可用 目标主机必须信任源主机 攻击者必须具备本地 shell 访问权限 后置条件 成功的漏洞利用会导致一个或多个后置条件，虽然漏洞利用的结果通常被称为后置条件，但这些后置条件有时也可以成为进一步漏洞利用的前提条件 因此，大多数研究人员将后置条件视为前提条件的延伸，并且 使用“目标”一词来指代最终的后置条件 条件逻辑要成功利用漏洞，必须满足一个或多个前提条件，这些前提条件的组合可以通过前提条件逻辑来表示。例如， 给定两个前提条件：pr1 和 pr2 如果需要同时满足这两个条件，则可以用如下形式的 合取表示：pr1 ∧ pr2 如果只需满足其中任意一个条件，则可以用如下形式的 析取表示：pr1 ∨ pr2 尽管前提条件逻辑的表示对于识别网络攻击的防御和应对措施至关重要，但许多攻击图很少涉及前提条件逻辑的具体表示。 漏洞利用漏洞利用是一组通过代码或手动步骤执行的操作，旨在利用目标系统中的一个或多个漏洞，为攻击者提供特定功能。 漏洞利用可以被定义为以下形式的表达式： **利用（漏洞，后置条件，来源，目标）&#x2F; exploit(vulnerability, postcondition, source, target)**，其中： 漏洞：被利用的脆弱性，漏洞可以分解为多个前提条件，所有这些前提条件或它们的组合必须存在，漏洞才能被利用 后置条件：漏洞利用产生的结果 来源（source）：源主机，即发起漏洞利用的主机 目标（target）：漏洞利用的目标主机 以下是漏洞形式表达的一些示例： **ftp_rhosts(ftp, trusthost, i, j)**：表示主机 i 利用主机 j 的 FTP 漏洞，并将受信任主机列表上传到主机 j **sshd_bof(sshd, root, i, j)**：表示主机 i 利用主机 j 的 SSH（安全 Shell）服务中的缓冲区溢出漏洞，从而获得对主机 j 的 root 访问权限 **local_bof(bofv, root, i, j)**：表示主机 i 利用主机 j 中的本地缓冲区溢出漏洞（bofv），从而获得对主机 j 的 root 访问权限 目前文献中并没有关于漏洞利用和漏洞形式化表达的统一标准或协议 非侵入事件 非侵入事件，也称为二次漏洞利用或可疑事件，是攻击者用于发现目标系统属性和漏洞的系统探测操作。与漏洞利用不同，非侵入事件不会改变系统属性，除非目标系统对这些事件作出程序化或手动的反应，例如阻塞端口或创建新的入侵检测系统规则。 非侵入事件的示例包括 rpcinfo，该工具能够显示目标机器上的端口和服务数据，以及各种探测和扫描工具，如 nmap、netcat、amap、XProbe、P0f 和 X-Scan。这些工具会返回系统的响应信息，但不会改变系统的状态。 入侵检测系统（IDS）能够检测并警告侵入事件（漏洞利用）和非侵入事件。 签名（漏洞利用） 前提条件 后置条件 RPC sadmind UDP PING 主机数据的泄露 运行服务的泄露；系统访问（非侵入） RPC portmap sadmind request UDP 主机数据的泄露 端口号的泄露；运行服务的泄露；系统访问；远程访问（非侵入） RPC sadmind UDP NET-MGT_PROC_SERVICE CLIENT_DOMAIN overflow attempt 主机数据的泄露；端口号的泄露；运行服务的泄露 系统访问；远程访问；管理员访问（侵入） RPC sadmind query with root credentials attempt UDP 主机数据的泄露；端口号的泄露；运行服务的泄露；系统访问；远程访问 远程访问；管理员访问（侵入） 如表所示，一些事件（如 RPC sadmind UDP PING 和 RPC portmap sadmind request UDP）既可以是侵入事件，也可以是非侵入事件。RPC sadmind UDP PING 会泄露主机的一些信息——这是非侵入事件，而 RPC portmap sadmind request UDP 则会提供对主机的系统访问权限——这是侵入事件，侵入事件和非侵入事件可以统称为 漏洞利用。 网络攻击网络攻击是一组包含一个或多个漏洞利用的操作，这些操作以顺序或并行的方式应用于目标系统，以暴露目标系统的漏洞并改变其状态。 一旦漏洞被利用，就会产生多个后置条件，这些后置条件中的每一个都可能成为进一步利用的前提条件。攻击的最终目标在攻击树和攻击图中被称为“目标”，而在故障树中则被称为“不良条件”。 值得注意的是，不同的观察者对网络攻击的视角可能有所不同。Moody 将这种视角差异称为“认知契合原则”。分析师通常对网络攻击的 低层次技术视角 感兴趣，特别是攻击所需的前提条件和具体的漏洞。他们有时需要向非技术领域的人员解释网络攻击。而非专家，如利益相关者、高管和决策者，更倾向于从 高层次的视角 看待网络攻击，这种视角通常 隐藏了技术细节。然而，在某些情况下，从分析师的技术视角来看待网络攻击也可能对他们有所帮助。 攻击路径 通常情况下，存在多种替代的攻击序列，每一种序列都可能导致攻击成功，这些被称为 攻击路径，并且在所有攻击模型（AMT）中都有表示。上图示例，其中包含两条攻击路径，可以描述为： 路径 1：sshd(3,1) ∧ user(3) → sshd_bof(3,1); user(1) ∧ sshd(1,2) → sshd_bof(1,2) → user(2) 路径 2：user(3) ∧ sshd(3,2) → sshd_bof(3,2) → user(2) 攻击路径分析 等技术通过概述已知和预测的攻击事件序列，有助于调查攻击图中的漏洞路径。这种分析能够帮助识别攻击路径中可能受影响的资源，以及路径上的具体漏洞。 上图展示了攻击图和攻击树在视觉表示上的另一个显著差异 —— 事件流方向。图中事件流采用 自上而下 的方式呈现，即观察者从顶部开始阅读，然后按事件顺序向下推进，在调查的 118 个攻击图配置中，有 102 个（86.4%）以自上而下的方式呈现事件；而在调查的 61 个攻击树中，有 59 个（96.7%）采用了自下而上的事件流表示。 上图还说明了攻击图和攻击树在可视化表示方面的另一关键区别，尽管该攻击图仅表示单个攻击目标（user 2），并展示了两条通向该目标的路径，但攻击图经常被用来表示具有多条路径和多个目标的复杂攻击，Aguessy 指出，攻击树的局限性在于它们仅能表示单一攻击，而攻击图则可以表示多个攻击。 结合攻击路径分析和加权边辅助攻击预测的一个示例是 Frigault 和 Wang 提出的 基于贝叶斯的攻击图，在这一示例中，攻击图使分析人员能够计算 成功攻击路径的概率。图中的每个节点代表一个潜在漏洞，以及与该漏洞相关的前提条件和后置条件，每个节点都被分配一个概率，用以表示 该漏洞被利用的可能 性。 Aguessy 提到的攻击图分为 完整攻击图 和 部分攻击图。完整攻击图概述了给定网络中所有潜在漏洞和可能的攻击路径。部分攻击图（也称为 最小攻击图）则概述了给定攻击中节点之间的交互模式。在 Stuxnet 和 Jeep Cherokee 攻击场景，以及分析复杂网络问题时，完整攻击图的表示能力尤为重要。 总体而言，攻击树通常仅表示单一攻击，而 攻击森林（攻击树的集合）是为解决这一局限性而提出的扩展方法。 攻击图应用攻击图在系统强化中的应用 预测策略 方法与内容 事件预测 度量事件的可能性 使用马尔可夫决策过程计算攻击成功的概率；超警报相关图和攻击策略图；受损置信指数；邻接矩阵聚类；警报相关矩阵；关联规则挖掘；未来场景排序；基于概率的攻击预测；吸收马尔可夫链用于漏洞分析和辅助评估妥协可能性的马尔可夫奖励模型；预测攻击图；pwnPr3d； 分析多步攻击 警报聚类、警报合并与意图识别；警报关联框架；因果关联；聚类邻接矩阵；分而治之框架；分层聚类算法；漏洞依赖图； 攻击路径分析 攻击链分析；计算实施攻击的难度；关联规则挖掘； 多样的 加强安全弱点 使用利用图；拓扑漏洞分析； 优先移除漏洞 技能水平分析；最小关键攻击集（MCSA）；预测图；网络强化图；基于博弈论的方法； IDS 警报相关性分析 超警报相关图；ADEPTS；关联规则挖掘算法；拓扑漏洞分析（TVA）； 确定最佳设备配置 识别关键设备 AssetRank 算法； 确定最佳设备部署位置 拓扑漏洞分析；成功测量模型； 最佳设备配置 基于图的网络漏洞分析；聚类邻接矩阵；使用 PageRank 排名的攻击图；依赖攻击图；最佳 IDS 部署；NetSPA；攻击响应图； 预测配置设置的影响 反向图遍历识别关键前提条件和漏洞；排序攻击图；邻接矩阵聚类方法和可达性分析；预测图；分层聚类算法； 攻击树&#x2F;图 特性 攻击树 攻击图 结构 树状结构，简单直观，逻辑清晰 图状结构，能表示更复杂的关系和路径 适用场景 单一目标、静态分析、小规模系统 多目标、动态分析、复杂系统 逻辑复杂度 支持简单的逻辑（AND&#x2F;OR 节点） 支持多路径分析和循环关系，表达更灵活 分析能力 聚焦于一个目标的分解，适合单一攻击目标 全面分析所有可能路径，适合多阶段攻击（如 APT）的建模 易用性 易于构建和理解 结构复杂，可能需要算法支持 动态性 通常为静态分析工具 可支持动态分析，结合实时监控数据更新状态 攻击图和攻击树都是基于图形的网络攻击表示，重要的是区分基于图论的图形和树的表示。在图论中，树是一种无环图，其中任意两个顶点之间都有一条路径相连，而图则是一个可能包含环的图。通常决策树、事件树、攻击树、故障树以及 Petri 网的可视化表示符合树的定义，因为它们在可视化时呈现为无环图。 图的定义基于图形的网络攻击表示可以用以下形式表示：G(V; E)，其中包含顶点 v ∈ V 和边 e ∈ E，边表示节点之间的关系。整体图形结构可以表示为一个元组，形式为 G &#x3D; (S, τ, S0, Ss, L, EX)，其中： S 是一个有限的状态集， τ ⊆ S × S 是一个转换关系， S0 ⊆ S 是初始状态集， Ss ⊆ S 是成功状态集 —— 例如，获得某一主机的 root 权限或用户权限， L : S → 2AP 是状态的标签，标记一组原子命题 (AP)， EX 是一个有限的漏洞集合，表示两个状态之间的转换。 攻击树攻击图视觉语法理论可视化语法分析逻辑攻击图属性攻击图贝叶斯攻击图参考文献 Lallie H S, Debattista K, Bal J. A review of attack graph and attack tree visual syntax in cyber security [J]. Computer Science Review, 2020, 35: 100219. Frigault M, Wang L. Measuring network security using bayesian network-based attack graphs [C]&#x2F;&#x2F;2008 32nd Annual IEEE International Computer Software and Applications Conference. IEEE, 2008: 698-703. - 最新的怎么做 Wang L, Islam T, Long T, et al. An attack graph-based probabilistic security metric [C]&#x2F;&#x2F;Data and Applications Security XXII: 22nd Annual IFIP WG 11.3 Working Conference on Data and Applications Security London, UK, July 13-16, 2008 Proceedings 22. Springer Berlin Heidelberg, 2008: 283-296.","tags":["Attack graph"],"categories":["Research"]},{"title":"使用 Golang 实现的简易 Redis 🔨","path":"/2023/12/12/go3/","content":"使用 Go 语言基于 Redis serialization protocol (RESP) 实现简易的 Redis 开源地址： https://github.com/hcjjj/redis-go 1234567891011121314151617181920212223242526272829# _ _ # | (_) # _ __ ___ __| |_ ___ ______ __ _ ___ # | &#x27;__/ _ \\/ _` | / __|______/ _` |/ _ \\ # | | | __/ (_| | \\__ \\ | (_| | (_) |# |_| \\___|\\__,_|_|___/ \\__, |\\___/ # __/ | # |___/ # git配置git config --global user.name &quot;hcjjj&quot;git config --global user.email &quot;hcjjj@foxmail.com&quot;# 生成密钥SSH keyssh-keygen -t rsa -C &quot;hcjjj@foxmail.com&quot;# 填入 github 设置的 SSH and GPG keys$ cat C:\\Users\\hcjjj/.ssh/id_rsa.pub# 验证$ ssh -T git@github.com# Hi hcjjj! You&#x27;ve successfully authenticated, but GitHub does not provide shell access.# 初始化本地仓库git inittouch .gitignoregit add .git commit -m &quot;first commit&quot; # 推送到 githubgit remote add origin git@github.com:hcjjj/redis-go.gitgit push -u origin master# 查看提交记录git reflog show master 编译运行： 123456# redis.conf 设置服务器信息、数据库核心数、aof 持久化相关、集群相关# 配置 peer 信息既开启集群模式，每个节点需要分别设置好各自配置文件的 self 和 peersgo build &amp;&amp; ./redis-go# 客户端： redis-cli/telnet/网络调试助手（开启转义符指令解析）redis-cli -h 127.0.0.1 -p 6379# telnet 127.0.0.1 6379 实现逻辑TCP 服务器： 协议解析器： 内存数据库： 持久化流程： 集群架构： 集群指令执行流程： 目录结构12345678910111213141516171819202122232425├── aof # AOF 持久化├── cluster # 集群层├── config # 解析配置文件 redis.conf├── database # 内存数据库├── datastruct # 支持的数据结构│ └── dict├── interface # 接口定义│ ├── database│ ├── resp│ └── tcp├── lib # 基础工具│ ├── consistenthash # 一致性哈希│ ├── logger # 日志记录│ ├── sync # 同步工具│ │ ├── atomic│ │ └── wait│ ├── utils # 格式转换│ └── wildcard # 通配符├── resp # RESP 协议解析器│ ├── client # 客户端│ ├── connection│ ├── handler│ ├── parser # 解析客户端发来的数据│ └── reply # 封装服务器对客户端的回复└── tcp # TCP 服务器实现 RESPRedis 序列化协议规范，**Redis serialization protocol specification** RESP 是一个二进制安全的文本协议，以行作为单位，客户端和服务器发送的命令或数据一律以 \\r （CRLF）作为换行符，RESP 的二进制安全性允许在 key 或者 value 中包含 \\r 或者 这样的特殊字符。 二进制安全是指允许协议中出现任意字符而不会导致故障 正确回复（Redis → Client） 以 + 开头，以 “\\r ” 结尾的字符串形式 如：+OK\\r 错误回复（Redis → Client） 以 - 开头，以 “\\r ” 结尾的字符串形式 如：-Error message\\r 整数（Redis ⇄ Client） 以 : 开头，以 “\\r ” 结尾的字符串形式 如：:123456\\r 单行字符串（Redis ⇄ Client） 以 $ 开头，后跟实际发送字节数，以 “\\r “ 结尾 “Redis”：$5\\r Redis\\r “”：$0\\r \\r “Redis\\r go”：$11\\r Redis\\r go\\r 多行字符串（数组）（Redis ⇄ Client） 以 * 开头，后跟成员个数 有 3 个成员的数组 [SET, key, value]：*3\\r $3\\r SET\\r $3\\r key\\r $5\\r value\\r 支持命令 PING SELECT Key 命令集 DEL EXISTS FlushDB TYPE RENAME RENAMENX KEYS String 命令集 GET SET SETNX GETSET STRLEN … 测试命令： ping $4\\r ping\\r set key value *3\\r $3\\r SET\\r $3\\r key\\r $5\\r value\\r set ke1 value *3\\r $3\\r SET\\r $3\\r ke1\\r $5\\r value\\r select 1 *2\\r $6\\r select\\r $1\\r 1\\r get key *2\\r $3\\r GET\\r $3\\r key\\r select 2 *2\\r $6\\r select\\r $1\\r 1\\r telnet 需要逐条发送如 $4↩︎ping↩︎ 性能测试1234❯ neofetchOS: Windows 11 💻 / Ubuntu 22.04.4 LTS on Windows 10 x86_64 🐧CPU: AMD Ryzen 7 6800H with Radeon Graphics (16) @ 3.200GHzMemory: 61159MiB redis-go 123456789101112131415❯ redis-benchmark -h 127.0.0.1 -p 6379 -t set,get -n 10000 -qERROR: ERR unknown command configERROR: failed to fetch CONFIG from 127.0.0.1:6379WARN: could not fetch server CONFIG====== SET ====== 10000 requests completed in 0.17 seconds 50 parallel clients 3 bytes payload keep alive: 1 multi-thread: no0.01% &lt;= 0.1 milliseconds...SET: 58823.53 requests per second...GET: 62500.00 requests per second redis 1234567891011121314❯ redis-benchmark -h 127.0.0.1 -p 6379 -t set,get -n 10000====== SET ====== 10000 requests completed in 0.15 seconds 50 parallel clients 3 bytes payload keep alive: 1 host configuration &quot;save&quot;: 900 1 300 10 60 10000 host configuration &quot;appendonly&quot;: no multi-thread: no0.01% &lt;= 0.1 milliseconds...66666.66 requests per second...71942.45 requests per second 排错记录 当客户端主动断开连接的时候服务器报错，panic: sync: negative WaitGroup counter waitDone.Add(1) 不小心写成 waitDone.Add(0)，导致后续的 waitDone.Done() 出现 panic imports redis-go/database: import cycle not allowed aof.go 文件导包错误，需要的是 “redis-go&#x2F;interface&#x2F;database”，而不是 “redis-go&#x2F;database” [ERROR][database.go:76] runtime error: index out of range [1] with length 1 execSelect 方法中的 strconv.Atoi(string(args[0])) 写成了 1 语法层面的 “坑” Go 的 for 循环的迭代变量都是共享地址 go1.22 版本之后解决了 for 循环变量共享的问题 ⚠️ Go 的数组只能用常量来初始化 Go 的切片有着共享内存的特性 Go 有类型推断，但是没有自动类型转换 参考资料 HDT3213&#x2F;godis","tags":["Golang","Redis"],"categories":["Golang"]},{"title":"IEEE S&P 2024 - 对车载攻击面的重新审视","path":"/2023/12/05/CarVal/","content":"论文阅读：《Revisiting Automotive Attack Surfaces: a Practitioners’ Perspective》 论文阅读 背景介绍 TARA、网络安全法规 访谈方法 访谈设置、访谈程序与数据处理、访谈结构 访谈结果 评估TARA 资产识别困难 缺乏客观的定义和标准 自动化程度低，效率低 评估威胁数据库 需要更多常见的汽车专用威胁，而不是照搬其他领域的现有威胁 从业人员对现有法规列出的具体威胁评价较低 现有法规的限制和建议 更详细的信息肯定会对安全小组有所帮助 传统 IT 威胁与汽车威胁之间存在差距 访谈研究摘要 缺乏高质量的针对汽车的威胁数据库 缺乏有效的 TARA 工具 改进威胁数据库 使用分层框架来呈现汽车特有的威胁 威胁描述（TD）， 一组描述特定威胁细节的自然语言句子 攻击描述 (AD) 威胁的根源 (RC) 识别威胁的安全测试方法 (STA) 预防威胁的措施 (MG) 威胁代码（TC），某一特定类别下的一组威胁描述 威胁主题（TT），一组遵循特定高级分类逻辑的威胁代码 威胁知识图谱（TKG），利用知识图谱来进一步表示威胁代码之间的关系 知识图谱可以用一组三元组来表示：头部实体、关系、尾部实体 实体是威胁代码，三元组表示两个代码之间的逻辑关系 威胁数据库的分类及其详细内容 T1：通用威胁代码（分类），各种 ECU 可共享一套适用于各种实施方案的通用模式 C1.Hardware, C2.Software, C3.RTOS, C4.Complex OS, C5.Data T2：车内组件，描述了对车内特定组件的威胁 C6.IVI, C7.Telematics, C8.Sensor, C9.Gateway and Zone Controller, C10.ADAS, C11.IVN, C12.BMS, C13.Other ECUs T3：车外组件，描述了车外特定组件面临的威胁 C14.Mobile APP, C15.Backend Server, C16.Charging Pile T4：通信协议，描述了通信协议所面临的威胁 C17.UWB, NFC and BLE, C18.V2X, C19.CAN, C20.Ethernet T5：通信通道&#x2F;接口，描述了对车辆通信通道和接口的威 C21.Wi-Fi, Bluetooth and Cellular, C22.Charging Port, C23.USB and SD card, C24.OBD T6：车辆功能&#x2F;服务，描述了对车辆功能和服务的威胁 C25.OTA, C26.Diagnostic, C27.Remote monitor and control T7：其他，包括不属于其他主题的其他威胁（如内部攻击） C28.Others 为了更好地说明威胁代码（分类）之间的关系，将28个代码分为两类： 实体代码 Entity code（T2车内组件、T3车外组件） 属性代码 Property code（T1、T4、T5、T6、T7） 一个属性代码代表一个实体代码中的一个特定安全属性 构建知识图谱的三元组进一步表述为（实体代码、易受威胁处、属性代码） 在11个实体代码和17个属性代码之间构建了109个三元组 威胁代码之间的这些联系使用户能够了解汽车威胁之间的相互依赖关系，帮助他们构建特定于汽车模型的 CarVal Datalog 规则。 此外，用户可以灵活地根据不同的汽车实现修改和创建自己的关系。 CarVal — 自动化路径推理和风险评估 挑战 传统的攻击路径推理引擎依赖于 IT 网络中人工制作的推理规则，目前还没有可用于推理 IVN 攻击路径的规则 IVN 是由具有各种硬件和软件设置的 ECU 组成，以前的方法没有考虑到这些新特征，无法表示最新的 IVN 模型 以往的工作只讨论了如何计算攻击路径中特定攻击的可行性（即可能性），没有考虑 ISO21434 TARA 所指出的攻击影响，这导致在特定汽车系统中的输出不完整 解决方案 根据访谈，构建推理规则集并定义网络攻击 引入一个混合模型，将代表车载总线（如 CAN 总线）广播性质的总线模型与代表最新网关设计的星形模型相结合 除了攻击可行性，通过计算路径上每个节点的攻击影响来增强推理引擎 工作流程 输入 攻击目标，指定作为数据模型推理目标的特定攻击 攻击入口，描述攻击者如何访问汽车系统，攻击路径的起点 漏洞集，由可能导致特定攻击的潜在漏洞组成 车辆配置，如 IVN 拓扑结构、IVN 中电子控制单元 (ECU) 和总线的属性 攻击路径推理，在接收到上述输入后启动数据逻辑推理 确定攻击者如何从攻击入口实现攻击目标 推理过程的有效性取决于精心设计的推理规则 攻击路径节点类型 攻击节点（AN）—— 攻击目标 入口节点（ EN） —— 攻击入口 漏洞节点（VN）—— 漏洞集 事实节点（FN）—— 车辆配置 风险评估，在考虑 feasibility 和 impact 的基础上对生成的攻击路径进行评估风险值 计算攻击路径上所有 AN（代表特定威胁）的攻击可行性和攻击影响 相关定义 EN、VN、AN 的可行性（概率） AN 的累积可行性、影响和风险值 VN、AN 的影响 攻击可行性计算 攻击节点的累积路径攻击可行性是由其所有前提节点的可行性值相乘计算得出的 由于所有可行性值都在 (0,1) 范围内，随着攻击路径变深，累积攻击可行性会降低 攻击影响传播 一个 AN 的累积路径上攻击影响是其所有前提节点影响值的乘积 由于所有影响值都大于 1，因此累积攻击影响会随着攻击路径的深入而增加 风险值计算 汽车系统中与特定威胁相关的风险值的确定基于两个因素，即可行性和影响 可行性和影响越大，风险值也就越大 节点的最终风险值是可行性和影响相乘后加上基线值 每个推导出的攻击节点都会被赋予特定攻击路径上的累计攻击可行性、影响和风险值 演示示例 CarVal 的输出是 Attributed Attack Path (AAP) 既提供如何在 IVN 中实施攻击的逻辑流程 也提供了与路径上每个攻击节点相关的定量指标（feasibility, impact, and risk value） 具体实施 攻击路径推理（MulVAL reasoning framework + XSB database system） 风险评估（Python + treelib library） 实车实验 Sup_Materials Codebook.pdf（用于访谈研究数据分析的最终代码手册） Insights_and_Database.pdf（从访谈中得出的更多见解，以及包含119个威胁的数据库） Interview_protocol.pdf（用于访谈过程中的访谈方案） Security_Report.pdf（对应于论文中安全分析的安全报告） 运行环境开源代码：CarVal: Automated Attack Path Reasoning in IVN. CarVal_Code： carval_infer.sh（启动推断攻击路径的脚本） input_IVN.P（CarVal的输入，包括 IVN 和待推断的攻击目标） interaction_rules.P（CarVal 推理的所有交互规则） risk_assessment.py（此代码将对由 carval_infer.sh 生成的 AttackGraph.dot 执行风险评估） 配置运行环境： XSB （用于Unix和Windows的逻辑编程和推理数据库系统） Graphviz （一款开源图形可视化软件） MulVAL （基于逻辑的企业网络安全分析器） 123456789101112131415161718sudo apt update# 安装 Graphvizsudo apt install graphviz graphviz-doc# 安装 epstopdfsudo apt install texlive-font-utils# 安装 jdksudo apt install default-jdk # 安装 XSBtar -zxf XSB-5.0.tar.gzcd XSB/build./configure./makexsb# 添加环境变量sudo vim /etc/profile# sudo vim ~/.zshrc# 加入 export PATH=/home/hcjjj/Desktop/CarVal/XSB/bin:$PATHsource /etc/profile# source ~/.zshrc 1234567891011121314151617181920212223242526# 安装 MulVAL# 依赖sudo apt install flex bisongit clone https://github.com/risksense/mulval.gitcd mulval# 创建文件夹，不然：cp: target &#x27;../../bin/adapter&#x27; is not a directorymkdir bin bin/adapter bin/metrics# mv -&gt; cp，不然 fatal error: graphit.tab.h: No such file or directoryvim src/attack_graph/Makefile# 环境变量sudo vim /etc/profile# export MULVALROOT=/home/hcjjj/Desktop/CarVal/mulval# export PATH=$MULVALROOT/bin:$MULVALROOT/utils:$PATHsource /etc/profile# 编译 注意 gcc 的版本，太高会编译报错sudo apt purge --autoremove -y gcc-11 g++-11sudo vim /etc/apt/sources.list# deb [arch=amd64] http://archive.ubuntu.com/ubuntu focal main universesudo apt updatesudo apt install gcc-7 g++-7cd /usr/bin/sudo mv gcc-7 gccsudo mv g++-7 g++# 回到 mulval 目录cd -make 运行 testcases 代码： 123456cd mulval/testcases/3host# 生成攻击图chmod u+x graph_gen.shgraph_gen.sh input.P -v -p# 运行 CVSS 度量程序probAssess.sh 运行 CarVal 代码： Copy the CarVal code into the MulVal directory, including: Replace mulval/kb/interaction_rules.P with CarVal_Code/interaction_rules.P Copy all other codes under CarVal_Code (carval_infer.sh, input_IVN.P, risk_assessment.py) into mulval/utils/. Now CarVal is ready to run. Execute the following code under the mulval/utils: 12345# 添加可执行权限chmod u+x carval_infer.sh ./render.sh# carval_infer.sh 用到 render.sh 和 interaction_rules.P# 这边要改一下 ./carval_infer.sh 里面 xsb 的路径./carval_infer.sh -v ./input_IVN.P Then the output attack path will be generated as AttackGraph.dot in the same directory. Then execute the python script to further calculate the risk values along the attack path. 123sudo apt install python3 pippip install pydot networkx matplotlibpython3 risk_assessment.py 代码分析攻击路径推理 carval_infer.sh（启动推断攻击路径的脚本） input_IVN.P（CarVal 的输入，包括 IVN 和待推断的攻击目标） interaction_rules.P（CarVal 推理的所有交互规则） 风险评估 risk_assessment.py（此代码将对由 carval_infer.sh 生成的 AttackGraph.dot 执行风险评估） TARA 1.0 资产识别（定义） 威胁场景识别 威胁情景识别的方法可以使用小组讨论和&#x2F;或系统方法，例如： 诱发因合理的可预见的误用或滥用而产生的恶意用例 基于 EVITA、TVRA、PASTA、STRIDE 等框架的威胁建模方法 影响等级评估 应根据安全、财务、操作和隐私（S、F、O、P）等影响类别分别对道路使用者的潜在不利后果进行评估损害情景 损害情景的影响等级应按每个影响类别确定为以下之一：severe、major、moderate、negligible（严重、主要的、中等、可忽略不计） 攻击路径分析 应分析威胁情景，以确定攻击路径 一个攻击路径分析可以基于 自上而下的方法，通过分析威胁情景的不同方式来推断攻击路径。 可以实现，例如攻击树、攻击图 自下而上的方法，从确定的网络安全漏洞中建立攻击路径 如果部分攻击路径没有导致威胁情景的实现，可以停止对该部分攻击路径的分析 一个攻击路径应与该攻击路径可实现的威胁情景相关 在产品开发的早期阶段，攻击路径往往是不完整或不精确的，因为具体的实施细节还不知道，无法识别具体的漏洞 在产品开发过程中，随着更多信息的出现，例如在漏洞分析之后，攻击路径可以被更新 攻击可行性评估 攻击可行性评级方法应根据以下情况之一来定义办法 基于攻击潜力的方法 基于 CVSS 的方法 基于攻击向量的方法 选择方法可以取决于生命周期中的阶段和可用的信息 如果使用基于攻击潜力的方法，应根据核心因素确定攻击可行性等级，包括： 经过的时间、专家的专业知识、对该项目或组件的了解、机会之窗、设备 如果使用基于 CVSS 的方法，则应根据以下情况确定攻击可行性等级在基本度量组的可利用度量上，包括： 攻击矢量、攻击的复杂性、需要的特权、用户互动 如果使用基于攻击矢量的方法，应根据评估攻击路径的主要攻击矢量（参见 CVSS 2.1.1 ）来确定攻击可行性等级 风险值的确定 对于每个威胁情景，应根据相关损害情景的影响和相关攻击路径的攻击可行性来确定风险值 如果一个威胁情景对应一个以上的损害情景或一个相关的损害情景在一个以上的影响类别中具有影响， 可以为每个影响等级单独确定一个风险值 如果威胁情景与一个以上的攻击路径相对应，相关的攻击可行性评级可以适当地汇总，例如，威胁情景被赋予相应攻击路径的攻击可行性评级中的最大值。 威胁情景的风险值应在 1 和 5 之间（包括 1 和 5），其中 1 的值代表最小风险 风险值确定的方法：风险矩阵、风险公式 风险处理决策 对于每种威胁情况，考虑到其风险值，应确定以下一种或多种风险处理方案： 避开风险、减少风险、分担风险、保留风险 参考资料： ISO&#x2F;SAE 21434:2021 - Road vehicles Cybersecurity engineering A Systematic Review of Threat Analysis and Risk Assessment Methodologies for Connected and Automated Vehicles 七大执行步骤详解如何进行 TARA 分析","tags":["Automotive"],"categories":["Research"]},{"title":"Windows Subsystem for Linux (WSL) 🪟","path":"/2023/11/24/wsl/","content":"“适用于 Linux 的 Windows 子系统 （WSL） 可让开发人员直接在 Windows 上按原样运行 GNU&#x2F;Linux 环境，且不会产生传统虚拟机或双启动设置的开销。” 参考资料 WSL 官方文档 WSL-Guide Oh My Posh 配置终端 安装 nerd-fonts 安装 Terminal + PowerShell 添加 Terminal-Icons 安装 Oh My Posh 安装 Scoop A command-line installer for Windows. 12345678910111213# 安装 OhMyPoshwinget install JanDeDobbeleer.OhMyPosh# 写入配置notepad $PROFILE# oh-my-posh init pwsh --config &quot;$env:POSH_THEMES_PATH\\di4am0nd.omp.json&quot; | Invoke-Expression# Import-Module -Name Terminal-Icons# 安装 scoop - Windows 包管理器iwr -useb get.scoop.sh | iex# 安装多线程下载scoop install aria2# 安装 neofetchscoop install neofetch powerShell 支持多个配置文件并按照优先级加载。下面按照优先级顺序列出 Windows 下 PowerShell 配置文件的路径 所有用户、所有主机 $PSHOME\\Profile.ps1 所有用户，当前主机 $PSHOME\\Microsoft.PowerShell_profile.ps1 当前用户、所有主机 $Home\\Documents\\PowerShell\\Profile.ps1 当前用户，当前主机 $Home\\Documents\\PowerShell\\Microsoft.PowerShell_profile.ps1 安装 WSL开启功能 安装 Linux 123456789101112# 直接 Microsoft Store 中安装 或wsl --install -d Ubuntu# 运行报错，重启一下电脑Installing, this may take a few minutes...WslRegisterDistribution failed with error: 0x8004032dError: 0x8004032d (null)Press any key to continue...# 查看安装镜像列表wsl --list --verbose# 资源访问 # \\\\wsl.localhost\\Ubuntu# 即 C:\\Users\\hcjjj\\AppData\\Local\\Packages\\CanonicalGroupLimited.Ubuntu_79rhkp1fndgsc\\LocalState 配置 1234567891011# wsl: 检测到 localhost 代理配置，但未镜像到 WSL。NAT 模式下的 WSL 不支持 localhost 代理vim ~\\.wslconfig # ...[experimental]autoMemoryReclaim=gradual networkingMode=mirroreddnsTunneling=truefirewall=trueautoProxy=true# ...wsl --shutdown 1234567891011121314151617181920212223242526272829303132# 修改镜像源 sudo vim /etc/apt/sources.list# https://mirrors.tuna.tsinghua.edu.cn/help/ubuntu/sudo apt update &amp;&amp; sudo apt upgrade# zshsudo apt install zsh curl -ysh -c &quot;$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)&quot;git clone https://github.com/zsh-users/zsh-autosuggestions $&#123;ZSH_CUSTOM:-~/.oh-my-zsh/custom&#125;/plugins/zsh-autosuggestionsgit clone https://github.com/zsh-users/zsh-syntax-highlighting.git $&#123;ZSH_CUSTOM:-~/.oh-my-zsh/custom&#125;/plugins/zsh-syntax-highlightingvim ~/.zshrc# ...plugins=( git zsh-autosuggestions zsh-syntax-highlighting)# ...source ~/.zshrc# 设置默认shellchsh -s `which zsh`# Vim 配置# 插件管理：https://github.com/junegunn/vim-plugnvim ~/.config/nvim/init.vim# ssh 服务sudo apt install openssh-serversudo service ssh startsudo apt install net-toolsifconfig 迁移 WSL1234567891011121314151617181920212223242526# 导出当前发行版hcjjj@laptop ~ wsl --shutdownhcjjj@laptop ~ wsl -l -v NAME STATE VERSION* Ubuntu Stopped 2 docker-desktop Stopped 2hcjjj@laptop ~ wsl --export Ubuntu D:\\WSL\\ubuntu24正在导出，这可能需要几分钟时间。操作成功完成。# 注销并卸载当前发行版hcjjj@laptop ~ wsl --unregister Ubuntu正在注销。操作成功完成。# 导入到 D 盘的新位置hcjjj@laptop ~ cd D:\\WSLhcjjj@laptop ~ ls Directory: D:\\WSLMode LastWriteTime Length Name---- ------------- ------ ----d---- 2024/11/12 21:28  Ubuntu-a--- 2024/11/12 21:20 2056519680  ubuntu24hcjjj@laptop ~ wsl --import ubuntu D:\\WSL\\Ubuntu .\\ubuntu24正在导入，这可能需要几分钟时间。操作成功完成。# 启动新的 WSL 实例hcjjj@laptop ~ wsl -d ubuntu","tags":["wsl"],"categories":["Linux"]},{"title":"Go 底层原理与源码初探 👾","path":"/2023/11/22/go2/","content":"学习 Go 的底层原理 参考资料 《Go 语言设计与实现》 《Go 语言高级编程》 《深入解析 Go》 重新认识 Go C&#x2F;C++ C 语言不是面向对象 直接编译为机器码，不需要执行环境 一次编码只能适用一种平台（不同平台源代码不一样） 需要自己处理垃圾回收（GC）问题 Java 编译为中间码（字节码） 需要特定执行环境（JVM） 一次编译多处执行 有虚拟化损失 JavaScript 不需要编译，直接解释执行 需要执行环境（浏览器） 有虚拟化损失 Go 直接编译为二进制，没有虚拟化损失 自带运行环境，无需处理 GC 问题 一次编码可以适用多种平台（不同平台源代码一样） 超强的并发支持能力与并发易用性 一次编码 一次编译 不需要运行环境 没有虚拟化损失 不需要自行处理GC 面向对象 非常易用的并发能力 C ❌ ✔️ ✔️ ✔️ ❌ ❌ ❌ C++ ❌ ✔️ ✔️ ✔️ ❌ ✔️ ❌ Java ✔️ ❌ ❌ ❌ ✔️ ✔️ ❌ JavaScript ✔️ ⭕ ❌ ❌ ✔️ ✔️ ❌ Go ✔️ ❌ ❌ ✔️ ✔️ ✔️ ✔️ 什么是 Runtime Runtime 就是程序的运行环境 Java：JVM JavaScript：浏览器内核 Go 的 Runtime Go 没有虚拟机的概念 Runtime 作为程序的一部分打包进二进制产物 Runtime 随用户程序一起运行 Runtime 与用户程序没有明显界限，直接通过函数调用 Go Runtime 的能力 内存管理能力 垃圾回收能力 超强的并发能力（协程调度） Runtime 有一定的屏蔽系统调用能力（跨平台） 一些 go 的关键字其实是 Runtime 下的函数 关键字 函数 go newproc new newobject make makeslice, makechain, makemap … &lt;- chansend1, chanrecv1 Go 程序是如何编译的？ go build -n 查看编译过程信息 词法分析 → 句法分析 → 语义分析 → 中间码生成（平台无关的） → 代码优化 → 机器码生成→ 链接 → 可执行文件 查看生成的中间码 SSA（平台无关） GO SSA FUNC $env:GOSSAFUNC=&quot;main&quot; 或 export GOSSAFUNC=main go build 查看生成的 Plan9 汇编代码（平台相关） go build -gcflags -S main.go 链接：将各个包（.a 文件）进行链接，包括 runtime，生成可执行文件 Go 程序是如何运行的？ Go 程序的入口不是 main 方法，是 runtime/rt0_xxx_xxx.s 汇编文件中的方法 读取命令行参数 初始化 g0 执行栈 运行时检测 参数初始化 runtime.args 调度器初始化 runtime.schedinit 创建主协程 主协程执行主函数 runtime.main Go 启动时经历了检查、各种初始化、初始化协程调度的过程 main.main() 也是在协程中运行 Go 程序的启动过程像不像一个虚拟机，或者框架 ? Go 是面向对象语言吗？Yes and No Go 允许 OO 的编程风格 Go 的 struct 可以看作其他语言的 class Go 缺乏其他语言的继承结构，所谓“继承”是组合 组合中的匿名字段，通过语法糖达成了类似继承的效果 struct 的每个实例并不是“对象”，而是此类型的“值” struct 并不显式实现接口，而是隐式实现 Go Modules 本质上，一个 Go 包就是一个项目的源码 gomod 的作用就是将 Go 包和 Git 项目关联起来 Go 包的版本就是 git 项目的 Tag gomod 就是解决“需要哪个 git 项目的什么版本” 无法连接远程仓库时，使用重定向或者mod vender方案 数据结构字符串 基本类型的字节数 int 大小跟随系统字长 指针的大小也是系统字长 空结构体 空结构体的地址均相同（不被包含在其他结构体中时） 空结构体主要是为了节约内存 map 不要值的时候，实现 hashset ChanneI 不需要携带信息的时候，纯信号 字符串 1234567891011// src/runtime/string.gotype stringStruct struct &#123;\tstr unsafe.Pointer\tlen int&#125;// src/reflect/value.gotype StringHeader struct &#123;\tData uintptr\tLen int&#125; 字符串本质是个结构体 Data 指针指向底层 Byte 数组 Len 表示 Byte 数组的长度而不是字符个数（Unicode 编码 Unicode 是一种统一的字符集 囊括了159种文字的144679个字符 14万个字符至少需要3个字节表示 英文字母均排在前128个 UTF-8 Unicode 的一种变长格式 128个 US-ASCII 字符只需一个字节编码 西方常用字符需要两个字节 其他字符需要3个字节，极少需要4个字节 字符串的访问 对字符串使用 len 方法得到的是字节数不是字符数 对字符串直接使用下标访问，得到的是字节 字符串被 range 遍历时，被解码成 rune 类型的字符 UTF-8 编码解码算法位于 runtime&#x2F;utf8.go 字符串的切分 转为rune数组 切片 转为 string s = string([]rune(s)[:3]) 字符串与切片都是对底层数组的引用 切片 切片 123456// runtime/slice.gotype slice struct &#123;\tarray unsafe.Pointer\tlen int\tcap int&#125; 切片是对数组的引用 切片的创建 根据数组创建：arr[0:3] or slice[0:3] 字面量，编译时插入创建数组的代码：slice :&#x3D; []int{1, 2, 3} make，运行时创建数组：slice :&#x3D; make([]int, 10) 切片的访问 下标直接访问元素 range 遍历元素 len(slice) 查看切片长度 切片的追加 不扩容时，只调整 len（编译器负责） 扩容时，编译时转为调用 runtime.growslice() （开一个新数组） 如果期望容量大于当前容量的两倍就会使用期望容量 如果当前切片的长度小于 1024，将容量翻倍 如果当前切片的长度大于1024，每次增加 25% 切片扩容时，并发不安全，注意切片并发要加锁 总结 字符串与切片都是对底层数组的引用 字符串有 UTF-8 变长编码的特点 切片的容量和长度不同 切片追加时可能需要重建底层数组 map HashMap 的基本方案 开放寻址法（碰撞横向移动） 拉链法（碰撞纵向移动） Go 的 map 1234567891011121314151617// runtime/map.go// A header for a Go map.type hmap struct &#123;\t// Note: the format of the hmap is also encoded in cmd/compile/internal/reflectdata/reflect.go.\t// Make sure this stays in sync with the compiler&#x27;s definition.\tcount int // # live cells == size of map. Must be first (used by len() builtin)\tflags uint8\tB uint8 // log_2 of # of buckets (can hold up to loadFactor * 2^B items)\tnoverflow uint16 // approximate number of overflow buckets; see incrnoverflow for details\thash0 uint32 // hash seed\tbuckets unsafe.Pointer // array of 2^B Buckets. may be nil if count==0.\toldbuckets unsafe.Pointer // previous bucket array of half the size, non-nil only when growing\tnevacuate uintptr // progress counter for evacuation (buckets less than this have been evacuated)\textra *mapextra // optional fields&#125; map 的初始化 m :&#x3D; make(map[string]int, 10) 字面量方式，实际是先 make 再赋值 Go 语言使用拉链实现了 hashmap 每一个桶中存储键哈希的前8位 桶超出8个数据，就会存储到溢出桶中 map 为什么需要扩容？ 哈希碰撞，溢出桶太多时会导致严重的性能下降 runtime.mapassign() 可能会触发扩容的情况： 装载因子超过6.5（平均每个槽6.5个key） 使用了太多溢出桶（溢出桶超过了普通桶） mao 扩容的类型 等量扩容：数据不多但是溢出桶太多了（就是整理） 翻倍扩容：数据太多了 map 扩容 步骤 Ⅰ 创建一组新桶 oldbuckets 指向原有的桶数组 buckets 指向新的桶数组 map标记为扩容状态 步骤 Ⅱ 将所有的数据从旧桶驱逐到新桶 采用渐进式驱逐 每次操作一个旧桶时，将旧桶数据驱逐到新桶 读取时不进行驱逐，只判断读取新桶还是旧桶 步骤 Ⅲ 所有的旧桶驱逐完成后，oldbuckets 回收 总结 装载系数或者溢出桶的增加，会触发 map 扩容 “扩容”可能并不是增加桶数，而是整理 map 扩容采用渐进式，桶被操作时才会重新分配 怎么解决 map 的并发问题？ map 的并发问题 map的读写有并发问题 A 协程在桶中读数据时，B 协程驱逐了这个桶 A 协程会读到错误的数据或者找不到数据 map 并发问题解决方案 给 map 加锁（mutex） 使用 sync.Map “读写” 与 “追加” 分离，避免扩容时候的并发问题 sync.Map 使用了两个map，分离了扩容问题 不加锁：不会引发扩容的操作（查、改）使用 read map 加锁：可能引发扩容的操作（新增）使用 dirty map 接口：隐式更好还是显式更好？ Go 隐式接口特点 只要实现了接口的全部方法，就是自动实现接口 可以在不修改代码的情况下抽象出新的接口 接口值的底层表示 接口数据使用 runtime.iface 结构体表示 iface 记录了数据的地址 iface 也记录了接口类型信息和实现的方法 类型断言（类型转换） 类型断言是一个使用在接口值上的操作 可以将接口值转换为其他类型值 （实现或者兼容接口） 可以配合 switch 进行类型判断 结构体和指针实现接口 结构体实现接口 —— 结构体初始化变量&#x2F;结构体指针初始化变量 结构体指针实现接口 —— 只能结构体指针初始化变量 空接口值 空接口底层不是普通接口，是 runtime.eface 结构体 空接口值可以承载任何数据 空接口的用途 空接口的最大用途是作为任意类型的函数入参 函数调用时，会新生成一个空接口，再传参 nil，空接口，空结构体有什么区别？ nil nil 是空，并不一定是“空指针” builtin&#x2F;builtin.go Type must be a pointer, channel, func, interface, map, or slice type nil 是6种类型的“零值” 每种类型的 nil 是不同的，无法比较 空结构体 空结构体是 Go 中非常特殊的类型 空结构体的值不是 nil 空结构体的指针也不是 nil，但是都相同（zerobase） 空接口 它是 runtime.eface 结构体 空接口不一定是 nil 接口 两个属性都 nil 才是 nil 接口 内存对齐 非内存对齐：内存的原子性与效率受到影响 内存对齐：提高内存操作效率，有利于内存原子性 对齐系数 unsafet.Alignof() 对产系数的含义是：变量的内存地址必须被对齐系数整除 如果对齐系数为4，表示变量内存地址必须是4的倍数 结构体对齐 结构体对齐分为内部对齐和外部填充对齐（结构体长度填充） 内部对齐 指的是结构体内部成员的相对位置（偏移量） 每个成员的偏移量是自身大小与其对齐系数较小值的倍数 结构体的内存地址顺序是严格按照内部成员的定义顺序 结构体长度填充 指的是结构体通过增加长度，对齐系统字长 结构体长度是最大成员长度与系统字长较小的整数倍 可以尝试通过调整成员顺序，节约空间 结构体对齐系数 为什么string的大小是16，对齐系数是8？ string 底层是一个结构体，包含两个成员（指针的长度是8，int的长度在64位机器也是8，那么其长度就是16） 结构体的对齐系数是其成员的最大对齐系数 空结构体的对齐 空结构体单独出现时，地址为 zerobase 空结构体出现在结构体中时，地址跟随前一个变量 空结构体出现在结构体末尾时，需要补齐字长 Goroutine 协程 为什么要有协程，线程不好用吗？ 进程 进程用来占用内存空间 进程相当于厂房，占用工厂空间 线程 每个进程可以有多个线程 线程使用系统分配给进程的内存，线程之间共享内存 线程用来占用CPU时间 线程的调度需要由系统进行 线程相当于厂房中的生产线，占用工人的工时 线程本身占用资源大，线程的操作开销大，切换开销大（CPU） 协程 协程就是将一段程序的运行状态打包，可以在线程之间调度 将生产流程打包，使得流程不固定在生产线上 协程并不取代线程，协程也要在线程上运行 协程使用线程的资源，精细利用线程 资源利用，快速调度，超高并发 协程的本质是什么？ runtime 中，协程的本质是一个 g 结构体 stack：堆栈地址 gobuf：目前程序运行现场 atomicstatus：协程状态 runtime 中将操作系统线程抽象为 m 结构体 g0：g0 协程，操作调度器 curg：current g，目前线程运行的 g mOS：操作系统线程信息 协程如何在线程上运行 单线程循环（Go 0.x） 多线程循环（Go 1.0） schedule() → execute() 从 runable queue 中取协程 → gogo() → 业务方法 → goexit() → schedule() 操作系统并不知道 Goroutine 的存在 操作系统线程执行一个调度循环，顺序执行 Goroutine调度循环非常像线程池 问题一：协程顺序执行，无法并发 问题二：多线程并发时，会抢夺协程队列的全局锁 G-M-P 调度模型 协程 g 结构体，线程 m 结构体，“送料器”（M 与 G 的中介） p 结构体 P 持有一些 G（本地队列），使得每次获取 G 的时候不用从全局找 大大减少了并发冲突的情况（解决问题二） 窃取式工作分配机制 如果在本地或者全局队列中都找不到 G 去别的 P 中“偷” 增强了线程的用率 新建协程 func newproc() 随机寻找一个 P 将新协程放入 P 的 runnext（插队） 若 P 本地队列满，放入全局队列 解决协程饥饿问题（问题一） 如果协程顺序执行，会有饥饿问题 基于系统调用和主动挂起 协程执行中间，将协程挂起，执行其他协程 切换时机 主动挂起（runtime.gopark） 系统调用完成时 防止全局队列饥饿，本地队列随机抽取全局队列 如果永远都不主动挂起，永远都不系统调用怎么办？ 基于协作的抢占式调度（需要协程有方法调用） 业务主动调用 runtime.morestack() morestack 的本意是检查协程栈是否有足够空间 调用方法时，会被编译器插入morestack() 标记抢占 统监控到 Goroutine 运行超过 10ms 将 g.stackguard0 置为 0xfffffade 抢占 执行 morestack() 时判断是否被抢占 如果被抢占，回到 schedule() 基于信号的抢占式调度 线程信号 操作系统中，有很多基于信号的底层通信方式 比如 SIGPIPE&#x2F;SIGURG&#x2F;SIGHUP 线程可以注册对应信号的处理函数 注册 SIGURG 信号的处理函数 强制线程调用 doSigPreempt() GC 工作时，向目标线程发送信号 线程收到信号，触发调度 协程太多会出现什么问题？ 资源限制 文件打开数限制 内存限制 调度开销过大 处理协程太多的方案 优化业务逻辑 利用 ChanneI 的缓存区 利用 ChanneI 的缓存机制 启动协程前，向 ChanneI 送入一个空结构体 协程结束，取出一个空结构体 协程池（tunny） 预创建一定数量的协程 将任务送入协程池队列 协程池不断取出可用协程，执行任务 慎用协程池 Go 语言的线程，已经相当于池化了 二级池化会增加系统复杂度 Go语言的初衷是希望协程即用即毁，不要池化 调整系统资源 锁 🔒 atomic 操作（sync&#x2F;atomic） 原子操作是一种硬件层面加锁的机制 保证操作一个变量的时候，其他协程&#x2F;线程无法访问 只能用于简单变量的简单操作 sema 锁（不对用户开放使用） 也叫信号量锁&#x2F;信号锁（semaphore） 核心是一个 uint32 值，含义是同时可并发的数量 每一个 sema 锁都对应一个 SemaRoot 结构体 SemaRoot 中有一个平衡二叉树用于协程排队 sema 操作（uint32 &gt; 0） 获取锁：uint32 减一，获取成功 释放锁：uint32 加一，释放成功 sema 操作（uint32 &#x3D;&#x3D; 0） 获取锁：协程休眠，进入堆树等待 释放锁：从堆树中取出一个协程，唤醒 sema 锁退化成一个专用休眠队列 sync.Mutex 互斥锁 Go 的互斥锁 Go 中用于并发保护最常见方案 正常模式 加锁 尝试 CAS（compare and swap，借用了CPU提供的原子性指令现） 直接加锁 若无法直接获取，进行多次自旋尝试 多次尝试失败，进入 sema 队列休眠 正常模式 解锁 尝试 CAS 直接解锁 若发现有协程在 sema 中休眠，唤醒一个协程 mutex 正常模式下，可能有锁饥饿问题（某个协程长时间获取不到锁，无法执行其业务） Mutex 饥饿模式 当前协程等待锁的时间超过了 10ms，切换到饥饿模式 饥饿模式中，不自旋，新来的协程直接 sema 休眠 饥饿模式中，被唤醒的协程直获取锁（不需要和别的协程竞争） 没有协程在队列中继续等待时，回到正常模式 互斥锁使用经验 减少锁的使用时间 善用 defer 确保锁的释放 多个协程同时只读 只读时，让其他人不能修改即可 只读时，多协程可以共享读 只读时，不需要互斥锁 读写锁需求（读锁是共享的，写锁是独占的） 每个锁分为读锁和写锁，写锁互斥 没有加写锁时，多个协程都可以加读锁 加了写锁时，无法加读锁，读协程排队等待 加了读锁，写锁排队等待 sync.RWMutex 读写锁 w：互斥锁作为获取加写锁的资格 writerSem：作为写协程队列 readerSem：作为读协程队列 readerCount：正值表示正在读或想读的协程数（读锁），负值表示加了写锁 readerWait：写锁应该等待读协程的个数 加写锁 先加 mutex 锁，若已经被加写锁会阻塞等待 将 readerCount 变为负值，阻塞读锁的获取 计算需要等待多少个读协程释放 如果需要等待读协程释放，陷入 writerSem 解写锁 将readerCount变为正值，允许读锁的获取 释放在 readerSem 中等待的读协程 解锁 mutex 加读锁 readerCount + 1 若 readerCount &gt; 0 加锁成功 若 readerCount &lt; 0 说明被加了写锁，陷入 readerSem 解读锁 readerCount - 1 若 readerCount &gt; 0 解锁成功 若 readerCount &lt; 0 ，有写锁在排队，如果自己是 readerwait 的最后一个，唤醒写协程 使用经验 RW 锁适合读多写少的场景，减少锁冲突 如何通过 WaitGroup 互相等待？ 实际业务中，一个（组）协程需要等待另一组协程完成 Wait() 如果被等待的协程没了，直接返回 否则，waiter 加一，陷入 sema Done() 被等待协程做完，给 counter 减一 通过 Add(-1) 实现 Add() 被等待协程没做完，或者没人在等待，返回 被等待协程都做完，且有人在等待，唤醒所有 sema 中的协程 WaitGroup 实现了一组协程等待另一组协程 等待的协程陷入 sema 并记录个数 被等待的协程计数归零时，唤醒所有 sema 中的协程 一段代码只能执行一次，怎么实现？ 思路1：Atomic 做法：CAS改值，成功就做 优点：算法非常简单 问题：多个协程竞争 CAS 改值会造成性能问题 思路2：Mutex 争抢一个 mutex，抢不到的陷入 sema 休眠 抢到的执行代码，改值，释放锁 其他协程唤醒后判断值已经修改，直接返回 sync.Once（采用思路2） 先判断是否已经改值 没改，尝试获取锁 获取到锁的协程执行业务，改值，解锁 冲突协程唤醒后直接返回 如何排查锁异常问题 锁拷贝问题 锁拷贝可能导致锁的死锁问题 使用 vet 工具可以检测锁拷贝问题 vet 还能检测可能的 bug 或者可疑的构造 go vet main.go RACE 竞争检测 多个协程同时对一个变量进行修改，可能会导致修改操作的丢失 发现隐含的数据竞争问题 可能是加锁的建议 可能是 bug 的提醒 go build -race main.go ./main go-deadlock 检测 go-deadlock 第三方包 检测可能的死锁 实际是检测获取锁的等待时间 用来排查 bug 和性能问题 ChanneI 管道 ChanneI 声明方法 make(chan int) &#x2F;&#x2F;无缓冲 make(chan bool, 0) &#x2F;&#x2F;无缓冲 make(chan string, 2) &#x2F;&#x2F;有缓冲 ChanneI 基本用法 ch &lt;- × &#x2F;&#x2F;发送数据 × = &lt;- ch &#x2F;&#x2F;接收数据，赋给 × &lt;- ch &#x2F;&#x2F;接收数据，并丢弃 内存与通信 “不要通过共享内存的方式进行通信，而是应该通过通信的方式共享内存” 1234567891011121314151617// 通过共享内存的方式进行通信func watch(i *int) &#123;\tfor true &#123; if *i == 1 &#123; fmt.Printf(&quot;bye&quot;) break &#125;\t&#125;&#125;func main() &#123;\ti := 0\tgo watch(&amp;i)\ttime.Sleep(time.Second)\ti = 1\ttime.Sleep(time.Second)&#125; 1234567891011121314// 通过通信的方式共享内存func watch(c chan int) &#123;\tif &lt;-c == 1 &#123; fmt.Println(&quot;bye&quot;)\t&#125;&#125;func main() &#123;\tc := make(chan int)\tgo watch(c)\ttime.Sleep(time.Second)\tc &lt;- 1\ttime.Sleep(time.Second)&#125; 为什么使用通信来共享内存 避免协程竞争和数据冲突的问题 更高级的抽象，降低开发难度，增加程序可读性 模块之间更容易解耦，增强扩展性和可维护性 ChanneI 的设计 环形缓存区可以大幅降低 GC 的开销 发送&#x2F;接收队列 互斥锁 互斥锁并不是排队发送&#x2F;接收数据 互斥锁保护 hchan 结构体（runtime&#x2F;chan.go）本身 ChanneI 并不是无锁的 状态值 ChanneI 是 go 的一等公民 运用 ChanneI 是如何发送数据的 c &lt;- 关键字是一个语法糖 编译阶段，会把 c &lt;- 转化为 runtime.chansend1() chansend1() 会调用 chansend() 方法 ChanneI 发送的情形 直接发送 发送数据前，已经有协程 G 在休眠等待接收 此时缓存肯定是空的，不用考虑缓存 将数据直接拷贝给等待接收的 G，唤醒 G 放入缓存 没有 G 在休眠等待，但是有缓存空间 将数据放入缓存（获取可存入的缓存地址，存入数据，维护索引） 休眠等待 没有 G 在休眠等待，而且没有缓存或满了 自己进入发送队列，休眠等待 把自己包装成 sudog, sudog 放入 sendq 队列 休眠并解锁 被唤醒后，数据已经被取走，维护其他数据 运用 ChanneI 是如何接收数据的 &lt;- c 关键字也是一个语法糖 编译阶段， i &lt;- c转化为 runtime.chanrecv1() 编译阶段，i, ok &lt;- c 转化为 runtime.chanrecv2() 最后会调用 chanrecv() 方法 ChanneI 接收的情形 有等待的 G，从 G 接收 接收数据前，已经有 G 在休眠等待发送 而且这个 ChanneI 没有缓存 将数据直接从 G 拷贝过来，唤醒 G 有等待的 G，从缓存接收 接收数据前，已经有 G 在休眠等待发送 而且这个 ChanneI 有缓存 从缓存取走一个数据将休眠G的数据放进缓存，唤醒 G 将休眠 G 的数据放进缓存，唤醒 G 接收缓存 没有 G 在休眠等待发送，但是缓存有内容 直接从缓存取走数据 阻塞接收 没有 G 在休眠等待，而且没有缓存或缓存空 自己进入接收队列，休眠等待 非阻塞的 Channel 怎么做？ select select 原理 同时存在接收、发送、默认路径 首先查看是否有可以即时执行的 case 没有的话，有 default，走 default 没有default，把自己注册在所有的 channel 中，休眠等待 timer (time.NewTimer) TCP 网络编程 Socket 系统提供了 Socket 作为 TCP 网络连接的抽象 如：Linux -&gt; lnternet domain socket -&gt; SOCK STREAM Linux 中 Socket 以“文件描述符” FD 作为标识 IO 模型 IO 模型指的是同时操作 Socket 的方案 阻塞 IO（一个连接对应一个线程） 同步读写 Socket 时，线程陷入内核态 当读写成功后，切换回用户态，继续执行 优点：开发难度小，代码简单 缺点：内核态切换开销大，性能差 非阻塞 IO（一个线程轮询） 如果暂时无法收发数据，会返回错误 应用会不断轮询，直到 Socket 可以读写 优点：不会陷入内核态，自由度高 缺点：需要自旋轮询 多路复用（事件池） 注册多个 Socket 事件 调用 epoll，当有事件发生，返回 优点：提供了事件列表，不需要查询各个 Scoket，性能好 缺点：开发难度大，逻辑复杂 Linux: epoll，Mac: kqueue，Windows: IOCP Go 是如何抽象 Epoll 的？ 在底层使用操作系统的多路复用 IO 在协程层次使用阻塞模型，阻塞协程时，休眠协程 多路复用抽象层 为了统一各个操作系统对多路复用器的实现 Linux: epoll，Mac: kqueue，Windows: IOCP 多路复用器 新建多路复用器 epoll_create() 往多路复用器里插入需要监听的事件 epoll_ctl() 查询发生了什么事件 epoll_wait() netpoll.go netpoll_epoll.go netpoll_kqueue.go netpoll_windows.go … Go Network PoIIer 是对不同操作系统多路复用器的抽象 将 epoll_create() 抽象为 netpollinit() 将 epoll_ctl() 抽象为 netpollopen() 将 epoll_wait() 抽象为 netpoll() 返回的不是事件，而是返回等待事件的协程列表 Go Network PoIIer 是如何工作的？ NetworkPoIIer 初始化 poll_runtime_pollServerlnit() 使用原子操作保证只初始化一次 调用 netpollinit() pollcache 与 pollDesc pollcache：一个带锁的链表头 pollDesc：链表的成员 poIlDesc 是 runtime 包对 Socket 的详细描述 其中的 rg，wg：1，或 2，或等待的协程 G 地址 Network PoIIer 新增监听 Socket poll_runtime_pollOpen() 在 pollcache 链表中分配一个 pollDesc 初始化 pollDesc（rg wg为0） 调用 netpollopen()（屏蔽了不同 OS 的底层调用） NetworkPoIIer 收发数据 收发数据分为两个场景 协程需要收发数据时，Socket 已经可读写 runtime 循环调用 netpoll() 方法（g0协程） 发现 Socket 可读写时，给对应的 rg 或者 wg 置为 pdReady(1） 协程调用 poll_runtimepollWait() 判断 rg 或者 wg 已经置为 pdReady(1)，返回 0 协程需要收发数据时，Socket 暂时无法读写 runtime 循环调用 netpoll() 方法（g0协程） 协程调用 poll_runtimepollWait() 发现对应的 rg 或者 wg 为 0 给对应的 rg 或者 wg 置为协程地址 休眠等待 runtime 循环调用 netpoll() 方法（g0协程） 发现 Socket 可读写时，查看对应的 rg 或者 wg 若为协程地址，返回协程地址 调度器开始调度对应协程 NetworkPoIIer 是 Runtime 的强大工具 抽象了多路复用器的操作 NetworkPoller 可以自动监测多个 Socket 状态 在 Socket 状态可用时，快速返回成功 在 Socket 状态不可用时，休眠等待 Go是如何抽象Socket的？ net 包 net 包是 go 原生的网络包 net 包实现了 TCP、UDP、HTTP 等网络操作 net.Listen() 新建 Socket 并执行 bind 操作 新建一个 FD（net包对Socket的详情描述） 返回一个 TCPListener 对象 将 TCPListener 的 FD 信息加入监听 TCPListener 对象本质上是一个 LISTEN 状态的 Socket TCPListener.Accept() 直接调用 Socket 的 accept() 如果失败，休眠等待新的连接 将新的 Socket 包装为 TCPConn 变量返回 将 TCPConn 的 FD 信息加入监听 TCPConn 本质上是一个 ESTABLISHED 状态的 Socket TCPConn.Read() &#x2F; Write() 直接调用 Socket 原生读写方法 如果失败，休眠等待可读&#x2F;可写 被唤醒后调用系统 Socket net 包抽象了 TCP 网络操作 使用 net.Listen() 得到 TCPListener（LISTEN状态的Socket） 使用 TCPListener.Accept() 得到TCPConn（ESTABLISHED） TCPConn.Read() &#x2F; Write() 进行读写 Socket 的操作 NetworkPoller 作为上述功能的底层支撑 goroutine-per-connection 编程风格 用主协程监听 Listener 每个 Conn 使用一个新协程处理 结合了多路复用的性能和阻塞模型的简洁 内存模型与 GC Go 协程栈的作用 记录协程的执行路径 记录局部变量 记录函数传参 Go 使用参数拷贝传递（值传递） 传递结构体时会拷贝结构体中的全部内容 传递结构体指针时会拷贝结构体指针 记录函数返回值 Go 协程栈的位置 Go 协程栈位于 Go 堆内存上（从堆上申请的） Go 堆内存位于操作系统虚拟内存上 逃逸分析（从栈跑到堆） 不是所有的变量都能放在协程栈上，如： 栈帧回收后，需要继续使用的变量 太大的变量 触发情形 指针逃逸（函数返回了对象的指针） 空接口逃逸 如果函数参数为 interface{} 函数的实参很可能会逃逸 因为 interface{} 类型的函数往往会使用反射（需要对象在栈上） 大变量逃逸 过大的变量会导致栈空间不足 64位机器中，一般超过 64KB 的变量会逃逸 栈扩容（汇编实现的）— 解决栈帧过多的问题 Go 栈的初始空间为 2KB 在函数调用前判断栈空间是否足够（morestack） 必要时对栈进行扩容 早期使用分段栈 1.13 之前使用 优点：没有空间浪费 缺点：栈指针会在不连续的空间跳转 后期使用连续栈 优点：同一个协程的栈空间一直连续 缺点：伸缩时的开销大 当空间不足时扩容，变为原来的 2 倍 当空间使用率不足 1&#x2F;4 时缩容，变为原来的 1&#x2F;2 Go 的堆内存结构 操作系统虚拟内存 指的是操作系统给应用提供的虚拟内存空间 背后是物理内存，也有可能有磁盘 Linux 获取虚拟内存：mmap、madvice 系统调用 内存单元 heapArena Go 每次申请的虚拟内存单元 heapArena 为 64MB 最多有 4,194,304 个虚拟内存单元（$2^{20}$，256 TB） 所有的 heapArena 组成了 mheap（Go 堆内存） heapArena 使用方案 线性分配或者链表分配容易出现空间碎片 分级分配 内存管理单元 mspan runtime&#x2F;sizeclasses.go, mheap.go 根据隔离适应策略，使用内存时的最小单位为 mspan 每个 mspan 为 N 个相同大小的 “格子” Go 中一共有 67 种 mspan 中心索引 mcentral runtime&#x2F;mcentral.go 136 个 mcentral 结构体 其中 68 个组需要 GC 扫描的 mspan 68 个组不需要 GC 扫描的 mspan mcentral 的性能问题 mcentral 实际是中心索引，使用互斥锁保护 在高并发场景下，锁冲突问题严重 参考协程 GMP 模型，增加线程本地缓存 线程缓存 mcache（大大减少了 mcentral 高并发加锁的情况） 每个 P 有一个mcache 一个mcache，拥有136个mspan，其中 68 个需要 GC 扫描的 mspan 68 个不需要 GC 扫描的 mspan Go 分配堆内存方案 对象分级 Tiny 微对象 (0，16B) 无指针 SmalI 小对象 [16B, 32KB] Large 大对象 (32KB, +∞) 微对象分配 从 mcache 拿到 2 级 mspan 将多个微对象合并成一个 16Byte 存入 mcache 的替换 mcache 中，每个级别的 mspan 只有一个 当 mpan 满了之后，会从 mcentral 中换一个新的 mcentral 的扩容 mcentral 中，只有有限数量的 mspan 当 mspan 缺少时，会从 heapArena 开辟新的 mspan 大对象分配 直接从 heapArena 开辟 0 级的 mspan 0 级的 mspan 为大对象定制 垃圾回收（Garbage CoIIecting） 思路 ”标记 — 清除“ ，会有碎片 “标记 — 整理” ，整理开销大 “标记 — 复制” ，空间消耗大 Go 因为堆内存结构的独特优势，选择最简单的 “标记 — 清除” GC 的起点 GCRoot 被栈上的指针引用 被全局变量指针引用 被寄存器中的指针引用 上述变量被称为 RootSet Root 节点进行广度优先搜索 BFS，可达性分析标记法 找到有引用的对象，剩下的就是没有引用的，标记有用的 串行 GC 步骤（Go 老版本） Stop The WorId，暂停所有其他协程 通过可达性分析，找到无用的堆内存 释放堆内存，恢复所有其他协程 STW 对性能影响很大 并发垃圾回收 三色标记法 BFS 黑色：有用，已经分析扫描 灰色：有用，还未分析扫描 白色：不可达，暂时无用（需要清除的对象） 并发标记问题（删除） Yuasa 删除屏障 并发标记时，对指针释放的白色对象置灰 删除屏障可以杜绝在 GC 标记中被释放的指针，被清理 并发标记问题（插入） Dijkstra 插入屏障 并发标记时，对插入的白色对象置灰 插入屏障可以杜绝在 GC 标记中被插入的指针，被清理 混合屏障 （Go 的 GC） 被删除的堆对象标记为灰色 被添加的堆对象标记为灰色 并发垃圾回收的关键在于标记安全 混合屏障机制兼顾了安全与效率 GC 触发的时机 系统定时触发 sysmon 定时检查 如果 2 分钟内没有过 GC，触发 谨慎调整 用户显式触发 用户调用 runtime.GC 方法 并不推荐调用 申请内存时触发 给对象申请堆空间时，可能导致 GC GC 优化原则 — 尽量少在堆上产生垃圾 内存池化 缓存性质的对象 频繁创建和删除 使用内存池，不 GC 减少逃逸 逃逸会使原本在栈上的对象进入堆中 fmt 包慎用，多用 log 的组件 方法返回了指针而不是拷贝，可能会发生逃逸 使用空结构体 空结构体指向一个固定地址 不占用堆空间 比如 channel 传递空结构体 GC 分析工具 go tool pprof go tool trace go build -gcflags=&quot;-m&quot; 设置环境变量 GODEBUG = &quot;gctrace = 1&quot; ，go run main.go 其他高级特性 如何实现 Go 调用 C 代码？ import &quot;C&quot; go tool cgo main.go 查看调用流程 原理 在内存中开辟一个结构体 结构体中含有参数和返回值 结构体地址传入 C 方法 C 方法将结果写入返回值的位置 调度器的配合 协程需要抢占式调度 进入 C 程序之后，调度器无法抢占协程 调度器停止对此协程的调度 协程栈的切换 C 的栈不受 Runtime 管理 进入 C 时，需要将当前栈切换到线程的系统栈上 cgo 的优缺点 cgo 可以让 go 调用现成的 C 实现 cgo 限制了 go 语言的跨平台特性 cgo 并不能提高 Go 语言的性能 defer 的底层原理是怎样的？ go build -gcflags -S main.go 通过其汇编来查看 思路1：协程记录 defer 信息，函数退出时调用 实现1：堆上分配 1.12 之前使用 在堆上开辟一个 sched.deferpool 遇到 defer 语句，将信息放入 deferpool 函数返回时，从 deferpool 取出执行 实现2：栈上分配 1.13 之后出现 遇到 defer 语句，将信息放入栈上 函数返回时，从栈中取出执行 只能保存一个 defer 信息 思路2：将 defer 代码直接编译进函数尾 实现3：开放编码（性能最高，但是不好触发） 1.14之后出现 如果 defer 语句在编译时就可以固定 直接改写用户代码，defer 语句放入函数末尾 recover 如何在 panic 中拯救程序？ panic panic 会抛出错误 终止协程运行 带崩整个 Go 程序 panic + defer panic 在退出协程之前会执行所有已注册的 defer 不会执行其他协程的 defer panic + defer + recover 在 defer 中执行 recover，可以拯救 panic 的协程 如果涉及 recover，defer 会使用堆上分配（deferpool） 遇到 panic，panic 会从 deferpool 取出的 defer 语句，执行 defer 中调用 recover，可以终止 panic 的过程 Go 是怎么实现反射的？ 需求 获取对象的类型 对任意类型变量赋值 调用任意方法 元数据 元数据就是“数据的数据”（数据的属性） 把对象的类型表示成一个数据类型 把对象的值表示成一个数据类型 对象的类型 接口 refIect.Type 把对象的类型表示成一个接口 就能对类型做各种操作 对象的值 结构体 reflect.Value 把对象的值表示成一个结构体 就能对值做各种操作 runtime.eface 是运行时对空接口的表示 reflect.emptylnterface 是 reflect 包对空接口表示 对象到反射对象时，编译器会将入参提前转为 eface 反射对象到对象时，根据类型和地址还原数据 使用反射调用不同方法 通过反射调用方法，可以将框架和用户方法解耦 往往需要用户注册方法，框架调用 很多框架的 HTTP 调用处理使用此思路","tags":["Golang"],"categories":["Golang"]},{"title":"《程序员的 README》","path":"/2023/11/18/readme/","content":"[美] 克里斯·里科米尼（Chris Riccomini）&#x2F; [美] 德米特里·里亚博伊（Dmitriy Ryaboy） 2023-7-10 译者序：“翻译完本书的最后一章时，正好是我踏入软件行业的12年整，此时的我却觉得自己的职业生涯好像才刚刚开始。” 有些地方的翻译好像有点怪怪的… 程序员的 README第1章 前面的旅程 目的地 ☸️ 技术知识 执行力 沟通能力 领导力 地图 🗺 新手营 试炼之河 贡献者之角 运维之海 胜任之湾 第2章 步入自觉阶段 学习如何学习 虽然说持续进步非常重要，但是把所有清醒的时间都花在工作上是不健康的 在工作的前几个月里，你要学习一切如何运作 错误是不可避免的。如果你失败了，也不要被击垮：写下经验教训，然后继续前行 调试器是你运行实例代码时最好的朋友 在复杂的情况下，特别是在多线程的应用程序中，输出调试信息可能会产生误导 不要试图一下子把所有东西都读完。请从团队文档和设计文档入手 不要像阅读小说一样从前到后地通读代码：请利用你的IDE来浏览代码 出版物大多很可靠，只是有些过时。在线资源则正好相反，不那么可靠，但很能跟上潮流 跟随一名高级工程师是学习新技能的好方法 从长远来看，获得明确的信息将保护你免受挫折（be careful 提出问题 有效地提出问题将帮助你快速地学习，而不会烦扰其他人 动手调查 设置一个时间限制 写下全过程 别打扰别人 多用“非打扰式”交流 批量处理 克服成长的障碍 冒充者综合征 — “有意识的无能力” 邓宁-克鲁格效应 — “无意识的无能力” 行为准则 需要做的 不应该做的 多尝试和实验代码 只是大量炮制劣质代码 多阅读设计文档和他人的代码 害怕承担风险和失败 参加一些聚会、在线社区、兴趣小组和导师计划 过于频繁地参加研讨会 多读论文和博客 害怕提出问题 多采用“非打扰式”交流 旁听面试以及参与软件的熵轮换 第3章 玩转代码 软件的熵 这种走向无序的趋势被称为软件的熵（software entropy） 持续的重构可以减少熵 技术债 技术债是为了修复现有的代码不足而欠下的未来工作 鲁葬的 谨慎的 有意的 ““我们没有时间去设计” ““让我们先发布再处理后续” 无意的 “什么是分层结构?” “现在我们知道了当时应该怎么做” 技术债总是不可避免的，因为你无法防止无意中的错误 技术债甚至可能是成功的标志：项目只有存活了足够长的时间，才会变得无序 不要把你的呼吁建立在价值判断上（“这代码又老又难看”），将重点放在技术债的成本和修复它带来的好处上 变更代码 善于利用现有代码 过手的代码要比之前更干净 对重构要务实 善用 IDE 请使用 VCS 的最佳实践 避“坑”指南 保守一些的技术选型 不要特立独行 不要只分叉而不向上游提交修改 克制重构的冲动 行为准则 需要做的 不应该做的 进行渐进式的重构 过度使用“技术债”这个词 从新特性的提交中剥离重构的部分 为了适应测试而将变量或方法变成公共的 保持以小规模的方式修改伐码 成为编程语言上的“势利眼” 将过手的代码整理得比之前更干净 忽视你公司的标准和工具集 使用保守的技术选型 只分叉而不向上游提交修改 第4章 编写可维护的代码 防御式编程 避免空值 保持变量不可变 使用类型提示和静态类型检查器 验证输入 不接受 Word 文档（非纯文本） 善用异常，异常要有精确含义 早抛晚捕，不能忽略 智能重试，何时重试以及重试的频率都需要技巧 构建幂等系统，幂等的操作是可以被进行多次并且仍然产生相同结果的操作 及时释放资源 关于日志的使用 给日志分级 日志的原子性，所谓原子日志，就是指在一行消息中包含所有相关的信息 关注日志性能 不要记录敏感数据 系统监控 使用标准的监控组件 测量一切 资源池 缓存 数据结构 CPU 密集型操作 I&#x2F;O 密集型操作 数据大小 异常和错误 远程请求和响应 跟踪器 配置相关注意事项 配置无须新花样 记录并校验所有的配置 提供默认值 给配置分组 将配置视为代码 保持配置文件清爽 不要编辑已经部署的配置 工具集 行为准则 需要做的 不应该做的 宁愿编译出错，也不要运行出错 在程序逻辑中应用异常 尽可能使事情不可变 在异常处理中只返回错误码 校验输入和输出 捕获你无法处理的异常 学习开放式 Web 应用程序安全项目 (OWASP) 的十大报告 写入带折行的日志 使用 bug 检查工具和类型提示的特性 在日志中记载秘密或敏感的数据 在异常之后清理资源（尤其是端口、文件指针和内存) 单独在某台计算机上手动修改配置 使用系统指标来监控你的代码 在配置文件中存储密码或者秘密信息 让你的程序可以配置 写定制化的配置格式 检验和记录所有的配置 在可以避免的情况下使用动态配置 第5章 依赖管理 依赖管理基础知识 相依性是指你的代码所依赖的代码 语义化版本（主版本号、次版本号和补丁版本号&#x2F;微版本号 - 预发布版本） 语义化版本同时具有唯一性、可比性、信息性 传递依赖 相依性地狱 比较常见的相依性地狱的罪魁祸首是循环依赖、钻石依赖和版本冲突 避免相依性地狱 隔离依赖项 在某些场景下，可以打破 DRY（Don’t Repeat Yourself）原则，将某些导致依赖问题的代码直接拷贝到项目中 按需添加依赖项 指定依赖项的版本 依赖范围最小化 保护自己免受循环依赖的影响 行为准则 需要做的 不应该做的 务必使用语义化版本 使用Git的哈希值当作版本号 明确指定依赖版本的范围 在收益未超过成本时添加依赖项 务必使用依赖关系报告工具来分析传递依赖 直接使用传递来的依赖项 添加新的依赖项时，请务必持怀疑态度 引入循环依赖 精确地使用依赖范围 第6章 测试 测试的多种用途 检查代码是否正常工作 保护代码不会被将来那些无意中的修改所影响 鼓励清爽的代码 强迫开发者试用他们自己的 API 记录组件之间如何交互 测试类型 单元测试 集成测试 系统测试 性能测试 验收测试 测试工具 模拟库 测试框架 代码质量工具 自己动手编写测试 编写干净的测试 避免过度测试 测试中的确定性 几种可以避免出现非确定性测试的手段 用一个常数作为随机数生成器的种子 不要在单元测试中调用远程系统 采用注入式时间戳 避免使用休眠和超时 记得关闭网络套接字和文件句柄 将网络套接字都绑定到0端口（操作系统会自动选择一个开放的端口） 动态地生成唯一的文件路径和数据库位置 隔离并清理剩余的测试状态 测试不应该依赖于特定的执行顺序 行为准则 需要做的 不应该做的 使用测试去重现bug 忽视添加新测试工具时的成本 使用模拟工具去帮助编写单元测试 依赖干他人为你编写测试用例 使用代码质量工具去检查覆盖率、格式和复杂度 仅仅为了提高覆盖率而编写测试 在测试中使用常教种子的随机救生成器 仅仅将代码覆盖率作为代码质量的衡量标准 在测试后关闭网络套接字和文件句柄 在测试中使用可以避免的休眠和超时 在测试中生成唯-的文件路径和数据库位置 在单元测试中调用远程系统 在测试执行的间隙清理掉遗留的测试状态 依赖于测试执行顺序 第7章 代码评审 为什么需要评审代码 代码评审是一种教学和学习工具 为了安全性与合规性，需要代码评审 对代码库的共同理解有助于团队更有凝聚力地扩展代码 当你的代码被评审时 代码修改由准备、提交、评审、最后批准和合并这几个环节组成 用评审草案降低风险 提交评审请勿触发测试 预排大体量的代码修改 评审意见是针对代码的，而不是针对个人的 保持同理心，但不要容忍粗鲁 不要羞于要求别人评审你的代码 评审别人的代码时 分流评审请求（轻重缓急） 给评审预留时间 理解修改的意图 提供全面的反馈 代码修改的正确性、可实施性、可维护性、可读性和安全性 要承认优点 区分问题、建议和挑剔 在反馈前加上字样 “可选” （optional） “接受或不接受” （take it or leave it） “非必须” （nonblocking） 不要只做橡皮图章 不要只局限于使用网页版的评审工具 不要忘记评审测试代码 推动决断（不要拖） 行为准则 需要做的 不应该做的 在提交评审请求之前保证通过了测试和代码检测工具的检查 仅仅为了触发持续集成（CI）系统而提交评审请求 为代码评审预留出专门的时间，像对待其他工作–样对待评审工作 只做橡皮图章 当评审意见很粗鲁、没有建设性或者有不当言论的时候，请明确指出来 和代码“坠入爱河”或者把评审的反馈意见当作私人恩怨 通过适当提供相应修改的背景信息来帮助评审者 在不了解整项政动的大背景的情况下就直接纠缠代码细节 在进行代码评审时，超越肤浅的对代码风格的指摘 过度地挑剔 用尽一切工具去理解棘手的代码改动，不要只依赖评审工具自身的界面 让“完美”成为“优秀”的敌人 将测试代码纳入评审范围 第8章 软件交付 软件交付流程 构建、发布、部署 和 展开（上线、投产） 分支策略 频繁地合并被称为持续集成（CI） 构建环节 打包需要带版本号 将不同的资源单独打包 发布环节 请勿只想着发布 将包发布到仓库 保持版本不变性 频繁发布 对发布计划保持透明 撰写变更日志和发行说明 部署环节 自动部署 部署的原子性 独立地部署应用 上线环节 系统监控 特性开关 熔断器 并行的服务版本梯队 金丝雀部署（金丝雀报警器） 蓝绿部署 摸黑启动（灰度发布） 行为准则 需要做的 不应该做的 使用基于主干的分支模式并在可能的条件下持续集成 发布未署版本号的包 使用 VCS 工具来管理分支 把配置、模式、图片和语言包–并打包在一起 与发布和运维团队合作为你的应用建立正确的流程 盲目地依赖发布经理和运维团队 一并发布变更日志和发行说明 使用 VCS 来分发软件 在新版发布时通知用户 更改已经发布的软件包 使用现成的工具来自动化部署 在没有监控结果的情况下执行展开步骤 使用特性开关逐步推出更新 依赖于顺序部署 使用熔断器防止应用造成重大的破坏 使用影子流量或摸黑启动来进行重大变更 第9章 On-Call On-Call 的工作方式 对事故分流、缓解症状和最终解决 On-Call 技能包 随时响应 保持专注 确定工作优先级 优先级分类 P1：严重影响（critical impact） — 服务在生产环境中无法使用 P2：高影响（high impact） — 服务的使用受到严重损害 P3：中等影响（medium impact） — 服务的使用部分受损 P4：低影响（low impact） — 服务完全可用 服务水平指标（SLI）：如错误率、请求延迟和每秒请求数 服务水平目标（SLO） 为健康的应用程序行为定义了 SLI 的目标 服务水平协议（SLA）是关于越过 SLO 范围时将会发生什么的协议 清晰的沟通 跟踪你的工作 事故处理 事故响应的 5个阶段：分流、协同、应急方案、解决方案、后续行动 行为准则 需要做的 不应该做的 将呼叫你的号码添加到电话联系人的白名单中 无视警告 使用优先级类别、SLI、SLO 和 SLA 来确定事故响应的优先级 在分流阶段就尝试排除故障 针对严重的事故采取分流、协同、应急方案、解决方案、后续行动的策略 在问题尚未缓解的情况下就去做根本原因分析 使用科学的方式去排除故障 在事后回顾总结的时候指责别人 在事故的后续行动环节使用 5W（Why）的方式来追根溯源 对关闭那些无响应的支持请求犹豫 确认响应支持类的请求 询问支持的请求者他们的优先级是什么，不询问问题的影响 针对下一次回复给予明确的时间预期 逞英雄修复所有的事情 在关闭请求类的任务票之前确认问题都已经修改好了 将支持请求重定向到适当的沟通渠道 第10章 技术设计流程 技术设计的 V 形结构 队友之间 - 团队内部 - 团队之间（确定性和清晰度 ↑ ） 关于设计的思考 定义问题 着手调查 进行实验 给些时间 撰写设计文档 文档持续变更 了解撰写文档的目的 学会写作 保证文档是最新的 使用设计文档模板 概要 现状与背景 变更的目的 需求 面向用户的需求 技术需求 安全性与合规性需求 其他（截至期限、预算） 潜在的解决方案 建议的解决方案 设计与架构 系统构成图 UI (user interface design) &#x2F; UX (user experience design) 变更点 代码变更点 API 变更点 持久层变更点 测试计划 发布计划 遗留的问题 附录 协作设计 理解你的团队的设计评审流程 不要让人惊讶 用设计讨论来进行头脑风暴 为设计出力 行为准则 需要做的 不应该做的 使用设计文档模板 在意早晚会变的实验性的代码 阅读博客、论文和–些演讲文稿来获取灵感 只讨论一项解决方案 对于你看到的一切保持批判性思考 让非母语阻止你写作 在设计阶段就编写实验性的代码 在具体实施方案和计划有些偏离时忘记更新设计文档 学会清晰地写作，并经常练习 消极地参与团队设计讨论 对设计文档进行版本控制 对队友的设计提出问题 第11章 构建可演进的架构 理解复杂性 高依赖性 高隐蔽性 高惯性 可演进的设计 你不是真的需要（You ain’t gonna need it，YAGNI） 最小惊讶原则（别搞一些骚操作⛏） 封装专业领域知识 领域驱动设计（domain-driven design，DDD） 可演进的 API 保持 API 小巧 默认值可使大型 API 在感觉上很小巧 公开定义良好的服务端 API 保持 API 变更的兼容性 API 版本化 API 版本通常由 API 网关或服务网格来管理 可持续的数据管理 数据库隔离 使用 schema 采用无模式的方法会产生明显的数据完整性和复杂性问题 不要将无模式的数据隐藏在已经模式化的数据中 schema 自动化迁移 保持 schema 的兼容性 行为准则 需要做的 不应该做的 牢记 YAGNI 原则：“You Aren’t Gonna Need It” 无目的地构建过多的抽象模型 使用标准类库和开发模型 编写隐含排序需求和参数需求的方法 使用 接口定义语言（IDL）来定义你的 API 使用怪异代码让其他开发者感到惊讶 对外部 API 和文档进行版本管理 对 API 进行不兼容的变更 隔离不同应用程序的数据库 对内部 API 的版本控制持教条态度 对所有的数据定义显式的 schema 在字符串或字节字段中嵌入无模式数据 使用迁移工具来进行数据库 schema 的自动化管理 如果下游数据消费者使用到了你的数据，保持 schema 的兼容性 第12章 敏捷计划（针对的是 项目经理 和 程序经理） 敏捷宣言 个人和互动高于流程和工具 工作的软件高于详尽的文档 客户合作高于合同谈判 响应变化高于遵循计划 敏捷计划的框架 Scrum 看板 Scrum 框架 用户故事 任务分解 故事点 消化积压 冲刺计划 站会（Scrum 会议 &#x2F; huddle会） 评审机制 回顾会 路线图 “在准备战斗时，我总是发现计划是无用的，但计划是不可缺少的。” 行为准则 需要做的 不应该做的 保持站会简短 痴迷于敏捷开发的“正确做法” 为用户故事写下详细的验收标准 害怕改变敏捷流程 承诺可以在冲刺迭代中实际完成的工作 将常规任务描述强加给“用户故事” 如果你无法在冲刺迭代中完成大块工作，请将其分解 忘记跟踪计划和设计工作 使用故事点来预估工作量 尚未完成已提交的工作时又在冲刺开始后追加工作 务必使用相对尺度和T恤尺码来帮助估算 盲目地遵循流程 第13章 与管理者合作 管理者是做什么的 管理者们构建团队、指导和培养工程师，并进行人际关系的动态管理 工程经理还计划和协调产品的开发 管理者们通过与高管或董事（“向上”）合作 与其他管理者（“横向”）合作 与他们的团队（“向下”）合作 沟通、目标与成长 一对一面谈 进展、计划与问题（progress-plans-problems，PPP） PPP 是一种常用的更新工作状态的格式 目标、关键和结果（Objective, Key, Result，OKR） OKR 框架是公司定义目标和衡量其是否成功的一种方式 关键绩效指标（Key Performance Indicator，KPI） 放弃了“O”，只关注关键结果 —关键绩效指标(KPI)，而不明确说明目标 绩效考核 你今年做了什么？ 今年有什么事情进展顺利？ 今年有什么事情可以做得更好？ 你在职业生涯中想得到什么？你认为自己在3到5年内会到达什么样的高度？ 不要忘了非工程类的项目 辅导实习生、代码评审、参与面试、博客文章、演讲、文档 … 向上管理 接收反馈 给予反馈 在提供反馈时，使用情况、行为和影响（situation-behavior-impact，SBI）框架 讨论你的目标 事情不顺时要采取行动 如果你已经给出了反馈意见，并保持了耐心，但事情仍然没有进展，那就起身离开 行为准则 需要做的 不应该做的 期望管理者能够平易近人且具有透明度 向管理者隐瞒困难 明确告知你的管理者你需要什么 仅仅把一对一面谈当作更新工作状态的会议 为一对一面谈设置议程 仅凭记忆进行自我总结 保有一对一面谈的纪要 给予他人肤浅的反馈 按照你希望收到的反馈来撰写具有可操作性的反馈 被 OKR 框住 跟踪工作成果，这样在自我评价时会更容易 将反馈视为攻击 采用 SBI 框架来减少反馈对个人的针对性 忍受糟糕的管理 考虑长期的职业目标 第14章 职业生涯规划 迈向资深之路 从初级工程师或软件工程师到资深工程师 从资深工程师到主任工程师或首席工程师 职业生涯建议 T 型人才（一专多长） 参加工程师训练营 主导你自己的晋升 换工作需谨慎 自我调节 你的职业生涯是一场马拉松，而不是短跑冲刺 ~","tags":["programmer"],"categories":["Reading"]},{"title":"Go 数据结构与算法、SQL 刷题 ⌨️","path":"/2023/11/13/gocode/","content":"刷题记录和总结 数组 题号 思路 备注 704. 二分查找 有序无重是前提，左右指针，不断缩小查找范围，注意边界处理 1️⃣ 27. 移除元素 快慢指针替换位置 1️⃣ 977. 有序数组的平方 两头对比选择，从后往前填充 2️⃣ 209. 长度最小的子数组 双指针滑动收缩窗口 2️⃣ 59. 螺旋矩阵 II 模拟过程，一圈圈往里缩，注意统一 [i, j) 填充范围 2️⃣ 15. 三数之和 排序 + 双指针 + 剪枝 ✅ 18. 四数之和 排序 + 双指针 + 剪枝（上一题多加一个 for） ✅ 链表 题号 思路 备注 203. 移除链表元素 设置虚拟头节点，统一处理 3️⃣ 707. 设计链表 注意 for 后 cur 的定位 3️⃣ 206. 反转链表 双指针同步移动，注意循环终止条件 3️⃣ 24. 两两交换链表中的节点 虚拟头节点 + 两个记录节点 4️⃣ 19. 删除链表的倒数第 N 个结点 虚拟头节点，快慢指针 4️⃣ 面试题 02.07. 链表相交 双指针走完互换起点，结尾的 nil 也可看做是交点 4️⃣ 142. 环形链表 II 快慢指针环内相遇后，起点位置和慢指针同步移动一定会相遇 4️⃣ 哈希表 题号 思路 备注 242. 有效的字母异位词 分别遍历，先 ++ 后 –，最后判断 5️⃣ 349. 两个数组的交集 分别遍历，判断收集去重 5️⃣ 202. 快乐数 模拟，map 判断是否出现过 5️⃣ 1. 两数之和 遍历，一边判断一边存 [val] index 5️⃣ 454. 四数相加 II 两个双重循环，用 map 优化 6️⃣ 383. 赎金信 ++ 后 –，– 时判断是否 &lt; 0 6️⃣ 字符串 题号 思路 备注 344. 反转字符串 双指针，往里夹 7️⃣ 541. 反转字符串 II 局部的反转 + 最后的边界判断 7️⃣ 151. 反转字符串中的单词 双指针删除冗余空格&#x2F;定位单词 + 反转整体再反转每个单词 8️⃣ 28. 找出字符串中第一个匹配项的下标 Knuth-Morris-Pratt 字符串查找算法 🤡 $O(n * m)$ → $O(n + m)$ 459. 重复的子字符串 KMP 基础上，首尾拼接查中间 🤡 栈与队列 题号 思路 备注 225. 用队列实现栈 使用两个 slice ，每添加一个元素都需要倒腾 9️⃣ 232. 用栈实现队列 输入栈 + 输出栈，出的时候触发倒腾 9️⃣ 20. 有效的括号 用 slice 模拟栈，遍历时添加或消除括号 9️⃣ 1047. 删除字符串中的所有相邻重复项 在栈中玩消消乐 9️⃣ 150. 逆波兰表达式求值 “后缀表达式” 求解，用栈模拟 1️⃣0️⃣ 239. 滑动窗口最大值 实现 “单调队列”，记录窗口内的最大值 1️⃣0️⃣ 347. 前 K 个高频元素 “优先队列”（添加和移除元素的时候维护单调性）；统计后排序（偷懒做法） 1️⃣0️⃣ 单调栈 题号 思路 备注 739. 每日温度 栈顶到栈底递增（即遇到 第一个 更高温，才开始更新等待的天数） 4️⃣1️⃣ 496. 下一个更大元素 I 上一题套了一个哈希映射 4️⃣1️⃣ 503. 下一个更大元素 II 在遍历的过程中使用 % 模拟走两遍 nums 4️⃣1️⃣ 42. 接雨水 凹，横着计算面积，算完一个面积后记得更新栈顶元素 4️⃣2️⃣ 84. 柱状图中最大的矩形 凸，数组头尾加个 0 避免数组原来就有序不走计算逻辑和拿不到 left 4️⃣2️⃣ 二叉树 题号 思路 备注 144. 二叉树的前序遍历，94. 中，145. 后 递归（注意 slice 是一个值类型）；迭代用个栈，注意中序的访问和处理节点不一致；后序为【左右中】即【中右左】的反转 1️⃣1️⃣ 102. 二叉树的层序遍历 使用 []*TreeNode 保存每一层节点 1️⃣1️⃣ 226. 翻转二叉树 每个节点的左右都交换一下即整棵树翻转（中序遍历不行） 1️⃣2️⃣ 101. 对称二叉树 只能后序遍历（左右中 + 右左中） 1️⃣2️⃣ 104. 二叉树的最大深度 根节点的高度就是二叉树的最大深度（后序） 1️⃣2️⃣ 111. 二叉树的最小深度 和上一题对比，区别在于处理非叶子节点的逻辑（后序） 1️⃣2️⃣ 110.平衡二叉树 计算以每个节点为根节点的二叉树的高度（后序） 1️⃣3️⃣ 257. 二叉树的所有路径 前序遍历，字符串的值传递隐含了回溯（先序） 1️⃣3️⃣ 404. 左叶子之和 通过节点的父节点来判断其左孩子是不是左叶子 1️⃣3️⃣ 222. 完全二叉树的节点个数 可以利用完全二叉树的特性，公式求解（后序） 1️⃣4️⃣ 513. 找树左下角的值 递归：深度最大的叶子节点是最后一行（先序）；迭代：模板 1️⃣4️⃣ 112. 路径总和 函数的值传递隐含了回溯，递归函数需要返回值 1️⃣4️⃣ 113. 路径总和 II 递归函数不需要返回值，注意指针类型会被修改要 copy 一下 1️⃣4️⃣ 106. 从中序与后序遍历序列构造二叉树 用散列表记录元素再前序中的索引，根据子树元素个数切割数组，[l, r] 1️⃣4️⃣ 654. 最大二叉树 前序遍历递归构建 1️⃣5️⃣ 617. 合并二叉树 同时遍历两棵树，递归的优雅表现 1️⃣5️⃣ 700.二叉搜索树中的搜索 利用二叉搜索树的性质 1️⃣5️⃣ 98.验证二叉搜索树 注意，不能陷入只判断局部（先序） 1️⃣5️⃣ 236. 二叉树的最近公共祖先 遍历整棵树，判断两种情况（后序） 1️⃣6️⃣ 501. 二叉搜索树中的众数 计数法不使用额外空间， prev 指针（中序） 1️⃣6️⃣ 530. 二叉搜索树的最小绝对差 在一个有序数组上求差值（中序） 1️⃣6️⃣ 235. 二叉搜索树的最近公共祖先 遇到 cur 节点数值在 [q, p] 区间中，即是最近公共祖先（往一边走就行，后序） 1️⃣7️⃣ 701.二叉搜索树中的插入操作 通过递归返回值来加入新节点，不涉及结构的调整（后序查找目标位置） 1️⃣7️⃣ 450.删除二叉搜索树中的节点 删除节点操作涉及到结构的调整（后序查找目标位置） 1️⃣7️⃣ 669. 修剪二叉搜索树 不需要删除，只需要做结构的调整 1️⃣8️⃣ 108. 将有序数组转换为二叉搜索树 寻找分割点 len(nums) / 2，递归左区间和右区间 1️⃣8️⃣ 538. 把二叉搜索树转换为累加树 即有序数组求 从后到前 的累加数组，反中序（右左中）遍历顺序累加 1️⃣8️⃣ 回溯 题号 思路 备注 77. 组合 注意切片里面是指针不能直接放，要 copy 一下（组合不考虑顺序） 1️⃣9️⃣ 216.组合总和 III 比上一题多了一个判断的条件，注意剪枝 1️⃣9️⃣ 17. 电话号码的字母组合 构建映射，不同集合，所以 i 都是从 0 开始 1️⃣9️⃣ 39. 组合总和 可重复选取，不用控制遍历的起始位置+1；排序剪枝 2️⃣0️⃣ 40. 组合总和 II 只能选取一次，在回溯中对同一层的元素去重，而不对同一枝去重 2️⃣0️⃣ 131. 分割回文串 切割线，切割问题抽象为组合问题 2️⃣0️⃣ 93. 复原 IP 地址 也是切割问题，终止条件判断不一样 2️⃣1️⃣ 78. 子集 集合无重复元素，无条件收集所有节点，无需剪枝 2️⃣1️⃣ 90. 子集 II 集合有重复元素，排序、同层去重、同枝不去 2️⃣1️⃣ 491. 非递减子序列 不能排序，对同枝元素去重，注意 used 数组的位置，只负责本层 2️⃣2️⃣ 46. 全排列 不包含重复元素，不需要 startIndex，需要标记一个排列里使用过的元素 2️⃣2️⃣ 47. 全排列 II 包含重复元素，排序、同层去重、同枝不去 2️⃣2️⃣ 332. 重新安排行程 🤡 51. N 皇后 🤡 37. 解数独 🤡 贪心 题号 思路 备注 455. 分发饼干 两者都排序后，胃口主动遍历，饼干的被动（优先满足胃口大的） 2️⃣3️⃣ 376. 摆动序列 “删除”单调坡度上的中间节点（统计峰值节点） 2️⃣3️⃣ 53. 最大子数组和 当前“连续和”为负数的时候立刻放弃 2️⃣3️⃣ 122. 买卖股票的最佳时机 II 只收集相邻的每个正利润 2️⃣4️⃣ 55. 跳跃游戏 判断跳跃覆盖范围能不能覆盖到终点 2️⃣4️⃣ 45. 跳跃游戏 II 每超过上一次可达最大范围，需要跳跃次数 +1 后扩大范围 2️⃣4️⃣ 1005. K 次取反后最大化的数组和 按绝对值进行排序 2️⃣4️⃣ 134. 加油站 当前累加 rest[i] 的和 curSum 一旦小于 0，起始位置至少要是 i+1 2️⃣5️⃣ 135. 分发糖果 先 → 比 右 ＞ 左，再 ← 比 左 ＞ 右 2️⃣5️⃣ 860. 柠檬水找零 简单模拟 2️⃣5️⃣ 406. 根据身高重建队列 按照身高大到小、人数小到大排序，优先按身高高的 k 来插入 2️⃣5️⃣ 452. 用最少数量的箭引爆气球 出现重叠的气球只需要一个箭；排序后，判断重叠区间，统计箭数 2️⃣6️⃣ 435. 无重叠区间 按右界排序，用总数减去非重叠区间的个数；修改范围模拟移除 2️⃣6️⃣ 763. 划分字母区间 字符最远出现位置下标和当前下标相等时即为分割点 2️⃣6️⃣ 56. 合并区间 排序、遍历、比较（拿结果集的最后一个元素）、合并 2️⃣7️⃣ 738. 单调递增的数字 后往前遍历，-1 时触发后面范围都置 9 2️⃣7️⃣ 968. 监控二叉树 🤡 动态规划 题号 思路 备注 509. 斐波那契数 感受一下 2️⃣8️⃣ 70. 爬楼梯 上一题套了一个壳 2️⃣8️⃣ 746. 使用最小花费爬楼梯 到达第 i 台阶所花费的最少体力为 dp[i] 2️⃣8️⃣ 62.不同路径 从 (0, 0) 出发，到 (i, j) 有 dp[i][j] 条不同的路径 2️⃣9️⃣ 63. 不同路径 II 障碍标记对应的 dp[i][j] 保持初始值（0） 2️⃣9️⃣ 343. 整数拆分 分拆正整数 i 可以得到的最大乘积为 dp[i]，max((i - j) * j), dp[i - j] * j) 2️⃣9️⃣ 96. 不同的二叉搜索树 1 - i 为节点组成的二叉搜索树的个数为 dp [i]，递推公式不好找 🤡 01 背包（二维&#x2F;一维） 每个物品只有一个，一维需要从大小遍历背包 3️⃣0️⃣ 416. 分割等和子集 背包大小为 sum / 2，商品大小和价值一样，若 dp[target] == target 则存在 （装满背包的最大价值&#x2F;重量） 3️⃣0️⃣ 1049. 最后一块石头的重量 II 让石头分成重量最相同的两堆，相撞之后剩下的石头最小 （装满背包的最大价值&#x2F;重量） 3️⃣1️⃣ 494. 目标和 dp[j] 表示填满 j（包括 j）这么大容积的包，有 dp[j] 种方法 （装满背包的组合数） 🤨 474. 一和零 物品的重量&#x2F;背包 有两个维度 （背包可以装的最大物品数量） 🔢 3️⃣1️⃣ 完全背包 每件物品都有无限个，一维需要从小到大遍历背包 3️⃣1️⃣ 518. 零钱兑换 II 凑成总金额 j 的货币组合数为 dp[j] （装满背包的组合数） 3️⃣2️⃣ 377. 组合总和 Ⅳ 注意是“排列”数，需要先遍历背包再遍历物品 （装满背包的排列数） 3️⃣2️⃣ 322. 零钱兑换 凑足总额为 j 所需钱币的最少个数为 dp[j] （装满背包的最小物品数量，加是否装满的判断）🔢 3️⃣3️⃣ 279. 完全平方数 和为 j 的完全平方数的最少数量为 dp [j]，注意初始化 （装满背包的最小物品数量）🔢 3️⃣3️⃣ 139. 单词拆分 wordDict 是物品，s 是背包，物品能不能装入是看能不能和背包后缀匹配 （装满背包的排列数） 3️⃣3️⃣ 打家劫舍 198. 打家劫舍 考虑下标 i（包括 i）以内的房屋，最多可以偷窃的金额为 dp [i] 3️⃣4️⃣ 213. 打家劫舍 II 包含首元素，不包含尾元素；包含尾元素，不包含首元素；两种情况取最大值 3️⃣4️⃣ 337. 打家劫舍 III dp 数组下标为 0 记录不偷该节点所得到的的最大金钱，下标为 1 记录偷该节点所得到的的最大金钱 （后序遍历） 3️⃣4️⃣ 买卖股票 买入卖出，但是同时只能持有一支股票 121. 买卖股票的最佳时机 dp[i][0] 表示第 i 天不持有，dp[i][1] 表示第 i 天持有股票所得最多现金 （只能买卖一次） 3️⃣5️⃣ 122.买卖股票的最佳时机 II 可以完成多笔交易，最多只能持有一股股票 （可以买卖多次） 3️⃣5️⃣ 123.买卖股票的最佳时机 III 可以完成最多两笔交易，不能同时 （可以买卖最多两次） 3️⃣5️⃣ 188. 买卖股票的最佳时机 IV 可以完成最多 k 笔交易，，除了 0 以外，偶数就是卖出，奇数就是买入 （可以买卖最多 k 次） 3️⃣6️⃣ 309. 买卖股票的最佳时机含冷冻期 卖出股票后，你无法在第二天买入股票，即冷冻期为 1 天 （可以买卖最多次） 3️⃣6️⃣ 714. 买卖股票的最佳时机含手续费 卖出的时候加个手续费即可 （可以买卖多次） 3️⃣6️⃣ 子序列问题 300.最长递增子序列 dp[i] 表示 i 之前包括 i 的以 nums[i] 结尾的最长递增子序列的长度 3️⃣7️⃣ 674. 最长连续递增序列 只要比较 nums[i] 与 nums[i - 1]，而不用去比较 nums[j] 与 nums[i]（j 是在 0 到 i 之间遍历） 3️⃣7️⃣ 718. 最长重复子数组 子数组就是连续子序列，以下标 i 为结尾的 A，和以下标 j 为结尾的 B，最长重复子数组长度为 dp[i][j]，注意初始化 3️⃣7️⃣ 1143.最长公共子序列 较上一题就是少了“连续”的要求，如果不等取各自前一个状态的最大值，注意初始化和上面有不同，两者都可以删除元素 3️⃣8️⃣ 1035.不相交的线 与上一题相同，只要相对顺序不变就行（就是求最长公共子序列） 3️⃣8️⃣ 53. 最大子数组和 （连续）子数组，dp[i] 表示以 i 为结尾的子数组的最大和 3️⃣8️⃣ 392. 判断子序列 以下标 i 为结尾的 s，和以下标 j 为结尾的 t，相同子序列的长度为 dp[i][j]，删除元素只能是 t（判断最长公共子序列长度是否和 t 长度一样即可） 3️⃣8️⃣ 115. 不同的子序列 以下标 i 为结尾的 s 子序列中出现以 j 为结尾的 t 的个数为 dp[i][j]，较上一题初始化和递推公式不同 3️⃣9️⃣ 583. 两个字符串的删除操作 找出最长公共子序列，用两个字符串的总长度减去两个最长公共子序列的长度 3️⃣9️⃣ 72. 编辑距离 3️⃣9️⃣ 647. 回文子串 4️⃣0️⃣ 516. 最长回文子序列 4️⃣0️⃣ 图论 题号 思路 备注 LC🔥100LeetCode 热题 100 题号 思路 备注 哈希 1. 两数之和 哈希（key: val，val: index） 49. 字母异位词分组 map[string][]string、排序每个元素后作为 key 128. 最长连续序列 map 用来快速查询某个元素是否存在并去重优化 双指针 283. 移动零 快慢指针，移动非 0，末尾置 0 11. 盛最多水的容器 左右指针往里夹，短板效应 15. 三数之和 排序去重，一数外循环，两数左右指针往里夹 18. 四数之和 套个 for + 三数之和 42. 接雨水 维护单调栈（栈底到栈顶递减），识别凹槽，持续按照行计算 ⬅️ 滑动窗口 3. 无重复字符的最长子串 一边遍历一边使用 map 记录字符的最后位置，滑动窗口 438. 找到字符串中所有字母异位词 滑动窗口 + [] int 记录判断是否为异位词 子串 560. 和为 K 的子数组 前缀和 + 哈希表优化（记录每个前缀和出现的次数） 239. 滑动窗口最大值 实现 “单调队列”，记录窗口内的最大值 76. 最小覆盖子串 哈希表记录，覆盖到后缩小范围，移除无用元素 普通数组 53. 最大子数组和 贪心：遇到负数直接置零；动规：取考虑 num [i] 后的最大值 56. 合并区间 排序后遍历，判断修改右边界 or 直接添加 189. 轮转数组 整体翻转后再翻转两个局部 238. 除自身以外数组的乘积 遍历两次，计算每个元素左侧&#x2F;右侧乘积 41. 缺失的第一个正数 把每个数放在 nums[nums[i] - 1] 的位置上，再遍历检查 矩阵 73. 矩阵置零 使用第一行&#x2F;列记录该行&#x2F;列是否有 0，再遍历一次判断置 0 54. 螺旋矩阵 定义好四个边界，模拟 48. 旋转图像 先转置（行列交换）再左右对称交换位置 240. 搜索二维矩阵 II 初始定位到第一行的最后一个元素，之后遍历判断移动行&#x2F;列 链表 160. 相交链表 到头了就走一遍对方的路 206. 反转链表 pre cur temp 234. 回文链表 快慢指针找到链表中点，反转后半部分后逐个与前半部分比较 $O(1)$ 空间 141. 环形链表 快慢指针，如果有环一定回相遇，有一个为 nil 就算没环 142. 环形链表 II 快慢相遇后，头节点和慢指针同步移动，返回相遇点；或者哈希 21. 合并两个有序链表 模拟合并，判断处理剩余部分 2. 两数相加 模拟相加，记录进位，节点为 nil 给个默认值 0 19. 删除链表的倒数第 N 个结点 快慢指针，fast 先移动，到位后一起移动 slow 定位到待删除节点前一个位置 24. 两两交换链表中的节点 设置虚拟头节点加两个临时记录的指针 25. K 个一组翻转链表 反转链表（head, tail → tail, head），上一个子链的 tail 是下一个的 hair 138. 随机链表的复制 map[*Node]*Node 建立新旧节点的映射关系，map [旧] → 新 148. 排序链表 归并排序，快慢指针找到中点，合并两个有序链表 23. 合并 K 个升序链表 146. LRU 缓存 双向链表 + 哈希表 二叉树 94. 二叉树的中序遍历 递归&#x2F;迭代（用个栈优先向左子树方向保存节点） 104. 二叉树的最大深度 后序递归，depth := max(leftDepth, rightDepth) + 1 226. 翻转二叉树 后序递归，翻转每一个节点的左右孩子 101. 对称二叉树 dfs(left.Left, right.Right) &amp;&amp; dfs(left.Right, right.Left) 543. 二叉树的直径 后序递归，和二叉树最大深度是一样的，中间多了一个判断收集结果 102. 二叉树的层序遍历 用两个队列，curLevel 和 nextLevel 轮换，两个 for 108. 将有序数组转换为二叉搜索树 前序遍历，idx := len(nums)/2 98. 验证二叉搜索树 前序遍历，检查的时候需要传递节点的 230. 二叉搜索树中第 K 小的元素 中序遍历是有序的，一边遍历一遍计算是否到第 K 个数 199. 二叉树的右视图 层序列遍历只收集每一层的最后一个节点 114. 二叉树展开为链表 前序遍历后构建链表&#x2F;前序遍历和展开同步进行 105. 从前序与中序遍历序列构造二叉树 查找划分、递归构造 437. 路径总和 III 递归遍历每个节点，并在每个节点上去查找路径 236. 二叉树的最近公共祖先 后序遍历，使用左右子树的递归结果来决定当前节点是否是最近公共祖先 124. 二叉树中的最大路径和 后序遍历，注意向上传递的额时候只能传递左右的一边 图论 200. 岛屿数量 遇到一个岛屿则 DFS&#x2F;BFS（单源） 进行标记 994. 腐烂的橘子 多源 BFS（队列里面同时有多个元素），烂 🍊 入队并统计新 🍊 数量 207. 课程表 检测课程之间的依赖关系是否存在环（DFS 构建邻接表 &#x2F;BFS 移除入度为 0 的节点） 208. 实现 Trie (前缀树) 注意结构体的定义，其余都是遍历判断每个字符 回溯 46. 全排列 排列问题，可回头，不需要 start，使用 used 避免重复选择一个数字 78. 子集 组合问题，不可回头，需要遍历下标 start 17. 电话号码的字母组合 组合问题，构建映射表，需要遍历下标 start 39. 组合总和 用 start 避免重复组合和支持无限次取，可排序剪枝 22. 括号生成 79. 单词搜索 131. 分割回文串 51. N 皇后 二分查找 35. 搜索插入位置 74. 搜索二维矩阵 34. 在排序数组中查找元素的第一个和最后一个位置 33. 搜索旋转排序数组 153. 寻找旋转排序数组中的最小值 4. 寻找两个正序数组的中位数 栈 20. 有效的括号 左括号入栈，右括号优先匹配或入栈，最后判断栈是否为空 155. 最小栈 维护两个栈，一个用于存储所有的元素，另一个用于维护历史最小值 394. 字符串解码 一个栈用于存储重复次数 k，另一个栈用于存储当前累积的字符串部分 739. 每日温度 维护一个单调递减栈（栈底到栈顶是递减的，栈顶是最小的）， 栈中存储的是索引 $O(n)$ 84. 柱状图中最大的矩形 维护一个单调递增栈（栈底到栈顶是递增的，栈顶是最大的） 堆 215. 数组中的第 K 个最大元素 347. 前 K 个高频元素 295. 数据流的中位数 贪心算法 121. 买卖股票的最佳时机 一次遍历模拟时间流逝，不断交易取最值 55. 跳跃游戏 维护最大覆盖范围，遍历判断 45. 跳跃游戏 II 维护当前遍历位置最远可达，如果遍历位置到达最远可达则 jump++ 763. 划分字母区间 遍历字符串并记录每个字符的最后出现位置，注意遍历的时候 end 需要取 max 动态规划 70. 爬楼梯 注意循环的结束条件 $f(n) &#x3D; f(n-1) + f(n-2)$ 118. 杨辉三角 创建模拟逐层填充 198. 打家劫舍 dp[i] 表示偷窃到 i 号房屋所获取的最高金额 $dp[i]&#x3D;max(dp[i−1],nums[i]+dp[i−2])$ 279. 完全平方数 dp[i] 表示数字 i 最少可以由多少个完全平方数组成 $dp[i]&#x3D;min(dp[i],dp[i−j^2]+1)$ 322. 零钱兑换 dp[i] 表示凑成金额 i 所需的最少硬币数 $dp[i]&#x3D;min(dp[i],dp[i−coin]+1)$ 139. 单词拆分 dp[i] 表示字符串 s 的前 i 个字符是否可以用字典中的单词拼接出来 $dp[i] &#x3D; dp[j]$ &amp;&amp; $s[j:i] ∈ wordDict$ 300. 最长递增子序列 dp[i] 表示以 nums[i] 结尾的最长递增子序列的长度 $dp[i]&#x3D;max(dp[i],dp[j]+1)$ 152. 乘积最大子数组 通过维护 maxProd 和 minProd 同时处理了包含当前元素的最大子数组乘积和最小子数组乘积的情况，而不需要回溯或进行额外的遍历（一次遍历即可） 416. 分割等和子集 0&#x2F;1 背包问题（先物后背，背倒序），dp[i] 表示是否能找到和为 i 的子集 $dp[i] &#x3D; dp[i]$ 32. 最长有效括号 用栈来做更方便，先把 -1 压入栈作为哨兵 多维动态规划 62. 不同路径 dp[i][j] 表示从左上角 (0, 0) 走到位置 (i, j) 的路径数 $dp[i][j]&#x3D;dp[i−1][j]+dp[i][j−1]$ 64. 最小路径和 dp[i][j] 表示从左上角 (0, 0) 到达位置 (i, j) 的最小路径和 $grid[i][j]+min(dp[i−1][j],dp[i][j−1])$ 5. 最长回文子串 dp[i][j] 表示子串 s[i:j+1] 是否是回文 $dp[i][j]&#x3D;(s[i]&#x3D;&#x3D;s[j])∧dp[i+1][j−1]$ 1143. 最长公共子序列 dp[i][j] 表示字符串 text1 的前 i 个字符和 text2 的前 j 个字符的最长公共子序列的长度 $dp[i][j]&#x3D;dp[i−1][j−1]+1$$dp[i][j]&#x3D;max(dp[i−1][j],dp[i][j−1])$ 72. 编辑距离 dp[i][j] 表示将 word1 的前 i 个字符转换为 word2 的前 j 个字符所需的最少操作数 技巧 136. 只出现一次的数字 全部元素的异或运算结果即为数组中只出现一次的数字 169. 多数元素 摩尔投票法，不通的元素数量 – 抵消、相同的 ++ $O(1)$ 空间 75. 颜色分类 分别遍历判断交换元素，确定 0 和 1 的位置 31. 下一个排列 287. 寻找重复数 数字都在 [1, n] 范围内，快慢指针，即 142. 环形链表 II 标准 I&#x2F;Ofmt.Scan()、fmt.Scanln()、bufio.NewScanner(os.Stdin) 多组输入、大批量输请使用 bufio.Reader 来替换 fmt.Scan ❗️ 不然可能会出现超时 OJ 在线编程常见输入输出练习场 输入： 包括两个正整数 a, b (1 &lt;&#x3D; a, b &lt;&#x3D; 10^9)，输入数据包括多组输出： a+b 的结果 123456789101112131415// 组数不确定，组内元素数量确定，无结束输入条件package mainimport &quot;fmt&quot;func main() &#123; var a, b int for &#123; //也可以用 fmt.Scan n, _ := fmt.Scanln(&amp;a, &amp;b) if n == 0 &#123; break &#125; else &#123; fmt.Printf(&quot;%d &quot;, a+b) &#125; &#125;&#125; 输入： 第一行包括一个数据组数 t (1 &lt;&#x3D; t &lt;&#x3D; 100)，接下来每行包括两个正整数 a, b (1 &lt;&#x3D; a, b &lt;&#x3D; 10^9)输出： a+b 的结果 12345678910111213141516171819202122232425// 组数确定，组内元素数量确定func main() &#123; var t, a, b int fmt.Scanln(&amp;t) for i := 0; i &lt; t; i++ &#123; fmt.Scanln(&amp;a, &amp;b) fmt.Printf(&quot;%d &quot;, a + b) &#125;&#125;func main() &#123;\treader := bufio.NewReader(os.Stdin)\t// 输入的组数\ttime, _ := reader.ReadString(&#x27; &#x27;)\ttimes, _ := strconv.Atoi(strings.TrimSpace(time))\t// 每一组两个元素\tfor i := 0; i &lt; times; i++ &#123; // 读取 n 和 k line, _ := reader.ReadString(&#x27; &#x27;) params := strings.Fields(line) n, _ := strconv.Atoi(params[0]) k, _ := strconv.Atoi(params[1]) fmt.Println(n, k)\t&#125;&#125; 输入： 包括两个正整数 a, b (1 &lt;&#x3D; a, b &lt;&#x3D; 10^9)，输入数据有多组，如果输入为 0 0 则结束输入输出： a+b 的结果 123456789101112// 组数不确定，组内元素确定，有结束输入条件func main() &#123; var a, b int for &#123; fmt.Scanln(&amp;a, &amp;b) if a == 0 &amp;&amp; b == 0 &#123; break &#125; else &#123; fmt.Printf(&quot;%d &quot;, a + b) &#125; &#125;&#125; 输入： 输入数据包括多组。每组数据一行，每行的第一个整数为整数的个数 n (1 &lt;&#x3D; n &lt;&#x3D; 100)，n 为 0 的时候结束输入。接下来 n 个正整数，即需要求和的每个正整数。输出： 每组数据输出求和的结果 123456789101112131415161718// 组数不确定，组内元素数量确定并用数组装，有结束输入条件func main() &#123; var t int for &#123; var sum int fmt.Scan(&amp;t) if t == 0 &#123; break &#125; else &#123; a := make([]int, t) for i := 0; i &lt; t; i++ &#123; fmt.Scan(&amp;a[i]) sum += a[i] &#125; &#125; fmt.Println(sum) &#125; &#125; 输入： 第一行包括一个正整数 t (1 &lt;&#x3D; t &lt;&#x3D; 100)，表示数据组数。接下来 t 行, 每行一组数据。每行的第一个整数为整数的个数 n (1 &lt;&#x3D; n &lt;&#x3D; 100)。接下来 n 个正整数，即需要求和的每个正整数。输出： 每组数据输出求和的结果 1234567891011121314// 组数确定，组内元素数量确定func main() &#123; var t int fmt.Scan(&amp;t) for i := 0; i &lt; t; i++ &#123; var num, sum, a int fmt.Scan(&amp;num) for j := 0; j &lt; num; j++ &#123; fmt.Scan(&amp;a) sum += a &#125; fmt.Println(sum) &#125;&#125; 输入： 输入数据有多组，每行表示一组输入数据。每行的第一个整数为整数的个数 n(1 &lt;&#x3D; n &lt;&#x3D; 100)。接下来 n 个正整数, 即需要求和的每个正整数。输出： 每组数据输出求和的结果 123456789101112131415161718// 组数不确定，组内元素数量确定并用数组装，无结束输入条件func main() &#123; var t int for &#123; var sum int n, _ := fmt.Scan(&amp;t) if n == 0 &#123; break &#125; else &#123; nums := make([]int, t) for i := 0; i &lt; t; i++ &#123; fmt.Scan(&amp;nums[i]) sum += nums[i] &#125; &#125; fmt.Println(sum) &#125;&#125; 输入： 输入数据有多组，每行表示一组输入数据。每行不定有 n (1 &lt;&#x3D; n &lt;&#x3D; 100) 个整数，空格隔开。输出： 每组数据输出求和的结果 12345678910111213141516171819202122232425// 组数不确定，组内元素数量不确定⚠️，无结束输入条件package mainimport ( &quot;bufio&quot; &quot;fmt&quot; &quot;os&quot; &quot;strconv&quot; &quot;strings&quot;)func main() &#123; sc := bufio.NewScanner(os.Stdin) //每次读入一行 for sc.Scan() &#123; //通过空格将他们分割，并存入一个字符串切片 strs := strings.Split(sc.Text(), &quot; &quot;) var sum int for i := range strs &#123; //将字符串转换为 int val, _ := strconv.Atoi(strs[i]) sum += val &#125; fmt.Println(sum) &#125;&#125; 输入： 输入有两行，第一行 n，第二行是 n 个空格隔开的字符串输出： 输出一行排序后的字符串，空格隔开，无结尾空格 1234567891011121314151617181920212223242526// 组数确定，组内元素数量确定package mainimport (\t&quot;fmt&quot;\t&quot;sort&quot;\t&quot;strings&quot;)func main() &#123; var t int fmt.Scanln(&amp;t) strs := make([]string, t) for i := 0; i &lt; t; i++ &#123; fmt.Scan(&amp;strs[i]) &#125; sort.Strings(strs) fmt.Println(strings.Join(strs, &quot; &quot;)) // sc := bufio.NewScanner(os.Stdin)\t// for sc.Scan() &#123;\t// strs := strings.Split(sc.Text(), &quot; &quot;)\t// sort.Strings(strs)\t// fmt.Println(strings.Join(strs, &quot; &quot;))\t// &#125;&#125; 输入： 多个测试用例，每个测试用例一行。每行通过空格隔开，有 n 个字符串，n＜100输出： 对于每组测试用例，输出一行排序过的字符串，每个字符串通过空格隔开 123456789// 组数不确定，组内元素数量不确定⚠️func main() &#123; sc := bufio.NewScanner(os.Stdin) for sc.Scan() &#123; strs := strings.Split(sc.Text(), &quot; &quot;) sort.Strings(strs) fmt.Println(strings.Join(strs, &quot; &quot;)) &#125;&#125; 输入： 多个测试用例，每个测试用例一行。每行通过 , 隔开，有 n 个字符串，n＜100输出： 对于每组用例输出一行排序后的字符串，用 , 隔开，无结尾空格 123456789// 和上面那个一样的func main()&#123; sc := bufio.NewScanner(os.Stdin) for sc.Scan()&#123; strs := strings.Split(sc.Text(),&quot;,&quot;) sort.Strings(strs) fmt.Println(strings.Join(strs, &quot;,&quot;)) &#125;&#125; 构造二叉树123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566package mainimport &quot;fmt&quot;type TreeNode struct &#123;\tVal int\tLeft *TreeNode\tRight *TreeNode&#125;func constructBinaryTree(array []int) *TreeNode &#123;\tvar root *TreeNode\tnodes := make([]*TreeNode, len(array))\t// 初始化二叉树节点\tfor i := 0; i &lt; len(nodes); i++ &#123; var node *TreeNode if array[i] != -1 &#123; node = &amp;TreeNode&#123;Val: array[i]&#125; &#125; nodes[i] = node if i == 0 &#123; root = node &#125;\t&#125;\t// 串联节点\tfor i := 0; i*2+2 &lt; len(nodes); i++ &#123; if nodes[i] != nil &#123; nodes[i].Left = nodes[i*2+1] nodes[i].Right = nodes[i*2+2] &#125;\t&#125;\treturn root&#125;// 层序列遍历func printBinaryTree(root *TreeNode) &#123;\tres := make([][]int, 0)\tif root == nil &#123; fmt.Println(res) return\t&#125;\tcurLevel := []*TreeNode&#123;root&#125;\tfor len(curLevel) &gt; 0 &#123; nextLevel := make([]*TreeNode, 0) vals := make([]int, 0) for _, node := range curLevel &#123; vals = append(vals, node.Val) if node.Left != nil &#123; nextLevel = append(nextLevel, node.Left) &#125; if node.Right != nil &#123; nextLevel = append(nextLevel, node.Right) &#125; &#125; res = append(res, vals) curLevel = nextLevel\t&#125;\tfmt.Println(res)&#125;func main() &#123;\t// 用 -1 来表示 nil\tarray := []int&#123;4, 1, 6, 0, 2, 5, 7, -1, -1, -1, 3, -1, -1, -1, 8&#125;\troot := constructBinaryTree(array)\tprintBinaryTree(root)&#125; 武器库标准库容器 slice（切片） map（散列表） list（双向链表） heap（堆） ring（环） 排序函数 123456789101112import &quot;sort&quot;// in ascending order.func sortExample(exampleSlice []int) &#123; sort.Slice(exampleSlice, func(i, j int) bool &#123; return exampleSlice[i] &lt; exampleSlice[j] &#125;)&#125;func sortExample(exampleSlice []int) &#123; sort.Ints(exampleSlice)&#125; 反转切片 123456func ReverseSlice(slice []int) &#123;\tfor i := 0; i &lt; len(slice)/2; i++ &#123; j := len(slice) - i - 1 slice[i], slice[j] = slice[j], slice[i]\t&#125;&#125; 使用 Map 计数 12345678// Example of using map for counting occurrences of elements in a slice.func countOccurrences(nums []int) map[int]int &#123;\tcounts := make(map[int]int)\tfor _, num := range nums &#123; counts[num]++\t&#125;\treturn counts&#125; 检查 Map 中是否存在某个元素 123456// Example of using map for checking if an element exists.func checkElements(numsMap map[int]int, certainValue int) bool &#123;\t// Check if the certainValue exists in the numsMap\t_, exists := numsMap[certainValue]\treturn exists&#125; 栈的 Push 和 Pop 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354package mainimport (\t&quot;fmt&quot;)// Stack Define a struct for the Stacktype Stack struct &#123;\tdata []interface&#123;&#125;&#125;// Push adds an element to the top of the stackfunc (s *Stack) Push(item interface&#123;&#125;) &#123;\ts.data = append(s.data, item)&#125;// Pop removes and returns the top element from the stackfunc (s *Stack) Pop() interface&#123;&#125; &#123;\tif len(s.data) == 0 &#123; return nil // Stack is empty\t&#125;\titem := s.data[len(s.data)-1]\ts.data = s.data[:len(s.data)-1]\treturn item&#125;// Peek returns the top element of the stack without removing itfunc (s *Stack) Peek() interface&#123;&#125; &#123;\tif len(s.data) == 0 &#123; return nil // Stack is empty\t&#125;\treturn s.data[len(s.data)-1]&#125;// isEmpty returns true if the stack is empty, false otherwisefunc (s *Stack) isEmpty() bool &#123;\treturn len(s.data) == 0&#125;func main() &#123;\t// Create a new stack\tstack := Stack&#123;&#125;\t// Push elements onto the stack\tstack.Push(1)\tstack.Push(2)\tstack.Push(3)\t// Peek at the top element\tfmt.Println(&quot;Top element:&quot;, stack.Peek())\t// Pop elements from the stack\tfmt.Println(&quot;Popped element:&quot;, stack.Pop())\tfmt.Println(&quot;Popped element:&quot;, stack.Pop())\t// Check if the stack is empty\tfmt.Println(&quot;Is stack empty?&quot;, stack.isEmpty())&#125; 常见排序冒泡 12345678910111213func bubbleSort(nums []int) []int &#123;\tif len(nums) &lt;= 1 &#123; return nums\t&#125;\tfor i := 0; i &lt; len(nums); i++ &#123; for j := 0; j &lt; len(nums)-i-1; j++ &#123; if nums[j] &gt; nums[j+1] &#123; nums[j], nums[j+1] = nums[j+1], nums[j] &#125; &#125;\t&#125;\treturn nums&#125; 快速 1234567891011121314151617181920212223242526272829303132/* 快速排序 */func quickSort(nums []int, left, right int) &#123;\t// 子数组长度为 1 时终止递归\tif left &gt;= right &#123; return\t&#125;\t// 哨兵划分\tpivot := partition(nums, left, right)\t// 递归左子数组、右子数组\tquickSort(nums, left, pivot-1)\tquickSort(nums, pivot+1, right)&#125;/* 哨兵划分 */func partition(nums []int, left, right int) int &#123;\t// 以 nums[left] 为基准数\ti, j := left, right\tfor i &lt; j &#123; for i &lt; j &amp;&amp; nums[j] &gt;= nums[left] &#123; j-- // 从右向左找首个小于基准数的元素 &#125; for i &lt; j &amp;&amp; nums[i] &lt;= nums[left] &#123; i++ // 从左向右找首个大于基准数的元素 &#125; // 元素交换 nums[i], nums[j] = nums[j], nums[i]\t&#125;\t// 将基准数交换至两子数组的分界线 // 此时 i 位置上的值并不会比基准数大\tnums[i], nums[left] = nums[left], nums[i]\treturn i // 返回基准数的索引&#125; 华为笔试回顾 2024.05.22 实习笔试沿用到秋招 2024.10.25 面试没问到笔试复盘 题目：给定两个链表，获取两者中相同节点值的 最大连续片段。如果没有公共片段，返回 -1 解答要求：时间限制: C&#x2F;C++ 1000ms, 其他语言: 2000ms 内存限制: C&#x2F;C++ 256MB, 其他语言: 512MB 输入：第一行表示链表 1，第二行表示链表 2，每条链表长度不超过 20 个元素，链表不会为空 输出：公共链表片段 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// 查找两个链表中最长的公共连续片段func findMaxCommonSegment(head1 *ListNode, head2 *ListNode) []int &#123;\tlist1 := linkedListToList(head1)\tlist2 := linkedListToList(head2)\tn := len(list1)\tm := len(list2)\t// 创建 DP 表\tdp := make([][]int, n+1)\tfor i := range dp &#123; dp[i] = make([]int, m+1)\t&#125;\tmaxLen := 0 // 记录最长公共片段的长度\tendIdx := -1 // 记录最长公共片段的结束位置\t// 动态规划填表\tfor i := 1; i &lt;= n; i++ &#123; for j := 1; j &lt;= m; j++ &#123; if list1[i-1] == list2[j-1] &#123; dp[i][j] = dp[i-1][j-1] + 1 if dp[i][j] &gt; maxLen &#123; maxLen = dp[i][j] endIdx = i - 1 &#125; &#125; &#125;\t&#125;\t// 如果没有公共片段，返回 -1\tif maxLen == 0 &#123; return []int&#123;-1&#125;\t&#125;\t// 获取最长公共片段\tstartIdx := endIdx - maxLen + 1\treturn list1[startIdx : endIdx+1]&#125;// 将链表转换为数组func linkedListToList(head *ListNode) []int &#123;\tvar list []int\tfor head != nil &#123; list = append(list, head.Val) head = head.Next\t&#125;\treturn list&#125; 题目：露天矿采矿作业的特点是规模大，矿石和废料的移动量达到百万吨，运输成本开销较大，需要寻求一种最优的运输路径节省成本。 已知矿场可以划分成 N*M 的网格图，每个网格存在地形的差异，因此通过不同网格时，成本开销存在差异 标志为’S’的网格为运输起点； 标志为’E”的网格时运输终点； 标志为’B’的网格为阻塞点，不允许通行； 标志为’C’的网格为检查点，矿车在运输路径中，至少需要进入一次检查点。 标志为‘数字”的网格，其数字表示经过该网格的成本开销。 运输矿车只能上下左右 4 个方向运行，不允许斜对角进入其他网格。必要时可重复进入网格，请根据输入的网格图，寻求一条从 S 网格到 E 网格，并且至少经过一次检查点的最低成本运输路径，并输出其成本开销 解答要求：时间限制: C&#x2F;C++ 1000ms, 其他语言: 2000ms 内存限制: C&#x2F;C++ 256MB, 其他语言: 512MB 输入： 第一行：网格图的行数 N [3,200] 和网格图的列数 M [3,200]，使用空格隔开。 第二行至第 N+1 行：网格图每一行的元素，可以为’S’，E’，’B’，‘C’或者数字 [0,100]，并且有且仅有一个’S’和一个’E’，同时存在一个或者多个‘C’，并依次使用空格隔开。 输出：第一行：输出运输最低成本开销。如果不存在可达通路，请输出-1 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114package mainimport (\t&quot;fmt&quot;\t&quot;math&quot;)type Node struct &#123;\tx, y int // 当前节点的坐标\tcost int // 到达该节点的开销\tvisitedC bool // 是否访问过检查点&#125;var directions = [][2]int&#123;&#123;-1, 0&#125;, &#123;1, 0&#125;, &#123;0, -1&#125;, &#123;0, 1&#125;&#125;func inBounds(x, y, N, M int) bool &#123;\treturn x &gt;= 0 &amp;&amp; x &lt; N &amp;&amp; y &gt;= 0 &amp;&amp; y &lt; M&#125;// 主函数：最短路径求解func findMinCostPath(grid [][]string, N, M int) int &#123;\tvar startX, startY, endX, endY int\t// 构建cost图\tcostGrid := make([][]int, N)\tfor i := 0; i &lt; N; i++ &#123; costGrid[i] = make([]int, M) for j := 0; j &lt; M; j++ &#123; if grid[i][j] == &quot;S&quot; &#123; startX, startY = i, j &#125; else if grid[i][j] == &quot;E&quot; &#123; endX, endY = i, j &#125; else if grid[i][j] == &quot;B&quot; &#123; costGrid[i][j] = math.MaxInt32 // 阻塞点不可达 &#125; else if grid[i][j] == &quot;C&quot; &#123; costGrid[i][j] = 0 // 检查点本身无需额外成本 &#125; else &#123; fmt.Sscanf(grid[i][j], &quot;%d&quot;, &amp;costGrid[i][j]) &#125; &#125;\t&#125;\t// 定义 BFS 队列\tqueue := []Node&#123;&#123;startX, startY, 0, false&#125;&#125;\t// 记录访问状态和最小成本\tvisited := make([][][]bool, N)\tminCost := make([][][]int, N)\tfor i := range visited &#123; visited[i] = make([][]bool, M) minCost[i] = make([][]int, M) for j := range visited[i] &#123; visited[i][j] = make([]bool, 2) // 记录是否访问过该点，分为是否经过检查点的两种状态 minCost[i][j] = []int&#123;math.MaxInt32, math.MaxInt32&#125; &#125;\t&#125;\tvisited[startX][startY][0] = true\tminCost[startX][startY][0] = 0\t// 开始 BFS\tfor len(queue) &gt; 0 &#123; node := queue[0] queue = queue[1:] x, y, cost, visitedC := node.x, node.y, node.cost, node.visitedC // 到达终点并且经过了检查点 if x == endX &amp;&amp; y == endY &amp;&amp; visitedC &#123; return cost &#125; // 扩展到四个方向 for _, dir := range directions &#123; nx, ny := x+dir[0], y+dir[1] if !inBounds(nx, ny, N, M) || grid[nx][ny] == &quot;B&quot; &#123; continue &#125; newCost := cost + costGrid[nx][ny] newVisitedC := visitedC || grid[nx][ny] == &quot;C&quot; state := 0 if newVisitedC &#123; state = 1 &#125; // 如果新状态的代价小于当前记录的最小代价，则更新并加入队列 if newCost &lt; minCost[nx][ny][state] &#123; minCost[nx][ny][state] = newCost queue = append(queue, Node&#123;nx, ny, newCost, newVisitedC&#125;) visited[nx][ny][state] = true &#125; &#125;\t&#125;\t// 无法找到满足条件的路径\treturn -1&#125;func main() &#123;\tvar N, M int\tfmt.Scan(&amp;N, &amp;M)\tgrid := make([][]string, N)\tfor i := 0; i &lt; N; i++ &#123; grid[i] = make([]string, M) for j := 0; j &lt; M; j++ &#123; fmt.Scan(&amp;grid[i][j]) &#125;\t&#125;\tresult := findMinCostPath(grid, N, M)\tfmt.Println(result)&#125; 资料 代码随想录 Hello 算法","categories":["Golang"]},{"title":"Go 基础与语法特性 🚪","path":"/2023/10/28/go/","content":"基本语法 + 函数式编程 + 面向接口 + 并发编程 参考资料 Go 入门指南 Gogogo!国内镜像 12345# Windowsgo env -w GO111MODULE=ongo env -w GOPROXY=https://goproxy.cn,direct$env:GO111MODULE = &quot;on&quot;$env:GOPROXY = &quot;https://goproxy.cn&quot; goimports 1go install golang.org/x/tools/cmd/goimports@latest 在 File Watchers 插件（文件修改时触发任务）中添加 go fmt，goimports 工具 GoLand 2023.1.3 使用 ideaVim 2.6.1 插件在普通模式下 u 按键无效，整了半天，最后降级插件版本问题消失。 新建模板 1234567// Package $&#123;GO_PACKAGE_NAME&#125; -----------------------------// @file : $&#123;FILE_NAME&#125;// @author : hcjjj// @contact : hcjjj@foxmail.com// @time : $&#123;DATE&#125; $&#123;TIME&#125;// -------------------------------------------package $&#123;GO_PACKAGE_NAME&#125; 基础语法 变量定义 变量类型写在变量名之后 编译器可推测变量类型 没有 char，只有 rune 原生支持复数类型 任何地方都可通过 _ 省略变量 条件语句 没有 while if 的条件里可以定义变量，作用域就在这个 if 语句里 switch 会自动 break，除非使用 fallthrough switch 后可以没有表达式 循环 for, if 后面的条件没有括号 for 的条件里可以省略初始条件，结束条件，递增表达式 for 省略初始条件，相当于 while for 省略全部，相当于无限循环 函数 返回值类型写在最后面 函数可返回多个值 函数返回多个值时可以起名字，仅用于非常简单的函数 对于调用者而言没有区别 函数作为参数 没有默认参数，可选参数 支持可变参数列表 指针 指针不能运算 go 只有值传递一种方式 内建容器 数组 数量写在类型前 如果只要 i，可写成 for i := range numbers 要下表和值，for i, v := range numbers 只要值， for _, v := ranger numbers [10]int 和 [20]int 是不同类型 数组是值类型，调用 func f(arr [10] int) 会拷贝数组 在 go 语言中一般不直接使用数组 Slice （切片） Slice 本身没有数据，是对底层 array 的一个 view Slice 可以直接修改 array 的值 Reslice s := arr[2;6] s = s[:3] Slice 的扩展（slice 包含三个变量 ptr len cap） Slice 可以向后扩展，不可以向前扩展 s[i] 不可以超越 len(s)，向后扩展不可以超越底层数组 cap(s) 添加元素时如果超越 cap，系统会重新分配更大的底层数组 由于值传递的关系，必须接收 append 的返回值，s = append(s, val) Map 创建：make(map[string]int) 获取元素：m[key] key 不存在时，获得 value 类型的初始值 用 value,ok := m[key] 来判断是否存在 key 用 delete 删除一个 key 使用 range 遍历 key，或者遍历 key, value 对 不保证遍历顺序，如需顺序，需手动对 key 排序 使用 len 获取元素的个数 map 使用哈希表，必须可以比较相等 除了 slice, map, function的内建类型都可以作为 key Struct 类型不包含上述字段，也可作为 key String 使用 range 遍历 pos, rune 对 使用 utf8.RuneCountInString 获得字符数量 使用 len() 获得字节长度 使用 []byte 获得字节 字符串的相关方法在 strings 包下 面向“对象” 结构体和方法 go 语言仅支持封装，不支持继承和多态 go 语言没有 class，只有 struct 结构可以使用自定义工厂函数 定义方法接收者 只有使用指针才可以改变结构内容 nil 指针也可以调用方法 值接收者 是 go 语言特有的 值&#x2F;指针接收者均可接收值&#x2F;指针 注意可以返回局部变量的地址给别人用！结构创建在堆上还是栈上？不需要知道 包和封装 命名一般使用 CamelCase 首字母大写：public，首字母小写：private（针对包） 每个目录一个包 main 包包含可执行入口 为结构定义的方法必须放在同一个包内，可以是不同文件 扩充系统类型或者别人的类型：定义别名（最简单）、组合（最常用）、内嵌（语法糖，省代码） 依赖管理依赖管理的三个阶段（三种方式）：GOPATH，GOVENDOR，GOMODULE GOPATH 默认在 ~/go (unix, linux)，%USERPROFILE%\\go (windows) 依赖查找顺序： GOROOT/src → GOPATH/src GOVERDOR 每个项目有自己的vendor目录，存放第三方库 大量第三方依赖管理工具：glide, dep, go dep, … 依赖查找顺序： verdor → GOROOT/src → GOPATH/src GOMODULE（go.mod） 由 go 命令统一的管理，用户不必关心目录结构 go get [@v...] add dependencies to current module and install them go mod tidy add missing and remove unused modules go.mod, go.sum 文件 依赖的位置在：GOPATH/pkg/mod 旧方式迁移到 go.mod go mod init initialize new module in current directory go build ./... compile packages and dependencies 目录的整理 go build ./... 编译多个目录的时候不产生 exe go install ./... compile and install packages and dependencies 生成的文件在 GOPATH/bin 面向接口 类似 duck typing，不关注内部细节，只关注行为 java 编码时检查 c++ 编译时检查 python 运行时检查 go 运行时类型检查 + 灵活性 接口由使用者定义 接口里面全是函数，不需要加 func 接口的实现是隐式的，只要实现接口里的方法 接口变量：实现者的类型 + 实现者的值（指针） 接口变量同样采用值传递（里面一般是实现者的指针，占用很小），几乎不需要使用接口的指针 指针接收者实现只能以指针方式使用，值接收者都可 查看接口变量 表示任何类型：interface{} Type Assertion Type Switch 常用系统接口 Stringer Reader Writer 函数式编程 函数式编程 vs 函数指针 函数是一等公民：参数，变量，返回值都可以是函数 高阶函数（函数的参数是函数） 函数 → 闭包 闭包 函数体：局部变量 + 自由变量（函数所处环境的变量） “函数类型”也可以作为接收者，实现接口 go 的闭包不需要修饰如何访问自由变量 go 没有Lambda表达式，但是有匿名函数 资源管理与错误处理 资源管理 - defer 调用 确保调用在函数结束时发生 参数在 defer 语句时计算 defer 列表为后进先出（栈） 何时使用 Open &#x2F; Close Lock &#x2F; Unlock PrintHeader &#x2F; PrintFooter 错误处理 服务器统一错误处理 panic 停止当前函数执行 一直向上返回，执行每一层的 defer 如果没有遇见recover，程序退出 recover 仅在 defer 调用中使用 获取 panic 的值 如果无法处理，可重新 panic error vs panic 意料之中的，使用error。如：文件打不开 意料之外的，使用panic。如：数组越界 错误处理综合示例 defer + panic + recover Type Assertion 函数式编程的灵活应用 测试与性能调优 传统测试 vs 表格驱动测试 传统测试（assertEquals） 测试数据和测试逻辑混在一起 出错信息不明确 一旦一个数据出错测试全部结束 表格驱动测试 分离测试数据和测试逻辑 明确的出错信息 可以部分失败 go 语言的语法使得我们更易实践表格驱动测试 go 测试 正确性测试 *testing.T go test . 命令行运行测试 代码覆盖率 性能测试 *testing.B go test -bench . 性能调优 go test -bench . -cpuprofile cpu.out go tool pprof cpu.out 输入 web 命令报错，需要安装 Gvedit 12345678910111213141516171819PS D:\\HiddenTrack\\LearnGo\\01_foundation\\code\\container onrepeatingsubstr&gt; go test -bench . -cpuprofile cpu.out goos: windows goarch: amd64 pkg: code/container/nonrepeatingsubstr cpu: AMD Ryzen 7 6800H with Radeon Graphics BenchmarkSubstr-16 396 3045160 ns/op --- BENCH: BenchmarkSubstr-16 nonrepeating_test.go:41: len(s) = 491520 nonrepeating_test.go:41: len(s) = 491520 nonrepeating_test.go:41: len(s) = 491520 PASS ok code/container/nonrepeatingsubstr 1.701s PS D:\\HiddenTrack\\LearnGo\\01_foundation\\code\\container onrepeatingsubstr&gt; go tool pprof cpu.out Type: cpu Time: Nov 18, 2023 at 2:01pm (CST) Duration: 1.66s, Total samples = 1.42s (85.78%) Entering interactive mode (type &quot;help&quot; for commands, &quot;o&quot; for options) (pprof) web http 测试 通过使用假的 Request &#x2F; Response 通过起服务器 httptest.NewServer 用注释写文档 自带的CLI go doc 查看文档 在 []_test.go 文件中加入 Example godoc 生成文档 go get golang.org/x/tools/cmd/godoc godoc -http :6060 Goroutine 协程 Coroutine 轻量级“线程” 非抢占式多任务处理，由协程主动交出控制权 编译器&#x2F;解释器&#x2F;虚拟机层面的多任务，操作系统层面只有线程 多个协程可能在一个或多个线程上运行 子程序是协程的一个特例，普通函数是单向，协程是双向 Goroutine Go 中的协程 任何函数只需加上 go 就能送给调度器运行 不需要在定义时区分是否是异步函数 调度器在合适的点进行切换 使用 go run -race 来检测数据访问冲突 goroutine 可能的切换点 I&#x2F;O, select channel 等待锁 函数调用（有时） runtime.Gosched() （手动） 只是参考，不能保证切换，不能保证在其他地方不切换 运行的机制还是非抢占式的 Channel 基础使用 channel buffered channel close, range 理论基础：Communication Sequential Process (CSP) Don’t communicate by sharing memory; share memory by communicating 使用 Channel 来等待 goroutine 结束 使用 Channel 来实现树的遍历（遍历结果序列化） 使用 Select 来进行调度（可以让 chan 变为非阻塞） 传统同步机制（很少使用，他们是用共享内存来通信） WaitGroup Mutex（lock&#x2F;unlock） Cond 标准库 html&#x2F;template, net&#x2F;rpc net&#x2F;http 使用 http客户端发送请求 使用 http.Client 控制请求头部等 使用 httputil 简化工作 http 服务器性能分析 import _ “net&#x2F;http&#x2F;pprof” 访问 http://localhost:8888/debug/pprof/ 或 go tool pprof http://localhost:8888/debug/pprof/ ... fmt, log, erors io, bufio, time charset, encoding, unicode, utf8 strings, bytes, strconv regexp, flag, math os, pprof, runtime reflect, testing 查看标准库文档 方式一：godoc -http :8888 方式二：https://studygolang.com/pkgdoc Go 没有的元素 类，继承，多态，重载 go语言拥有不同的世界观 在面向对象界，也流行变继承为组合的思维 这些面向对象的元素太容易被滥用 go语言为组合提供了便捷的支持 try&#x2F;catch&#x2F;finally 太多错误被当做异常 很多 c++ 项目组本身禁用 try&#x2F;catch 正确的使用 try&#x2F;catch 处理错误，导致代码混乱 try&#x2F;catch 在产品代码中并不能减小开发人员负担 go 使用 defer&#x2F;panic&#x2F;recover 模式 构造函数&#x2F;析构函数&#x2F;RAII 大型项目中很少使用构造函数，多使用工厂函数 值类型的构造由结构体初始化语法实现 RAII技巧性太强，隐藏了意图 析构函数与垃圾回收不匹配 泛型 泛型作为模板类型 实际想实现 duck typing go语言提供了对 duck typing，及接口组合的支持 泛型约束参数类型 本身非常复杂：类型通配符，covariance 等问题 go 语言本身自带强类型的 slice, map, channel 使用 type assertion 甚至 go generate 来实现自己的泛型 泛型支持是作者唯一态度不强硬的点 操作符重载，assert 要抛弃“模拟”的思想，直接使用 Go 的元素来搭建系统。","tags":["Golang"],"categories":["Golang"]},{"title":"「一本十年前的书」程序员生存定律","path":"/2023/10/06/laws/","content":"程序员生存定律 李智勇， 2014-06-08 书中试图用四个可控变量来定义程序人生的规律，它们分别是： 自身价值 —— 你能干什么 自身价值上的表达力 —— 别人认为你能干什么 自身价值的稀缺性 —— 在特定时空背景下，市场对某种技能的渴求程度 身处公司的特质和未来 —— 公司提供了怎样的平台给人发挥 这四个变量一起决定了一个人在职场中的市场价值，个人的一切选择主要是为了在这四个变量上有所收益，并使市场价值最大化。 代码之外的人生程序员的人生出口： 成就超一流高手 积累、爆发、开始创业 转向管理之路 维持原状的老码农 提前退场、向代码说再见 职场生存定律 交换是职场里一切的根本 生存定律总纲 技能 S 是指一个人所能做的事，即自身价值； 实现程度 A 则是指各种技能被周围的人认知的程度； 如果收入水平为 I，那么当 S × A ＞ I 时一个人是有选择权的也是安全的，否则一个人对于公司而言是负资产（至少是被认为是负资产），潜在的有被剔除的风险； 有几个因素会使实现程度 A 急速膨大，为：自身价值表达力，自身价值的稀缺性，公司的特质和未来。 软件的世界是怎样的 技术更迭偏快 介入门槛偏低 软件和软件差别可以很大 这三者类似于全局常量，而个人努力则类似于变量，它们共同在生存定律之下起作用，影响人生的最终高度。从自我增值的角度看，最关键的事情是不能与这三者所带来的效应相违背。 程序员的增值之路对程序员而言最根本的始终是自己的价值，忽视自身价值提升而单纯沉迷于成功学这类方法论，早晚会吃到苦果。 方向的选择：技术还是管理 增值之路的起点 如何顺利的成为高手 高手的定义和养成关键 全局性的地图 程序员到架构师 程序员到CodeGuru 程序员到纯管理 增值路上常见的“坑” 学习失去焦点 学习与实践相分离 “博”与“专”上的迷失 错过人生中的好时机 停止知识更新 给自己找一个驱动力 纯物质上的驱动力 兴趣的力量 使人生永动的势能 程序员的表达力磨砺 表达力的类别和作用 改善表达力的途径 影响表达力的关键因素：资历、性格与习惯、借势与公司政治 给自己一点资历 去除性格和习惯中的致命缺陷 善用借势 了解一点“政治” 检查自己的表达力 检查自己的表达力 程序员的稀缺性营造 稀缺性可带给你什么 改善稀缺性的途径 提升自己 顺应时势 检查自己的稀缺性 从技术角度看，稀缺性就是选定一个技术路径长的，不处在衰落期的领域，不停的打磨，不停的前行 程序员的公司选择 公司的分类 一个人要想做对选择，一要有选择权，二则要了解待选项 公司的选择 六个程序员的故事 一个40岁老程序员的无奈 一个普通码农的退场过程 一个关于项目经理的故事 一个技术牛人的成长经历 一个创业者的十年 一个女程序员的编程之旅","tags":["programmer"],"categories":["Reading"]},{"title":"《时间的秩序》","path":"/2023/10/03/time/","content":"作者：[意] 卡洛·罗韦利，出版年：2019 The Order of TimeThe Crumbling of Time 不存在单一的时间，每个轨迹都有自己的持续时间；根据位置与速度，时间会以不同节奏流逝。 时间是没有方向的：在世界的基本方程中，过去与未来的区别并不存在；方向性只在我们进行观察并忽略细节时偶然出现。 在这种模糊的视角下，宇宙的过去处于一种奇特的“特定”状态。“当下”的概念不再奏效：在广袤的宇宙中，没有我们可以合理地称为“当下”的东西。 决定时间长度的物理基础不是一个区别于世界其他组成部分的独立实体，而是动态场的一个方面。它会跳跃、涨落，只在相互作用时实体化，在最小尺度之下无法被发现。 时间失去了统一性、方向性、当下、独立性、连续性。 The World without Time 基本方程中“时间”的消失并不意味着世界会静止不变，恰恰相反，这意味着变化普遍存在，无须被时间国王指挥。 我们可以把世界看作由物体、物质、实体这一类东西构成。或者我们可以把它看作由事件、发生、过程、出现组成。它不能持久，会不断转化，无法在时间中永恒。这是一种领悟，认识到无常的普遍性，而不是一切在静止的时间里停滞。 研究得越多，越难以从“存在的东西”这个角度去理解世界，而从事件之间的关系来理解世界却容易得多。 时间的缺失并不意味着一切都停滞不变。它只能说明，让世界感到疲倦的不间断的事件并不是按时间顺序排列的，无法被一个巨大的钟表测量。 这些都来自生命自身的体验：脆弱，短暂，充满幻觉。这段话谈到的事情比时间的物理本质还要深刻。 但带来伤感的并非失去，而是情感与爱。没有情感，没有爱，失去也就不会带来痛苦。因此，即使是失去带来的痛苦，也是好事，甚至很美妙，因为它让生命充满意义。 The Sources of Time 时间的流动不是宇宙的特征，就像天空的旋转，来自我们在自己角落中的独特视角。 世界是事件的集合，不按时间顺序排列。这些事件会在先验的物理量之间显示出同一层次的关系。世界的每个部分与全部变量的一小部分相互作用，数值决定了“世界相对于那个特殊子系统的状态”。 一个小系统无法区分宇宙其余部分的细节，因为它只与宇宙其余部分的很少一部分变量相互作用。 存在的是过去的痕迹，而非未来的痕迹，仅仅是因为过去的熵较低。不可能有其他原因，因为过去与未来之间区别的唯一来源就是过去的低熵。 我们的现在充斥着过去的痕迹。我们是自己的历史。我是我自己讲述的故事。 时间是我们身份的来源，当然也是我们痛苦的来源。 一切生起的必然灭去。使我们受苦的不在过去或未来，它就在那儿，现在，在我们的记忆里，在我们的期待里。我们渴望永恒，我们忍受着时间的流逝，我们因时间而受苦。时间即苦。 我们停下来，屏住呼吸，神秘地感觉到这一定是意义的源头，这就是时间的来源。 然后乐声逐渐消失。“银链折断，金罐破裂，瓶子在泉旁损坏，水轮在井口破烂；尘土仍归于地。”这样很好。我们可以闭上双目，开始休息了。对我来说，这一切合理又美妙。这就是时间。 Time is a Feeling","categories":["Reading"]},{"title":"C++ 多线程编程","path":"/2023/09/01/cpp/","content":"C++ 多线程编程入门实践 创建线程函数指针1234567891011121314151617181920212223242526#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;thread&gt;#include &lt;unistd.h&gt;using namespace std;void show(int id, int count, const string &amp;str);int main() &#123; // 创建线程, 传递参数 thread t1(show, 1, 10, &quot;hello&quot;); thread t2(show, 2, 20, &quot;world&quot;); // 主线程阻塞，等待子线程运行结束 t1.join(); t2.join(); cout &lt;&lt; &quot;Bye!&quot; &lt;&lt; endl; return 0;&#125;void show(int id, int count, const string &amp;str) &#123; for (int i = 0; i &lt; count; ++i) &#123; cout &lt;&lt; &quot;Thread &quot; &lt;&lt; id &lt;&lt; &quot;: &quot; &lt;&lt; str &lt;&lt; endl; sleep(1); &#125;&#125; 编译运行：g++ lesson1.cpp -pthread &amp;&amp; ./a.out 函数对象123456789101112131415161718192021222324252627282930313233343536#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;thread&gt;#include &lt;unistd.h&gt;using namespace std;class Show &#123; private: int id; int count; string str; public: Show(int i, int c, string s) : id(i), count(c), str(s) &#123;&#125;; void operator()() const &#123; for (int i = 0; i &lt; count; ++i) &#123; cout &lt;&lt; &quot;Thread &quot; &lt;&lt; id &lt;&lt; &quot;: &quot; &lt;&lt; str &lt;&lt; endl; sleep(1); &#125; &#125;&#125;;int main() &#123; // Show s1(1, 10, &quot;Hello&quot;); // Show s2(2, 10, &quot;World&quot;); // 类的对象当作函数来用 // thread t1(s1); // thread t2(s2); // 构造函数返回匿名对象 thread t1(Show(1, 10, &quot;Hello&quot;)); thread t2(Show(2, 10, &quot;World&quot;)); t1.join(); t2.join(); cout &lt;&lt; &quot;Bye!&quot; &lt;&lt; endl; return 0;&#125; Lambda表达式12345thread t3([](int id, int count, string str) &#123; for (int i = 0;i &lt; count; ++i) &#123; cout &lt;&lt; &quot;Thread &quot; &lt;&lt; id &lt;&lt; &quot;: &quot; &lt;&lt; str &lt;&lt; endl; &#125;&#125;, 3, 10, &quot;good&quot;); 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;thread&gt;#include &lt;unistd.h&gt;using namespace std;class Show &#123; private: int id; int count; string str; public: Show(int i, int c, string s) : id(i), count(c), str(s) &#123;&#125;; void operator()() const &#123; for (int i = 0; i &lt; count; ++i) &#123; cout &lt;&lt; &quot;Thread &quot; &lt;&lt; id &lt;&lt; &quot;: &quot; &lt;&lt; str &lt;&lt; endl; sleep(1); &#125; &#125; void display() &#123; for (int i = 0; i &lt;count; ++i) &#123; cout &lt;&lt; &quot;Thread &quot; &lt;&lt; id &lt;&lt; &quot;: &quot; &lt;&lt; str &lt;&lt; endl; sleep(1); &#125; &#125;&#125;;int main() &#123; Show s1(1, 10, &quot;Hello&quot;); // Show s2(2, 10, &quot;World&quot;); // 类的对象当作函数来用 thread t1(s1); // thread t2(s2); // 构造函数返回匿名对象 // thread t1( Show(1, 10, &quot;Hello&quot;)); thread t2( Show(2, 10, &quot;World&quot;)); // lambda 表达式创建线程 thread t3([](int id, int count, string str) &#123; for (int i = 0;i &lt; count; ++i) &#123; cout &lt;&lt; &quot;Thread &quot; &lt;&lt; id &lt;&lt; &quot;: &quot; &lt;&lt; str &lt;&lt; endl; &#125; &#125;, 3, 10, &quot;good&quot;); // 成员函数创建线程 Show s4(4, 10, &quot;nice&quot;); thread t4(&amp;Show::display, s4); t1.join(); t2.join(); t3.join(); t4.join(); cout &lt;&lt; &quot;Bye!&quot; &lt;&lt; endl; return 0;&#125; detach12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;thread&gt;#include &lt;unistd.h&gt;using namespace std;void funct();class Show &#123; private: int id; int count; string str; public: Show(int i, int c, string s) : id(i), count(c), str(s) &#123;&#125;; void operator()() const &#123; for (int i = 0; i &lt; count; ++i) &#123; cout &lt;&lt; &quot;Thread &quot; &lt;&lt; id &lt;&lt; &quot;: &quot; &lt;&lt; str &lt;&lt; endl; sleep(1); &#125; &#125;&#125;;int main() &#123; funct(); for (int i = 0; i &lt; 10; ++i) &#123; cout &lt;&lt; &quot;Main thread is running!&quot; &lt;&lt; endl; sleep(1); &#125; cout &lt;&lt; &quot;Bye!&quot; &lt;&lt; endl; return 0;&#125;// 在函数创建线程，要注意是否使用到局部变量的引用或者指针void funct() &#123; int id = 1; int count = 10; string str = &quot;Hello World&quot;; // 线程访问局部变量的隐患 // 按值传递没有问题，按引用传递要出问题 Show s1(id, count, str); thread t1(s1); // 主线程阻塞 // t1.join(); // 线程分离 t1.detach();&#125; thread_local123456789101112131415161718192021222324252627#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;unistd.h&gt;using namespace std;void threadFunction(int id);// 线程之间共享变量 iint i = 0;// 线程本地存储// 每个线程拷贝变量 j, 之间不共享thread_local int j = 0;int main() &#123; thread t1(threadFunction, 1); t1.join(); thread t2(threadFunction, 2); t2.join(); cout &lt;&lt; &quot;i = &quot; &lt;&lt; i &lt;&lt; &quot;, j = &quot; &lt;&lt; j &lt;&lt; endl;&#125;void threadFunction(int id) &#123; cout &lt;&lt; &quot;Thread &quot; &lt;&lt; id &lt;&lt; &quot;: i = &quot; &lt;&lt; i &lt;&lt; &quot;, j = &quot; &lt;&lt; j &lt;&lt; endl; ++i; ++j;&#125; move 1234567891011121314151617181920212223242526272829303132333435363738394041#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;unistd.h&gt;#include &lt;string&gt;using namespace std;void show(int count, const string &amp;str);int main() &#123; thread t1(show, 10, &quot;Hello&quot;); cout &lt;&lt; &quot;Thread1 id = &quot; &lt;&lt; t1.get_id() &lt;&lt; endl; sleep(5); // 线程移动 两个id 是一样的 thread t2 = std::move(t1); cout &lt;&lt; &quot;Thread2 id = &quot; &lt;&lt; t2.get_id() &lt;&lt; endl; cout &lt;&lt; &quot;t1.joinable = &quot; &lt;&lt; t1.joinable() &lt;&lt; endl; cout &lt;&lt; &quot;t2.joinable = &quot; &lt;&lt; t2.joinable() &lt;&lt; endl; // 判断子线程是否可以汇合到主线程 if (t1.joinable()) &#123; t1.join(); &#125; if (t2.joinable()) &#123; t2.join(); &#125; cout &lt;&lt; &quot;t1.joinable = &quot; &lt;&lt; t1.joinable() &lt;&lt; endl; cout &lt;&lt; &quot;t2.joinable = &quot; &lt;&lt; t2.joinable() &lt;&lt; endl; // 默认构造的线程 thread t3; cout &lt;&lt; &quot;t3.joinable = &quot; &lt;&lt; t3.joinable() &lt;&lt; endl; cout &lt;&lt; &quot;Bye!&quot; &lt;&lt; endl; return 0;&#125;void show(int count, const string &amp;str) &#123; for (int i = 0; i &lt; count; ++i) &#123; cout &lt;&lt; str &lt;&lt; endl; sleep(1); &#125;&#125; RAII机制子线程出现异常，导致主线程提前结束，子线程被迫终止。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;thread&gt;#include &lt;unistd.h&gt;using namespace std;void funct();class Show &#123; private: int id; int count; string str; public: Show(int i, int c, string s) : id(i), count(c), str(s) &#123;&#125;; void operator()() const &#123; for (int i = 0; i &lt; count; ++i) &#123; cout &lt;&lt; &quot;Thread &quot; &lt;&lt; id &lt;&lt; &quot;: &quot; &lt;&lt; str &lt;&lt; endl; sleep(1); &#125; &#125;&#125;;int main() &#123; funct(); for (int i = 0; i &lt; 10; ++i) &#123; cout &lt;&lt; &quot;Main thread is running!&quot; &lt;&lt; endl; sleep(1); &#125; cout &lt;&lt; &quot;Bye!&quot; &lt;&lt; endl; return 0;&#125;void funct() &#123; int id = 1; int count = 10; string str = &quot;Hello World&quot;; Show s1(id, count, str); thread t1(s1); int n1, n2; cout &lt;&lt; &quot;Please enter two numbers: &quot; &lt;&lt; endl; cin &gt;&gt; n1 &gt;&gt; n2; try &#123; if (n2 == 0) &#123; // 子线程出现异常 导致主线程结束 子线程被迫终止 throw runtime_error(&quot;n2 can&#x27;t be 0&quot;); &#125; cout &lt;&lt; &quot;n1 / n2 = &quot; &lt;&lt; n1 / n2 &lt;&lt; endl; &#125; catch(runtime_error) &#123; cout &lt;&lt; &quot;Quit with exception&quot; &lt;&lt; endl; // 主 等 子 t1.join(); // 主线程结束 return; &#125; t1.join();&#125; RAII机制，不需要多次 join() 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;thread&gt;#include &lt;unistd.h&gt;using namespace std;void funct();class Show &#123; private: int id; int count; string str; public: Show(int i, int c, string s) : id(i), count(c), str(s) &#123;&#125;; void operator()() const &#123; for (int i = 0; i &lt; count; ++i) &#123; cout &lt;&lt; &quot;Thread &quot; &lt;&lt; id &lt;&lt; &quot;: &quot; &lt;&lt; str &lt;&lt; endl; sleep(1); &#125; &#125;&#125;;class thread_guard &#123; private: thread &amp;g_thread; public: explicit thread_guard(thread &amp;my_thread) : g_thread(my_thread) &#123;&#125; ~thread_guard() &#123; if (g_thread.joinable()) &#123; g_thread.join(); &#125; &#125;&#125;;int main() &#123; funct(); for (int i = 0; i &lt; 10; ++i) &#123; cout &lt;&lt; &quot;Main thread is running!&quot; &lt;&lt; endl; sleep(1); &#125; cout &lt;&lt; &quot;Bye!&quot; &lt;&lt; endl; return 0;&#125;void funct() &#123; int id = 1; int count = 10; string str = &quot;Hello World&quot;; Show s1(id, count, str); thread t1(s1); thread_guard gt(t1); int n1, n2; cout &lt;&lt; &quot;Please enter two numbers: &quot; &lt;&lt; endl; cin &gt;&gt; n1 &gt;&gt; n2; try &#123; if (n2 == 0) &#123; // 子线程出现异常 throw runtime_error(&quot;n2 can&#x27;t be 0&quot;); &#125; cout &lt;&lt; &quot;n1 / n2 = &quot; &lt;&lt; n1 / n2 &lt;&lt; endl; &#125; catch(runtime_error) &#123; cout &lt;&lt; &quot;Quit with exception&quot; &lt;&lt; endl; // 结束后会自动执行析构函数 // t1.join(); // 主线程结束 // return; &#125; // 结束后会自动执行析构函数 // t1.join();&#125; 传递引用12345678910111213141516171819202122232425262728#include &lt;iostream&gt;#include &lt;thread&gt;using namespace std;// void threadFunction(int n);// void threadFunction(int *pt);void threadFunction(int &amp;r);int main() &#123; int i = 0; // thread t1(threadFunction, i); // thread t1(threadFunction, &amp;i); // 子线程修改主线程的变量 // 按引用的方式传递参数, 此时 i 不是副本了，而是 i 的引用 // 传递字符串的字面值的话是按照指针进行传递 char const *, 会发生隐式转换,可以不需要ref() thread t1(threadFunction, ref(i)); t1.join(); cout &lt;&lt; &quot;i = &quot; &lt;&lt; i &lt;&lt; endl; return 0;&#125;// void threadFunction(int n) &#123;// void threadFunction(int *pt) &#123;void threadFunction(int &amp;r) &#123; r += 100;&#125; CPU核心数 cout &lt;&lt; thread::hardware_concurrency() &lt;&lt; endl 查看cpu核心数 ps -eLF 查看线程运行在哪个核心上 1234567891011121314151617181920212223242526272829303132#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;thread&gt;#include &lt;unistd.h&gt;using namespace std;void show(int id, int count, const string &amp;str);int main() &#123; // 查看cpu核心数 cout &lt;&lt; thread::hardware_concurrency() &lt;&lt; endl; // 创建线程, 传递参数 thread t1(show, 1, 100, &quot;hello&quot;); thread t2(show, 2, 100, &quot;world&quot;); thread t3(show, 3, 100, &quot;good&quot;); thread t4(show, 4, 100, &quot;hcjjj&quot;); // 主线程阻塞，等待子线程运行结束 t1.join(); t2.join(); t3.join(); t4.join(); cout &lt;&lt; &quot;Bye!&quot; &lt;&lt; endl; return 0;&#125;void show(int id, int count, const string &amp;str) &#123; for (int i = 0; i &lt; count; ++i) &#123; cout &lt;&lt; &quot;Thread &quot; &lt;&lt; id &lt;&lt; &quot;: &quot; &lt;&lt; str &lt;&lt; endl; sleep(1); &#125;&#125; 多线程应用12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#include &lt;iostream&gt;#include &lt;numeric&gt;#include &lt;thread&gt;#include &lt;vector&gt;using namespace std;int parallel_accumulate(vector&lt;int&gt;::iterator first, vector&lt;int&gt;::iterator last, int init);void accumulate_block(vector&lt;int&gt;::iterator first, vector&lt;int&gt;::iterator last, int &amp;sum);int main() &#123; vector&lt;int&gt; ivec(100); for (int i = 1; i &lt;= 100; ++i) &#123; ivec.push_back(i); &#125; cout &lt;&lt; parallel_accumulate(ivec.begin(), ivec.end(), 0) &lt;&lt; endl; return 0;&#125;int parallel_accumulate(vector&lt;int&gt;::iterator first, vector&lt;int&gt;::iterator last, int init) &#123; // 元素数量 const unsigned int length = distance(first, last); if (!length) return init; // 每个线程处理25个数 const unsigned int min_per_thread = 25; // 需要多少个线程 理论和硬件取最小值 const unsigned int max_threads = (length + min_per_thread - 1) / min_per_thread; const unsigned int hardware_threads = thread::hardware_concurrency(); const unsigned int num_threads = min((hardware_threads != 0 ? hardware_threads : 2), max_threads); const unsigned int block_size = length / num_threads; // 减去一个主线程, 主线程也参与进来 vector&lt;thread&gt; threads(num_threads - 1); vector&lt;int&gt; results(num_threads); vector&lt;int&gt;::iterator block_start = first; // 分配子线程 for (int i = 0; i &lt; (num_threads - 1); ++i) &#123; vector&lt;int&gt;::iterator block_end = block_start; // 迭代器向前调整 block_size 个位置 advance(block_end, block_size); threads[i] = thread(accumulate_block, block_start, block_end, ref(results[i])); block_start = block_end; &#125; for (auto &amp;r : threads) &#123; r.join(); &#125; // 主线程收尾 accumulate_block(block_start, last, results[num_threads - 1]); return accumulate(results.begin(), results.end(), init);&#125;void accumulate_block(vector&lt;int&gt;::iterator first, vector&lt;int&gt;::iterator last, int &amp;sum) &#123; sum = accumulate(first, last, sum);&#125; 使用互斥123456789101112131415161718192021222324252627282930313233343536373839404142#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;mutex&gt;#include &lt;vector&gt;#include &lt;unistd.h&gt;using namespace std;void write_to_vector(int id, int value);vector&lt;int&gt; ivec;mutex guard_mutex;int main() &#123; thread t1(write_to_vector, 1, 100); thread t2(write_to_vector, 2, 200); thread t3(write_to_vector, 3, 300); thread t4(write_to_vector, 4, 400); thread t5(write_to_vector, 5, 500); t1.join(); t2.join(); t3.join(); t4.join(); t5.join(); for (int i = 0; i &lt; ivec.size(); ++i) &#123; cout &lt;&lt; ivec[i] &lt;&lt; &quot; &quot;; &#125; return 0;&#125;void write_to_vector(int id, int value) &#123; cout &lt;&lt; &quot;Thread &quot; &lt;&lt; id &lt;&lt; &quot; is running&quot; &lt;&lt; &quot; value: &quot; &lt;&lt; value &lt;&lt; endl; // 使用互斥锁初始化 lock_guard // RAII 机制 lock_guard&lt;mutex&gt; guard(guard_mutex); cout &lt;&lt; &quot;Thread &quot; &lt;&lt; id &lt;&lt; &quot; lock to the resource&quot; &lt;&lt; endl; ivec.push_back(value); sleep(1);&#125; 游离指针不要将受保护的数据，以指针或者引用的方式传递到所保护范围之外 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;mutex&gt;#include &lt;unistd.h&gt;using namespace std;class User_data &#123;public: int a; char c; void change_data() &#123; a *= 10; c += 10; &#125;&#125;;// 游离指针User_data *unprotect_pt;void function(User_data &amp;my_data) &#123; unprotect_pt = &amp;my_data;&#125;class Protect_data &#123;private: User_data data; mutex guard_mutex;public: Protect_data() &#123; data.a = 1; data.c = &#x27;A&#x27;; &#125; void process_data() &#123; // 加锁 lock_guard&lt;mutex&gt; guard(guard_mutex); data.a += 10; data.c += 1; // 受保护的data 被一个外部的一个游离指针捕获(禁止这么干⚠️) function(data); sleep(2); &#125; void print() &#123; cout &lt;&lt; &quot;data.a = &quot; &lt;&lt; data.a &lt;&lt; &quot;, data.c = &quot; &lt;&lt; data.c &lt;&lt; endl; &#125;&#125;;void thred_function(Protect_data &amp;pd) &#123; // 修改pd中的数据 pd.process_data();&#125;int main() &#123; Protect_data pd; pd.print(); // 有加锁 所以 t1 t2 不能同时进行修改 thread t1(thred_function, ref(pd)); thread t2(thred_function, ref(pd)); t1.join(); t2.join(); pd.print(); // 游离的指针改变了受保护的数据 unprotect_pt-&gt;change_data(); pd.print(); return 0;&#125; 死锁的产生情况112345678910111213141516171819202122232425262728293031323334353637383940414243#include &lt;chrono&gt;#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;mutex&gt;// linux 下的一个库#include &lt;unistd.h&gt;using namespace std;void thread1();void thread2();mutex mt;int num = 100;int main() &#123; thread t1(thread1); thread t2(thread2); t1.join(); t2.join(); cout &lt;&lt; &quot;All threads end.&quot; &lt;&lt; endl; return 0;&#125;void thread1() &#123; cout &lt;&lt; &quot;Thread1 is runnning: &quot; &lt;&lt; endl; lock_guard&lt;mutex&gt; guard(mt); cout &lt;&lt; &quot;Thread1: Shared date ---&gt; num = &quot; &lt;&lt; num &lt;&lt; endl; // 一直占据资源 while(1);&#125;void thread2() &#123; cout &lt;&lt; &quot;Thread2 is runnning: &quot; &lt;&lt; endl; // linux 的 // sleep(1); // c++ 的 this_thread::sleep_for(chrono::seconds(1)); lock_guard&lt;mutex&gt; guard(mt); cout &lt;&lt; &quot;Thread2: Shared date ---&gt; num = &quot; &lt;&lt; num &lt;&lt; endl;&#125; 情况21234567891011121314151617181920212223242526272829303132333435363738394041424344454647#include &lt;chrono&gt;#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;mutex&gt;// linux 下的一个库#include &lt;unistd.h&gt;using namespace std;void thread1();void thread2();mutex mt1;mutex mt2;int a = 100;int b = 200;int main() &#123; thread t1(thread1); thread t2(thread2); // 主线程阻塞等待子线程运行结束 t1.join(); t2.join(); // 子线程因为产生了死锁也互相阻塞 cout &lt;&lt; &quot;All threads end.&quot; &lt;&lt; endl; return 0;&#125;void thread1() &#123; cout &lt;&lt; &quot;Thread1 is runnning: &quot; &lt;&lt; endl; lock_guard&lt;mutex&gt; guard1(mt1); cout &lt;&lt; &quot;Thread1: Shared date ---&gt; a = &quot; &lt;&lt; a &lt;&lt; endl; sleep(1); lock_guard&lt;mutex&gt; guard2(mt2); cout &lt;&lt; &quot;Thread1: Shared date ---&gt; b = &quot; &lt;&lt; b &lt;&lt; endl; cout &lt;&lt; &quot;Thread1: Get shared data: a + b = &quot; &lt;&lt; a + b &lt;&lt; endl;&#125;void thread2() &#123; cout &lt;&lt; &quot;Thread2 is runnning: &quot; &lt;&lt; endl; lock_guard&lt;mutex&gt; guard2(mt2); cout &lt;&lt; &quot;Thread2: Shared date ---&gt; b = &quot; &lt;&lt; b &lt;&lt; endl; sleep(1); lock_guard&lt;mutex&gt; guard1(mt1); cout &lt;&lt; &quot;Thread2: Shared date ---&gt; a = &quot; &lt;&lt; b &lt;&lt; endl; cout &lt;&lt; &quot;Thread2: Get shared data: a + b = &quot; &lt;&lt; a + b &lt;&lt; endl;&#125; 避免的死锁lock + lock_guard123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#include &lt;chrono&gt;#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;mutex&gt;// linux 下的一个库#include &lt;unistd.h&gt;using namespace std;void thread1();void thread2();mutex mt1;mutex mt2;int a = 100;int b = 200;int main() &#123; thread t1(thread1); thread t2(thread2); // 主线程阻塞等待子线程运行结束 t1.join(); t2.join(); // 子线程因为产生了死锁也互相阻塞 cout &lt;&lt; &quot;All threads end.&quot; &lt;&lt; endl; return 0;&#125;void thread1() &#123; cout &lt;&lt; &quot;Thread1 is runnning: &quot; &lt;&lt; endl; // 同时加锁 lock(mt1, mt2); // 使用lock_guard在析构函数中自动解锁, adopt_lock检查是否上锁 lock_guard&lt;mutex&gt; guard1(mt1, adopt_lock); lock_guard&lt;mutex&gt; guard2(mt2, adopt_lock); cout &lt;&lt; &quot;Thread1: Shared date ---&gt; a = &quot; &lt;&lt; a &lt;&lt; endl; sleep(1); cout &lt;&lt; &quot;Thread1: Shared date ---&gt; b = &quot; &lt;&lt; b &lt;&lt; endl; cout &lt;&lt; &quot;Thread1: Get shared data: a + b = &quot; &lt;&lt; a + b &lt;&lt; endl;&#125;void thread2() &#123; cout &lt;&lt; &quot;Thread2 is runnning: &quot; &lt;&lt; endl; lock(mt1, mt2); lock_guard&lt;mutex&gt; guard1(mt1, adopt_lock); lock_guard&lt;mutex&gt; guard2(mt2, adopt_lock); cout &lt;&lt; &quot;Thread2: Shared date ---&gt; b = &quot; &lt;&lt; b &lt;&lt; endl; sleep(1); cout &lt;&lt; &quot;Thread2: Shared date ---&gt; a = &quot; &lt;&lt; b &lt;&lt; endl; cout &lt;&lt; &quot;Thread2: Get shared data: b - a = &quot; &lt;&lt; b - a &lt;&lt; endl;&#125; unique_lock + lockunique_lock的使用 12345678910111213141516171819202122232425262728293031323334353637383940#include &lt;chrono&gt;#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;mutex&gt;using namespace std;void thread1(int id, const string &amp;str);mutex mt;int main() &#123; thread t1(thread1, 1, &quot;Hello world&quot;); // this_thread::sleep_for(chrono::seconds(1)); t1.join(); return 0;&#125;// void thread1(int id, const string &amp;str) &#123;// lock_guard&lt;mutex&gt; guard(mt);// cout &lt;&lt; &quot;Thread&quot; &lt;&lt; id &lt;&lt; &quot;: &quot; &lt;&lt; str &lt;&lt; endl;// &#125;void thread1(int id, const string &amp;str) &#123; // 在构造函数中不自动加锁 unique_lock&lt;mutex&gt; guard(mt, defer_lock); // ... // 手动加锁 guard.lock(); cout &lt;&lt; &quot;Thread&quot; &lt;&lt; id &lt;&lt; &quot;: &quot; &lt;&lt; str &lt;&lt; endl; // 手动解锁 guard.unlock(); int sum = 0; for (int i = 0; i &lt; 100; ++i) &#123; sum += i; &#125; guard.lock(); cout &lt;&lt; &quot;Thread&quot; &lt;&lt; id &lt;&lt; &quot;: &quot; &lt;&lt; sum &lt;&lt; endl; // 析构函数中会自动解锁&#125; 避免死锁 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#include &lt;chrono&gt;#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;mutex&gt;using namespace std;void thread1();void thread2();mutex mt1;mutex mt2;int a = 100;int b = 200;int main() &#123; thread t1(thread1); thread t2(thread2); // 主线程阻塞等待子线程运行结束 t1.join(); t2.join(); // 子线程因为产生了死锁也互相阻塞 cout &lt;&lt; &quot;All threads end.&quot; &lt;&lt; endl; return 0;&#125;void thread1() &#123; unique_lock&lt;mutex&gt; guard1(mt1, defer_lock); unique_lock&lt;mutex&gt; guard2(mt2, defer_lock); // guard1.lock(); // guard2.lock(); lock(guard1, guard2); cout &lt;&lt; &quot;Thread1 is runnning: &quot; &lt;&lt; endl; cout &lt;&lt; &quot;Thread1: Shared date ---&gt; a = &quot; &lt;&lt; a &lt;&lt; endl; this_thread::sleep_for(chrono::seconds(1)); cout &lt;&lt; &quot;Thread1: Shared date ---&gt; b = &quot; &lt;&lt; b &lt;&lt; endl; cout &lt;&lt; &quot;Thread1: Get shared data: a + b = &quot; &lt;&lt; a + b &lt;&lt; endl;&#125;void thread2() &#123; unique_lock&lt;mutex&gt; guard1(mt1, defer_lock); unique_lock&lt;mutex&gt; guard2(mt2, defer_lock); lock(guard1, guard2); cout &lt;&lt; &quot;Thread2 is runnning: &quot; &lt;&lt; endl; cout &lt;&lt; &quot;Thread2: Shared date ---&gt; b = &quot; &lt;&lt; b &lt;&lt; endl; this_thread::sleep_for(chrono::seconds(1)); cout &lt;&lt; &quot;Thread2: Shared date ---&gt; a = &quot; &lt;&lt; b &lt;&lt; endl; cout &lt;&lt; &quot;Thread2: Get shared data: b - a = &quot; &lt;&lt; b - a &lt;&lt; endl;&#125; scoped_lockc++17 g++ lesson20.cpp -pthread -std=c++17 &amp;&amp; ./a.out 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#include &lt;chrono&gt;#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;mutex&gt;using namespace std;void thread1();void thread2();mutex mt1;mutex mt2;int a = 100;int b = 200;int main() &#123; thread t1(thread1); thread t2(thread2); // 主线程阻塞等待子线程运行结束 t1.join(); t2.join(); // 子线程因为产生了死锁也互相阻塞 cout &lt;&lt; &quot;All threads end.&quot; &lt;&lt; endl; return 0;&#125;void thread1() &#123; cout &lt;&lt; &quot;Thread1 is runnning: &quot; &lt;&lt; endl; // scoped_lock&lt;mutex, mutex&gt; guard(mt1, mt2); // C++ 17类模板参数自动推导 scoped_lock guard(mt1, mt2); cout &lt;&lt; &quot;Thread1: Shared date ---&gt; a = &quot; &lt;&lt; a &lt;&lt; endl; this_thread::sleep_for(chrono::seconds(1)); cout &lt;&lt; &quot;Thread1: Shared date ---&gt; b = &quot; &lt;&lt; b &lt;&lt; endl; cout &lt;&lt; &quot;Thread1: Get shared data: a + b = &quot; &lt;&lt; a + b &lt;&lt; endl;&#125;void thread2() &#123; cout &lt;&lt; &quot;Thread2 is runnning: &quot; &lt;&lt; endl; // scoped_lock&lt;mutex, mutex&gt; guard(mt1, mt2); scoped_lock guard(mt1, mt2); cout &lt;&lt; &quot;Thread2: Shared date ---&gt; b = &quot; &lt;&lt; b &lt;&lt; endl; this_thread::sleep_for(chrono::seconds(1)); cout &lt;&lt; &quot;Thread2: Shared date ---&gt; a = &quot; &lt;&lt; b &lt;&lt; endl; cout &lt;&lt; &quot;Thread2: Get shared data: a + b = &quot; &lt;&lt; a + b &lt;&lt; endl;&#125; 线程并发同步1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071#include &lt;chrono&gt;#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;mutex&gt;#include &lt;condition_variable&gt;using namespace std;void thread1();void thread2();void thread3();int count = -1;mutex mtx;condition_variable flag;int main() &#123; thread t1(thread1); thread t2(thread2); thread t3(thread3); t1.join(); t2.join(); t3.join(); return 0;&#125;void thread1() &#123; int i = 0; this_thread::sleep_for(chrono::seconds(1)); while (1) &#123; // &#123; // lock_guard&lt;mutex&gt; lck(mtx); // // count = i++; // count = i; // ++i; // // RAII自动释放锁 // &#125; unique_lock&lt;mutex&gt; lck(mtx); count = i++; lck.unlock(); // 发生信号 给一个线程 // flag.notify_one(); flag.notify_all(); this_thread::sleep_for(chrono::seconds(1)); &#125;&#125;void thread2() &#123; while(1) &#123; // lock_guard无法暂时释放锁 // lock_guard&lt;mutex&gt; lck(mtx); unique_lock&lt;mutex&gt; lck(mtx); cout &lt;&lt; &quot;Thread2 waits for count: &quot;; // 等待信号 会自动暂时释放锁 flag.wait(lck); cout &lt;&lt; count &lt;&lt; endl; &#125;&#125;void thread3() &#123; while(1) &#123; // lock_guard无法暂时释放锁 // lock_guard&lt;mutex&gt; lck(mtx); unique_lock&lt;mutex&gt; lck(mtx); cout &lt;&lt; &quot;Thread3 waits for count: &quot;; // 等待信号 会自动暂时释放锁 flag.wait(lck); cout &lt;&lt; count &lt;&lt; endl; &#125;&#125; 生产者消费者1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950 #include &lt;chrono&gt;#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;mutex&gt;#include &lt;condition_variable&gt;using namespace std;void consumer();void producer(int n);mutex mtx;condition_variable produce, consume;int cargo = -1;int main() &#123; thread consumers[10], producers[10]; for (int i = 0; i &lt; 10; ++i) &#123; consumers[i] = thread(consumer); producers[i] = thread(producer, i + 1); &#125; for (int i = 0; i &lt; 10; ++i) &#123; consumers[i].join(); producers[i].join(); &#125; return 0;&#125;void consumer() &#123; unique_lock&lt;mutex&gt; lck(mtx); if (cargo == -1) &#123; cout &lt;&lt; &quot;Consumer waits for cargo!&quot; &lt;&lt; endl; // 等待生产者生产 consume.wait(lck); &#125; cout &lt;&lt; cargo &lt;&lt; endl; cargo = -1; // 通知生产者进行生产 produce.notify_one();&#125;void producer(int n) &#123; this_thread::sleep_for(chrono::seconds(5)); unique_lock&lt;mutex&gt; lck(mtx); if (cargo != -1) &#123; produce.wait(lck); &#125; cargo = n; consume.notify_one();&#125; condition_variablewait() 函数的第二种使用方式 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#include &lt;iostream&gt;#include &lt;mutex&gt;#include &lt;condition_variable&gt;#include &lt;chrono&gt;#include &lt;thread&gt;using namespace std;mutex mtx;condition_variable flag;int count = -1;void signal();void wait(int n);int main() &#123; thread t1(signal); thread t2(wait, 2); thread t3(wait, 3); t1.join(); t2.join(); t3.join(); return 0;&#125;void signal() &#123; this_thread::sleep_for(chrono::seconds(1)); unique_lock&lt;mutex&gt; lck(mtx); cout &lt;&lt; &quot;notify all threads&quot; &lt;&lt; endl; lck.unlock(); flag.notify_all(); this_thread::sleep_for(chrono::seconds(1)); lck.lock(); count = 1; cout &lt;&lt; &quot;notify all threads again&quot; &lt;&lt; endl; lck.unlock(); flag.notify_all();&#125;void wait(int id) &#123; unique_lock&lt;mutex&gt; lck(mtx); cout &lt;&lt; &quot;Thread&quot; &lt;&lt; id &lt;&lt; &quot; waits for count: &quot; &lt;&lt; endl; // wait 的第二个参数[需要满足的条件] flag.wait(lck, []()&#123;return count == 1;&#125;); cout &lt;&lt; &quot;Thread &quot; &lt;&lt; id &lt;&lt; &quot;: &quot; &lt;&lt; count &lt;&lt; endl;&#125; 创建异步任务async123456789101112131415161718192021222324252627#include &lt;iostream&gt;#include &lt;future&gt;#include &lt;chrono&gt;#include &lt;thread&gt;using namespace std;bool is_prime(int x);int main() &#123; // 方式一 future&lt;bool&gt; fut = async(is_prime, 313222313); cout &lt;&lt; &quot;Checking whethe 313222313 is prime.&quot; &lt;&lt; endl; // 等待结果 bool ret = fut.get(); if (ret) cout &lt;&lt; &quot;It is prime&quot; &lt;&lt; endl; else cout &lt;&lt; &quot;It is not prime&quot; &lt;&lt; endl; return 0;&#125;bool is_prime(int x) &#123; cout &lt;&lt; &quot;Calculating. Please wait ... &quot; &lt;&lt; endl; this_thread::sleep_for(chrono::seconds(5)); for (int i = 2; i &lt; x; ++i) &#123; if (x % i == 0) return false; &#125; return true;&#125; 1234567891011121314151617181920212223242526272829#include &lt;iostream&gt;#include &lt;future&gt;#include &lt;chrono&gt;#include &lt;thread&gt;using namespace std;class Prime &#123;public: bool is_prime(int x) &#123; cout &lt;&lt; &quot;Calculating. Please wait ... &quot; &lt;&lt; endl; this_thread::sleep_for(chrono::seconds(5)); for (int i = 2; i &lt; x; ++i) &#123; if (x % i == 0) return false; &#125; return true; &#125;&#125;;int main() &#123; // 方式二 Prime p; future&lt;bool&gt; fut = async(&amp;Prime::is_prime, p, 31322313); cout &lt;&lt; &quot;Checking whethe 313222313 is prime.&quot; &lt;&lt; endl; bool ret = fut.get(); if (ret) cout &lt;&lt; &quot;It is prime&quot; &lt;&lt; endl; else cout &lt;&lt; &quot;It is not prime&quot; &lt;&lt; endl; return 0;&#125; async选项123456789101112131415161718192021222324252627282930313233#include &lt;iostream&gt;#include &lt;future&gt;#include &lt;chrono&gt;#include &lt;thread&gt;using namespace std;bool is_prime(int x);int main() &#123; // lacunch::async 异步线程 // launch:deferred 同步线程(线程id相同， 只有一个线程) // future&lt;bool&gt; fut = async(std::launch::async, is_prime, 313222313); future&lt;bool&gt; fut = async(std::launch::deferred, is_prime, 313222313); // future&lt;bool&gt; fut = async(launch::deferred|launch::async, is_prime, 313222313); cout &lt;&lt; &quot;Checking whethe 313222313 is prime.&quot; &lt;&lt; endl; cout &lt;&lt; &quot;main() thread id = &quot; &lt;&lt; std::this_thread::get_id() &lt;&lt; endl; this_thread::sleep_for(chrono::seconds(5)); // 子线程传递数据给主线程 bool ret = fut.get(); if (ret) cout &lt;&lt; &quot;It is prime&quot; &lt;&lt; endl; else cout &lt;&lt; &quot;It is not prime&quot; &lt;&lt; endl; return 0;&#125;bool is_prime(int x) &#123; cout &lt;&lt; &quot;Calculating. Please wait ... &quot; &lt;&lt; endl; cout &lt;&lt; &quot;is_prime() thread id = &quot; &lt;&lt; std::this_thread::get_id() &lt;&lt; endl; this_thread::sleep_for(chrono::seconds(5)); for (int i = 2; i &lt; x; ++i) &#123; if (x % i == 0) return false; &#125; return true;&#125; promise通过promise对象实现主线程与子线程、子线程与子线程之间数据的传输 123456789101112131415161718192021222324252627282930#include &lt;chrono&gt;#include &lt;iostream&gt;#include &lt;future&gt;#include &lt;thread&gt;using namespace std;void add_function(promise&lt;int&gt; &amp;, int , int);int main() &#123; promise&lt;int&gt; pm; future&lt;int&gt; future; // make future promise get relationship future = pm.get_future(); thread t1(add_function, ref(pm), 10, 20); // wait for child thread finish, blocked function int sum = future.get(); cout &lt;&lt; &quot;sum = &quot; &lt;&lt; sum &lt;&lt; endl; t1.join(); return 0;&#125;void add_function(promise&lt;int&gt; &amp;mypromise, int x, int y) &#123; cout &lt;&lt; &quot;x = &quot; &lt;&lt; x &lt;&lt; &quot;, y = &quot; &lt;&lt; y &lt;&lt; endl; int sum = 0; sum = x + y; this_thread::sleep_for(chrono::seconds(3)); mypromise.set_value(sum);&#125; 123456789101112131415161718192021222324252627282930313233#include &lt;iostream&gt;#include &lt;future&gt;#include &lt;thread&gt;using namespace std;void thread1(promise&lt;int&gt; &amp;mypromise, int n);void thread2(future&lt;int&gt; &amp;fut);int main() &#123; promise&lt;int&gt; pm; future&lt;int&gt; future; future = pm.get_future(); // 主线程通过 pm 传递数据给 t1 thread t1(thread1, ref(pm), 5); // t1 通过 future 传递给 t2 thread t2(thread2, ref(future)); t1.join(); t2.join(); return 0;&#125;void thread1(promise&lt;int&gt; &amp;mypromise, int n) &#123; cout &lt;&lt; &quot;thread1 input value: &quot; &lt;&lt; n &lt;&lt; endl; n *= 100; this_thread::sleep_for(chrono::seconds(3)); mypromise.set_value(n);&#125;void thread2(future&lt;int&gt; &amp;fut) &#123; cout &lt;&lt; &quot;thread2 get value: &quot; &lt;&lt; fut.get() &lt;&lt; endl;&#125; packaged_task123456789101112131415161718192021222324252627282930313233#include &lt;iostream&gt;#include &lt;future&gt;#include &lt;thread&gt;using namespace std;int add_func(int, int);int main() &#123; cout &lt;&lt; &quot;main() thread id = &quot; &lt;&lt; this_thread::get_id() &lt;&lt; endl; // 不需要对可调用对象进行过多的修改 // 可调用对象 -&gt; 异步线程 // packaged_task&lt;int(int, int)&gt; ptk([](int x, int y)&#123; // cout &lt;&lt; &quot;child() thread id = &quot; &lt;&lt; this_thread::get_id() &lt;&lt; endl; // cout &lt;&lt; &quot;x = &quot; &lt;&lt; x &lt;&lt; &quot;, y = &quot; &lt;&lt; y &lt;&lt; endl; // return x + y; // &#125;); packaged_task&lt;int(int, int)&gt; ptk(add_func); future&lt;int&gt; future; future = ptk.get_future(); thread t(std::move(ptk), 10, 20); int result = future.get(); cout &lt;&lt; &quot;Add result = &quot; &lt;&lt; result &lt;&lt; endl; t.join(); return 0;&#125;int add_func(int x, int y) &#123; cout &lt;&lt; &quot;child() thread id = &quot; &lt;&lt; this_thread::get_id() &lt;&lt; endl; cout &lt;&lt; &quot;x = &quot; &lt;&lt; x &lt;&lt; &quot;, y = &quot; &lt;&lt; y &lt;&lt; endl; return x + y;&#125; 限时等待123456789101112131415161718192021222324252627282930313233343536373839404142#include &lt;chrono&gt;#include &lt;iostream&gt;#include &lt;future&gt;#include &lt;thread&gt;using namespace std;void thread1(promise&lt;int&gt; &amp;mypromise, int n);void thread2(future&lt;int&gt; &amp;fut);int main() &#123; promise&lt;int&gt; pm; future&lt;int&gt; future; future = pm.get_future(); // 主线程通过 pm 传递数据给 t1 thread t1(thread1, ref(pm), 5); // t1 通过 future 传递给 t2 thread t2(thread2, ref(future)); t1.join(); t2.join(); return 0;&#125;void thread1(promise&lt;int&gt; &amp;mypromise, int n) &#123; cout &lt;&lt; &quot;thread1 input value: &quot; &lt;&lt; n &lt;&lt; endl; n *= 100; // 需要20s this_thread::sleep_for(chrono::seconds(20)); mypromise.set_value(n);&#125;void thread2(future&lt;int&gt; &amp;fut) &#123; chrono::milliseconds span(10000); // 限时等待 10s if (fut.wait_for(span) == future_status::timeout) &#123; cout &lt;&lt; &quot;Time out&quot; &lt;&lt; endl; cout &lt;&lt; &quot;Thread2 cannot wait any more!&quot; &lt;&lt; endl; return; &#125; cout &lt;&lt; &quot;thread2 get value: &quot; &lt;&lt; fut.get() &lt;&lt; endl;&#125; 记录程序执行时间123456789101112131415161718192021222324#include &lt;iostream&gt;#include &lt;ratio&gt;#include &lt;thread&gt;#include &lt;chrono&gt;using namespace std;void do_something() &#123; // 计时数据为 int 类型 // 1/1s 为一个计时单位 // 共5个计时单位 , 延时 5s this_thread::sleep_for(chrono::duration&lt;int, ratio&lt;1, 1&gt;&gt;(2)); cout &lt;&lt; &quot;do something&quot; &lt;&lt; endl;&#125;int main() &#123; // 高精度时钟类 auto start = chrono::high_resolution_clock::now(); do_something(); auto stop = chrono::high_resolution_clock::now(); auto durations = chrono::duration&lt;double, ratio&lt;1, 1&gt;&gt;(stop - start).count(); cout &lt;&lt; &quot;do_something takes &quot; &lt;&lt; durations &lt;&lt; endl; return 0;&#125; 限时等待的互斥 12345678910111213141516171819202122232425262728293031323334353637383940#include &lt;chrono&gt;#include &lt;iostream&gt;#include &lt;mutex&gt;#include &lt;thread&gt;using namespace std;timed_mutex tmx;void func1(int id, const string &amp;str) &#123; if (tmx.try_lock()) &#123; cout &lt;&lt; &quot;Thread1 &quot; &lt;&lt; id &lt;&lt; &quot;locked and do something&quot; &lt;&lt; endl; for (int i = 0; i &lt; 10; ++i) &#123; cout &lt;&lt; str &lt;&lt; endl; this_thread::sleep_for(chrono::seconds(1)); &#125; tmx.unlock(); &#125;&#125;void func2(int id, const string &amp;str) &#123; this_thread::sleep_for(chrono::seconds(1)); // 尝试等待5s if (tmx.try_lock_for(chrono::seconds(5))) &#123; cout &lt;&lt; &quot;Thread &quot; &lt;&lt; id &lt;&lt; &quot;: &quot; &lt;&lt; str &lt;&lt; endl; tmx.unlock(); &#125; else &#123; cout &lt;&lt; &quot;Thread2 cannot wait anymore&quot;; &#125; &#125;int main() &#123; thread t1(func1, 1, &quot;Hello world&quot;); thread t2(func2, 2, &quot;Gooooood&quot;); t1.join(); t2.join(); return 0;&#125; atomic原子操作123456789101112131415161718192021222324252627282930313233343536373839#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;mutex&gt;#include &lt;chrono&gt;#include &lt;atomic&gt;using namespace std;void my_thread();int count = 0;mutex my_mutex;atomic&lt;int&gt; count2(0);int main() &#123; thread t1(my_thread); thread t2(my_thread); auto start = chrono::high_resolution_clock::now(); t1.join(); t2.join(); auto stop = chrono::high_resolution_clock::now(); auto durations = chrono::duration&lt;double, ratio&lt;1, 1&gt;&gt;(stop - start).count(); cout &lt;&lt; &quot;durations = &quot; &lt;&lt; durations &lt;&lt; endl; // cout &lt;&lt; &quot;count = &quot; &lt;&lt; count &lt;&lt; endl; cout &lt;&lt; &quot;count = &quot; &lt;&lt; count2 &lt;&lt; endl; return 0;&#125;void my_thread() &#123; for (int j = 0; j &lt; 5; ++j) &#123; for (int i = 0; i &lt; 10000000; ++i) &#123; // 加锁解锁 消耗资源 // my_mutex.lock(); // ++count; // my_mutex.unlock(); ++count2; &#125; &#125;&#125;","tags":["Linux","C++"],"categories":["C/C++"]},{"title":"广义随机 Petri 网 (GSPN)","path":"/2023/08/30/Petri/","content":"Petri 网的基础知识和建模工具介绍 Petri Net Petri Nets World ISO&#x2F;IEC 15909 （Systems and software engineering — High-level Petri nets）《系统和软件工程 - 高级 Petri 网》 车辆功能安全与可靠性的关系分析 厘清功能安全VS预期功能安全VS网络安全的关系 吴哲辉：中国计算机学会Petri网专业委员会的成立与早期发展——我校在其中发挥过重要作用 书籍 《Petri网导论》 - 吴哲辉 《随机Petri网与系统性能分析》 - 林闯 《Petri网原理与应用》 - 袁崇义 Petri 网在系统可靠性分析中的应用主要有以下几个方面：基本行为描述、故障树的表示与简化、可靠性指标的解析计算以及可靠性仿真等 基本 Petri 网Petri 网（ PN ） 为一个三元组，即 $PN&#x3D;(P,T;F)$ ，其中： $P&#x3D;(p_1,p_2,\\cdots p_n)$ 为有限库所集， $n$ 为库所个数； $T&#x3D;(t_1,t_2,\\cdots t_m)$ 为有限变迁集， $m$ 为变迁个数； $P\\cap T&#x3D;\\emptyset $ ，即库所集合 $P$ 和变迁集合 $T$ 不相交；$P\\cup T eq\\emptyset$ ，即库所集合 $P$ 和变迁集合 $T$ 不同时为空； $F\\subseteq(P{\\times}T)\\cup(T{\\times}P)$ 为流关系，即弧集合; $dom(F)\\bigcup cod(F)&#x3D;P\\bigcup T$ ，即没有孤立元素，其中 $dom(F)&#x3D;{x\\mid\\exists y:(x,y)\\in F}$，$cod(F)&#x3D;{y\\mid\\exists x:(x,y)\\in F}$ 分别为 $F$ 的定义域和值域； 集合 $X&#x3D;P\\cup T$ 是网元素集合。 库所&#x2F;变迁（P&#x2F;T）系统为一个六元组 $\\Sigma&#x3D;\\left(P,T;F,K,W,M_0\\right)$ ，其中： $PN&#x3D;(P,T;F)$ 是一个网， $P$ 元素是位置，$T$ 元素是变迁； $K:\\ P\\to N^+\\cup{\\infty}$ 称为位置容量函数（capacity function），容量表示每个位置存储资源的最大数量，但它不是当前实际的资源数量； $W:F\\to N^+$ 称为 $PN$ 上的弧权函数，表示实际消耗或产生的资源量； $M_0:P\\to N$ 是 $PN$ 初始的标识(marking)，满足：$\\forall p\\in P:M_0(p)\\leq K(p)$ ，标识是标记在库所中的一种分布。 Petri 网的图形化表述为一种网状模型： 库所（Place） 变迁（Transition） 有向弧（Connection） 令牌（token） Petri 网的主要性质： 结构性质：和Petri网初始标识无关的性质 动态性质：可达性、活性与死锁、冲突、可逆性、可覆盖性、有界性、安全性 随机 Petri 网Stochastic Petri Nets（SPN） 把固定时间参数引入Petri网的网模型叫做时间Petri网，在每个变迁的可激发与激发之间联系一个随机的延迟时间，这种类型的Petri网叫做随机Petri网（SPN）。 随机Petri网 $SPN&#x3D;(P,T;F,W,M_0,\\lambda)$ ，其中 $(P,T;F,W,M_0)$ 是一 个 $P&#x2F;T$ 系统， $\\lambda&#x3D;{\\lambda_1,\\lambda_2,\\cdots,\\lambda_m}$ 是变迁平均实施速率集合。 $\\lambda_i$ 是变迁 $t_{i}\\in T$ 的平均实施速率，表示在可实施的情况下单位时间内平均实 施次数，单位是 次数／单位时间。在机械可靠性研究中，$\\lambda_i$ 可用来表示零部件的故障率及维修率。 大多数随机Petri网的性能分析是建立在其状态空间与马尔可夫链同构的基础上的。随机Petri网为系统的性能模型提供良好的描述手段；随机马尔可夫过程为模型的评价提供坚实的数学基础。 广义随机 Petri 网Generalized Stochastic Petri nets (GSPN) SPN的状态空间会随着问题的增大而指数性地增长，使得SPN同构的MC难以求解。广义随机Petri网（generalized stochastic Petri nets，GSPN）的提出为缓解状态爆炸提供了一种途径。 GSPN是SPN的一种扩充，主要表现在将变迁分成两类： 一种为瞬时变迁与随机开关关联（根据一个概率分布函数）且实施延时为零； 令一种为时间变迁与指数随机分布的实施延时相关联。 一个 $GSPN&#x3D;(P,T;F,W,M_0,\\lambda)$ ，其中： $P$，$W$，$M_0$，$\\lambda$ 与 $SPN$ 的定义相同； $F$ 中允许有禁止弧，禁止弧仅存在于从库所到变迁的弧。禁止弧所连接的库所的原可实施条件变为不可实施（disenable）条件，原不可实施条件变为可实施条件，且在相连变迁实施时，没有标记从相连的库所移出； 变迁集 $T$ 划分为两个子集：$T&#x3D;T_t\\cup T_i$ ，$T_t\\cap T_i&#x3D;\\emptyset $ ，时间（timed）变迁集 $T_t&#x3D;\\left{t_1,t_2,\\cdots,t_k\\right}$ ，瞬时(immediate)变迁集 $T_{i}&#x3D;\\left{t_{k+1},t_{k+2},\\cdots,t_{n}\\right}$ ，与时间变迁集相关联的平均实施速率集合 $\\lambda&#x3D;{\\lambda_1,\\lambda_2,\\cdots,\\lambda_t}$。 为在一个标识 $M$ 下多个可实施瞬时变迁定义一个随机开关，确定他们之间实施概率选择。 $GSPN$ 建模元素的图形化表示： 分析方法Petri 网分析方法： 可达树（可达图） 关联矩阵 状态方程 化简分析 马尔科夫链同构 仿真模拟 马尔科夫链同构法： 马尔科夫 $GSPN$ 模型，能通过数值分析或者仿真分析的方法，可以得到库所中标记转移概率、变迁的激发概率的瞬态变化过程以及稳态结果；非马尔科夫 $GSPN$ 网络，只能通过仿真的方式来分析，主要得到库所标记转移和变迁激发的稳态结果。 当Petri网变迁的时延服从指数分布时，一个Petri网同构于一个连续时间马尔可夫链（MC），每个标识对应马尔可夫链的一个状态。两者同构的条件有两个，一个是变迁的实施速率服从指数分布所导致的无记忆性，另一个是标识的可数性。在Petri网模型的可达图上可以很容易地获得 MC 转移速率矩阵的参数，能够计算出 MC的每个状态（标识）的稳定状态下的稳定概率，对Petri网进行分析。 PN Generation Deadlock and Liveness Analysis Model Parameter Assignment Performance Analysis Reachability Graph Creation Markov Chain Creation Transition Probability Computation Design Matrix Evaluation Reliability Prediction Sensitivity analysis 蒙特卡罗模拟法： 通过逆变换从指数分布采样，$t&#x3D;\\frac{-\\ln(K)}{\\lambda}$，$K$ 的取值范围是 $[0,1]$ ，利用蒙特卡洛模拟可以确定 $K$ 的取值进而每一步仿真得到随机延迟 $t$，进而进行petri 网模型的模拟。 基于 Petri 网的蒙特卡洛模拟流程： CTMC 求解GSPN 模型可达集同构于连续时间马尔可夫链 （Continuous-time Markov chain，CTMC） 求解步骤： 构建转移速率矩阵 Kolmogorov 正向方程 $\\boldsymbol{P}^{\\prime}(t)&#x3D;\\boldsymbol{P}(t)\\boldsymbol{Q}$ 实存状态的稳态概率满足：$\\begin{cases}P\\cdot Q&#x3D;0\\\\sum_{i&#x3D;1}^lP_i&#x3D;1&amp;\\end{cases}$ 三个式子组成方程组，求解即为稳态： $P&#x3D;[p_1,p_2,\\ldots,p_n]$，是稳态概率分布的向量，其中 $p_{i}$ 表示状态 $i$ 的稳态概率 Kolmogorov 正向方程：$\\frac d{dt}P(t)&#x3D;P(t)\\cdot Q$ 平衡方程：$P\\cdot Q&#x3D;0$ P 的和为1：$\\sum_{i&#x3D;1}^np_i&#x3D;1$ 案例分析： 稳态概率向量：$P&#x3D;[p_0,p_2,\\ldots,p_8]$ 转移速率矩阵： $Q &#x3D; \\begin{bmatrix} &amp; M_0 &amp; M_1 &amp; M_2 &amp; M_3 &amp; M_4 &amp; M_5 &amp; M_6 &amp; M_7 &amp; M_8 \\M_0 &amp; q_{00} &amp; \\lambda_7+\\lambda_9+\\lambda_{11}+\\lambda_{13} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\M_1 &amp; \\lambda_{15} &amp; q_{11} &amp; \\lambda_{6} &amp; \\lambda_7+\\lambda_9+\\lambda_{11}+\\lambda_{13} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\M_2 &amp; \\lambda_{15} &amp; 0 &amp; q_{22} &amp; 0 &amp; \\lambda_7+\\lambda_9+\\lambda_{11}+\\lambda_{13} &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\M_3 &amp; 0 &amp; \\lambda_{15} &amp; 0 &amp; q_{33} &amp; \\lambda_6 &amp; \\lambda_7+\\lambda_9+\\lambda_{11}+\\lambda_{13} &amp; 0 &amp; 0 &amp; 0 \\M_4 &amp; 0 &amp; 0 &amp; \\lambda_{15} &amp; 0 &amp; q_{44} &amp; 0 &amp; \\lambda_7+\\lambda_9+\\lambda_{11}+\\lambda_{13} &amp; 0 &amp; 0 \\M_5 &amp; 0 &amp; 0 &amp; 0 &amp; \\lambda_{15} &amp; 0 &amp; q_{55} &amp; \\lambda_{6} &amp; \\lambda_7+\\lambda_9+\\lambda_{11}+\\lambda_{13} &amp; 0 \\M_6 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \\lambda_{15} &amp; 0 &amp; q_{66} &amp; 0 &amp; \\lambda_7+\\lambda_9+\\lambda_{11}+\\lambda_{13} \\M_7 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \\lambda_{15} &amp; 0 &amp; q_{77} &amp; \\lambda_{6} \\M_8 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \\lambda_{15} &amp; 0 &amp; q_{88}\\end{bmatrix}$ $q_{ii}&#x3D;-\\sum_{j eq i}q_{ij}$ $\\lambda_a &#x3D; \\lambda_7+\\lambda_9+\\lambda_{11}+\\lambda_{13}$ $Q &#x3D; \\begin{bmatrix} &amp; M_0 &amp; M_1 &amp; M_2 &amp; M_3 &amp; M_4 &amp; M_5 &amp; M_6 &amp; M_7 &amp; M_8 \\M_0 &amp; -(\\lambda_7+\\lambda_9+\\lambda_{11}+\\lambda_{13}) &amp; \\lambda_7+\\lambda_9+\\lambda_{11}+\\lambda_{13} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\M_1 &amp; \\lambda_{15} &amp; -(\\lambda_{15} + \\lambda_{6} + \\lambda_7+\\lambda_9+\\lambda_{11}+\\lambda_{13}) &amp; \\lambda_{6} &amp; \\lambda_7+\\lambda_9+\\lambda_{11}+\\lambda_{13} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\M_2 &amp; \\lambda_{15} &amp; 0 &amp; -(\\lambda_{15} + \\lambda_7+\\lambda_9+\\lambda_{11}+\\lambda_{13}) &amp; 0 &amp; \\lambda_7+\\lambda_9+\\lambda_{11}+\\lambda_{13} &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\M_3 &amp; 0 &amp; \\lambda_{15} &amp; 0 &amp; -(\\lambda_{15} + \\lambda_6 + \\lambda_7+\\lambda_9+\\lambda_{11}+\\lambda_{13}) &amp; \\lambda_6 &amp; \\lambda_7+\\lambda_9+\\lambda_{11}+\\lambda_{13} &amp; 0 &amp; 0 &amp; 0 \\M_4 &amp; 0 &amp; 0 &amp; \\lambda_{15} &amp; 0 &amp; -(\\lambda_{15} + \\lambda_7+\\lambda_9+\\lambda_{11}+\\lambda_{13}) &amp; 0 &amp; \\lambda_7+\\lambda_9+\\lambda_{11}+\\lambda_{13} &amp; 0 &amp; 0 \\M_5 &amp; 0 &amp; 0 &amp; 0 &amp; \\lambda_{15} &amp; 0 &amp; -(\\lambda_{15} + \\lambda_{6} + \\lambda_7+\\lambda_9+\\lambda_{11}+\\lambda_{13}) &amp; \\lambda_{6} &amp; \\lambda_7+\\lambda_9+\\lambda_{11}+\\lambda_{13} &amp; 0 \\M_6 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \\lambda_{15} &amp; 0 &amp; -(\\lambda_{15} + \\lambda_7+\\lambda_9+\\lambda_{11}+\\lambda_{13}) &amp; 0 &amp; \\lambda_7+\\lambda_9+\\lambda_{11}+\\lambda_{13} \\M_7 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \\lambda_{15} &amp; 0 &amp; -(\\lambda_{15} + \\lambda_{6}) &amp; \\lambda_{6} \\M_8 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \\lambda_{15} &amp; 0 &amp; -\\lambda_{15}\\end{bmatrix}$ 解方程组： $P(0)&#x3D;[1,0,0,0,0,0,0,0,0]$，$M_0$为初态 $\\frac d{dt}P(t)&#x3D;P(t)\\cdot Q$ $\\begin{cases}{P}^{\\prime}(t)&#x3D;{P}(0)\\cdot Q\\P(t&#x3D;\\infty)\\cdot Q&#x3D;0\\\\sum_{i&#x3D;0}^8P_i&#x3D;1&amp;\\end{cases}$ 这个方程组描述了连续时间马尔可夫链的稳态概率。在这里，$P(t)$ 是状态分布向量，$Q$ 是状态转移速率矩阵。 首先，我们可以通过解微分方程 $\\frac d{dt}P(t)&#x3D;P(0)\\cdot Q$ 来得到稳态概率分布，这个微分方程的解是 $P(t)&#x3D;P(0)\\cdot e^{tQ}$ 接下来，我们需要找到稳态概率分布 $P(t&#x3D;\\infty)$，这可以通过解方程 $P(t&#x3D;\\infty)\\cdot Q&#x3D;0$ 来实现。解这个方程可以得到马尔可夫链的稳态概率分布。 最后，我们需要确保概率分布的总和为1，即$\\sum_{i&#x3D;0}^8P_i&#x3D;1$ 使用 python 求解： 123456789101112131415161718192021222324252627282930import numpy as npfrom scipy.integrate import odeint# 定义矩阵 QQ = np.array([ [-360.0000645, 360.0000645, 0, 0, 0, 0, 0, 0, 0], [3600, -3961.000065, 1, 360.0000645, 0, 0, 0, 0, 0], [3600, 0, -3960.000065, 0, 360.0000645, 0, 0, 0, 0], [0, 3600, 0, -3961.000065, 1, 360.0000645, 0, 0, 0], [0, 0, 3600, 0, -3960.000065, 0, 360.0000645, 0, 0], [0, 0, 0, 3600, 0, -3961.000065, 1, 360.0000645, 0], [0, 0, 0, 0, 3600, 0, -3960.000065, 0, 360.0000645], [0, 0, 0, 0, 0, 3600, 0, -3601, 1], [0, 0, 0, 0, 0, 0, 3600, 0, -3600]])# 定义初始条件P0 = np.array([1, 0, 0, 0, 0, 0, 0, 0, 0])# 定义微分方程组def dPdt(P, t): dPdt = P @ Q return dPdt# 数值求解t = np.linspace(0, 1, 100) # 时间步长sol = odeint(dPdt, P0, t)# 输出结果print(sol[-1]) 1234567891011121314151617181920212223import numpy as np# 定义速率矩阵 QQ = np.array([ [-360.0000645, 360.0000645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [3600, -3961.000065, 1.0, 360.0000645, 0.0, 0.0, 0.0, 0.0, 0.0], [3600, 0.0, -3960.000065, 0.0, 360.0000645, 0.0, 0.0, 0.0, 0.0], [0.0, 3600, 0.0, -3961.000065, 1.0, 360.0000645, 0.0, 0.0, 0.0], [0.0, 0.0, 3600, 0.0, -3960.000065, 0.0, 360.0000645, 0.0, 0.0], [0.0, 0.0, 0.0, 3600, 0.0, -3961.000065, 1.0, 360.0000645, 0.0], [0.0, 0.0, 0.0, 0.0, 3600, 0.0, -3960.000065, 0.0, 360.0000645], [0.0, 0.0, 0.0, 0.0, 0.0, 3600, 0.0, -3601, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3600, 0.0, -3600],])# 求解稳态概率w, v = np.linalg.eig(Q.T)pi = v[:, 0] / np.sum(v[:, 0])# 输出稳态概率print(&quot;稳态概率向量:&quot;)print(pi) 使用 Mathematica 求解： 1234567891011121314151617181920212223242526272829303132333435(*定义未知向量 P*)P = Array[p, 9];(*定义转移速率矩阵 Q*)Q = &#123;&#123;-(\\[Lambda]7 + \\[Lambda]9 + \\[Lambda]11 + \\[Lambda]13), \\\\[Lambda]7 + \\[Lambda]9 + \\[Lambda]11 + \\[Lambda]13, 0, 0, 0, 0, 0, 0, 0&#125;, &#123;\\[Lambda]15, -(\\[Lambda]15 + \\[Lambda]6 + \\[Lambda]7 + \\\\[Lambda]9 + \\[Lambda]11 + \\[Lambda]13), \\[Lambda]6, \\[Lambda]7 + \\\\[Lambda]9 + \\[Lambda]11 + \\[Lambda]13, 0, 0, 0, 0, 0&#125;, &#123;\\[Lambda]15, 0, -(\\[Lambda]15 + \\[Lambda]7 + \\[Lambda]9 + \\[Lambda]11 + \\\\[Lambda]13), 0, \\[Lambda]7 + \\[Lambda]9 + \\[Lambda]11 + \\[Lambda]13, 0, 0, 0, 0&#125;, &#123;0, \\[Lambda]15, 0, -(\\[Lambda]15 + \\[Lambda]6 + \\[Lambda]7 + \\[Lambda]9 + \\\\[Lambda]11 + \\[Lambda]13), \\[Lambda]6, \\[Lambda]7 + \\[Lambda]9 + \\\\[Lambda]11 + \\[Lambda]13, 0, 0, 0&#125;, &#123;0, 0, \\[Lambda]15, 0, -(\\[Lambda]15 + \\[Lambda]7 + \\[Lambda]9 + \\[Lambda]11 + \\\\[Lambda]13), 0, \\[Lambda]7 + \\[Lambda]9 + \\[Lambda]11 + \\[Lambda]13, 0, 0&#125;, &#123;0, 0, 0, \\[Lambda]15, 0, -(\\[Lambda]15 + \\[Lambda]6 + \\[Lambda]7 + \\[Lambda]9 + \\\\[Lambda]11 + \\[Lambda]13), \\[Lambda]6, \\[Lambda]7 + \\[Lambda]9 + \\\\[Lambda]11 + \\[Lambda]13, 0&#125;, &#123;0, 0, 0, 0, \\[Lambda]15, 0, -(\\[Lambda]15 + \\[Lambda]7 + \\[Lambda]9 + \\[Lambda]11 + \\\\[Lambda]13), 0, \\[Lambda]7 + \\[Lambda]9 + \\[Lambda]11 + \\[Lambda]13&#125;, &#123;0, 0, 0, 0, 0, \\[Lambda]15, 0, -(\\[Lambda]15 + \\[Lambda]6), \\[Lambda]6&#125;, &#123;0, 0, 0, 0, 0, 0, \\[Lambda]15, 0, -\\[Lambda]15&#125;&#125;;(*定义方程组*)eqns = &#123;P . Q == ConstantArray[0, 9], Total[P] == 1&#125;;(*求解方程组*)sol = Solve[eqns, P];(*打印解*)sol 性能分析 稳态概率：分析系统达到稳态时不同库所令牌分布的概率。这有助于了解系统在长期运行中各个状态的概率分布。 吞吐量：计算系统在单位时间内完成的任务数或处理的事务数量。吞吐量是衡量系统性能的一个重要指标。 平均延迟：计算任务或事务从提交到完成所需的平均时间。平均延迟是衡量系统响应时间的指标。 资源利用率：分析系统中各个资源（如处理器、内存等）的利用率，以评估资源的使用效率。 并发性：分析系统中并发执行的任务或事务数量，了解系统的并行处理能力。 死锁分析：检查系统是否存在死锁情况，即无法进行任何进一步状态转移的情况。 故障分析：通过引入故障或随机性来模拟系统的可靠性，以评估系统在故障情况下的性能表现。 灵敏度分析：分析系统参数的变化对性能指标的影响，帮助优化系统设计和参数配置。 优化：根据性能分析的结果，优化系统结构、资源分配或策略，以提高系统性能。 建模工具 PIPEPIPE 5 is currently in beta stage due to an entire re-write of the back end and so is missing most of the analysis modules. If you require Petri net analysis, please use PIPE 4. CPN IDECPN Tools has been replaced now by CPN IDE. Development on CPN Tools has stopped. TimeNET Net Toolbox for MATLAB GRIF Petri – Petri Net software（收费） PIPETimeNET TimeNET 4.0 User Manual Objects Places Exponential transitions 指数跃迁的激发速率必须通过取其倒数来转换为延迟 Immediate transitions Arc Inhibitor arcs Constant definition Performance measures Validate Statespace 状态空间 Traps 陷阱 Siphons 虹吸管 Analysis Transient 运行一周后，系统仍然可运行的概率是多少？ 制造系统重新设置后一小时生产了多少零件？ Stationary (Steady-State) 通信通道的最大带宽是多少？ 制造系统缓冲区中的预期零件数量是多少？ Analysis 通过对可达性图的充分探索来进行直接、准确的数值性能评估 Approximation 也是直接数值技术，但尝试通过允许某种不准确性来避免一些昂贵的评估部分 Simulation 不计算可达性图，而是遵循标准蒙特卡罗风格模拟方法并进行一些改进 Evaluation 概率与统计概率分布（Poisson Distribution）就是在统计图中表示概率，横轴是数据的值，纵轴是横轴上对应数据值的概率。 泊松分布某个时间范围内，发生某件事情x次的概率是多大，如一个月内某机器损坏的次数。若某事件的发生是完全随机的，则在单位时间（或空间）事件发生0次、1次、2次、…、X次相应的概率为：$$P(X&#x3D;k)&#x3D;\\frac{e^{-\\lambda}\\lambda^k}{k!},k&#x3D;0,1,2,\\cdots$$则称该事件的发生服从参数为 $𝜆$ 的Poisson分布，$𝜆$ 是其唯一参数，为Poisson分布的均数(𝜆＞0)，式中 $e &#x3D;2.71828$ 为自然对数的底，是常数，$X$ 是事件发生次数，$P(X)$ 为事件发生次数为 $X$ 时的概率。 指数分布指数分布（Exponential distribution）是一种形式简单地连续型分布，传统上常用于表述电子元器件或某些产品的寿命分布规律。若产品在一定时间区间内的失效数服从泊松分布，则该产品的寿命服从指数分布。若产品的寿命分布服从指数分布，则其失效率为常数。 指数分布的故障密度函数（概率密度函数）为：$$f(x)&#x3D;\\left{\\begin{array}{cc}{\\lambda}e^{-{\\lambda}x}&amp;,&amp;x\\geq0,\\0&amp;,&amp;x&lt;0.\\end{array}\\right.$$ 累积分布函数为：$$F(x)&#x3D;\\left{\\begin{array}{cc}1-e^{-{\\lambda}x}&amp;,&amp;x\\geq0,\\0&amp;,&amp;x&lt;0.\\end{array}\\right.$$ 指数分布具有“无记忆性”，这是指数分布的重要性质。即产品的寿命服从指数分布，则已工作了 t 时间正常的产品，在 t 时间以后的剩余寿命与新的产品一样，与 t 无关。 威布尔分布威布尔分布（Weibull distribution）在可靠性工程中被广泛使用。威布尔分布有三参数和两参数两种形式。 三参数威布尔分布的概率密度函数为：$$f(t)&#x3D;\\begin{cases}\\dfrac{m}{t}(t-\\gamma)^{m-1}\\exp[-\\dfrac{(t-\\gamma)^m}{t_0}]&amp;&amp;t\\geq\\gamma\\l_0&amp;&amp;t&lt;\\gamma&amp;\\end{cases}$$三参数威布尔分布记为 $T\\sim W(m,t_0,\\gamma)$，其中 m 为形状参数， $t_0$为尺度参数，$\\gamma$ 为位置参数，其取值范围都是$(0,\\infty)$ 。 在可靠性工程中，通常取 $\\gamma$ &#x3D; 0，则三参数威布尔分布简化为两参数威布尔分布，其概率密度函数为：$$f(t)&#x3D;\\frac{m}{t_0}t^{m-1}\\exp(-\\frac{t^m}{t_0})\\quad\\quad t\\geq0$$根据 m 值的不同，威布尔分布等价或近似于其他分布。例如，当 m &#x3D; 1 时， 威布尔分布等同于指数分布；当 m &#x3D;2.5 时，威布尔分布近似于对数正态分布； 当 m &#x3D; 3.6 时，威布尔分布近似于正态分布。 由于威布尔分布的参数众多，指数分布、正态分布、瑞利分布等均可看作是它特例，所以它适用范围很广。 国外常把它作为机械产品和电子产品的通用故障分布，每当遇到故障分布很不明显，难以断定时，就当威布尔分布来统计、检验， 在工程上往往可得到圆满的结果。 逆变换采样在已知任意概率分布的累积分布函数时，可用于从该分布中生成随机样本。即，生成符合特定概率分布的随机数。 从指数分布采样： 指数分布的概率密度$$f(x;\\lambda)&#x3D;\\left{\\begin{array}{ll}\\lambda e^{-\\lambda x}&amp;,&amp;\\quad x\\geq0,\\0&amp;,&amp;\\quad x&lt;0.\\end{array}\\right.$$从采样逆变换可知，如果我们让指数分布的累积分布函数服从均匀分布，那么其逆函数服从指数分布，$$P(x)&#x3D;\\mathrm{P}(V\\leqslant x)&#x3D;\\int_0^xp(x)\\mathrm{d}x&#x3D;1-\\mathrm{e}^{-{\\lambda}x}$$求逆函数：$$x&#x3D;\\frac{-\\ln(1-u)}{\\lambda}$$因此从均匀分布 $U[0,1]$ 中采样一系列的 $u_i$ ，代入上式得到的 $xi$ 就是符合指数分布的随机变量。 $xi$ （随机延迟时间）服从指数分布，用于模拟随机Petri网中时间变迁的触发间隔 置信区间置信水平（Confidence Intervals）：区间包含总体平均值的概率 置信区间（Confidence Level）：误差范围 95%置信区间表示在重复抽样的情况下，有95%的概率包含了总体参数的真实值。置信区间通常以估计值加减一个误差范围来表示。当我们进行蒙特卡罗模拟时，会生成大量的随机样本，并基于这些样本进行统计分析。利用蒙特卡罗模拟得到的参数估计值和方差（或标准差），我们可以计算置信区间。 蒙特卡罗模拟蒙特卡罗方法（Monte Carlo method），也称统计模拟方法，是1940年代中期由于科学技术的发展和电子计算机的发明，而提出的一种以概率统计理论为指导的数值计算方法。作为一种常用的模拟技术，其主要出现在风险管理知识领域中的定量风险分析过程，是用于做项目定量风险分析的工具之一，同时蒙特卡洛模拟也可以用于估算进度或成本以及制定进度计划等。 蒙特卡罗仿真的基本流程如下： 系统建模。根据系统的目标和结构构建一个合理的数学逻辑模型。建模型的方法有多种，如对系统的动态变化建立系统的 SPN 模型。 确定随机变量及其分布，在可靠性仿真中，元件的寿命分布和维修时间分布是仿真的基础，这些分布函数的获得可以通过以往的经验及大量统计来完成。 确定随机变量的分布后，选择适当的随机变量抽样方法，实现对已知概率分布抽样。即通过产生随机数的方式进行对已知概率分布的抽样。这是蒙特卡罗仿真最为主要的一步，也是蒙特卡罗仿真思想的体现。 统计计算。得到仿真数据后，对系统及元件进行可靠性指标分析。 蒙特卡洛模拟(Monte Carlo Simulation)浅析","tags":["Petri net"],"categories":["Research"]},{"title":"《程序员的底层思维》","path":"/2023/08/28/mindset/","content":"作者：张建飞，出版时间：2022-02 基础思维能力抽象思维 若想捉大鱼，就得潜入深渊。深渊里的鱼更有力，也更纯净。硕大而抽象，且非常美丽。 ——大卫·林奇 抽象思维是程序员最重要的思维能力之一，抽象的过程就是通过归纳概括、分析综合来寻找共性、提炼相关概念的过程。 语言和抽象是一体的，抽象的概念只有通过语言才能表达出来，因此命名至关重要。 过多地使用基础类型可能意味着抽象的缺失，需要对这些业务概念进行封装和抽象。 重复代码通常意味着抽象缺失，提取重复代码只是完成了重构的第一步，关键是后续的命名。 抽象具有层次性，抽象层次越高，内涵越小，外延越大，扩展性越好；反之，抽象层次越低，内涵越大，外延越小，扩展性越差，但语义表达能力越强。 对抽象层次的拿捏体现了我们的设计功力，抽象层次要视具体情况而定，既不能太高，也不能太低。 强制类型转换意味着抽象层次有问题，可以通过提升抽象层次来解决。 抽象层次要保持一致性，即要遵循LSP，一致性可以减少混乱和降低理解成本。 Liskov Substitution Principle（里氏替换原则）：子类应该可以替换任何父类会出现的地方，并且经过替换以后，代码还能正常工作。 我们可以通过刻意练习来提升抽象能力，这些练习包括阅读、总结、命名训练、建模训练等。 逻辑思维 不合乎逻辑的观点只需一根绳索就可将它绞死。 ——比勒尔 逻辑思维是最底层的思维能力，其本质是判断关系是否合理。 逻辑的三要素是概念、判断和推理，只有概念清晰、判断无误、推理符合形式逻辑要求，才算逻辑正确。 软件设计从理解问题域开始，而理解问题域的核心是要深入理解领域的核心概念。 判断分为肯定判断和否定判断，判断要么真、要么假，不能非真非假。 逻辑推理可以分为演绎推理、归纳推理和溯因推理。 演绎推理：因为，因为，所以 归纳推理：从特殊到一般 溯因推理：大胆假设，小心求证 思考的深度取决于逻辑链的深度，5Why和5So思考法是非常有用的深度思考工具。但是推导要注意逻辑的严密性，否则逻辑链很容易形成滑坡谬误。 形式逻辑虽然强大但不实用，掌握常见的逻辑谬误能帮助我们更快地辨别真伪。 逻辑需要理性，但感性同样重要，不要“得理不饶人”，把自己变成了“杠精”。 结构化思维 金字塔原理是思考、表达和解决问题的逻辑。 ——芭芭拉·明托 结构是万物之本，小到分子，大到宇宙，只有了解其结构才能真正认识它。 结构性问题是本质问题，不改变结构，再多的努力也白费。 人脑记忆的特点是概念不能多，要有逻辑，金字塔结构能满足这样的特征。 在金字塔结构里，纵向逻辑关系有演绎和归纳两种；横向逻辑关系有时间顺序、空间顺序和程度顺序三种。 构建结构可以采用自上而下和自下而上两种方法，凡事没有绝对，更多的时候需要上下结合。 针对不同的问题域，有很多现成的解决问题的框架，熟悉这些“套路”可以帮助我们快速搭建结构和解决问题。 制定市场营销策略的“4P”模型 组织战略的“7S”模型 分析竞争力的SWOT模型 制定目标的SMART模型 批判性思维 未经审视的人生不值得过。 ——苏格拉底 批判要基于理性的逻辑思维，而不是耍嘴皮子。 在当今信息爆炸的社会，我们需要批判精神来看待事情。 业务多样性、多变性的特性决定了业务中台很难成功。 代码复制也是一种复用，而且是耦合性最低的复用。 架构是一种能力，而不仅仅是职位。 技术管理者不能仅仅是一个管理者(Manager)，也要是一个领导者(Leader)。 坚持自我批判，才能持续成长。 在软件领域，很多问题都要批判、辩证地来看。比如，敏捷开发就一定比瀑布式好吗？微服务就一定比单体好吗？ “不要把自信建立在贬低他人的基础上，什么时候你能发自内心地欣赏你不喜欢的人，你就成长了。”寸有所长，尺有所短，要看得见别人的优（不妒忌，学会欣赏别人），用得上别人的劣（从他人错误中学习）。 维度思维 这个世界不是只有是非黑白，还有很多灰色地带。 ——白岩松 维度思维的关键是理解维度，维度是问题域独立参数或变量的数量。 不借助工具，大脑很难处理多维问题，矩阵分析是解决多维问题的利器。 矩阵分析首先要找到影响问题域的核心要素，也可以叫变量、维度，然后显性化地构建矩阵，当维度和维度属性值比较少的时候，可以用四象限、九宫格或立方体进行视觉上的呈现。 业务代码的复杂度主要取决于业务场景和业务流程的复杂度。再复杂的业务，其业务场景都是可以枚举的，关键是找到构成业务场景的核心要素。例如，商品业务的场景主要由商品类型、商品售卖方式、商品仓储方式3个要素组成。 多维度思考是思考的高级形式，矩阵分析在其中是无处不在的。从商业分析的波士顿矩阵、RFM模型到逻辑推理，都能看到矩阵分析的身影。 分类思维 设计就是分类。 ——“微信之父”张小龙 分类就是设计，分类对设计至关重要。 人类有分类的本能，这和我们认识世界的方式有关。 分类的本质是寻找共性，这些共性既可以是物理属性，也可以是概念属性。 没有完美的分类，任何分类都与进行分类的观察者的视角和目的有关。 分类是软件设计的基础，主要体现为对象分类、构建分类和领域分类。 不同维度的分类选择造就了不同的组织，既可以按照业务划分，也可以按照职能划分。 按照供给和履约的不同对互联网进行分类，可以更好地看清互联网。 分治思维 要把大象装进冰箱，拢共分几步？ ——小品《钟点工》 解决复杂问题要分治，计算机涉及的问题都比较复杂，需要分而治之来解决。 软件中存在大量的分治思想，比如管道模式、分层架构、分布式架构等，无不体现了分治的强大。 “分治并”是分治的进阶，有些问题除了分治，还需要整合、合并。 “分治并”本质上对应的是定义问题、分析问题、解决问题的通用步骤。 很多问题在解决过程中都显性或隐性地使用到了“分治并”，比如分治算法、流式计算、分布式数据库系统。 简单思维 一旦做到了简洁，你将无所不能。 ——乔布斯 简单不是一个简单的目标，而是一个非常高的目标。所有的UNIX哲学浓缩为一条铁律就是KISS原则。 简单不是简陋。简单是一种洞察问题本质、化繁为简的能力，简陋是对问题不加思考地简单处理，二者有本质区别。 简单需要我们付出很多的精力，对问题深入思考，进行熵减逆向做功。往往需要经历简单—复杂—简单的演化过程。 我们可以利用隐藏、减少选择及奥卡姆剃刀来实现简化的目的。 E &#x3D; mc² （E能量 m质量 c光速）和 F &#x3D; ma（F外力 m质量 a加速度） 证明，上帝似乎不是一个喜欢复杂的人。 不管是弃用流程引擎、重新设计状态机引擎，还是COLA的迭代、产品的博弈，我总是能从化繁为简中受益。 成长型思维 决定你成长的第一步不是你是否努力，而是你是否相信努力。 固定型思维让信心和成功都充满脆弱性。因为相信能力是固定的，所以你需要不断证明自己的能力与价值。 成长型思维认为成功是学习的结果，努力是通往成功的关键。成功个体的标志在于他们热爱学习、喜欢挑战、重视努力，并在面对苦难时坚韧不拔。 研究表明，我们的大脑具有可塑性，这是成长型思维的生理基础。 培养成长型思维，需要我们有一个好的心态，相信努力的意义，改变错误的归因习惯，摆脱精神内耗，相信水滴石穿，持续精进。 培养成长型思维，最好从小开始，父母要更多地鼓励小孩的努力、过程、选择、策略……而不是天赋。不要做养成固定型思维的助推器。 成功人士或多或少具备成长型思维，因为唯有如此，他们才能战胜磨难和逆境，没有人能随随便便成功。 专业思维能力解耦思维 人生最难熬的痛苦，就是你跟本该远离的东西纠缠在了一起。 “高内聚、低耦合”是软件设计追求的重要目标之一，组件、模块、层次设计都应该遵循“高内聚、低耦合”的设计原则。 正交的关键在于如何识别耦合性，我们可以通过识别系统需要扩展的地方来识别耦合性。比如，关于配置系统的设计不应该耦合于某一种特定的实现方式，而是应该更灵活一些。 解耦主要有依赖倒置和中间层映射两种方式。 我们要尽可能多地依赖抽象而不是具体，这能使系统更灵活，这种编程方式也叫作面向接口编程。 “计算机中的任何问题，都可以通过加一层来解决”，中间层的价值也在于解耦。 契约思维 人是生而自由的，但却无往不在枷锁之中。 ——卢梭 “写代码是自由的，但无往不在规则之下”。 社会大规模分工协作离不开契约思维，编程在很大程度上是一种“制定契约”。 在软件领域，契约思维主要有软件规范和软件标准两方面的重要价值。 一致性可以降低复杂度，我们可以在命名、异常处理、应用架构等方面在团队内制定规范。 不管是前端标准化，还是JCP(Java Community Process)，都体现了规范和标准在软件中的重要作用。 “一流的企业定标准，二流的企业做品牌，三流的企业卖产品”，谁掌握了标准制定权，谁就掌握了主动权。从这个意义上来说，提供SPI(Service Provider Interface)要比调用他人的API更主动。 模型思维 建模的艺术就是去除实在中与问题无关的部分。 ——菲利普·安德森（1977年诺贝尔物理学奖得主） 模型是对现实世界的抽象和映射。没有完美的模型，甚至连正确的模型都没有，就像类比永远不能代替问题本身一样。 我们可以将模型分成物理模型、数学模型、概念模型、思维模型等。 UML是在软件工程中具有广泛共识的建模方法、语言和表示法，其类图也常被用来做领域建模。 领域建模和技术实现无关，是问题域分析、明晰概念、获得关键实体对象的重要过程。领域模型反映了关键的业务概念，刻画了关键领域实体，以及实体之间关系。 语言是有边界的，同样，模型也有其作用的上下文。我们可以通过共享内核、防腐层等技术实现模型在不同上下文中的映射和协作。 领域模型和数据模型有明显区别，领域模型关心的是业务概念，其要义是显性化地表达业务语义；数据模型关心的是数据存储，其核心是数据访问的性能、数据的扩展性等非功能属性。 工具化思维 懒人的逻辑中也有其合理的一面，勤劳奋斗的逻辑中也必定有其荒唐的一面。 ——张方宇 工具化是一种“偷懒”的智慧，工作中要有阶段性地停下来思考，不要用战术上的勤奋掩盖战略上的懒惰。 工具化的步骤：首先，发现问题，找到重复3次以上的手工劳动；其次，明确问题，找到现状和期望之间的差距；最后，制造工具，解决问题。 创新不一定都是从无到有的，对现有工具的组合和整合也是一种创新和工具化。 要不遗余力地提升研发效率，比如TestsContainer和通用的MyBatis Mapper。 要善于利用工具，白板和便签贴是讨论问题时非常有用的工具。有价值的不是工具本身，而是如何利用它。 量化思维 No measurement，no improvement.（没有量化，就无法优化。） ——“科学管理之父”温斯洛·泰勒 No measurement，no improvement.（没有量化，就无法优化。） 量化的一般步骤包括定义指标、数字化和优化指标。 对于研发效能来说，目前还没有特别有效的度量手段，所以指标的设定非常关键。错误的度量不仅不会带来效率提升，反而会带来伤害。 团队管理的首要任务是目标管理，我们可以采用OKR进行目标管理，在设定OKR时要遵循SMART原则。指标只是管理手段，不可完全迷信指标。 量化工作本身是一件非常困难和极具挑战的事情，但量化思维要求我们不要轻易放弃关于量化的思考和尝试。没有量化的目标，就像是断了线的风筝，没有方向，缺少指引，飞到哪里是哪里，而量化后的目标可以为我们清楚地指引方向。 数据思维 一切业务数据化，一切数据业务化。 ——阿里巴巴 一切业务数据化，一切数据业务化。数据是公司的重要资产，工程师必须了解公司的数据体系。 整个大数据体系很庞大，对于应用开发者来说，不一定要面面俱到，非常精通，但至少要做到能理解、会使用。 典型的企业的大数据解决方案包括数据仓库、ETL、元数据、分布式数据存储、流式计算等。 数据库关注的是OLTP，数据仓库关注的是OLAP，数据仓库中对数据的操作通常包括切片切块、上卷下钻等。 数仓建模通常采用Ralph Kimball提出的维度模型，其中针对维度表和事实表，为了提升查询性能和响应速度，通常采用大宽表代替雪花模型，用空间换时间的方式。 阿里巴巴的生意参谋是数据业务化的典型代表和成功案例，通过大数据赋能商家，既让商家更好地在平台做生意，同时平台也实现了数据变现，可谓双赢。 产品思维 产品就是用来解决某个问题的东西。 ——苏杰《人人都是产品经理》 产品就是用来解决某个问题的东西。产品无处不在，每个人都需要具备一些产品思维，人人都是产品经理。 产品对上支撑业务价值，对下要求业务功能和质量属性的实现。产品的核心要素包括用户、需求和场景。 产品有多种视角的分类，按照用户需求可以分为工具型产品、社交型产品、交易型产品、平台型产品；按照用户类型可以分为2C、2B和2G产品等。 产品架构主要分为用户感知层、功能模块层和数据层3个层次。 产品化是把一种技术、一种服务通过标准化、规范化的流程形成一种可大规模复制生产和发布的能力。 平台也是一种产品形态，在不同的语境下，平台的含义不一样。在技术的上下文中，平台是指可复用的硬件或软件的操作环境，其目的是节约成本、提升软件研发效率。 用产品思维去建设平台，我们可以从价值的角度出发，更多地关注用户体验，从而有机会做出不错的平台型产品。 思维能力的综合应用我的商品团队之旅 人是能够习惯于任何环境的生物，之前你认为自己难以克服的困难，慢慢都会适应了。 ——维克多·弗兰克《活出生命的意义》 看起来很困难的事，刻意练习多了，也就不困难了。我从一开始进入新团队的不知所措，到后来的从容谈定，就经历了刻意练习的过程。 落地新团队，要抓住企业的核心要素——人、业务、技术和文化，可以做到事半功倍。 再复杂的业务也可以进行结构化分解，一旦把业务的结构梳理清楚，工作就完成一半了。实现方式最好采用简洁朴素的CMP或管道模式，复杂的流程引擎通常不仅帮不上忙，还会增加额外的复杂度。 复杂业务的应对之道是结合自上而下的结构化分解+自下而上的抽象建模，同时要在过程中随时调整、重构结构和模型，将可复用的能力下沉，从而提升系统的可维护性。 COLA的演进过程 Software’s primary technical imperative：managing complexity.（软件的首要技术使命：管理复杂度。） ——Steve McConnell 架构的要义在于约束。 “在一个架构良好的系统中，评估代码改动点不应该是线性地按图索骥，而是应该像散列查找一样，直接定位到需要改动的地方，它们之间是O(n)和O(1)的差别。” 🥤 COLA: Clean Object-oriented &amp; Layered Architecture","categories":["Reading"]},{"title":"简明 Linux 系统编程 🐧","path":"/2023/08/03/linux2/","content":"即 Linux 环境下的应用程序开发，开发环境 Ubuntu22 常用命令：man Linux Programmer’s Manual 基本概念 程序：源代码、指令（静态） 进程：运行着的程序（动态） 线程：线程从属于进程，一个进程可以有多个线程，线程之间共享进程的资源 任务：具体要做的事情 12345678910111213#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt;#include &lt;stdio.h&gt;int main() &#123; pid_t pid; while (1) &#123; printf(&quot;pid = %d &quot;, getpid()); printf(&quot;ppid = %d &quot;, getppid()); sleep(1); &#125; return 0;&#125; pstree -p 查看系统进程树 创建进程123456789101112#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt;#include &lt;stdio.h&gt;int main() &#123; pid_t pid; // parent 进程返回子进程的id，子进程返回0 pid = fork(); printf(&quot;pid = %d &quot;, pid); printf(&quot;Hello world &quot;); return 0;&#125; 1234567891011#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt;#include &lt;stdio.h&gt;int main() &#123; pid_t pid1, pid2; pid1 = fork(); pid2 = fork(); printf(&quot;pid1 = %d, pid2 = %d &quot;, pid1, pid2); return 0;&#125; 12345678910111213141516171819202122232425262728#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt;#include &lt;stdio.h&gt;int main() &#123; pid_t pid; // parent 和 child 是独立的， 放全局也是独立的 int count = 0; pid = fork(); // parent process if (pid &gt; 0) &#123; // 运行结束不影响子进程的运行 for (int i = 0; i &lt; 10; ++i) &#123; printf(&quot;hello world, count = %d &quot;, count++); sleep(1); &#125; // child process &#125; else if (pid == 0) &#123; while (1) &#123; printf(&quot;gooood, count = %d &quot;, count++); sleep(3); &#125; &#125; else &#123; perror(&quot;fork&quot;); &#125; return 0;&#125; 监控子进程123456789101112131415161718192021222324252627282930313233343536373839#include &lt;sys/types.h&gt;#include &lt;sys/wait.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;// run model: ./a.out 10 5 15 (三个子进程 10 5 15s 后运行结束)int main(int argc, char *argv[]) &#123; pid_t child_pid; int numDead; int i; for (i = 1; i &lt; argc; ++i) &#123; switch(fork()) &#123; case -1: perror(&quot;fork()&quot;); exit(1); case 0: printf(&quot;Child %d started with PID = %d, sleeping %s &quot;, i, getpid(), argv[i]); // string -&gt; int sleep(atoi(argv[i])); exit(0); // parent default: break; &#125; &#125; numDead = 0; while (1) &#123; // 阻塞等待任意子进程结束 child_pid = wait(NULL); if (child_pid == -1) &#123; printf(&quot;No more children, Byebye! &quot;); exit(0); &#125; ++numDead; printf(&quot;wait() return child PID %d(numDead = %d) &quot;, child_pid, numDead); &#125; return 0;&#125; 创建线程12345678910111213141516171819202122232425262728293031323334#include &lt;pthread.h&gt;#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;stdlib.h&gt;void *thread_funciton(void *);int main() &#123; pthread_t pthread; int ret; // 传递参数给线程 int count = 5; // 创建线程 ret = pthread_create(&amp;pthread, NULL, thread_funciton, &amp;count); if (ret != 0) &#123; perror(&quot;pthread_create&quot;); exit(1); &#125; // 等待线程 pthread_join(pthread, NULL); printf(&quot;The thread is over, process is over too. &quot;); return 0;&#125;void *thread_funciton(void *arg) &#123; int i; printf(&quot;Thread begins running &quot;); // void* -&gt; int* for (i = 0; i &lt; *(int*)arg; ++i) &#123; printf(&quot;Hello world &quot;); sleep(1); &#125; return NULL;&#125; 线程数据共享1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#include &lt;pthread.h&gt;#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;stdlib.h&gt;void *thread1_funciton(void *);void *thread2_funciton(void *);// 线程共享该变量int count = 0;int main() &#123; pthread_t pthread1, pthread2; int ret; // 传递参数给线程 // 创建线程 ret = pthread_create(&amp;pthread1, NULL, thread1_funciton, NULL); if (ret != 0) &#123; perror(&quot;pthread1_create&quot;); exit(1); &#125; ret = pthread_create(&amp;pthread2, NULL, thread2_funciton, NULL); if (ret != 0) &#123; perror(&quot;pthread2_create&quot;); exit(1); &#125; // 等待线程 pthread_join(pthread1, NULL); pthread_join(pthread2, NULL); printf(&quot;The thread is over, process is over too. &quot;); return 0;&#125;void *thread1_funciton(void *arg) &#123; printf(&quot;Thread1 begins running &quot;); while (1) &#123; printf(&quot;Thread1 count = %d &quot;, count++); sleep(1); &#125; return NULL;&#125;void *thread2_funciton(void *arg) &#123; printf(&quot;Thread2 begins running &quot;); while (1) &#123; printf(&quot;Thread2 count = %d &quot;, count++); sleep(1); &#125; return NULL;&#125; 管道通信无名管道无名管道只适用于有“亲缘关系”的进程 创建管道 1234567891011121314151617181920212223242526272829#include &lt;unistd.h&gt;#include &lt;sys/types.h&gt;#include &lt;stdio.h&gt;int main() &#123; int fd[2]; int pid; if (pipe(fd) == -1) &#123; perror(&quot;pipe&quot;); &#125; pid = fork(); // parent write if (pid &gt; 0) &#123; // 关闭读端 close(fd[0]); sleep(5); write(fd[1], &quot;ab&quot;, 2); // while(1); &#125; else if (pid == 0) &#123; // child read char ch[2]; printf(&quot;Child process is waiting for data: &quot;); // 关闭写端 close(fd[1]); read(fd[0], ch, 2); printf(&quot;Read from pipe: %s&quot;, ch); &#125; return 0;&#125; 管道大小 1234567891011121314151617181920212223242526272829#include &lt;unistd.h&gt;#include &lt;sys/types.h&gt;#include &lt;stdio.h&gt;#include &lt;sys/wait.h&gt;int main() &#123; pid_t pid; int fd[2]; if (pipe(fd) == -1) &#123; perror(&quot;pipe&quot;); &#125; pid = fork(); // child process if (pid == 0) &#123; int n = 0; char ch = &#x27;*&#x27;; close(fd[0]); while (1) &#123; write(fd[1], &amp;ch, 1); // 管道容量为 65536Byte printf(&quot;count = %d &quot;, ++n); &#125; &#125; else if (pid &gt; 0) &#123; waitpid(pid, NULL, 0); &#125; return 0;&#125; 管道交互 1234567891011121314151617181920212223242526272829303132#include &lt;unistd.h&gt;#include &lt;sys/types.h&gt;#include &lt;stdio.h&gt;#include &lt;sys/wait.h&gt;int main() &#123; pid_t pid; int fd[2]; if (pipe(fd) == -1) &#123; perror(&quot;pipe&quot;); &#125; pid = fork(); // child process if (pid == 0) &#123; char tmp[100]; close(fd[0]); while (1) &#123; scanf(&quot;%s&quot;, tmp); write(fd[1], tmp, sizeof(tmp)); &#125; &#125; else if (pid &gt; 0) &#123; char tmp[100]; close(fd[1]); while(1) &#123; printf(&quot;Parent process is waiting for the data from pipe. &quot;); read(fd[0], tmp, sizeof(tmp)); printf(&quot;read from pipe: %s &quot;, tmp); &#125; &#125; return 0;&#125; 双向传输 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#include &lt;unistd.h&gt;#include &lt;sys/types.h&gt;#include &lt;stdio.h&gt;#include &lt;sys/wait.h&gt;#include &lt;string.h&gt;#include &lt;ctype.h&gt;int main() &#123; pid_t pid; // 一条管道只能单向, 用两条 int fd[2]; int fd2[2]; if (pipe(fd) == -1) &#123; perror(&quot;pipe&quot;); &#125; if (pipe(fd2) == -1) &#123; perror(&quot;pipe2&quot;); &#125; pid = fork(); // child process if (pid == 0) &#123; char tmp[100]; int i; // fd 用来读 fd2 用来写 close(fd[1]); close(fd2[0]); while (1) &#123; memset(tmp, &#x27;\\0&#x27;, sizeof(tmp)); // 读取fd中的数据 read(fd[0], tmp, sizeof(tmp)); for (i = 0; i &lt; sizeof(tmp); ++i) &#123; tmp[i] = toupper(tmp[i]); &#125; // 将转换后的数据写入fd2 write(fd2[1], tmp, sizeof(tmp)); &#125; &#125; else if (pid &gt; 0) &#123; char tmp[100]; close(fd[0]); close(fd2[1]); while(1) &#123; memset(tmp, &#x27;\\0&#x27;, sizeof(tmp)); printf(&quot;Parent input: &quot;); // gets(tmp); scanf(&quot;%s&quot;, tmp); write(fd[1], tmp, sizeof(tmp)); memset(tmp, &#x27;\\0&#x27;, sizeof(tmp)); read(fd2[0], tmp, sizeof(tmp)); printf(&quot;After child change: %s &quot;, tmp); &#125; &#125; return 0;&#125; 有名管道man 3 mkfifo mkfifo, mkfifoat - make a FIFO special file (a named pipe) 读 12345678910111213141516171819202122232425262728293031#include &lt;stdio.h&gt;#include &lt;sys/stat.h&gt;#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt;#include &lt;fcntl.h&gt;#include &lt;string.h&gt;int main() &#123; int ret; int fd; char buf[100]; // 创建有名管道 权限666 ret = mkfifo(&quot;./my_fifo&quot;, 0666); if (ret != 0) &#123; perror(&quot;mkfifo&quot;); &#125; printf(&quot;Prepare reading from named pipe: &quot;); // 读管道 fd = open(&quot;./my_fifo&quot;, O_RDWR); if (fd == -1) &#123; perror(&quot;open&quot;); &#125; while(1) &#123; memset(buf, &#x27;\\0&#x27;, sizeof(buf)); read(fd, buf, sizeof(buf)); printf(&quot;Read from named pipe: %s &quot;, buf); sleep(1);\t&#125;\treturn 0;&#125; 写 12345678910111213141516171819202122232425#include &lt;stdlib.h&gt;#include &lt;stdio.h&gt;#include &lt;sys/stat.h&gt;#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt;#include &lt;fcntl.h&gt;#include &lt;string.h&gt;int main(int argc, char *argv[]) &#123; int fd; char buf[100]; // 写管道 fd = open(&quot;./my_fifo&quot;, O_WRONLY, 0666); if (fd == -1) &#123; perror(&quot;open&quot;); &#125; if (argc == 1) &#123; printf(&quot;Please send something to the named pipe: &quot;); exit(EXIT_FAILURE); &#125; strcpy(buf, argv[1]); write(fd, buf, sizeof(buf)); printf(&quot;Write to the pipe: %s &quot;, buf); return 0;&#125; 共享内存亲缘关系123456789101112131415161718192021222324252627282930313233343536373839#include &lt;stdio.h&gt;#include &lt;sys/ipc.h&gt;#include &lt;sys/shm.h&gt;#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt;#include &lt;string.h&gt;#include &lt;wait.h&gt;char msg[] = &quot;Hello world&quot;;int main() &#123; int shmid; pid_t pid; // 开辟共享内存，权限0666 不需要root权限 shmid = shmget(IPC_PRIVATE,1024,IPC_CREAT | 0666); pid = fork(); if (pid &gt; 0) &#123; // 映射共享内存 char *p_addr; p_addr = shmat(shmid, NULL, 0); // 写入数据 memset(p_addr, &#x27;\\0&#x27;, sizeof(msg)); memcpy(p_addr, msg, sizeof(msg)); // 解除映射 shmdt(p_addr); // 等待子线程结束 waitpid(pid, NULL, 0); &#125; else if (pid == 0) &#123; char *c_addr; c_addr = shmat(shmid, NULL, 0); printf(&quot;Child process waits a short time... &quot;); sleep(2); printf(&quot;Chile process read from shared memory: %s &quot;, c_addr); shmdt(c_addr); &#125; else &#123; perror(&quot;fork&quot;); &#125; return 0;&#125; 非亲缘关系写 1234567891011121314151617181920212223#include &lt;stdio.h&gt;#include &lt;sys/ipc.h&gt;#include &lt;sys/shm.h&gt;#include &lt;unistd.h&gt;#include &lt;string.h&gt;#define MY_KEY 9527char msg[] = &quot;Hello world&quot;;int main() &#123; int shmid; // key 设置为自定义的 shmid = shmget(MY_KEY,1024,IPC_CREAT | 0666); char *p_addr; p_addr = shmat(shmid, NULL, 0); memset(p_addr, &#x27;\\0&#x27;, sizeof(msg)); memcpy(p_addr, msg, sizeof(msg)); // 解除绑定 shmdt(p_addr); // 控制共享内存 删除 // shmctl(shmid, IPC_RMID, NULL); return 0;&#125; 读 1234567891011121314151617#include &lt;stdio.h&gt;#include &lt;sys/ipc.h&gt;#include &lt;sys/shm.h&gt;#include &lt;unistd.h&gt;#include &lt;string.h&gt;#define MY_KEY 9527int main() &#123; int shmid; shmid = shmget(MY_KEY,1024,IPC_CREAT | 0666); char *c_addr; c_addr = shmat(shmid, NULL, 0); printf(&quot;Read from shared memory: %s&quot;, c_addr); shmdt(c_addr); return 0;&#125; 消息队列亲缘关系12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#include &lt;stdio.h&gt;#include &lt;sys/ipc.h&gt;#include &lt;sys/shm.h&gt;#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt;#include &lt;string.h&gt;#include &lt;wait.h&gt;#include &lt;sys/msg.h&gt;#define MY_TYPE 9527int main() &#123; int msgid; pid_t pid; // 定义消息内容 struct msgbuf &#123; long mtype; char mtext[100]; int number; &#125;; struct msgbuf buff; // 创建消息队列 ⚠️注意权限的配置、返回状态的异常处理 msgid = msgget(IPC_PRIVATE, IPC_CREAT|0666); pid = fork(); if (pid &gt; 0) &#123; sleep(1); buff.mtype = MY_TYPE; printf(&quot;Please enter a string you want to send: &quot;); // fgets(buff.mtext, sizeof(buff.mtext), stdin); gets(buff.mtext); printf(&quot;Please enter a number you want to send: &quot;); scanf(&quot;%d&quot;, &amp;buff.number); // 发送数据到队列 // if (msgsnd() ... )&#123;&#125; msgsnd(msgid, &amp;buff, sizeof(buff) - sizeof(buff.mtype), 0); waitpid(pid, NULL, 0); &#125; else if (pid == 0) &#123; printf(&quot;Child process is waiting for msg... &quot;); // 接收消息 msgrcv(msgid, &amp;buff, sizeof(buff) - sizeof(buff.mtype), MY_TYPE, 0); printf(&quot;Child process read from msg: %s, %d&quot;, buff.mtext, buff.number); // 删除消息队列 msgctl(msgid, IPC_RMID, NULL); &#125; else &#123; perror(&quot;fork&quot;); &#125; return 0;&#125; ipcs -q 查看到该消息队列 ipcrm -q [消息队列qid] 删除消息队列 非亲缘关系发送 12345678910111213141516171819202122232425262728293031#include &lt;stdio.h&gt;#include &lt;sys/ipc.h&gt;#include &lt;sys/shm.h&gt;#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt;#include &lt;string.h&gt;#include &lt;wait.h&gt;#include &lt;sys/msg.h&gt;#define MY_TYPE 9527#define MY_KEY 1314int main() &#123; int msgid; struct msgbuf &#123; long mtype; char mtext[100]; int number; &#125;; struct msgbuf buff; msgid = msgget(MY_KEY, IPC_CREAT|0666); buff.mtype = MY_TYPE; printf(&quot;Please enter a string you want to send: &quot;); gets(buff.mtext); printf(&quot;Please enter a number you want to send: &quot;); scanf(&quot;%d&quot;, &amp;buff.number); // 发送数据到队列 msgsnd(msgid, &amp;buff, sizeof(buff) - sizeof(buff.mtype), 0); return 0;&#125; 接收 123456789101112131415161718192021222324252627282930#include &lt;stdio.h&gt;#include &lt;sys/ipc.h&gt;#include &lt;sys/shm.h&gt;#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt;#include &lt;string.h&gt;#include &lt;wait.h&gt;#include &lt;sys/msg.h&gt;#define MY_TYPE 9527#define MY_KEY 1314int main() &#123; int msgid; struct msgbuf &#123; long mtype; char mtext[100]; int number; &#125;; struct msgbuf buff; msgid = msgget(MY_KEY, IPC_CREAT|0666); while (1) &#123; printf(&quot;Process is waiting for msg... &quot;); // 接收消息 msgrcv(msgid, &amp;buff, sizeof(buff) - sizeof(buff.mtype), MY_TYPE, 0); printf(&quot;Process read from msg: %s, %d &quot;, buff.mtext, buff.number); &#125; return 0;&#125; 信号量无名信号量parenti child 进程之间的示例 1234567891011121314151617181920212223242526272829303132#include &lt;semaphore.h&gt;#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;stdlib.h&gt;#include &lt;sys/mman.h&gt;int main() &#123; pid_t pid; sem_t *sem_id = NULL; // 开辟虚拟空间映射 sem_id = mmap(NULL, sizeof(sem_t), PROT_READ | PROT_WRITE, MAP_SHARED | MAP_ANONYMOUS, -1, 0); // 创建信号量 // pshared 1 表示进程之间的 需要借助进程之前的共享空间 sem_init(sem_id, 1, 0); pid = fork(); if (pid &gt; 0) &#123; while(1) &#123; // 等待(消耗)信号量 sem_wait(sem_id); printf(&quot;This is paremt process. &quot;); sleep(1); &#125; &#125; else if (pid == 0) &#123; while(1) &#123; printf(&quot;This is child process. &quot;); sleep(3); // 发布信号量 sem_post(sem_id); &#125; &#125; return 0;&#125; 命名信号量非亲缘进程之间的示例 发布 12345678910111213141516171819#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;stdlib.h&gt;#include &lt;semaphore.h&gt;#include &lt;fcntl.h&gt;#include &lt;sys/stat.h&gt;int main() &#123; int i = 0; sem_t *sem = NULL; // 创建或打开命名信号量 sem = sem_open(&quot;NAMED_SEM&quot;, O_CREAT, 666, 0); while (1) &#123; printf(&quot;Process 0: i = %d &quot;, i++); sleep(1); sem_post(sem); &#125; return 0;&#125; 等待 123456789101112131415161718#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;stdlib.h&gt;#include &lt;semaphore.h&gt;#include &lt;fcntl.h&gt;#include &lt;sys/stat.h&gt;int main(void) &#123;\tsem_t *sem = NULL;\tint i = 0;\tsem = sem_open(&quot;NAMED_SEM&quot;, O_CREAT, 666, 0);\twhile(1) &#123; sem_wait(sem); printf(&quot;Process 1: i = %d &quot;, i++);\t&#125;\treturn 0;&#125; ls -l /dev/shm/sem.NAMED_SEM 查看权限 修改代码后运行删去旧创建的同名信号量文件，可能会出现权限问题导致 sem_open 函数执行失败，sem 为空指针，后续程序出现 segmentation fault 信号量同步线程间示例，修改至 线程数据共享 代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#include &lt;pthread.h&gt;#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;stdlib.h&gt;#include &lt;semaphore.h&gt;void *thread1_funciton(void *);void *thread2_funciton(void *);// 线程共享该变量int count = 0;sem_t sem;int main() &#123; // 创建信号量 sem_init(&amp;sem, 0, 0); pthread_t pthread1, pthread2; int ret; // 传递参数给线程 // 创建线程 ret = pthread_create(&amp;pthread1, NULL, thread1_funciton, NULL); if (ret != 0) &#123; perror(&quot;pthread1_create&quot;); exit(1); &#125; ret = pthread_create(&amp;pthread2, NULL, thread2_funciton, NULL); if (ret != 0) &#123; perror(&quot;pthread2_create&quot;); exit(1); &#125; // 等待线程 pthread_join(pthread1, NULL); pthread_join(pthread2, NULL); printf(&quot;The thread is over, process is over too. &quot;); return 0;&#125;void *thread1_funciton(void *arg) &#123; while (1) &#123; sem_wait(&amp;sem); printf(&quot;Thread1 count = %d &quot;, count++); &#125; return NULL;&#125;void *thread2_funciton(void *arg) &#123; while (1) &#123; printf(&quot;Thread2 is running! &quot;); sleep(3); sem_post(&amp;sem); &#125; return NULL;&#125; 互斥锁通常用于线程间任务的同步，修改至 线程数据共享 代码 sudo apt install glibc-doc sudo apt install manpages-posix-dev man pthread_mutex_init 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768#include &lt;bits/types.h&gt;#include &lt;pthread.h&gt;#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;stdlib.h&gt;#include &lt;semaphore.h&gt;void *thread1_funciton(void *);void *thread2_funciton(void *);// 线程共享该变量int count = 0;pthread_mutex_t mutex;int main() &#123; // 创建互斥锁 pthread_mutex_init(&amp;mutex, NULL); pthread_t pthread1, pthread2; int ret; // 传递参数给线程 // 创建线程 ret = pthread_create(&amp;pthread1, NULL, thread1_funciton, NULL); if (ret != 0) &#123; perror(&quot;pthread1_create&quot;); exit(1); &#125; ret = pthread_create(&amp;pthread2, NULL, thread2_funciton, NULL); if (ret != 0) &#123; perror(&quot;pthread2_create&quot;); exit(1); &#125; // 等待线程 pthread_join(pthread1, NULL); pthread_join(pthread2, NULL); printf(&quot;The thread is over, process is over too. &quot;); return 0;&#125;void *thread1_funciton(void *arg) &#123; int i; while (1) &#123; // 加锁 🔒 pthread_mutex_lock(&amp;mutex); for (i = 0; i &lt; 3; ++i) &#123; printf(&quot;Hello world &quot;); sleep(1); &#125; // 解锁 pthread_mutex_unlock(&amp;mutex); sleep(1); &#125; return NULL;&#125;void *thread2_funciton(void *arg) &#123; sleep(1); int i; while (1) &#123; pthread_mutex_lock(&amp;mutex); for (i = 0; i &lt; 3; ++i) &#123; printf(&quot;Hcjjjjjjj &quot;); sleep(1); &#125; pthread_mutex_unlock(&amp;mutex); sleep(1); &#125; return NULL;&#125; 信号用于任务间传递控制命令，而不是数据 kill -l man 2 kill parent 进程发送控制命令给 child 进程 1234567891011121314151617181920212223#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;signal.h&gt;#include &lt;sys/types.h&gt;int main() &#123; pid_t pid; pid = fork(); if (pid &gt; 0) &#123; sleep(3); kill(pid, SIGKILL); &#125; else if (pid == 0) &#123; int i = 0; printf(&quot;Child process id = %d &quot;, getpid()); while (1) &#123; printf(&quot;Count to %d &quot;, ++i); sleep(1); &#125; &#125; else &#123; perror(&quot;fork()&quot;); &#125; return 0;&#125; 捕获命令后执行想要重定向的操作 man signal 12345678910111213141516171819202122232425262728293031#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;stdlib.h&gt;#include &lt;signal.h&gt;void fun(int signo);int main() &#123; int i = 0; printf(&quot;pid = %d &quot;, getpid()); signal(SIGINT, fun); signal(SIGKILL, fun); while (1) &#123; printf(&quot;Count to %d &quot;, ++i); sleep(1); &#125; return 0;&#125;void fun(int signo) &#123; if (signo == SIGINT) &#123; printf(&quot;You hava just triggered a ctrl+c operation. &quot;); exit(1); &#125; else if (signo == SIGKILL) &#123; // 无法修改 SIGKILL 的处理机制 printf(&quot;Trig a SIGKILL signal. &quot;); &#125; else if (signo == SIGQUIT) &#123; // 无法修改 SIGQUIT 的处理机制 printf(&quot;Trig a SIGQUIT signal. &quot;); &#125;&#125; 1234567891011#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;stdlib.h&gt;#include &lt;sys/types.h&gt;#include &lt;signal.h&gt;int main(int argc, char *argv[]) &#123; // kill(atoi(argv[1]), SIGKILL); kill(atoi(argv[1]), SIGQUIT); return 0;&#125; 网络编程TCP 服务端socket() → bind() → listen() → accept() → read()&#x2F;recv() → write()&#x2F;send() → close() 123456789101112131415161718192021222324252627282930313233343536373839404142#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/socket.h&gt;#include &lt;netinet/in.h&gt;#include &lt;arpa/inet.h&gt;#define PORT_ID 8801#define SIZE 100int main() &#123; int sockfd, client_sockfd; struct sockaddr_in my_addr, client_addr; int addr_len; char welcome[SIZE] = &quot;Welcome to connect to the server&quot;; // 1.socket() sockfd = socket(AF_INET, SOCK_STREAM, 0); // 2.bind() my_addr.sin_family = AF_INET; // 主机序转网络序 my_addr.sin_port = htons(PORT_ID); my_addr.sin_addr.s_addr = INADDR_ANY; //sockaddr_in * 转 sockaddr * bind(sockfd, (struct sockaddr *)&amp;my_addr, sizeof(struct sockaddr)); // 3.listen() listen(sockfd, 10); addr_len = sizeof(struct sockaddr); while (1) &#123; printf(&quot;Server is waiting for client wo connect: &quot;); // 4.accept() client_sockfd = accept(sockfd, (struct sockaddr *)&amp;client_addr, &amp;addr_len); // 二进制ip转点分十进制形式 printf(&quot;Client address = %s &quot;, inet_ntoa(client_addr.sin_addr)); // 5.send() send(client_sockfd, welcome, sizeof(welcome), 0); printf(&quot;Disconnect the client request. &quot;); // 6.close() close(client_sockfd); &#125; close(sockfd); return 0;&#125; TCP 客户端socket() → connect() → write()&#x2F;send() → read()&#x2F;recv() → close() 12345678910111213141516171819202122232425262728293031323334#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/socket.h&gt;#include &lt;netinet/in.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;stdlib.h&gt;#define PORT_ID 8801#define SIZE 100// ./client [IP]int main(int argc, char *argv[]) &#123; int sockfd; struct sockaddr_in server_addr; char buf[SIZE]; if (argc &lt; 2) &#123; printf(&quot;Usage: ./client [server IP address] &quot;); &#125; // 1.socket() sockfd = socket(AF_INET, SOCK_STREAM, 0); // 2.connect server_addr.sin_family = AF_INET; server_addr.sin_port = htons(PORT_ID); // 点分十进制转二进制 server_addr.sin_addr.s_addr = inet_addr(argv[1]); connect(sockfd, (struct sockaddr *)&amp;server_addr, sizeof(struct sockaddr)); // 3. recv() recv(sockfd, buf, SIZE, 0); printf(&quot;Client receive from server: %s &quot;, buf); // 4.close() close(sockfd); return 0;&#125; 在使用时，应该检查返回值，以确保操作成功！ UDP 服务器端socket() → bind() → recvfrom()&#x2F;sento() 123456789101112131415161718192021222324252627282930313233#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/socket.h&gt;#include &lt;netinet/in.h&gt;#include &lt;arpa/inet.h&gt;#define PORT_ID 8801#define SIZE 100int main() &#123; int sockfd, client_sockfd; struct sockaddr_in my_addr, client_addr; int addr_len; char welcome[SIZE] = &quot;Welcome to connect to the server&quot;; char buf[SIZE]; // 1.socket() sockfd = socket(AF_INET, SOCK_DGRAM, 0); // 2.bind() my_addr.sin_family = AF_INET; my_addr.sin_port = htons(PORT_ID); my_addr.sin_addr.s_addr = INADDR_ANY; bind(sockfd, (struct sockaddr *)&amp;my_addr, sizeof(struct sockaddr)); addr_len = sizeof(struct sockaddr); while (1) &#123; printf(&quot;Server is waiting for client wo connect: &quot;); // 3. recvfrom 来保存客户端的信息 recvfrom(sockfd, buf, SIZE, 0, (struct sockaddr *)&amp;client_addr, &amp;addr_len); printf(&quot;Server receive from client: %s &quot;, buf); &#125; close(sockfd); return 0;&#125; UDP 客户端socket() → sendto()&#x2F;recvfrom() → close() 12345678910111213141516171819202122232425262728293031323334#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/socket.h&gt;#include &lt;netinet/in.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;stdlib.h&gt;#define PORT_ID 8801#define SIZE 100// ./client [IP]int main(int argc, char *argv[]) &#123; int sockfd; int i; struct sockaddr_in server_addr; char buf[SIZE]; if (argc &lt; 2) &#123; printf(&quot;Usage: ./client [server IP address] &quot;); &#125; // 1.socket() sockfd = socket(AF_INET, SOCK_DGRAM, 0); server_addr.sin_family = AF_INET; server_addr.sin_port = htons(PORT_ID); server_addr.sin_addr.s_addr = inet_addr(argv[1]); // 2.sendto() for (i = 0; i &lt; 10; ++i) &#123; sprintf(buf, &quot;%d &quot;, i); sendto(sockfd, buf, SIZE, 0, (struct sockaddr *)&amp;server_addr, sizeof(struct sockaddr)); printf(&quot;Client sends to server: %s: %s &quot;, argv[1],buf); sleep(1); &#125; close(sockfd); return 0; 并发服务器模型 方式一：预先创建多个 child 进程等待客户端的连接 方式二：客户端请求到来了再创建并发线程 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#include &lt;stdio.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/socket.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;netinet/in.h&gt;#include &lt;unistd.h&gt;#include &lt;pthread.h&gt;#define PORT_ID\t8800#define SIZE\t100void *thread_function(void *arg);struct sockaddr_in client_addr;int client_sockfd;char welcome[SIZE] = &quot;Welcome to connect to the sever!&quot;;int main(void) &#123;\tint sockfd;\tstruct sockaddr_in my_addr;\tint addr_len;\tpthread_t pthread;\t//1.socket()\tsockfd = socket(AF_INET, SOCK_STREAM, 0);\t//2.bind()\tmy_addr.sin_family = AF_INET;\tmy_addr.sin_port = htons(PORT_ID);\tmy_addr.sin_addr.s_addr = INADDR_ANY;\tbind(sockfd, (struct sockaddr *)&amp;my_addr, sizeof(struct sockaddr));\t//3.listen()\tlisten(sockfd, 10);\taddr_len = sizeof(struct sockaddr);\twhile(1) &#123; printf(&quot;Server is waiting for client to connect: &quot;); client_sockfd = accept(sockfd, (struct sockaddr *)&amp;client_addr, &amp;addr_len); pthread_create(&amp;pthread, NULL, thread_function, NULL);\t&#125;\tclose(sockfd);\treturn 0;&#125;void *thread_function(void *arg) &#123;\tprintf(&quot;Client IP address = %s &quot;, inet_ntoa(client_addr.sin_addr));\tsend(client_sockfd, welcome, SIZE, 0);\tprintf(&quot;Disconnect the client request. &quot;);\tclose(client_sockfd);\tpthread_exit(NULL);\treturn NULL;&#125;","tags":["Linux","C++"],"categories":["C/C++"]},{"title":"《人性的优点》","path":"/2023/07/31/people2/","content":"Author: Dale Carnegie, Country: United States, Publication date: 1948 How to Stop Worrying and Start Living Fundamental Facts You Should Know about Worry 若想避免忧虑，请学习威廉·奥泽尔爵士的方法，活在“今天”这个舱室中。不要为明天烦恼，只要把当下活到淋漓尽致。 被忧虑逼到墙角的时候，请按照下面三个步骤，运用威利斯·H．卡里尔的神奇法则： 问问自己：“最坏的可能是什么？” 万一发生了最坏情况，做好接受它的心理准备。 冷静地着手改进最坏情况。 提醒自己，为了烦恼付出健康的代价是不划算的。“不知道如何战胜忧虑的企业家往往英年早逝。” Basic Techniques in Analysing Worry 了解事实。请记住，哥伦比亚大学的霍克斯院长曾经说过：“世界上有一半的烦恼，都是源于人们尚未充分了解问题就试图做出决定。” 认真评估事实，谨慎做出决策。 一旦做出决策，就立即行动吧！专注执行决策，不要为结果担忧。 当你或同事遇到烦恼的时候，不妨把问题写下来，然后问自己下述问题： 问题是什么？ 问题的成因是什么？ 有哪些措施有可能解决这个问题？ 你建议采取何种措施？ How to Break the Worry Habit before It Breaks You 用忙碌驱逐忧虑。行动是治愈忧愁的最佳药方。 不要为琐事烦恼。不要让生活的鸡毛蒜皮毁掉你的幸福。 用概率排除忧虑。问问自己：“这件事发生的概率究竟有多高？” 接受无法避免之事。如果事情不是你的能力能够改变的，告诉自己：“事成定局，没有其他可能。” 为忧虑设置止损线。判断事情值得焦虑多久，不要浪费更多时间。 把过去留在过去，不要试图做无用功。 Seven Ways to Cultivate a Mental Attitude that Will Bring You Peace and Happiness 让心中充满平和、勇敢、健康与希望，因为“思想塑造人生”。 不要报复敌人，因为得不偿失。让我们像艾森豪威尔将军一样，不要浪费一秒钟时间想那些我们讨厌的人。 与其为别人忘恩负义而烦恼，不如不对别人抱有期待。请记住，耶稣在一天之内治好了十个麻风病患者，却只得到了一人的感谢。我们凭什么期待自己比耶稣得到更多感谢呢？ 请记住，获得幸福的唯一方式，是享受给予的快乐，不期待对方的感激。 请记住，感恩是教养的结果。如果希望子女懂得感恩，就要以身作则。 多想自己的收获，少想自己的烦恼。 不要模仿他人。找到自我，从容做自己，因为“嫉妒源自无知”，“模仿无异于自杀”。 如果命运交给我们一颗酸柠檬，试着用它榨出柠檬汁。 让我们忘记自己的不幸，试着为他人创造幸福。“善待他人就是善待自己。” the Golden Rule for Conquering Worry 祷告让我们把内心的忧虑用语言表达出来。 祷告让我们感觉身上的重负有人分担，不再是孤零零的一个人。 祷告是行动的助推剂。 How to Keep from Worrying about Criticism 不公的言论是变相的赞美，因为人红才会是非多。 尽力而为，然后撑起内心的伞，无论风吹雨打都置之不理。 把自己做过的蠢事写下来，时常自我批评。既然我们无法做到事事尽善尽美，不妨学学利特尔先生，主动寻求公正有益的建设性批评。 Six Ways to Prevent Fatigue and Worry and Keep Your Energy and Spirits High 不要等到累了才休息。 学会在工作时小憩。 家庭主妇要学会如何在家里休息，进而保持青春。 培养下述四个良好的工作习惯： 清理书桌上所有资料，只留下和手头工作相关的文件。 按照轻重缓急处理事务。 遇到问题的时候，如果你已经掌握了决策所需的信心就立即着手解决，不要拖延。 学会组织、委任和监督指导。 以工作热情击败忧虑和疲劳。 请记住，没有人会因为失眠而死，为失眠担心对你造成的伤害远大于失眠本身。 How to Find the Kind of Work in Which You May Be Happy and Successful 考虑就业指导咨询师的建议。 远离供大于求的热门领域。 远离挣钱概率只有10%的工作。 在决定投身于某个领域之前，先花几周甚至几个月的时间充分了解这个行业。 很多人认为世界上只有一种职业适合自己，这种想法是错误的。 How to Lessen Your Financial Worries 坚持记账； 按自己的需求合理制定预算； 学会明智地消费； 量入为出； 如果需要借钱，借这个机会累积信用额度； 为疾病、火灾等意外情况做好保障； 不要让你的人寿保险以大额现金形式结算给受益人； 让孩子养成正确的金钱观； 开源节流，用烤箱挣点儿外快吧； 永远不要赌博； 如果财务状况无法改善，至少对自己好一些，不要为了无法改变的事情郁郁寡欢。 “How I Conquered Worry”（32 True Stories） “负面情绪的存在是一种警示，提醒我们放慢脚步，将窥视他人生活的目光收回，聚焦于自己，聚焦于当下，积极寻求解决方案，给自己的心灵创造多一点儿自由。”","categories":["Reading"]},{"title":"《人性的弱点》","path":"/2023/07/26/people/","content":"Author: Dale Carnegie, Country: United States, Publication date: October 1936 How to Win Friends and Influence People 人际关系的基本技巧 不要批评，不要指责，不要抱怨 真心实意地感谢他人、赞美他人 激发他人的需求 赢得他人喜爱的六个方式 建立对他人的兴趣，真心诚意地关注他人 微笑 无论对于何人，无论以何种语言，自己的名字都是世界上最甜蜜最重要的词汇 专注地倾听，鼓励他人谈论自己 谈论对方感兴趣的事情 真心实意地让对方知道他有多重要 如何让他人想你之所想 赢得争论的方法只有一个，那就是避免争论 尊重他人的观点，绝不要说“你错了” 如果你错了，请坚决果断地承认错误 沟通始于友善原则5 让对方点头称“是” 让对方主导谈话 循循善诱，让对方自行得出结论 抛开成见，将心比心 体谅他人的想法和愿望 激发对方内心深处的高尚情操 戏剧化你的想法 激将法 如何改变他人，成为领导者 欲抑先扬 间接地引起对方的注意 批评对方之前，先谈谈你自己的过错 以引导代替命令 给对方留足面子 夸奖他人每一点微小的进步，“由衷地赞许，不吝啬赞美之词” 用美誉激励他人，他就会努力不辜负你的期望 鼓励对方勇于改变，让改正错误听起来轻而易举 让对方乐于为你做事 创造奇迹的信 幸福家庭生活的七个法则 别唠叨了 不要试图改变对方 请勿责难 真心诚意地欣赏对方 细微之处见真情 谦和有礼 读一本解析婚姻中性事的好书","categories":["Reading"]},{"title":"CMU 15-445 Database Systems","path":"/2023/06/06/CMU445/","content":"CMU 15-445&#x2F;645 关系型数据库管理系统 课程网站： https://15445.courses.cs.cmu.edu/fall2022/ PROJECTS： C++ Primer Buffer Pool Manager B+Tree Index Query Execution Concurrency Control STEPS： Linux 环境 安装依赖 克隆 Bustub 项目 完成项目要求 提交到 Gradescope 环境搭建SSH 免密登录： 在本地生成 ssh 公钥 id_rsa.pub 把本地的 id_rsa.pub 拷贝到远程服务器上的 authorized_keys 本机： Linux： 操作系统：Ubuntu 22.04.2 LTS x86_64 配置 SSH 远程连接： 1234567# 生成密钥ssh-keygen -t rsa# 添加本机的公钥在此vim ~/.ssh/authorized_keys# 查看ip地址sudo apt install net-toolsifconfig 安装相关依赖： 1234567891011121314151617181920212223242526# install_linux() &#123;# apt-get -y update# apt-get -y install \\# build-essential \\# clang-12 \\# clang-format-12 \\# clang-tidy-12 \\# cmake \\# doxygen \\# git \\# g++-12 \\# pkg-config \\# zlib1g-dev#&#125;sudo apt updatesudo apt install g++ cmake clang clang-format clang-tidy# VSCode 可以安装 clangd 插件# clangd helps developers write, understand and improve C/C++ code# 报错：# libc6-i386 : Depends: libc6 (= 2.35-0ubuntu3) but 2.35-0ubuntu3.1 is to be installedsudo apt install aptitude# 解决依赖关系问题sudo aptitude install clang-formatsudo aptitude install clang-tidy 下载 Bustub 项目： https://github.com/cmu-db/bustub 123git clone https://github.com/cmu-db/bustub.git cd bustubgit checkout -b branchname v20221128-2022fall 线上提交注册课程 https://www.gradescope.com/ 邀请码在课程网站的 FAQ 里，用于上传代码做线上评测 本地测试： 12345678910111213141516171819202122# /home/hcjjj/Desktop/bustub# install the packages that BusTub requires（前面安装过了）sudo build_support/packages.shmkdir buildcd build# /home/hcjjj/Desktop/bustub/build# 执行 cmakecmake ..# 本地测试 p0 为例# -j 6核 编译make starter_trie_test -j 6# 测试./test/starter_trie_test# 代码格式检查make formatmake check-lintmake check-clang-tidy-p0# 打包 p0cd ..zip project0-submission.zip src/include/primer/p0_trie.h 执行 make check-clang-tidy-p0 报错：Unable to run clang-tidy. 1234where python3ls -l /usr/bin | grep pythonsudo ln -s /usr/bin/python3 /usr/bin/python# 然后检查一下 clang-tidy 有没有安装上 本地测试案例代码： 打包： 线上提交： 后面几个项目 CMakeLists.txt 写好了打包操作，不需要自己 zip 12# 执行 make 打包项目1 源代码make submit-p1 上传 project1-submission.zip 到网站相应位置进行评测： 调试工具In brief, LLDB and GDB are two debuggers. The main difference between LLDB and GDB is that in LLDB, the programmer can debug programs written in C, Objective C and C++ while, in GDB, the programmer can debug programs written in Ada, C, C++, Objective C, Pascal, FORTRAN and Go. LLDB：https://lldb.llvm.org/ LLDB 调试的原理：基于操作系统的 ptrace 系统调用，用于进程跟踪，它可以让 A 进程监听和控制 B 进程的内存和寄存器。 GDB：https://www.sourceware.org/gdb/ 123456789sudo apt install lldb# ubuntu 22.04 出现问题hcjjj@ubuntu22:~/Desktop » lldbTraceback (most recent call last): File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;ModuleNotFoundError: No module named &#x27;lldb.embedded_interpreter&#x27;# 解决办法sudo apt install python3-lldb-14sudo ln -s /usr/lib/llvm-14/lib/python3.10/dist-packages/lldb/* /usr/lib/python3/dist-packages/lldb/ Project #0In this project, you will implement a key-value store backed by a concurrent trie. Identification: src&#x2F;include&#x2F;primer&#x2F;p0_trie.h 力扣 208. 实现 Trie (前缀树) Task #1 - Templated Trie Task #2 - Concurrent Trie 实现思路 TrieNode TrieNodeWithValue Trie Insert Remove GetValue 本地测试 123cd buildmake starter_trie_test./test/starter_trie_test 代码格式化 1234cd buildmake formatmake check-lintmake check-clang-tidy-p0 代码提交 123cd ..zip project0-submission.zip src/include/primer/p0_trie.h# 然后将 project0-submission.zip 上传至平台即可 Project #1Project #2Project #3Project #4总结","tags":["database"],"categories":["Course"]},{"title":"MIT Missing Semester","path":"/2023/06/04/missing/","content":"计算机教育中缺失的一课资料：官方讲义、仓库 中文：讲义、双语字幕 课程概览与 Shell 一些类Unix shell的简单命令，包括重定向输入输出流和管道符 Shell 工具和脚本 bash作为脚本语言的一些基础操作和几种常用的shell工具 查找文件：find 、fd 查找代码：grep、ack、 ag、rg 查找shell命令： history | grep xxx、Ctrl + R fzf 、fish、 zsh-autosuggestions 目录导航： fasd、autojump、 tree、broot 、nnn 、ranger 编辑器（Vim） Vim 是程序员为程序员编写的编辑器 除了 Vim，Neovim，还有模拟 Vim 的插件，比如 IdeaVim，VSCodeVim，Vimium … normal insert replace visual line block command-line 数据整理 将某种格式存储的数据转换成另外一种格式 正则表达式调试器：https://regex101.com/ 流编辑器：sed 列流编辑器：awk 排序工具：sort 统计信息：wc 统计整理工具：uniq 查看：cat、head、tail 合并工具：paste 计算器：bc xargs 可以将输入列表转换为参数 命令行环境 如何更加“优雅”地使用命令行环境 Job Control（任务控制） 信号机制 Terminal Multiplexers（终端复用器） tmux Dotfiles（配置文件） alias ~/.bashrc、~/.vimrc、~/.config/... 使用dotfiles仓库和符号链接进行统一管理 Remote Machines（远程设备） ssh ssh-keygen ssh-copy-id scp rsync ~/.ssh/config Shells &amp; Frameworks（Shell和框架） Terminal Emulators（终端模拟器） 版本控制（Git） Git Version Control System 官方手册：https://git-scm.com/book/zh/v2 数据模型 分支、合并 手动处理合并冲突 远程仓库 Git 本地的三个工作区域： 工作目录 （Working Directory） 暂存区 （Stage&#x2F;Index） 资源库 （Repository&#x2F;Git Directory） 文件的四种状态： Untracked: 未跟踪，不参与版本控制，git add 变为 Staged Staged: 暂存状态，git commit 同步到库中 Unmodified: 修改后变为Modified，git rm 移出版本库，变为Untracked Modified: 文件已修改，git add 进入staged状态, git checkout 丢弃修改 调试及性能分析 打印调试 日志记录 调试器 专门工具 strace Wireshark 开发者工具 静态分析 性能分析 元编程 这里的“元编程” ，不是指用于操作程序的程序，更像是自动化流程 构建系统 make 依赖管理 持续集成系统 安全和密码学 熵 散列函数 密钥生成函数 对称加密 非对称加密 混合加密 大杂烩 修改键位映射 守护进程 FUSE（用户空间文件系统） 备份 API（应用程序接口） 常见命令行标志参数及模式 窗口管理器 VPN Markdown Hammerspoon (macOS桌面自动化) 开机引导以及 Live USB Docker, Vagrant, VMs, Cloud, OpenStack 交互式记事本编程 GitHub 提问&amp;回答","tags":["tools"],"categories":["Course"]},{"title":"《软技能2：软件开发者职业生涯指南》","path":"/2023/05/23/softSkills2/","content":"[美]约翰 Z.森梅兹（John Z.Sonmez），出版时间：2020-06-01 软技能2 软件开发者职业生涯指南第一篇 入行成为软件开发者 编写优质的、整洁的、不需要太多注释就能理解的通俗易懂的代码，因为代码本身是用于沟通的。 精通各类算法的开发者用区区一个小时就可以解决盘亘在其他开发者手上好几天都束手无策的问题。 几乎所有的事物都服从所谓的“二八原则”，即20%的东西产生80%的结果，学习一项技术技能的关键就是弄清楚那20%是什么。 理解编程语言的语法、掌握如何使用某个框架是一回事，而深刻领会这方面的习惯用法是另一回事。 了解一门编程语言并精通它很重要，但牢固掌握则不是一项有价值的技能。 如果你拥有一个大学学位，这些学位课程虽然也可以帮你得到就业机会，但很多情况下你还是不得不吞下“毕业即失业”的苦果，除非你参加过实习工作。 第二篇 找到一份工作 任何你认为自己喜欢的工作，最终都会变成你不喜欢的工作，有时甚至变成你厌恶的工作。这是必然结果。 这里还要小心，不要把岗位描述中的每件事都投其所好地堆砌到你的简历里，因为你这么做很明显就是在刻意奉迎公司的需求。也就是说，你应该尽可能地与之相匹配，但是不要做得太过曲意逢迎。 你的简历必须要有好几个版本，而且你在申请每一份工作的时候，都需要对这些版本做出进一步调整。如果你真的想脱颖而出找份好工作，这些都是你必须去做的事情。 没人在乎你想要什么。我再说一遍：没人在乎你想要什么。人们只关心自己想要什么。 你做过什么，如何做的，成果如何。 简历上如果有录入错误、语法错误或者拼写错误，就是挑明了在说：“我是个白痴，我很粗心，不注重细节。” 对软件开发者来说，没有什么比面试更让人害怕的了，尤其是在白板上写代码的面试。（哈哈哈哈哈哈 如果你觉得自己在面试中陷入人身攻击了，那就随它去吧。拥有坚韧的决心表明你对自己能力的自信是如此之高——你可以承认你的弱点，你不害怕被人看上去很愚蠢或不称职。 怎么才能真正有信心呢？当然是准备充分了。你为面试做的准备越充分，参加面试就会越有信心，前期的准备工作之所以要从难从严也是为此。 “我是善于自我激励的人。我清楚自己该做什么，而且我一定会去做。” 练习在白板上解决编程问题。练习，练习，再练习。练习，我怎么强调都不为过。 你要确保不要把自己置于孤注一掷的境地。因此，在找到另一份工作之前不要辞职——哪怕你现在的老板是个混蛋。 确保你对求职市场有所了解，对正在与之谈判的公司有所了解，对我们在上面谈到的薪酬信息有所了解。“知识就是力量”。在任何谈判中，掌握信息较多的一方总归要比缺乏信息的一方处于更有利的位置。 不管任何时候，只要是针对金钱问题展开严肃的谈判，你都应该对事实真相洞若观火。 当你得到一份录用通知书的时候，最重要的是你一定要记住，录用通知书只是工作邀约，它并不意味着你绝对拥有这个工作岗位（尽管机会很大），也不意味着你在任何方面能得到任何保障。 一旦讨论“小时薪酬”，你会发现，工资数额往往会掩盖真相。 无论是人为设置的还是真实存在的时间节点。当你面临时间压力时，你会感到焦头烂额，所以你有很大可能做出错误的决定。 从根本上讲，同时拥有多份工作邀约的真正价值并不是利用这一份来胁迫另一份，而是让你拥有选择的权利。 当你拥有选择的权力的时候，你在谈判中就站在最有立的位置：你有转身离开的能力。 怎样才能确认自己是否已经身处“温水”之中？怎样才能让自己意识到现在该是离职的时候了？最好的指标之一是缺乏成长的机会。 身为软件开发者（并且作为一个普通人），如果你正在从事的工作没有给你带来新的挑战，而且你没有看到任何成长的机会，那么这可能就是一个很好的标志，预示着你是时候该离开了。 另一个能够预示你该提出辞职的标志（也许也是最好的一个），就是当你发现当前的工作环境已经乌烟瘴气的时候。 并非所有促使你离开当前工作的原因都是消极的或者是基于情绪上的原因。有时候，之所以选择离职仅仅就是因为有更好的机会出现了，而你需要把握住这个机会。 如果你在提出辞职后停留的时间超过两周，你很快就会失去人们对你的好感，而且你也可能因为推迟离开而危及你的新机会。 一旦你威胁要离职，你的老板就会开始寻找你的替代者。没有人喜欢被威逼的感觉。一旦你被认为是一个喜欢靠威胁来得到自己想要的东西的人，你就会被贴上办事没谱、不负责任的标签。 因此，尽管想一想觉得很是诱人，但是绝不要事先通知老板你要离职。不要告诉你的老板你打算只在公司再待两个月或一年，或者不管是多长时间。 当你离职的时候，不管你是否是自愿离职的，都一定要确保在这两周的时间里尽你所长，做到最好，培养你的接班人。 不仅是因为一切的一切都太晚了，还因为一切的一切都已不再重要，因为你行将离开。 你不会真的以为，因为你在离职的时刻提出了改善组织的真知灼见，他们会给你颁发一枚奖章、外加上一张1万美元的支票吧？不会。什么都不会发生。 时下，软件开发者越来越倾向于“货物崇拜编程[插图]”模式，即程序员开发软件的模式并不是基于他们的工作本身，而是因为其他开发者也在这么做，而这些开发者的做法往往被认为是“最佳实践”。 招聘人员并不是为你工作的，他们是为那些有空缺职位的公司工作的，这些公司雇用招聘人员填补自己的空缺岗位。 我并不是说所有的招聘人员都是居心叵测、肆无忌惮，但是你一定要自己小心，充分意识到招聘行业充满刀光剑影。 第三篇 关于软件开发你需要知道些什么 “有些事情，是已知的已知，这些都是我们已经知道的自己所知之事。有些事情，是已知的未知，也就是说，这些都是我们已经知道的自己未知之事。但是还有些事情，是未知的未知，也就是说，我们并不知道的自己不知道之事。” ——唐纳德·亨利·拉姆斯菲尔德 走马观花：编程语言概述 知难而进：什么是Web开发 蓬勃发展：移动开发 幕后英雄：后端开发 游戏人生：游戏开发者的职业生涯 事无巨细：数据库管理员与DevOps 高屋建瓴：软件开发方法论 层层设防：测试和质量保证基础 源头把关：测试驱动开发与单元测试 清清爽爽：源代码控制 步步为营：持续集成 火眼金睛：调试 日臻完善：代码维护 实至名归：工作岗位与头街 多姿多彩：软件开发者的工作类型 第四篇 软件开发者的日常工作 在做技术领域工作的时候，你不得不仔细关注其中的社会动力学因素。 世界并不总是公平的，也不是一个热情友好的地方。科技界概莫能外，事实上，在某些方面有时还会更加冷漠苛刻。 当你听到办公室里的谈话内容充斥着宫斗戏码上演前的嗡嗡声时，就是你戴上耳机开始打字的大好时机了。 你的目标应该是找到解决问题的最佳方法，而不是极力去证明你是对的，也不是要证明你比同事更聪明，更不是为了证明他们的想法愚不可及。 愤怒或怨恨会毒害你在工作和家庭当中的人际关系。 你管好自己就行，把自己的工作做完，尽可能提高自己的生产力。别管别人做什么、不做什么。 生活中，有些战斗根本就不值得去打。 不要在不知道测试方式和测试通过标准的情况下编写将要被测试的代码。 在很多情况下，这个人只是在寻找一些承认与认可，一旦你给予他们认可，他们就会跟紧你。一点儿真诚与诚挚的赞许就能起到很大的作用，记住这一点。 要想实现真正的工作&#x2F;生活平衡，就根本不要想着去实现它，而是要模糊工作&#x2F;生活之间的界限，让所有一切都变成“生活”。 有时你并不需要平衡，你需要的是“季节”。有些“季节”我的生活主要就是工作。 当你缺乏自我的时候，你带给别人的只有痛苦和怨恨。因此，在帮助别人之前，先给自己戴上氧气面罩。 我们中的许多人把我们的大部分思考都花在过去或者未来上，我们没有意识到生活就在当下，生活正在流逝。 如果你被称作是“不仅出色地了完成了自己的工作，而且还带动提高了整个团队绩效”的软件开发者，那么你在找一份好工作时永远不会遇到问题，而且你也一定可以获得晋升。 想成为一名高效能的团队成员，你需要成为高效能的沟通者。 说某些话之前，先想想别人听到时的感受。换位思考，如果一个团队成员对你说了你将要说的这些话，你会有怎样的感受。 别害羞，在这件事上不用谦虚。当你走上绩效评估的法庭时，你要带好这一整套的证据，即使是最强硬的陪审团都不能忽视这些。 战术和技术手段并不能用来代替艰苦的工作和努力的付出。 每个人，包括你，都有一些根深蒂固的偏见，都会因循一套刻板的陈规成见。 消除偏见的最好方法就是：不要让偏见影响到你对自己的看法。 你不能改变别人，不能改变别人的想法，不能直接改变人们对你的感觉、人们对你所采取的行动，但你可以改变自己，你可以变得更加坚强、更加坚韧。 并不是所有事情都可以无视之。有时候你必须站出来为自己辩护，你不能容忍别人的无知，因为从实用主义的角度来说它确实对你产生了严重的影响。 为了获得加薪或晋升所能采取的最坏方法之一就是威胁你要离开。 要从商业角度给出加薪的理由，谈论你为什么应该得到钱，而不是你为什么需要钱。 如果你已经尝试过其他每一件事情仍然无法获得加薪或晋升，那可能就是换个地方的时候了。 老实说，我能给出的最好的建议就是保持平常心。真的。不要表现得太过殷勤，也不用小心翼翼。 做一个冷静的、正常的男人，平等地对待每个人。再说一次，不是“相同”，而是“平等”。 要“平常心”是很困难的，但你能做的最好的事情就是不要把整件事当回事。 第五篇 推进你的职业发展 高谈阔论 + 无所事事 &#x3D; 江湖骗子；沉默寡言 + 埋头苦干 &#x3D; 烈士；高谈阔论 + 兢兢业业 &#x3D; 真正有才干的人 如果你只有一个选择，那么选择具有“中等程度的声望 + 中等水平的技能”要比“中等程度的声望 + 高水平技能”更为实用、收益更大。 你要为他人创造价值。如果你不是基于这条重要的原则做事，那么在这个世界上再完美无缺的品牌以及所有的自我推销工作都是徒劳无功的。 大多数人终其一生也没有取得过任何伟大的成就，因为他们过早地放弃了。不要与他们为伍。 我曾听有人说过“你的人脉就是你的净资产”，我发现这句话比大多数人能想象到的更为真实可信。 制订一个积极进取的计划来保持你的技能与时俱进。 为了做到专业化，必须有广泛的基础，专业化并不妨碍你成为一个通才，它只是可以给你更多的选择，让你的价值更高。 你只要挑选一些东西然后阔步前行就好了。这比什么都不做要好得多，因为只要有需要，你可以随时调整策略，然后再改变方向。 宁可错误地选择过于狭小、太过具体的专业方向，也不要选择太宽泛。 “独自前行是危险的！”你需要一些支持，这很关键。 如果你没能在一家拥有先进技术路线的大公司工作，你甚至可能都没得选择。进入管理层可能是你能够得到晋升的唯一选择——要么转去做管理工作，要么自己选择退出。 要一直思考“我要去哪里” 无论你决定做什么，最重要的是：你需要做出决策，并且为此做出计划。 即使你做出了选择，你也不必死守在一条通道上一成不变，你可以不断调整改变计划。 如果你不能接受它或者改变它，你可能就不得不让自己离开它。 我会打消你对工作保障和工作稳定性的最后一丝幻想：拥抱不确定性，而不是逃避。 “你的生活质量与你在充满不确定性的生活中感觉到通体舒畅的程度成正比。” 当你不去试图控制你无法控制的事情的时候，当你愿意欣然接受任何发生在你身上的事情的时候，你的生活会更加快乐，你自己也会更加愉悦。 证书和培训本身并没有价值，就像大学教育并不一定有价值一样。就像生活中的许多事情一样，最重要的是你投入了多少精力，这种努力决定了你从中可以得到的价值。 这也意味着你要制订一个工作计划，哪怕身在地狱，哪怕洪水来临，你都要坚守这个计划。 虽然我并不能把我手中的每一个项目都点石成金，但是我可以告诉你，它们都完成了。 知识不付诸实践，就毫无价值。","tags":["Soft skills"],"categories":["Reading"]},{"title":"《软技能：代码之外的生存指南》","path":"/2023/05/08/softSkills/","content":"[美]约翰 Z.森梅兹（John Z.Sonmez），出版时间：2022-08-01 软技能：代码之外的生存指南第一篇 职业 你所能犯的最大错误就是相信自己是在为别人工作。这样一来你对工作的安全感已然尽失。职业发展的驱动力一定是来自个体本身。记住：工作是属于公司的，而职业生涯却是属于你自己的。 ——厄尔·南丁格尔 经营自己的职业生涯就像经营一家企业 面试前和目标公司的人建立联系 走专业化道路（成为细分领域的专家） 不要陷入对某个技术的狂热之中 第二篇 自我营销 营销就是一场争夺人们注意力的竞赛。 ——赛斯·高汀 博客、视频频道、社交媒体、演讲、培训和报告、著书立说 第三篇 学习 教育就是当一个人把在学校所学全部忘光之后剩下的东西。 ——阿尔伯特·爱因斯坦 主动学习：用自己的语言将信息组织起来，把你的思想表述给别人，通过动手实践和教会他人。 十步学习法： 了解全局 确定范围 定义目标 寻找资源 创建学习计划 筛选资源 开始学习，浅尝辄止 动手操作，边玩边学 全面掌握，学以致用 乐为人师，融会贯通 1 - 6 只做一次 7 - 10 循环反复 弄清“未知之未知”（unknown unknowns） 抵制诱惑，保持专注，一次只学一样东西 “学习—实践—掌握—教授”，教学相长 当局者迷，不妨跳出来换个视角。 我们能够识别模式，并且套用这些固定的模式去解决许多问题，而没有做到“知其然”也“知其所以然”。 学习是暂时的，而理解是永久性的。 最好的思维方法就是解释某样东西并将其记录，将互不连贯的碎片信息收集起来，并以一种有效的方法重新组织。 现最好的教学方式就是以谦虚的视角来观察问题，以权威的口吻去诠释问题，即心态谦卑，信心满满（而不是傲慢自大）。 如何检查知识短板： 在哪些工作上花费时间最多 可以改进的重复性劳动 自己没有完全理解的东西 你回答不出来的面试题 发现自己的知识短板，追踪自己的短板（维护一份清单）。 第四篇 生产力 外行静坐等待灵感，其他人则唤起激情努力工作。 ——斯蒂芬·金，《写作这回事：创作生涯回忆录》 懒惰、缺乏动力、泡在Facebook上聊天、沉湎于搞笑的猫咪视频……种种原因总让我们的计划泡汤。（真实。。。 一切始于专注。 但我们所承担的很多任务都有“环境切换”的成本，当从一个任务切换到另一个任务时，我们必须要唤醒某些记忆之后才可以重新开始工作。（想到了进程的上下文切换开销） 专注有着自己的冲量。你的目标是熬过前5～10分钟。如果能撑过10分钟，你就有足够的冲量继续。在这种情形下，即使是轻微的分心也不大可能打破你的专注。 目标是完成“X个番茄钟”，而不是“完成X项任务。 番茄工作法： 设置一个时长25分钟的定时器，专注于完成计划中的一项任务 在25分钟结束的时候，设置一个5分钟的定时器用于休息，25+5 即为一个“番茄钟” 每4个番茄钟后，你都需要休息一会儿，通常为15分钟 用番茄工作法最重要的是要学会”设置优先级“。（让我想到了做事的”轻重缓急“，能在一定时间内，根据任务的优先级，把多个任务处理好，就是一种能力） 我们不一定能够控制完成一项任务到底需要多少时间，但是我们可以控制自己这一天中愿意为某项任务花多少时间。 制订任务列表全凭主观臆断，每天能够专注完成的工作量才是最重要的。 当你在一天中为自己设置了x个番茄钟的工作目标并且达成的时候，你就可以知道自己一天到底可以完成多少工作，这会让自己感觉良好，更重要的是，还能让自己放松身心。 在一天的大多数时间里都保持专注是非常困难的，可能远远超过我们之前遇到过的困难。 “定额工作法” 挑选一项重复性任务。 明确有效时限，在此期间该任务被重复执行。 明确在给定的有效时限内该任务应该完成的次数的定额。 给自己承诺：一定要达成定额。 调整。调高或者调低定额，但是不能在有效时间段之内调整。 缓慢但稳定的节奏工作，要优于快速但缺乏持久和坚持的工作方式。 以定额的形式将决策转变为命令，你无须再做决策，也就避免了意志力耗尽的问题。 对自己负责，内部动机要比外部动机有效得多。 条理性能帮你关注任务，做好该做的事情，避免被冲动和情绪所左右。 通过在小组内部讨论每个人各自的计划，互相监督计划的落实情况，没人希望因为自己不遵守计划而令组员失望。（有每周开组会那味了 …） 对于很多活动，我们可能会自认为是在进行多任务并行，但实际上我们做的不过是在不断地进行任务切换。 一次性完成一系列互相关联的任务，而不是将它们拆分完成。 什么才是真正的多任务并行：将一项不费脑筋的任务和一项一定程度上需要精神专注才能完成的任务组合起来。 提高生产力的最大障碍之一就是身体和心理上的倦怠。（我感觉类似长跑时的“极点”） 事实上，我们中大多数人无论如何努力最终都会发生撞墙的现象——当我们最初的兴趣和动力消退的时候，我们没有足够的成就去说服自己找回它们。 墙的另一侧有东西在等着你，大多数人之所以放弃就因为他们没有意识到，如果持续，穿越那堵墙，事情会变得更好。 设定规则和约束条件，帮助（强迫）自己穿过那堵不可避免的墙。 时间杀手：视频、社交媒体、不必要的会议、游戏，只有当你没有在做你想做的事情时，才是在浪费时间。 如果你总是在事情出现的时候被动地处理事情而不是主动地规划，那么周围的环境会左右你的生活，而不是你自己。 通过将大任务分解为小任务，你会发现自己更有动力去完成它们，也更加稳妥地向着目标前进。 每当我们试图提升自己至一个更高水平的时候，阻力一定会伸出它那丑陋的脑袋，试图让我们原地不动. 至少你知道，对我来说坐下来写完这本书和对你来说坐下来读完这本书一样难。（哈哈哈哈哈哈哈哈哈） 你要想实现目标，要想发挥出自己的全部潜力，唯一的途径就是自愿咬紧牙关、硬着头皮、开始工作。 通盘考虑后再做出明智的决策非常重要，但是往往你并不具备自己想要的所有信息，因此不得不勇往直前，做出选择——采取行动。 第五篇 理财 金钱是糟糕的主人，却是极好的仆人。 ——菲尼尔斯·泰勒·巴纳姆 资产与负债 资产 可获得股息的股票 可供出租的不动产 债券 音乐、软件版权授权 负债 信用卡债务 房产、车（如果超过你的实际需要） 所有随着时间推移会贬值的设备 作者在以股票举例“资产”的时候，显然忽略了购买股票时所付出的成本，在以房产举例“负债”的时候，显然忽略了房产增值时所能带来的价值。——译者注 一定要清楚自己值什么价钱。尽可能详细地研究一下自己求职的公司的薪酬范围，研究一下与你申请的职位类似的职位的薪酬范围。 只要你拥有“转身离开”的能力，在任何谈判中你就都具有明显的优势,要想处于这种地位，你就需要握有多个offer。 真正获得财务成功的唯一方法就是用钱生钱。如果想获得财务自由，你就必须要能够让你的钱为你所用。如果说收益给我们自由，那么后面一定要再加上一句——债务会给我们套上枷锁。 背负债务的底线就是确保在背上债务之前，这笔债务实际上是一笔投资，它将为你产生的回报高于你为这笔债务所支付的利息。只有在绝对紧急的情况下，才可以背上不产生盈利的债务。 “富有”与“有钱”的区别 如果你手头只有1000美元，或者更少，不要投到股票上，不要投到房地产上，不要投到债券上，更不要投到比特币上，你应该投资你自己。 作者是如何做到33岁退休的：“我开始拥有源源不断的多个被动收入流，我的博客也开始通过广告和加盟销售开始赚钱，我出售自己编写的跑步应用的Android和iOS版本，我也有每个季度都会送达并且持续增加的Pluralsight版税支票，并且我在房地产投资上也看到有几个月出现了正向的现金流。” 我的目标是每个月有5000美元的被动收入。如果我能达到这个目标，我知道我就可以正式退休了。在2013年1月，我记得很清楚，我的目标达成了。于是我写邮件给我的老板，告诉他我要辞职，原因不是我找到了更好的工作，也不是不喜欢这份工作，只是不需要再上班了。我自由了。 你把钱看得越重，你就越难以在理财方面做出明智的、成功的投资选择。 第六篇 健身如果你和我一样是个瘦子的话，去B站搜索一下：卓叔增重，可以帮助你少走很多弯路。 作者是“一日一餐”的拥趸，这对于瘦子完全不适用啊 … 人的身体就是人的灵魂的最好写照。 ——路德维希·维特根斯坦 当你总觉得疲倦、无心工作的时候，或者你觉得自己状态不佳的时候，你可能会发现，改变饮食和加强锻炼可以让你的身心同时获得新活力。 没有目标，你永远也达不成目标，健身也不例外。 可能的健身目标： 减肥（减掉脂肪） 增肌（增长肌肉） 增加力量（不一定是增长肌肉） 增加肌肉耐力（改善运动表现） 改善心血管健康 在某些运动上表现更好 基础代谢率、延迟性肌肉酸痛症 如果你想扼杀自己的动力，那么你尽可以犯这样的错误：在做好工作之前就因为“做好工作”而奖励自己。 有时候，只是知道自己走了很远就能带来足够的动力继续前行在这条路上。人人都讨厌打破长时间的连胜纪录。 人类的身体具有令人惊讶的适应性。如果你用手抓住粗糙的东西，手掌上会生出老茧来保护双手；如果你长跑，你的心血管系统会产生适应性，让长跑变得更轻松；如果你举重，你的身体会长出更大的肌肉。（这边的举重🏋️‍，就是撸铁的意思啦） 肌酸是我发现的唯一真正有效的补剂之一，它可以帮助你举起更重的杠铃，让你的肌肉看起来更饱满。 高强度间歇式训练（HITT）是短时间内高强度的有氧运动，与长跑等常规有氧运动相比，这一有氧运动能更好地在燃烧脂肪的同时保留无脂肪组织。 如果你也像我一样使用番茄工作法，那么你可以在5分钟的休息时间里进行拉伸、俯卧撑、引体向上和别的练习。 第七篇 心态 如果你不征服自己，你就会被自己征服。 ——拿破仑·希尔 “如果你相信，你就能做到”这个观点很容易被迅速忽视，但是这个观点确实有些道理。至少，这个观点的反面更有道理：如果你不相信，你肯定不会获得成功。 积极思考与现实主义是不矛盾的。积极思考在应用层面上是现实主义的最终体现，因为它是一种信念，这种信念让你有力量改变现实，让你确信你不是环境的受害者。 如果想改变自己的态度，你就必须改变自己的想法。如果想改变自己的想法，你就必须转变自己的思维模式。你的思维模式是由你的习惯决定的，因此我们可以追溯到改变你生活中处理任何关键事情所采用的主要方式——养成一个习惯。 关键是积极思考不会从天而降，也不是一夜间就能获得的，你要付出持续的努力，将思想转向积极的方向。但这是值得付出的努力。不单是因为积极思考能让你活得更长久、更健康、更成功，还因为这绝对会让你活得更有乐趣，同时你可能会影响你周围的人同样生活得越来越有乐趣。 自我形象是在甩掉别人对你的看法，摆脱所有用来自我安慰的谎言和欺骗以后，你看到的自己的样子。 那些关于你自己身体上的特性是无法改变的，但是其他许多对你自己的自我想象是后天获得的，是自我形象的现实表现，许多情况下是随机出现的。 你说的关于你自己的事情，都是你相信的。你的潜意识就是一个倾听你的声音的敏感的孩子，相信你所说的一切。如果你常常说自己笨或者说自己健忘，你的潜意识就会相信事实的确如此。 失败不同于被打败。失败是暂时的，被打败是永恒的。失败是那些碰巧发生在你身上的——你不能完全控制它。被打败却是你可以选择的——是对失败的某种程度的接受。 不要畏惧失败，要拥抱失败。不只是因为失败和被打败不同，还因为失败是通往成功的必经之路。生活中所有值得拥有、值得去完成的事情都需要经历失败。 即使你在本书中什么都没有学到，那也要记下下面这条建议：学会拥抱失败、期待失败、接受失败，并准备直面失败。 当你全神贯注做最好的自己而不担心事情的结果时，当你坦然接受命运带给你的一切并学会热爱命运时，从此你就没什么好担心的。 关注每一天每一刻，把你的一切都奉献给你所做的每一件事。","tags":["Soft skills"],"categories":["Reading"]},{"title":"GitHub Pages + Hexo 简明教程","path":"/2023/04/17/hexo/","content":"一次简单记录 GitHub Pages + Hexo 安装 nodejs 1234567891011121314151617181920$ npm -v9.5.1$ npm config set registry https://registry.npmmirror.com# 安装 hexo$ npm i hexo-cli -gchanged 60 packages in 31snpm noticenpm notice New minor version of npm available! 9.5.1 -&gt; 9.6.4npm notice Changelog: &lt;https://github.com/npm/cli/releases/tag/v9.6.4&gt;npm notice Run `npm install -g npm@9.6.4` to update!npm notice$ hexo -v# 初始化目录$ hexo init# 生成页面$ hexo g# 启动本地服务$ hexo s 安装 git 12345678910111213141516171819202122232425262728# 基础操作（工作区 → 暂存区 → 本地仓库区 → 远程仓库区）git statusgit addgit commitgit loggit remote add origin git@github.com:xxxgit push -u origin master# 配置用户信息git config --global user.name &quot;hcjjj&quot;git config --global user.email &quot;hcjjj@foxmail.com&quot;git config --global --list# 生成密钥SSH keyssh-keygen -t rsa -C &quot;hcjjj@foxmail.com&quot;# 填入 github 设置的 SSH and GPG keys$ cat C:\\Users\\hcjjj/.ssh/id_rsa.pub# 验证$ ssh -T git@github.comHi hcjjj! You&#x27;ve successfully authenticated, but GitHub does not provide shell access.# 若：ssh: connect to host github.com port 22: Connection timed out$ ssh -T -p 443 git@ssh.github.comHi hcjjj! You&#x27;ve successfully authenticated, but GitHub does not provide shell access.$ vim ~/.ssh/config```# Add section below to itHost github.com Hostname ssh.github.com Port 443``` 推送到 github 在博客根目录下，安装扩展：npm i hexo-deployer-git 修改目录下的 _config.yml 文件： 12345678# Deployment## Docs: https://hexo.io/docs/one-command-deploymentdeploy: type: git # repository: https://github.com/hcjjj/hcjjj.github.io.git # 如果经常推送失败用下面这个方式 repository: git@github.com:hcjjj/hcjjj.github.io.git branch: master 123456# 生成静态网页hexo g# 本地预览hexo s# 上传到githubhexo d","tags":["Git","Hexo"],"categories":["Notes"]},{"title":"上手终端复用神器 Tmux","path":"/2020/05/17/tmux/","content":"Tmux is an open-source terminal multiplexer for Unix-like operating systems. 安装： 123456789Debian/Ubuntu...$ sudo apt install tmux# RedHat/CentOS...$ sudo yum install tmux# Arch/Manjrao...$ sudo pacman -S tmux# Mac$ brew install tmux... 执行 tmux 命令启动服务，（Ctrl+d 或 exit 退出），一个 tmux 服务可以包含多个会话，一个会话可以包含多个窗口，一个窗口可以包含多个窗格。 Pane 窗格默认激活键为 Ctrl+B ，激活后按 % 为竖直分割窗口，以下同理： %：纵向分隔窗口 &quot;：横向分隔窗口 ;：光标切换到上一个窗格 o：光标切换到下一个窗格 ;： 切换到上一个使用的窗口 t： 显示时钟 x：关闭当前窗格 z：全屏显示切换 q：显示窗格编号 !：将当前窗格拆分为一个独立窗口 Ctrl + Arrow keys：调整窗格大小 Window 窗口 c：创建一个新窗口 p：切换到上一个窗口 n：切换到下一个窗口 0~9： 切换窗口 w：从列表中选择窗口 ,：窗口重命名 l ：切换到最后使用的窗口 &amp; ：关闭窗口 Sessions 会话新建会话： 1tmux new -s &lt;session-name&gt; s ：以菜单方式显示和选择会话 $：重命名会话 d ：分离会话，tmux 仍在后台运行 123456789101112重新接入某个已存在的会话，使用会话编号$ tmux attach -t 0 # 使用会话名称$ tmux attach -t &lt;session-name&gt;# 杀死某个会话$ tmux kill-session -t &lt;session-name&gt;# 切换到某个会话$ tmux switch -t &lt;session-name&gt;# 列出当前所有 Tmux 会话的信息$ tmux info# 重新加载当前的 Tmux 配置$ tmux source-file ~/.tmux.conf 修改配置新建 ~/.tmux.conf 文件，并写入： 12345678910111213141516# tmux里vim按ESC反应慢的解决方法set -s escape-time 0# 解绑默认激活键unbind C-b# 设置激活键为 Ctrl+jset -g prefix C-j# 将创建窗格设置成vim模式bind-key L split-window -hbind-key J split-window# 将切换窗格设置成vim模式bind-key k select-pane -Ubind-key j select-pane -Dbind-key h select-pane -Lbind-key l select-pane -R# 在终端中显示颜色set -g default-terminal &quot;screen-256color&quot; 保存后执行：tmux source-file ~/.tmux.conf 参考* http://www.ruanyifeng.com/blog/2019/10/tmux.html * https://blog.csdn.net/qushaming/article/details/90712886","tags":["Tmux"],"categories":["Tools"]},{"title":"终端模拟器入门指南","path":"/2020/03/11/iterm/","content":"Linux 上叫 Terminal，macOS 上叫 iTerm，Android 上有 Termux 操作系统分为两个部分，一部分叫内核，另一部分叫用户交互界面在UNIX&#x2F;LINUX系统中，用户登录系统后会有一个Shell进程，它是一个用 C 语言编写的程序，既是一种命令语言，又是一种程序设计语言，它是管理系统的命令解析器，终端是敲命令的工具，是连接内核与交互界面的桥梁 美化终端 以 macOS 为例，安装 iTerm2 更换 主题 ： Preferences -&gt; Profiles -&gt; ColorPresets -&gt; Import 导入 iTerm2-Color-Schemes/schemes/xxx.itermcolors 打开 Status bar ： Preferences -&gt; Profiles -&gt; Session -&gt; Status bar -&gt; Configure Status Bar 终端一般默认的shell都是 bash，建议安装更换 zsh、fish … 查看已安装的shell：cat /etc/shells 更换shell：chsh -s [shell路径] zshMacOS 默认的shell为 bash，但自带了 zsh 安装 oh-my-zsh (切换到zsh后进行安装) 12345678Shell successfully changed to &#x27;/bin/zsh&#x27;. __ __ ____ / /_ ____ ___ __ __ ____ _____/ /_ / __ \\/ __ \\ / __ `__ \\/ / / / /_ / / ___/ __ \\/ /_/ / / / / / / / / / / /_/ / / /_(__ ) / / /\\____/_/ /_/ /_/ /_/ /_/\\__, / /___/____/_/ /_/ /____/ ....is now installed!Please look over the ~/.zshrc file to select plugins, themes, and options. 更换主题 下载 powerlevel10k（需要安装 Hack Nerd Font 字体和配置） 编辑 ~/.zshrc ，修改 ZSH_THEME=&quot;powerlevel10k/powerlevel10k&quot; 安装插件 zsh-syntax-highlighting 语法高亮 git clone https://github.com/zsh-users/zsh-syntax-highlighting.git $&#123;ZSH_CUSTOM:-~/.oh-my-zsh/custom&#125;/plugins/zsh-syntax-highlighting zsh-autosuggestions 自动补全 git clone https://github.com/zsh-users/zsh-autosuggestions $&#123;ZSH_CUSTOM:-~/.oh-my-zsh/custom&#125;/plugins/zsh-autosuggestions 下载后编辑 ~/.zshrc ，添加： 12345plugins=( git zsh-syntax-highlighting zsh-autosuggestions) 执行 source ~/.zshrc 后重启 zsh zsh-incremental 提示补全 brew install wget wget -O incr-0.2.zsh https://mimosa-pudica.net/src/incr-0.2.zsh cp incr-0.2.zsh ~/.oh-my-zsh/plugins/ 添加 source ~/.oh-my-zsh/plugins/incr*.zsh 到 ~/.zshrc 中 fishfish 开箱即用，不需要怎么配置 http://fishshell.com brew install fish 按Ctrl+F或者 右方向键→， 即可自动补全 设置fish为默认shell： sudo vim /etc/shells，添加 &#x2F;usr&#x2F;local&#x2F;bin&#x2F;fish 1234567891011# List of acceptable shells for chpass(1).# Ftpd will not allow users to connect who are not using# one of these shells./bin/bash/bin/csh/bin/ksh/bin/sh/bin/tcsh/bin/zsh/usr/local/bin/fish chsh -s /usr/local/bin/fish 更换shell fish插件管理：oh-my-fish fish_config 网页可视化配置 fish 的PATH路径为：~/.config/fish/config.fish 格式：set PATH /usr/local/mysql/bin $PATH 常用快捷键 快捷键 描述 Command+T 新建标签页 Command+W 关闭标签页 Command+N 新建终端窗口 Command+Q 关闭终端窗口 Command+N 切换到第N个标签页（N&#x3D;1，2，…） Command+- 缩写窗口（包括窗口内的字体） Command+0 普通大小（阿拉伯数字0） Ctrl+D 在空白处执行将结束当前会话 Ctrl+P 显示上一条历史命令 Ctrl+N 显示下一条历史命令 Ctrl+R 反向搜索历史命令 Ctrl+J 回车（同enter键功能） Ctrl+M 回车（同enter键功能） Ctrl+O 执行并保留命令 Ctrl+A 光标移动到行的开头 Ctrl+E 光标移动到行的结尾 Ctrl+B 光标向后移动一个位置（backward） Ctrl+F 光标向前移动一个位置（forward）,补全提示 Ctrl+Left-Arrow 光标移动到上一个单词的词首 Ctrl+Right-Arrow 光标移动到下一个单词的词尾 Ctrl+T 将光标字符和前一个字符进行位置交换 Ctrl+U 剪切从行的开头到光标前一个所有字符 Ctrl+K 剪切从光标位置到行末的所有字符 Ctrl+Y 粘贴剪切的内容（撤销删除） Ctrl+H 删除光标前一个字符 Ctrl+* 删除光标前一个字符 Ctrl+D 删除光标后一个字符 Ctrl+C 终止命令 Ctrl+W 删除光标前一个单词 Ctrl+L 清除当前屏幕内容 Ctrl+S 暂停屏幕输出 Ctrl+Q 继续屏幕输出 小提示Linux 下同理，把 Command 换成 Ctrl+Shift 或 Ctrl在终端窗口命令提示符下，按一次 Tab 键补全；未匹配到命令时，连续按两次 Tab 键 或 按 Ctrl+i ，将显示所有的命令及工具名称","tags":["macOS","iTerm","terminal"],"categories":["Tools"]},{"title":"Mac OS 手动安装 Homebrew","path":"/2020/03/07/homebrew/","content":"Homebrew （package manager） 在国内使用 Homebrew 官网的安装命令常常会连接不上或者速度太慢安装失败： curl: (7) Failed to connect to raw.githubusercontent.com port 443: Connection refused 通过国内镜像站手动安装Homebrew ：https://github.com/Homebrew Git ：https://git-scm.com 国内镜像站： 码云 阿里云 清华大学 中科大 软件包： brew 预编译二进制软件包 brew-core 核心软件仓库 brew-cask 提供 macOS 应用和大型二进制文件 删除历史版本 sudo rm -rf /usr/local/Homebrew/ 删除主体 sudo rm -rf /usr/local/var/homebrew/ 删除数据 sudo rm -f /usr/local/bin/brew 删除链接 克隆到本地 示例使用的是中科大的源，可根据实际情况更换其他源 创建 Homebrew 目录，从仓库克隆到本地，链接 brew 到 &#x2F;usr&#x2F;local&#x2F;bin&#x2F; 123sudo mkdir /usr/local/Homebrewsudo git clone https://mirrors.ustc.edu.cn/brew.git /usr/local/Homebrewsudo ln -s /usr/local/Homebrew/bin/brew /usr/local/bin/brew 创建 homebrew-core 目录，克隆 12sudo mkdir -p /usr/local/Homebrew/Library/Taps/homebrew/homebrew-coresudo git clone https://mirrors.ustc.edu.cn/homebrew-core.git /usr/local/Homebrew/Library/Taps/homebrew/homebrew-core 创建 homebrew-cask 目录，克隆 12sudo mkdir -p /usr/local/Homebrew/Library/Taps/homebrew/homebrew-casksudo git clone https://mirrors.ustc.edu.cn/homebrew-cask.git /usr/local/Homebrew/Library/Taps/homebrew/homebrew-cask 赋予权限，设置环境变量123sudo mkdir -p /usr/local/var/homebrewsudo chown -R $(whoami) /usr/local/var/homebrewsudo chown -R $(whoami) /usr/local/Homebrew bash： 12echo &#x27;export HOMEBREW_BOTTLE_DOMAIN=https://mirrors.ustc.edu.cn/homebrew-bottles&#x27; &gt;&gt; ~/.bash_profilesource ~/.bash_profile zsh： 12echo &#x27;export HOMEBREW_BOTTLE_DOMAIN=https://mirrors.ustc.edu.cn/homebrew-bottles&#x27; &gt;&gt; ~/.zshrcsource ~/.zshrc 更换国内源，运行更新1234567cd &quot;$(brew --repo)&quot;git remote set-url origin https://mirrors.ustc.edu.cn/brew.gitcd &quot;$(brew --repo)/Library/Taps/homebrew/homebrew-core&quot;git remote set-url origin https://mirrors.ustc.edu.cn/homebrew-core.gitcd &quot;$(brew --repo)&quot;/Library/Taps/homebrew/homebrew-caskgit remote set-url origin https://mirrors.ustc.edu.cn/homebrew-cask.gitbrew update # 耐心等待 显示 Already up-to-date 表示成功 一些小问题： 执行 brew -v，提示： 123$ brew -vHomebrew &gt;=2.2.0 (shallow or no git repository)Homebrew/homebrew-core (no git repository) 解决办法： 1234cd &quot;$(brew --repo)&quot;git initcd &quot;$(brew --repo)/Library/Taps/homebrew/homebrew-core&quot;git init 执行brew update ，提示： 1234Error: Could not &#x27;git stash&#x27; in /usr/local/Homebrew!Please stash/commit manually if you need to keep your changes or, if not, run: cd /usr/local/Homebrew git reset --hard origin/master 依次执行 run：后的两条命令即可 brew doctor 诊断 Homebrew 的问题 brew 所安装程序的位置： 配置文件在 &#x2F;usr&#x2F;local&#x2F;etc 安装文件在 &#x2F;usr&#x2F;local&#x2F;Cellar 二进制可执行程序的软连接在 &#x2F;usr&#x2F;local&#x2F;bin Homebrew Cask 是 Homebrew 的扩展，借助它可以方便地用命令行管理 macOS 应用，它是将应用直接移动到 Application 文件夹，这与去官网下载安装包安装是一致的 常用命令 更新 1234brew update # 更新brew outdated # 查看哪些安装包需要更新brew upgrade # 更新所有的包brew upgrade [包名] # 更新指定的包 查看 1234brew list # 列出已安装包brew info [包名] # 显示某个包的信息brew info # 显示安装了包数，文件数，总占用空间brew deps --installed --tree # 树形查看已安装的包的依赖 清理 123brew cleanup # 清理所有包的旧版本brew cleanup [包名] # 清理指定包的旧版本brew cleanup -n # 查看可清理的旧版本包，不执行实际操作 删除 12brew rm [包名] # 删除某个包brew uninstall --force [包名] # 删除所有版本 锁定 12brew pin [包名] # 锁定某个包brew unpin [包名] # 取消锁定","tags":["macOS","Homebrew"],"categories":["Tools"]},{"title":"Vim/Neovim 的使用和配置","path":"/2020/01/10/vim/","content":"Vi → Vim → Neovim Vim 是文本&#x2F;代码编辑器之中最为优秀经典的上古神器之一，也是早年 Vi 编辑器的加强版，强大、高效、免费开源且跨平台。 Neovim 可以说是 Vim 的改进版，而且与 Vim 的编辑模型和 Vimscript 语言完全兼容。 基础操作Vim 在终端中启动命令为 vim，Neovim 为 nvim， 共分为三种模式： 命令模式（Command mode） 写入模式（Insert mode） 底线命令模式（Last line mode） 初次使用进入 vim 后初始为命令模式，k j h l 为上下左右移动光标 按 i 进入 写入模式，ESC 回到 命令模式 在命令模式下，按 : 进入 底线命令模式 底线命令模式下输入 :w 后回车为写入文件；:q 为退出 nvim；:wq 为保存文件并退出 ctrl+[ 或 ctrl+c 为 ESC 默认快捷键，可自己设置为更方便的映射 指令详解主要是掌握 操作逻辑 , 都是以 先指令后动作 这个模式 移动 w：跳到下一个单词的开头 e：跳到下一个单词的结尾 b：跳到上一个单词的开头，由 blank 字符分隔的单词，使用 W 和 E %：匹配括号移动（需要把光标先移到括号上） *：匹配光标当前所在的单词（下一个） #：匹配光标当前所在的单词（上一个） 插入 i：insert 在光标前插入 I：在行最前面插入，快捷键为 &#96;Shift+i&#96;&#96; a：append 在光标后开始编辑 A：在行最后面开始编辑 o：在当前行下一行开始编辑 O：在当前行上一行开始编辑 删除 s：删除当前字符并进入插入模式 u：撤回上一步操作 Ctrl + R ：重做 U： 撤销对整行的操作 x：删除光标下的字符 dl：删除光标右边的字符 ( 同 x ) dh：删除光标左边的字符 d3l ：删除光标右边的三个字符 dd：删除该行(等于剪贴，p 粘贴） dj：删除该行和下一行 dG ： 删除当前行至文档尾部 dt&quot; ：删除 “ 前的所有内容 cc ：与 d 操作同理，删除并进入写入模式 复制 y、d、x 都会把文本复制到剪切板（默认不与系统剪切板共享） &quot;+y 复制文本共享至系统剪切板 y：与 d 操作同理 更改 r ：替换光标所在位置的字符 R：连续替换字符 c3l：替换右边三个字符 cw：更改下一个词 cb：更改上一个词 cc：替换整行 ci&quot;：修改双引号内的字符 change in “ f&quot; ：光标跳到当前行下一个 “ 3fa：光标跳到当前行第三个出现的 a F ：反向查找 t&quot;：光标跳到当前行下一个 “ 的前一个字符 T：反向 cfx：修改 x 字符前的内容(包括 x) 搜索 /：输入后回车 n：下一条搜索结果 N：上一条搜索结果 zz：跳到光标位置 分屏 :split 上下分屏 :vsplit 左右分屏 :set vsplitright 光标右边 :e [文件路径] 打开新文件 Ctrl+w 后按 hjkl 光标在分屏中移动 跳转 gg：跳到首行 G：跳到尾行 N G ：到第 N 行 8G 跳到第 8 行 选中 v ：字符选中 V ：行选中 Ctrl+v ：块选中 vi&quot;：选中 “ 中的字符 替换 :s/from/to/ 将当前行中的第一个 from 替换成 to :s/from/to/g 将当前行中的所有 from 都替换成 to :%s/from/to/g 对所有行的内容进行替换 配色 :color (color 后一个空格 按 Tab 选择, 通过插件安装更好看的配色) 配置通过修改 vim 的配置文件和安装插件，能让它更加强大高效 vim 的配置文件目录在：~/.vimrc neovim 的配置文件目录在：~/.config/nvim/init.vim 没有的话需自己创建， nvim ~/.config/nvim/init.vim 创建软链接，方便修改 ln -s ~/.config/nvim/init.vim .nvim 在配置文件中 &quot; 为注释 ::: collapse 把 macOS 终端默认的文本编辑器由 vim 替换为 neovim 123456❯ where vim/usr/bin/vim❯ where nvim/usr/local/bin/nvim❯ sudo mv /usr/bin/vim /usr/bin/vim-original❯ sudo ln /usr/local/bin/nvim /usr/bin/vim ::: 修改按键在命令模式下起作用： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758 _ ___ _____ __ __| \\ | \\ \\ / /_ _| \\/ || \\| |\\ \\ / / | || |\\/| || |\\ | \\ V / | || | | ||_| \\_| \\_/ |___|_| |_|--------------------------imap &lt;Up&gt; &lt;Nop&gt;nmap &lt;Up&gt; &lt;Nop&gt;imap &lt;Down&gt; &lt;Nop&gt;nmap &lt;Down&gt; &lt;Nop&gt;imap &lt;Left&gt; &lt;Nop&gt;nmap &lt;Left&gt; &lt;Nop&gt;imap &lt;Right&gt; &lt;Nop&gt;nmap &lt;Right&gt; &lt;Nop&gt;&quot; 让方向键失效imap kj &lt;esc&gt;&quot; 按 kj 等同于按 Escnoremap a b &quot; 在普通模式下，让按a键等于按b键盘，仅为示例noremap K 5knoremap J 5j&quot; 实现快速换行map S :w&lt;CR&gt;&quot; 让按 S 等同于执行 :w 即保存map ? :nohlsearch&lt;CR&gt;&quot; 按 ? 取消高亮搜索结果map s &lt;nop&gt; &quot; 让按 s 无效果map Q :q&lt;CR&gt; &quot; 按 Q 退出nvimnmap &lt;CR&gt; o&lt;Esc&gt;&quot; 按回车等于换行vnoremap Y &quot;+y&quot; 可视模式下按Y等于&quot;+y，复制到系统剪切板map sl :set splitright&lt;CR&gt;:vsplit&lt;CR&gt;&quot; 按 sl 向右分屏，后面同理map sh :set nosplitright&lt;CR&gt;:vsplit&lt;CR&gt; map sk :set nosplitbelow&lt;CR&gt;:split&lt;CR&gt; map sj :set splitbelow&lt;CR&gt;:split&lt;CR&gt;let mapleader=&quot; &quot;map &lt;LEADER&gt;l &lt;C-w&gt;lmap &lt;LEADER&gt;k &lt;C-w&gt;kmap &lt;LEADER&gt;h &lt;C-w&gt;hmap &lt;LEADER&gt;j &lt;C-w&gt;j&quot; 修改 空格+hjkl 为光标在分屏中移动map &lt;up&gt; :res +5&lt;CR&gt;map &lt;down&gt; :res -5&lt;CR&gt;map &lt;left&gt; :vertical resize-5&lt;CR&gt;map &lt;right&gt; :vertical resize+5&lt;CR&gt;&quot; 通过上下左右箭头修改分屏大小map sv &lt;C-w&gt;t&lt;C-w&gt;Hmap sh &lt;C-w&gt;t&lt;C-w&gt;K&quot; sv 改为左右分屏map &lt;LEADER&gt;tt :tabe&lt;CR&gt;map &lt;LEADER&gt;th :-tabnext&lt;CR&gt;map &lt;LEADER&gt;tl :+tabnext&lt;CR&gt;&quot; tt 新建标签页 th移动在左边的标签页 tl右 修改设置1234567891011121314151617181920212223242526set clipboard+=unnamedplus&quot; 让vim与系统共享同一个剪切板set number&quot; 显示行号set wildmenu&quot; 底线命令模式下，按Tab显示补全set relativenumber&quot; 显示相对行号set norelativenumber&quot; 取消显示相对行号set cursorline&quot; 突显当前行set scrolloff=5&quot; 光标与窗口的距离为5行set wrap&quot; 设置字符不超出窗口set ignorecase&quot; 搜索忽略大小写set smartcase&quot; 智能搜索匹配set tabstop=4set shiftwidth=4&quot; 调整Tab和每一级缩进的长度let &amp;t_SI = &quot;\\&lt;Esc&gt;]50;CursorShape=1\\x7&quot;let &amp;t_EI = &quot;\\&lt;Esc&gt;]50;CursorShape=0\\x7&quot;&quot; 插入状态的光标改为竖线,nvim默认开启 安装插件vim-plug Vim 的一款插件管理器 https://github.com/junegunn/vim-plug 安装 Vim 12curl -fLo ~/.vim/autoload/plug.vim --create-dirs \\ https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim Neovim 12curl -fLo ~/.local/share/nvim/site/autoload/plug.vim --create-dirs \\ https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim 使用 以下命令均在命令模式下使用 安装插件 :PlugInstall 更新插件 :PlugUpdate 删除插件 PlugClean(先在 init.vim 中，注释掉该插件，然后打开 Nvim 使用 :PlugClean 命令清除该插件) 查看插件状态：:PlugStatus 升级 vim-plug：:PlugUpgrade 如果想暂时禁用某个插件，但不删除它： 在 inti.vim 中注释掉该插件 或者 Plug &#39;插件名&#39;, &#123; &#39;on&#39;: [] &#125; vim-airline 状态栏插件 https://github.com/vim-airline/vim-airline https://github.com/vim-airline/vim-airline-themes 在配置文件中添加： 1234call plug#begin(&#x27;~/.vim/plugged&#x27;)Plug &#x27;vim-airline/vim-airline&#x27; Plug &#x27;vim-airline/vim-airline/vim-airline-themes&#x27;call plug#end() 保存后输入命令 PlugInstall（按 Tab 键可以补全），显示 Finishing … Done! 就安装好了 vim-snazzy 配色主题 https://github.com/connorholyday/vim-snazzy https://github.com/w0ng/vim-hybrid vim-devicons 显示图标 https://github.com/ryanoasis/vim-devicons nerdtree 文件树 https://github.com/scrooloose/nerdtree vim-nerdtree-syntax-highlight nerdtree 文件名高亮 https://github.com/tiagofumo/vim-nerdtree-syntax-highlight vim-floaterm 悬浮窗口使用终端 https://github.com/voldikss/vim-floaterm https://zhuanlan.zhihu.com/p/107749687 coc.nvim 一款针对 neovim 所开发的代码补全插件 https://github.com/neoclide/coc.nvim ::: collapse 示例安装 java 代码补全 安装插件：Plug &#39;neoclide/coc.nvim&#39;, &#123;&#39;branch&#39;: &#39;release&#39;&#125;执行：CocInstall coc-java 安装成功： 打开 java 文件会自动下载 jdt.ls： 默认下载地址是 eclipse.org ： 下载太慢的话可以从 中科大镜像站 下载，解压文件至 ~/.config/coc/extensions/coc-java-data/server ::: Coc.nvim 系列（一）： 为了更好的补全体验 tagbar 生成标签 https://github.com/majutsushi/tagbar 如果在加载该插件时，报错: Tagbar: Exuberant ctags not found! 安装 ctags 即可解决问题 Manjaro Linux：sudo pacman -S ctags macOS：brew install ctags Markdown Preview for Neovim https://github.com/iamcco/markdown-preview.nvim goyo 优雅的文本编辑体验 https://github.com/junegunn/goyo.vim vim-startify 快捷启动页 https://github.com/mhinz/vim-startify indentLine 缩进 “刻度尺” https://github.com/Yggdroot/indentLine nerdcommenter 代码注释 https://github.com/scrooloose/nerdcommenter undotree 编辑历史记录 https://github.com/mbbill/undotree auto-pairs 自动补全一对括号 https://github.com/jiangmiao/auto-pairs YouCompleteMe 强大的代码补全 https://github.com/ycm-core/YouCompleteMe 安装： cd ~/.vim/plugged/YouCompleteMe sudo python3 install.py 参考 https://www.bilibili.com/video/av55498503 https://www.imooc.com/learn/1129","tags":["Linux","Neovim","Vim"],"categories":["Linux"]},{"title":"部署 Hexo 博客到云服务器","path":"/2020/01/04/hexo2/","content":"使用 Nginx Web 服务器托管即可 总体思路： 通过 git 将本地 hexo 生成的博客静态资源上传至服务器 修改 nginx 配置，让访问指向博客静态资源所在的目录 云服务器配置安装必要程序我服务器安装的 Linux 发行版为 CentOS yum install curl-devel expat-devel gettext-devel openssl-devel zlib-devel 安装依赖库 yum install gcc perl-ExtUtils-MakeMaker package 安装编译工具 yum install git nginx 安装 git 和 nginx Nginx：一款轻量级、高性能的 Web 服务器程序 service nginx start 启动 Nginx 在浏览器中打开服务器 ip 地址 测试 Nginx 是否成功启动，或者 wget http://127.0.0.1 进行测试： 创建 git 仓库创建并修改目录的所有权和用户权限： 123mkdir /home/git/chown -R $USER:$USER /home/git/chmod -R 755 /home/git/ 创建一个裸的 git 仓库： 12cd /home/git/git init --bare hexoBlog.git 创建一个新的 git 钩子，用于自动部署： 1vim /home/git/hexoBlog.git/hooks/post-receive 编辑添加： 12#!/bin/bashgit --work-tree=/home/hexoBlog --git-dir=/home/git/hexoBlog.git checkout -f 修改文件权限，使得其可执行： 1chmod +x /home/git/hexoBlog.git/hooks/post-receive 配置 Nginx 托管文件目录创建 /home/hexoBlog 目录，用于存放博客静态资源: 123mkdir /home/hexoBlog/chown -R $USER:$USER /home/hexoBlog/chmod -R 755 /home/hexoBlog/ nginx -t 查看 Nginx 配置文件位置： 123[root@aliyun ~]# nginx -tnginx: the configuration file /etc/nginx/nginx.conf syntax is oknginx: configuration file /etc/nginx/nginx.conf test is successful vim /etc/nginx/nginx.conf 编辑配置文件： 将其中的 root 值改为 /home/hexoBlog （刚才创建的托管仓库目录） 检查配置文件是否准确 &#96;.&#x2F;sbin&#x2F;nginx -t&#96;&#96; &#96;&#96;service nginx restart&#96; 重启 Nginx 服务 访问服务器上面的静态文件 把文件上传到服务器后配置文件地址，即可通过 [IP 地址]/guitar/2019.12.17.mp4 访问该文件 这里的 root 指的是上面配置的 &#x2F;home&#x2F;hexoBlog 配置 404 页面 本地主机配置编辑 hexo 站点配置文件 _config.yml repo: root@[服务器 IP 地址]:&#x2F;home&#x2F;git&#x2F;hexoBlog 进入 hexo 博客目录： 12hexo cleanhexo d 部署成功，打开服务器公网 IP 即可访问博客了 参考资料 Hexo 博客部署到腾讯云教程","tags":["Hexo","Nginx"],"categories":["Notes"]},{"title":"Linux 基础入门 🐧","path":"/2019/11/28/linux/","content":"Linux 是一套免费使用和自由传播的类 Unix 操作系统。 它的内核是由芬兰人 Linus 编写的，后来经过世界各地程序员的共同努力，衍生了几百种发行版本。 参考阅读： 半人半神，Unix、C 语言和 Linux 诞生记 关于 Unix&#x2F;Linux 的终端、伪终端、控制台和 Shell 2019 年最好的 Linux 发行版 部署学习环境使用虚拟机安装虚拟机软件 VirtualBox 是一款开源 虚拟机软件。VirtualBox 是由德国 Innotek 公司开发，由 Sun Microsystems 公司出品的软件，使用 Qt 编写，在 Sun 被 Oracle 收购后正式更名成 Oracle VM VirtualBox 在虚拟机上安装 linux 下载镜像：https://www.centos.org/download 创建虚拟机： 设置 - 存储 - 分配光盘 - 加载 ISO 文件 ，启动虚拟机进行 CentOS 安装 使用安卓设备 设备：华为平板 M6 安装使用 termux，参考 国光 的教程： Termux 高级终端安装使用配置教程 在 GNU&#x2F;Linux 和 Android-Termux 上一键安装 GNU&#x2F;Linux 容器，More ： https://gitee.com/mo2/linux 使用云服务器 使用 SSH 远程连接： 快速入门终端三种 linux 终端的使用方式： 图像终端（桌面环境） 命令行终端（命令行模式） 远程终端(SSH、VNC) 普通用户的命令提示符：**$** Root 用户的命令提示符：**#** 目录结构现在大多数 Linux 的文件系统是 EXT4（ Fourth extended filesystem 第四代扩展文件系统） 所有文件都在 / 根目录下： root root 用户的家目录 home/username 普通用户的家目录 etc 系统配置文件目录 bin 可执行文件（程序）目录 boot 系统启动相关 dev 硬件(一切皆文件，以文件的形式表现出来) mnt 挂载(U 盘、光盘…) opt 第三方程序目录 proc 进程文件夹 srv 服务文件夹 sys 系统文件夹( 更改屏幕亮度…) tmp 存放临时文件 usr Unix Software Resource var 程序缓存 软件包deb deb 是 Debian 软件包格式的文件扩展名，在 Debian 系 linux 中，双击 deb 包即可进入自动安装进程rpm RPM(Redhat Linux Packet Manager) 是 Red Hat 公司随 Redhat Linux 推出了一个软件包管理器，通过它能够更加轻松容易地实现软件的安装tar.gz 是一种压缩文件，在所有的 Linux 版本中都能使用，但安装过程麻烦一点点 帮助命令 man help info man ls 查看 ls 命令的功能及使用方法 man man 查看 man 命令的功能及使用方法（共有 9 个章节的帮助） man 1 passwd 查看命令 passwd 的帮助 man 5 passwd 查看文件 passwd 的帮助 man -a passwd 查看关键字 passwd 的帮助 shell（命令解释器）自带的命令称为内部命令，其他的是外部命令 type cd 查看 cd 是内部还是外部命令 查看内部命令 cd 的帮助：help cd man cd 查看的是命令解释器的帮助 查看外部命令 ls 的帮助：ls --help Info 帮助比 help 更详细，比 man page 编写得要更友好、更容易理解，但全是英文版的 文件管理Linux 中所有内容都是以文件的形式保存和管理的，即 一切皆文件 普通文件是文件，目录（文件夹）是文件，硬件设备（键盘、硬盘、打印机…）是文件，就连套接字（socket）、网络通信等资源也都是文件 文件查看su - root 切换为 root 用户 exit 退出当前用户（ Ctrl + d ） pwd 显示当前目录名称（类似资源管理器的地址栏） clear 清除页面内容（ Ctrl + l ） ls 命令ls [选项，选项…] [参数…(目录对象)] 不同颜色的目录代表不同的权限 ls /root / 显示 root 用户目录 及 根目录（目录之间用至少用一个空格间隔开） ls -l 以长格式显示当前目录（第一个字符 - 表示普通文件 d 表示是一个目录） 类型 数量 创建者 创建者所属的用户组 大小 最后修改时间 名称 ls -a 显示隐藏文件（隐藏文件为了避免误操作） ls -r 逆序显示文件（默认以文件名排序） ls -lh 人性化显示文件大小 ls -ltr 按时间顺序逆向显示文件 ls -R 递归显示文件 cd 命令 更改当前的操作目录，按 Tab 键进行目录补全 cd ~ 切换到当前用户的家目录 cd - 回到上一目录 cd .. 回到上一级目录 cd /path/to/... 绝对路经（/ 表示根目录） cd ./path/to/... 相对路经（./ 表示当前目录） cd ./path/to/... 相对路经（../ 表示上一级目录） 文本内容查看cat 查看文件所有内容，显示到终端 head 查看文件开头 head -3 filename 查看文本前 3 行 tail 查看文件结尾 -f 文件内容更新后，显示信息同步更新(ctrl+c 停止命令) wc 统计文件内容信息 -l 查看文件行数 more、less 分行显示(空格翻页，回车换行) less 不必读整个文件，加载速度会比 more 更快less 退出后不会留下刚显示的内容，more 会less 可以按键盘上下方向键显示上下内容，more 不能 创建touch filea 在当前位置创建文件 a mkdir a 在当前位置新建目录 a mkdir b c d 新建多个目录 b c d mkdir /a/b/c 在目录 a&#x2F;b&#x2F;下新建目录 c mkdir -p /a/b/c 新建多级目录 &#x2F;a&#x2F;b&#x2F;c 删除rm filea 删除文件 a rmdir a 删除空目录 a rm -r a 删除目录 a（包括目录内的所有文件） rm -rf a 删除目录 a（不进行提示） sudo rm -rf / 机毁人亡 复制cp -r /root/a /tmp 复制 root 下的目录 a 到&#x2F;tmp cp filea /tmp 复制文件 filea 到&#x2F;tmp -v 显示复制信息 -p 保留源文件时间-a 保留权限、属组、时间 移动mv dira /tmp 移动目录 dira 到&#x2F;tmp mv filea fileb 重命名 filea 为 fileb mv fileb /tmp/filea 移动 fileb 到&#x2F;tmp 并重命名为 filea 通配符* 匹配任意字符? 匹配一个字符cp file* /tmp 复制当前文件夹所有以 file 开头的文件到&#x2F;tmpcp file? /tmp 复制当前文件夹所有以 file 开头并且后面只有一个字符的的文件到&#x2F;tmp 压缩和解压缩 最早 Linux 备份介质是磁带，使用的命令是 tar 可以对打包后的磁带文件进行压缩储存，压缩的命令是 gzip 和 bzip2 经常使用的拓展名是 .tar.gz .tar.bz2 .tar（ .tgz .tbz2 ） tar cf /tmp/etc-backup.tar /etc 将&#x2F;etc 目录打包到&#x2F;tmp 下的 etc-backup.tar -c：建立一个压缩文件 (create) -f ：使用档名 -v : 显示解压信息 tar czf /tmp/etc-backuo.tar.gz /etc 打包并 压缩 yum install -y bzip2 安装 bzip2 tar cjf /tmp/etc-backuo.tar.bz2 /etc 压缩比率更高，速度比 gzip 慢 tar xf etc-backup.tar -C /root 解压 etc-backup.tar 到 root 目录 用户与权限管理useradd 新建用户 userdel 删除用户 passwd 修改用户密码 usermod 修改用户属性 chage 修改用户属性 新建useradd hcj 新建用户 hcj id hcj 查看用户 hcj 是否存在 用户会被记录到 &#x2F;etc&#x2F;passwd 和 &#x2F;etc&#x2F;shadow没有指定用户组的时候会自动创建一个同名的用户组root 用户才有创建普通用户的权限 passwd hcj 为用户 hcj 创建密码 删除userdel hcj 删除用户 hcj，但是保留相关数据 userdel -r hcj 删除用户及其相关文件数据 修改&#96;useradd h&#96;&#96; &#96;&#96;usermod -d &#x2F;home&#x2F;h1 h&#96; 修改用户 h 的家目录为 h1 用户组groupadd group1 新建用户组 group1 suermod -g group1 h 将用户 h 的用户组改为 group1 useradd -g group1 user2 新建用户 user2 并加入 group1 中 用户切换su - user1 切换到用户 user1（ - 改变当前工作目录以及 HOME，SHELL，USER，LOGNAME，切换为新用户的工作环境） switch user 切换用户sudo 是一种权限管理机制，依赖于&#x2F;etc&#x2F;sudoers，其定义了授权给哪个用户可以以管理员的身份能够执行什么样的管理命令 用户和用户组的配置文件用户配置文件： &#x2F;etc&#x2F;passwd用户名称 : x 需要密码验证 : uid : gid : 注释 : 家目录位置 : 登入后使用的命令解释器 /sbin/nologin 不允许登入终端 用户密码相关：&#x2F;etc&#x2F;shadow用户名 : 加密后的密码 用户组相关：&#x2F;etc&#x2F;group用户组名称 : x 需要密码验证 : gid : 同时属于其他组 文件权限权限的表示前十个字符（- — — —）： 第一个：文件类型 前三个：当前用户对该文件有什么权限 中三个：当前用户组对该文件有什么权限 后三个：其他人对该文件有什么权限 文件类型- 普通文件 字符：r 读 w 写 x 执行数字：r &#x3D; 4 w &#x3D; 2 x &#x3D; 1 d 目录文件 r 查看目录内文件 w 删除目录内文件 x 进入目录 b 块特殊文件（插入的设备） c 字符特殊文件（终端） l 符号链接（快捷方式） f 命名管道 s 套接字文件 修改权限123[root@aliyun ~]# mkdir test[root@aliyun ~]# ls -ld testdrwxr-xr-x 2 root root 4096 Jan 4 17:07 test 修改属主与属组chown user1 test 修改目录 test 的属主为 user1chown :group1 test 修改目录 test 的属组为 group1chown user1:group1 test 修改目属主为 user1 属组为 group1chgrp group1 test 修改目录 test 的属组为 group1 ctrl + r 搜索命令历史记录 u 属主 g 属组 o 其他 a 所有 + 增加权限 - 减少权限 = 设置权限 字符chmod u+x testfile 添加文件 testfile 的属主对它的执行权限数字chmod 446 testfile 只读 只读 读写chmod 777 testfile 赋予所有用户最大权限 特殊权限SUID 用于 二进制可执行文件，执行命令时取得文件属主权限 如 &#x2F;usr&#x2F;bin&#x2F;passwd执行 passwd 命令时候，会自动获取 root 用户的身份，让每个用户都有修改自己密码的权限（&#x2F;etc&#x2F;shadow 的权限为 000 ） SGID 用于 目录，在该目录下创建新的文件和目录，权限自动更改为该目录的属组 文件共享的情况会使用到 SBIT 用于 目录，该目录下新建的文件和目录，仅 root 和自己可以删除 如 &#x2F;tmp 特殊权限不建议手动设置 网络管理进程管理","tags":["Linux"],"categories":["Linux"]},{"title":"MacOS (Hackintosh) 使用笔记","path":"/2019/11/27/mac/","content":"自从苹果采用 Intel 的处理器，OS X 被黑客破解后可以安装在 Intel CPU 与部分 AMD CPU 的机器上 出现了一大批非苹果设备而使用苹果操作系统的机器，被称为黑苹果（Hackintosh），在 Mac 苹果机上面安装原版 Mac 系统的被称为白苹果(Macintosh)。 安装教程我的机型：ACER-E5-575G wifi、蓝牙、隔空投送 无法使用（可更换网卡一次性解决） 更换网卡比较贵，我的解决方案是使用外置 usb 网卡（将内置的网卡直接拆除） 独立显卡 无法驱动（无解） 精选几个接近完美的 EFI 配置文件： ① Acer E5 575g I5 7200U HD620 安装 Mojave 整理分享 EFI（不支持 VGA 输出，电池下无法睡眠） 镜像：macOS Mojave 10.14.2 18C54 ② Acer E5 575G i5+7200u+hd620+Alc255 安装 10.13.4 （麦克风无法使用，HDMI 音频输出异常） 镜像：macOS High Sierra 10.13.4 17E199 ③ Davix2301 ACER-E5-575G-Hackintosh（不支持视频输出） 镜像：macOS Mojave 10.14.6 18G84 ④ 作者还未在远景论坛分享（ 魂牵梦 Mong 说他处女座都表示舒服） 镜像：macOS Catalina 10.15.3 19D76 ⚠️ 10.15 存在软件兼容性问题 镜像下载：黑果小兵的部落阁 安装教程参考：联想小新 Air 13 黑苹果安装教程 踩坑总结 Mac 安装系统提示应用程序 副本已损坏, 不能用来安装 macOS（实用工具 -&gt; 终端 date 修改时间） 亮度 无法调节（现已无该问题） Intel 蓝牙 无法关闭 WIFI 无法使用：19.80￥ 买了个外置 usb 网卡（或者直接更换电脑网卡同时解决蓝牙的问题） 插入 3.5mm 耳机 声音输出异常（在设置中把声音输出的 平衡 调为最左或最右） 无法使用手机 usb 共享网络（安装 HoRNDIS 后重启） 把 ipad 作为 扩展屏（安装 xdisplay 或 duet，前者免费，后者移动端收费，10.15 增加了随航功能） 从网上下载的应用无法打开（开启应用任何来源） 无法读写 NTFS 格式硬盘（安装 Tuxera NTFS for Mac，双系统太方便了！） 精简 clover 启动项（安装 Clover Configurator，在引导界面里面设置添加隐藏卷 Recovery、Preboot） 键盘 稍有不同（Alt -&gt; command，win -&gt; Option，还可在键盘设置里将 Caps Lock 改为 Esc） HiDPI 是什么？以及黑苹果如何开启 HiDPI 开启应用任何来源有的时候从网上下载的应用无法打开，提示 应用已损坏这是系统为了加强安全机制，默认不允许用户只能使用从 App Store 里下载的应用解决办法：sudo spctl --master-disable 输入密码即完成 打开 系统偏好设置 » 安全性与隐私 ，左下角输入密码解锁，可选择来源 sudo trimforce enable 开启固态硬盘 TRIM 卸载自带应用程序在终端中 执行 sudo -i 输入密码cd /Applications 打开程序目录ls 查看系统自带软件还有一部分在 Applications/Utilities 执行 rm -rf [程序名] 即可删除应用如：rm -rf Maps.app 删除地图 如果无法卸载，则是 SIP(系统完整性保护) 没有关闭，解决办法如下：重启电脑，在过程中按住 command + R 或者进入 clover 引导 选择进入 恢复工具界面上方打开 实用工具 » 终端，执行 csrutil disable卸载完后记得打开保护，执行 csrutil enable 关闭 nsurlsessiond 进程nsurlsessiond 是 macOS 后台自动更新的线程，经常会占满带宽 12345/bin/shlaunchctl unload /System/Library/LaunchDaemons/com.apple.nsurlstoraged.plistlaunchctl unload /System/Library/LaunchAgents/com.apple.nsurlsessiond.plistsudo launchctl unload /System/Library/LaunchDaemons/com.apple.nsurlsessiond.plistsudo launchctl unload /System/Library/LaunchDaemons/com.apple.nsurlstoraged.plist 使用 TripMode 解决 MAC nsurlsessiond 狂走流量问题 禁止.DS_store 生成” .DS_Store，英文全称 Desktop Services Store，是 Mac OS 中保存文件夹自定义属性的隐藏文件，目的在于存贮文件夹的自定义属性，例如文件图标位置、视图设置，或背景色等，相当于 Windows 下的 desktop.ini。.DS_Store 默认放在每个文件夹的下面，这给我们带来了诸多不便…“ https://www.jianshu.com/p/f83e85443c50 不用關閉 SIP 也可以用 Asepsis ，在 El Capitan 下解決 .DS_Store 悲劇！ 修改状态栏苹果 logo 关闭 SIP(系统完整性保护) csrutil status 查看 SIP 状态 disabled 表示系统完整性保护处于关闭状态 在访达中按快捷键 Shift+Command+G 前往目录： &#x2F;System&#x2F;Library&#x2F;CoreServices&#x2F;SystemAppearance.bundle&#x2F;Contents&#x2F;Resources&#x2F;Assets.car 备份文件 Assets.car 到桌面或者其他用户目录下(否则无权限修改文件内的苹果图标) 下载 ThemeEngine ，用于打开修改 Assets.car 中的图标文件 按住元素预览图标拖拽到其他目录即可备份 拖入要替换的图标后保存文件，再将修改完的 Assets.car 覆盖到 &#x2F;System&#x2F;Library&#x2F;CoreServices&#x2F;SystemAppearance.bundle&#x2F;Contents&#x2F;Resources&#x2F; 重新登入后即生效 替换 电脑-&gt; Macintosh HD-&gt; 资源库-&gt; Desktop Pictures 里的文件可修改登入界面壁纸 调整启动台图标大小调整每一列显示图标数量defaults write com.apple.dock springboard-rows -int n调整每一行显示图标数量defaults write com.apple.dock springboard-columns -int nn 为你想设置每一行或者每一列图标的个数修改后重置生效Launchpaddefaults write com.apple.dock ResetLaunchPad -bool TRUE;killall Dock 解决双系统时间不一致安装完黑苹果后，切换 Windows，发现时间跟 macOS 下不一样，总慢八小时, 是因为两个系统读取时间的方式不一样windows 下 管理员模式 运行 cmd 或者 powershell，输入以下命令:Reg add HKLM\\SYSTEM\\CurrentControlSet\\Control\\TimeZoneInformation /v RealTimeIsUniversal /t REG_DWORD /d 1重启解决问题，这也适用于一些 linux 和 windows 共存的时间问题 安装常用程序Homebrew Homebrew 是 macOS 缺失的软件包的管理器，拥有安装、卸载、更新、查看、搜索等功能 官网：https://brew.sh/index_zh-cn 安装前先安装 Command Line Tools for Xcode终端执行 xcode-select --install安装好后，执行：/usr/bin/ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot; 如果提示 curl: (7) Failed to connect to raw.githubusercontent.com port 443: Connection refused，更换网络环境再尝试 Mac OS 手动安装 Homebrew 1234➜ ~ brew -vHomebrew 2.2.9Homebrew/homebrew-core (git revision ffb1d; last commit 2020-03-07)Homebrew/homebrew-cask (git revision d43a8; last commit 2020-03-07) brew 所安装程序的位置： 配置文件在 &#x2F;usr&#x2F;local&#x2F;etc 安装文件在 &#x2F;usr&#x2F;local&#x2F;Cellar 二进制可执行程序的软连接在 &#x2F;usr&#x2F;local&#x2F;bin Homebrew Cask 是 Homebrew 的扩展，借助它可以方便地用命令行管理 macOS 应用，它是将应用直接移动到 Application 文件夹，这与我们自己去官网下载安装是一致的 123456789➜ ~ brew search chrome==&gt; Formulaechrome-cli chrome-export==&gt; Caskschrome-devtools google-chromechrome-remote-desktop-host mkchromecastchromedriver homebrew/cask-versions/google-chrome-betadmm-player-for-chrome homebrew/cask-versions/google-chrome-canaryepichrome homebrew/cask-versions/google-chrome-dev 安装谷歌浏览器：brew cask install google-chrome git brew install git Node.js 之前下载安装包安装过，通过 brew 安装时提示： 12345678➜ ~ brew install node......==&gt; nodeBash completion has been installed to: /usr/local/etc/bash_completion.d......Warning: node 13.10.1 is already installed, it&#x27;s just not linkedYou can use `brew link node` to link this version. 1234➜ node brew link --overwrite nodeLinking /usr/local/Cellar/node/13.10.1...Error: Could not symlink share/doc/node/gdbinit/usr/local/share/doc/node is not writable. sudo chown -R $(whoami):admin /usr/local 赋予权限后即可链接成功 Vim brew install vim 基于 Vim 的超扩展文本编辑器 brew install neovim figlet brew install figlet 123456Hackintosh:~ hcj$ figlet Hackintosh _ _ _ _ _ _| | | | __ _ ___| | _(_)_ __ | |_ ___ ___| |__| |_| |/ _` |/ __| |/ / | &#x27;_ \\| __/ _ \\/ __| &#x27;_ \\| _ | (_| | (__| &lt;| | | | | || (_) \\__ \\ | | ||_| |_|\\__,_|\\___|_|\\_\\_|_| |_|\\__\\___/|___/_| |_| ranger https://ranger.github.io/index.html brew install ranger fish Finally, a command line shell for the 90s http://fishshell.com brew install fish 按 Ctrl+F 或者 右方向键 →， 即可自动补全 设置 fish 为默认 shell： sudo vim /etc/shells，添加 &#x2F;usr&#x2F;local&#x2F;bin&#x2F;fish 1234567891011# List of acceptable shells for chpass(1).# Ftpd will not allow users to connect who are not using# one of these shells./bin/bash/bin/csh/bin/ksh/bin/sh/bin/tcsh/bin/zsh/usr/local/bin/fish chsh -s /usr/local/bin/fish 更换 shell fish 插件管理：oh-my-fish fish_config 网页可视化配置 oh my zsh macOS 10.15 前终端的默认 shell 为 bash，但自带了 zsh 安装 oh-my-zsh (切换到 zsh 后进行安装) 12345678Shell successfully changed to &#x27;/bin/zsh&#x27;. __ __ ____ / /_ ____ ___ __ __ ____ _____/ /_ / __ \\/ __ \\ / __ `__ \\/ / / / /_ / / ___/ __ \\/ /_/ / / / / / / / / / / /_/ / / /_(__ ) / / /\\____/_/ /_/ /_/ /_/ /_/\\__, / /___/____/_/ /_/ /____/ ....is now installed!Please look over the ~/.zshrc file to select plugins, themes, and options. 更换 主题 下载 powerlevel10k（需要安装 Hack Nerd Font 字体和配置） 编辑 ~/.zshrc ，修改 ZSH_THEME=&quot;powerlevel10k/powerlevel10k&quot; 安装插件 zsh-syntax-highlighting 语法高亮 git clone https://github.com/zsh-users/zsh-syntax-highlighting.git $&#123;ZSH_CUSTOM:-~/.oh-my-zsh/custom&#125;/plugins/zsh-syntax-highlighting zsh-autosuggestions 自动补全 git clone https://github.com/zsh-users/zsh-autosuggestions $&#123;ZSH_CUSTOM:-~/.oh-my-zsh/custom&#125;/plugins/zsh-autosuggestions 下载后编辑 ~/.zshrc ，添加： 12345plugins=( git zsh-syntax-highlighting zsh-autosuggestions) 执行 source ~/.zshrc 后重启 zsh zsh-incremental 提示补全 brew install wget wget -O incr-0.2.zsh https://mimosa-pudica.net/src/incr-0.2.zsh cp incr-0.2.zsh ~/.oh-my-zsh/plugins/ 添加 source ~/.oh-my-zsh/plugins/incr*.zsh 到 ~/.zshrc 中 iTerm2 - 自带终端的替代品 Bartender - 菜单栏图标管理工具 Alfred - 强大的工具台（需要开启 Spotlight） win10：Wox + Everything iPic - 图床、文件上传工具 Snipaste - 截图神器 IINA - 免费开源强大好用的播放器 MagicanRest - 定时提醒 Paste - 剪切板管理器 Text Scanner - 文字识别 ScreenFlow - 录屏编辑软件 Permute - ”格式工厂“ PhotoScape X - 多功能图片处理软件 Typora - a markdown editor Magnet - 窗口管理 Downie 3 - 视频下载工具 Karabiner-Elements 改键神器 卸载方法：Preferences - Misc - Uninstall Karabiner-Elements Renamer 文件重命名 SSDReporter 固态硬盘健康检测 Caffeine 防止显示器熄屏 DaisyDisk 磁盘分析 Asepsis 禁止 .DS_Store 生成 a smart solution for .DS_Store pollution 常用快捷键Mac 键盘快捷键 通用 Command + X 剪切 Command + V 粘贴 Command + Shift + V 去格式粘贴 Command + Z 撤销 Command + Shift + Z 重做 Ctrl + H 等于 Delete (Backspace) Command + C 拷贝（Copy） Command + A 全选（All） Command + S 保存（Save) Command + F 查找（Find） Command 大多数情况下相当于 Windows 下的 Ctrl Finder Space 预览所选文件 Return/Enter 重命名所选文件 Command + O 打开文件 Command + ↑ 打开上一级目录 Command + Shift + . 显示隐藏文件 Command + Shift + N 新建文件夹 Command + Shift + G 前往绝对路径 Command + Delete(Backspace) 将文件移至废纸篓 Command + Shift + Delete 清倒废纸篓 应用窗口 Command + Tab 在应用程序间切换 Command + Shift + Tab 在应用程序间反向切换 Command + N 新建当前应用窗口 Command + ~ 在应用中的窗口间切换 Command + H 隐藏（Hide）当前应用程序窗口 Command + Option + H 隐藏其他应用程序窗口 Command + M 最小换应用程序窗口，最小化的窗口无法再直接切换出来，需要按住 Option Command + Q 退出（Quit）当前应用程序 Command + Option + esc 打开强制退出窗口 截图 Command + Shift + 3 截取全部屏幕到文件 Command + Shift + Control + 3 截取全部屏幕到剪贴板 Command + Shift + 4 截取选定区域到文件（按空格捕捉单个窗口） Command + Shift + Control + 4 截取选定区域到剪贴板，我通常使用 Snipaste 来截图 浏览器 Command + L 对焦至地址栏 Command + T 新建标签页 Command + W 关闭标签页 Command + Shift + T 撤销关闭标签页 Control + Tab 标签页切换 Control + Shift + Tab 标签页反向切换 Command + &#39;=&#39; 放大页面 Command + &#39;-&#39; 缩小页面 文本 Command + B 加粗文字 Command + [方向键] 光标快速跳转 Option + → 将光标移至下一个单词的末尾 Option + ← 将光标移至上一个单词的开头 Control + A 移至行或段落的开头","tags":["macOS","Hackintosh"],"categories":["Notes"]},{"title":"终端文件管理器 ranger 入门","path":"/2019/11/10/ranger/","content":"Ranger is a file manager with text-based user interface for Unix-like systems. 更新： Joshuto：ranger-like terminal file manager written in Rust. ranger 是用 Python 写的，joshuto 是用 Rust 重写的，速度更快 操作 j 上 k 下（切换当前文件夹文件） [ 上 ] 下（切换上一层文件夹） h 左（进入文件夹或打开文件） l 右（返回上一层） : 启动命令行 Esc 退出命令行 r 输入打开文件的方式 zh 显示隐藏文件 zf 过滤文件 q 退出 ranger gg 跳到当前文件夹最上面 Shift + G 跳到当前文件夹最下面 Shift + h 跳到上一条操作历史记录 Shift + l 跳到下一条操作历史记录 om &#x2F; oM 按文件名排序 os 按文件大小排序 oc 按修改日期排序，文件夹默认是按文件名排序 / 搜索 n 下一个搜索结果 N 上一个搜索结果 Shift + s 在此文件夹位置打开终端 yp 复制当前文件路径 yn 复制文件名 y 复制去掉后缀的文件名 cw 重命名文件 i 在文件名前开始重命名 a 在文件后缀前开始重命名 A 在文件后缀后开始重命名 文件操作 v 批量选中文件，后可执行批量复制文件名、重命名等操作 yy 复制文件 dd 剪切文件 pp 粘贴文件 po 覆盖文件 dD 删除文件 du 查看文件夹大小 配置执行 ranger --copy-config=all 生成默认配置文件: 123456789creating: /Users/hcj/.config/ranger/rifle.confcreating: /Users/hcj/.config/ranger/commands.pycreating: /Users/hcj/.config/ranger/commands_full.pycreating: /Users/hcj/.config/ranger/rc.confcreating: /Users/hcj/.config/ranger/scope.sh&gt; Please note that configuration files may change as ranger evolves. It&#x27;s completely up to you to keep them up to date.&gt; To stop ranger from loading both the default and your custom rc.conf, please set the environment variable RANGER_LOAD_DEFAULT_RC to FALSE. 将 ranger 的默认编辑器配置成 neovim 编辑 ~/.config/ranger/rifle.conf 12345# Define the &quot;editor&quot; for text files as first actionmime ^text, label editor = $EDITOR -- &quot;$@&quot;mime ^text, label pager = &quot;$PAGER&quot; -- &quot;$@&quot;!mime ^text, label editor, ext xml|json|csv|tex|py|pl|rb|js|sh|php = $EDITOR -- &quot;$@&quot;!mime ^text, label pager, ext xml|json|csv|tex|py|pl|rb|js|sh|php = &quot;$PAGER&quot; -- &quot;$@&quot; 将 $EDITOR 修改成 nvim, 如下: 123456# Define the &quot;editor&quot; for text files as first actionmime ^text, label editor = nvim -- &quot;$@&quot;mime ^text, label pager = &quot;$PAGER&quot; -- &quot;$@&quot;!mime ^text, label editor, ext xml|json|csv|tex|py|pl|rb|js|sh|php = nvim -- &quot;$@&quot;!mime ^text, label pager, ext xml|json|csv|tex|py|pl|rb|js|sh|php = &quot;$PAGER&quot; -- &quot;$@&quot; 插件Ranger Devicons plugin 使用前需要安装 nerd-fonts 字体并在终端设置，否则图标无法显示，macOS 下为： 12brew tap homebrew/cask-fontsbrew cask install font-hack-nerd-font 安装玩字体后，在 iTerm2 中设置字体： Image Previews (图片预览) 需先安装 w3m 浏览器 ：`brew install w3m`，打开配置文件 ` ~/.config/ranger/rc.conf` ，搜索修改： 12set preview_images trueset preview_images_method iterm2","tags":["Linux","Ranger"],"categories":["Tools"]},{"title":"SSH 连接云服务器","path":"/2019/11/01/ssh/","content":"SSH （Secure Shell）是一种网络协议，可以用于计算机之间的加密登录 连接服务器 ssh user@remote (-v -p port) ，如：ssh &#x72;&#x6f;&#x6f;&#x74;&#64;&#49;&#49;&#x32;&#46;&#x37;&#x34;&#x2e;&#x78;&#x78;&#46;&#120;&#x78; user 是在远程机器上的用户名 remote 是云服务器的地址，可以是 IP 或域名 port 是 SSH Server 监听的端口，默认值为 22 -v 打印出详细的连接信息 -p 指定连接 SSH Server 的端口 ssh user@remote [指令] 连接远程服务器并执行指令，发回 stdout 到本机后结束连接 免密登入公私钥非对称加密方式登入，方便又安全： 配置公钥 在自己计算机的终端中执行 ssh-keygen 即可生成 SSH 钥匙 （一路回车即可） 生成的文件在 ~/.ssh 上传公钥到服务器 执行 ssh-copy-id user@remote ，如：ssh-copy-id &#114;&#x6f;&#111;&#116;&#64;&#x31;&#49;&#50;&#46;&#x37;&#52;&#x2e;&#120;&#x78;&#x2e;&#120;&#120; 让远程服务器记住我们自己的计算机，文件保存在服务器的 ~/.ssh/authorized_keys 上传下载文件 s ecure c o p y 上传本地文件到服务器 scp /path/filename（本地文件） username@remote:/remote_dir（远程目录或文件） scp -r /local_dir/（本地目录） username@remote:/remote_dir/（远程目录） 下载服务器上的文件 scp username@remote:/path/filename（远程文件）/local_dir（本地目录或文件） scp -r username@remote:/remote_dir/（远程目录） /local_dir/（本地目录） 配置文件本地： 编辑 ~/.ssh/config，添加 123456789101112Host * ServerAliveInterval 60 # 每 60 秒发送一个 no-op 包，防止空闲时被服务器断开 # 保持 ssh 连接不断开 Host yun Hostname 112.74.xx.xx User root Port 22 Host xxx ...... yun 服务器别名、Hostname 服务器地址 保存后即可使用 ssh yun 来登入对应的服务器 服务端： 文件在 /etc/ssh/ssh_config SSH 的默认保留端口为 22，可以修改为其他合理的端口，修改后需要重启服务器或 ssh 服务 1234567891011❯ curl 112.74.38.53:22 # 可以查看端口是否可连接SSH-2.0-OpenSSH_7.4curl: (56) Recv failure: Connection reset by peer❯ curl 112.74.38.53:80 # http&lt;!doctype html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;&lt;meta charset=&quot;utf-8&quot;&gt;&lt;title&gt;Hidden track&lt;/title&gt; ......","tags":["Linux","SSH"],"categories":["Tools"]},{"title":"Manjaro Linux 使用记录","path":"/2019/09/06/mj/","content":"Manjaro 是一个基于 Arch Linux 专业制作的桌面操作系统 修改按键交换 Esc 和 Caps Lock 的按键位置 方法一: sudo pacman -S xorg 在 ~&#x2F; 下 创建 .xmodmaprc 文件,加入以下内容： 1234remove Lock = Caps_Lockadd Lock = Escapekeysym Caps_Lock = Escapekeysym Escape = Caps_Lock 执行 xmodmap .xmodmaprc 即生效 (重启后失效) 方法二: 编辑 /etc/X11/xorg.conf.d/00-keyboard.conf 增加 Option &quot;XkbOptions&quot; &quot;caps:swapescape&quot; : 123456789# Read and parsed by systemd-localed. It&#x27;s probably wise not to edit this file# manually too freely.Section &quot;InputClass&quot; Identifier &quot;system-keyboard&quot; MatchIsKeyboard &quot;on&quot; Option &quot;XkbOptions&quot; &quot;caps:swapescape&quot; Option &quot;XkbLayout&quot; &quot;cn&quot; Option &quot;XkbModel&quot; &quot;pc105&quot;EndSection 参考 https://www.cnblogs.com/lepeCoder/p/swap_ESC_and_Caps.html 修改主目录为英文选择中文语言后，家目录下的文件夹名是中文，不方便终端下的操作 123456sudo pacman -S xdg-user-dirs-gtkexport LANG=en_USxdg-user-dirs-gtk-update# 会弹出窗口提示语言更改，更新名称即可export LANG=zh_CN.UTF-8# 以显示中文 安装中文输入法安装输入法工具 sudo pacman -S fcitx fcitx-im fcitx-configtool 如果安装后一直提示输入法异常则选择 sudo pacman -S fcitx-qt4 fcitx-configtool 安装搜狗输入法 sudo pacman -S fcitx-sogoupinyin 皮肤下载：https://pinyin.sogou.com/skins/ 修改全局变量 sudo vi ~/.xprofile 输入： 123export GTK_IM_MODULE=fcitxexport QT_IM_MODUE=fcitxerport XMODIFERS=”@im=fcitx 重启后即可使用中文输入法 安装常用软件dock栏 sudo pacman -S latte-dock 安装配置后设置开机自启 TIM sudo pacman -S deepin.com.qq.office 安装后如果打不开： 安装gnome-settings-daemon sudo pacman -S gnome-settings-daemon 设置开启自启动 1系统设置-&gt;开机或关机-&gt;自动启动-&gt;添加脚本-&gt;输入/usr/lib/gsd-xsettings，重启后即可打开 WPSsudo pacman -S wps-office 安装wps必要字体 sudo pacman -S ttf-wps-fonts 安装windows字体： 由于版权问题，linux版WPS 没有自带字体，而许多字体是平时要使用的 到windows字体目录(双系统)下，复制字体文件到wps-fonts 123sudo cp *.ttf /usr/share/fonts/wps-fonts/sudo cp *.TTF /usr/share/fonts/wps-fonts/sudo cp simsun.ttc /usr/share/fonts/wps-fonts/ 添加可执行权限 1234cd /usr/share/fonts/sudo chmod 755 wps-fonts/cd /usr/share/fonts/wps-fonts/sudo chmod 644 * 生成字体缓存 123sudo mkfontscalesudo mkfontdirfc-cache 这下wps里就有了平时那些常用的字体 网易云音乐 sudo pacman -S netease-cloud-music 搜索栏无法输入中文解决办法： yay -S qcef sudo vim /opt/netease/netease-cloud-music/netease-cloud-music.bash 修改为： 1234567#!/bin/shHERE=&quot;$(dirname &quot;$(readlink -f &quot;$&#123;0&#125;&quot;)&quot;)&quot;#export LD_LIBRARY_PATH=&quot;$&#123;HERE&#125;&quot;/libs#export QT_PLUGIN_PATH=&quot;$&#123;HERE&#125;&quot;/plugins #export QT_QPA_PLATFORM_PLUGIN_PATH=&quot;$&#123;HERE&#125;&quot;/plugins/platformsexport XDG_CURRENT_DESKTOP=DDE exec &quot;$&#123;HERE&#125;&quot;/netease-cloud-music $@ VirtualBox 虚拟机 sudo uname -r 查看内核版本 sudo pacman -S virtualbox 安装对应内核的版本 sudo pacman -Ss virtualbox-ext-oracle 安装扩展包 谷歌浏览器 sudo pacman -S google-chrome Vim sudo pacman -S vim Neovim sudo pacman -S neovim Ranger sudo pacman -S ranger 微信 sudo pacman -S electronic-wechat Markdown编辑器 sudo pacman -S typora VS Code sudo pacman -S code 百度网盘 sudo pacman -S baidunetdisk-bin 截图工具 sudo pacman -S deepin-screenshot sudo pacman -S flameshot yay pacman不直接支持AUR，yay是一个AUR助手 sudo pacman -S yay 配置终端安装Monaco字体 curl -kL https://raw.github.com/cstrap/monaco-font/master/install-font-archlinux.sh | bash fish sudo pacman -S fish 安装oh-my-fish curl -L https://get.oh-my.fish | fish 更换shell为fish chsh -s /usr/bin/fish 更改配色样式 fish_config PacmanPacman是Manjaro系统中的软件包管理器，Manjaro也提供了可视化操作的 pacman-manager 配置国内镜像源Manjaro本身包含了很多国内的源，测试并自动选择国内源sudo pacman-mirrors -c China 添加archlinuxcn源： sudo vi /etc/pacman.d/archlinuxcn在archlinuxcn中写入国内的镜像源地址： Server = https://mirrors.tuna.tsinghua.edu.cn/archlinuxcn/$arch Server = https://mirrors.ustc.edu.cn/archlinuxcn/$arch sudo vi /etc/pacman.conf在末尾添加： [archlinuxcn] SigLevel = Never Include = /etc/pacman.d/archlinuxcn 保存后更新软件源 sudo pacman -Syy 常用命令 更新 sudo pacman -Sy 更新软件库，获取最新软件情报，如果刚刚更新过就不再更新 sudo pacman -Syy 强制更新软件库，无论刚刚是否更新过 sudo pacman -Su 更新软件包 sudo pacman -Syyu 更新软件库并更新软件包 安装 sudo pacman -S [软件包名] 安装软件包 查询 sudo pacman -Ss [要查询的软件包名] 查询软件仓库中的软件 sudo pacman -Q 查询本地所有已安装的软件包 sudo pacman -Q | wc -l 查看本地已安装的软件包数量 sudo pacman -Qe | wc -l 查看本地自己安装的软件包数量（不包括系统自带的软件包） sudo pacman -Qqe 查询本地自己安装的软件包（不显示版本号） sudo pacman -Qs [要查询的软件包名] 查询本地软件包 sudo pacman -Qdt 查询系统中不再被需要的依赖 sudo pacman -Qdtq 查询系统中不再被需要的依赖（不显示版本号） 删除 sudo pacman -Sc 删除本地安装的软件包缓存 sudo pacman -R [要删除的软件包名] 删除软件包 sudo pacman -Rs [要删除的软件包名] 删除软件包及其依赖 sudo pacman -Rn [要删除的软件包名] 删除软件包及其配置文件 sudo pacman -Ru [要删除的软件包名] 删除软件包与不再被需要的依赖 sudo pacman -R (sudo pacman -Qdtq) 删除系统中不再被需要的依赖","tags":["Linux","Manjaro"],"categories":["Linux"]},{"title":"Markdown 常用语法整理","path":"/2019/07/28/markdown/","content":"Markdown 是一种可以使用普通文本编辑器编写的标记语言，通过解析器将 markdown 语法的文件解析为 html 文件 编辑器各平台都有许多 Markdown 编辑器客户端，或者使用 Web 的 Markdown 编辑器。使用 md 编辑器可以带来语法高亮、实时预览、快捷补全等功能，比使用普通文本编辑器的体验更好 Typora、Cmd Markdown、Visual Studio Code（安装插件）、各种云笔记软件 基础语法按 标记语法 和 效果 顺序演示，所有符号都是英文输入状态下的 文本效果标题# 一级标题 ## 二级标题 ### 三级标题 注意 # 后有一个空格 字体*斜体文本* **粗体文本** ***粗斜体文本*** 用 _ 替换 * 也可达到相同效果 斜体文本粗体文本粗斜体文本 分割线*** 两个以上的 * 或者 - 删除线~~删除线~~ 前后两个波浪线删除线 下划线&lt;u&gt; 下划线 &lt;/u&gt; HTML 的 &lt;u&gt; 标签 下划线 结构效果列表无序列表* 第一项 * 第二项 * 第三项 * 替换为 + or -，一样效果 第一项 第二项 第三项 有序列表1. 第一项 2. 第二项 3. 第三项 注意 . 后有一个空格 第一项 第二项 第三项 列表嵌套1. 第一项： * 第一项嵌套的第一个元素 * 第一项嵌套的第二个元素 2. 第二项： * 第二项嵌套的第一个元素 * 第二项嵌套的第一个元素 子列表前有四个空格 第一项： 第一项嵌套的第一个元素 第一项嵌套的第二个元素 第二项： 第二项嵌套的第一个元素 第二项嵌套的第一个元素 区块&gt; 站到天空下来晒晒太阳吧 &gt; 不要在角落里弹着吉他 站到天空下来晒晒太阳吧不要在角落里弹着吉他 &gt; 好静 &gt; &gt; 只有风 好静 只有风 可以在区块中使用列表，列表中使用区块 代码三个反引号 &#96; 把代码块包裹起来 12345public class HelloWorld &#123; public static void main(String []args) &#123; System.out.println(&quot;Hello World&quot;); &#125;&#125; 每行代码前加 4 个空格，代码块无行号和高亮 public class HelloWorld &#123; public static void main(String [] args) &#123; System.out.println(&quot;Hello World&quot;); &#125; &#125; 一个反引号 &#96; 把代码块包裹，效果如下： Hello World 链接我的博客 [Hidden track](https://www.allalright.site) 我的博客 Hidden track 图片1&#123;% image 图片地址 %&#125; 图片链接失效则会显示图片描述 左对齐：在单行图片前加一个空格 可使用 &lt;img&gt; 标签指定图片的高度与宽度 表格| 左对齐 | 右对齐 | 居中对齐| | :-----| ----: | :----: | | 单元格 | 单元格 | 单元格 | | 单元格 | 单元格 | 单元格 | 左对齐 右对齐 居中对齐 单元格 单元格 单元格 单元格 单元格 单元格","tags":["Markdown"],"categories":["Notes"]},{"title":"在 Android 上搭建 Hexo 博客","path":"/2019/07/27/hexo1/","content":"Termux is an Android terminal emulator and Linux environment app 前期准备 Termux : 一个 Android 下的高级的终端模拟器 Node.js : 一个基于 Chrome V8 引擎的 JavaScript 运行环境 Git : 一个开源的分布式版本控制系统 Hexo : 一款基于 Node.js 的静态博客框架 Termux 高级终端安装使用配置 搭建步骤安装 node.js、git pkg update 更新软件源，建议先更换国内源：清华源 pkg install nodejs git 安装 nodejs、git node --version 执行显示版本号 git --version 查看是否安装成功 安装 Hexo npm install -g hexo-cli 安装 Hexo hexo --version 查看版本号 初始化博客可以在任意位置创建文件夹来存放博客初始化的文件，这个文件夹就是博客的 根目录 mkdir hexoblog 创建博客根目录 cd hexoblog 打开根目录 hexo init 初始化 hexo 环境，可能需要几分钟，取决于网速 初始化成功后，可以查看到以下博客目录： hexo s 启动 hexo 本地预览 我的博客根目录是在 Desktop&#x2F;blog ，在根目录执行 hexo s 后，浏览器打开 http://localhost:4000 即可本地预览博客 部署到 Gitee注册打开 https://gitee.com/ 注册并登入，右上角 “加号” 新建仓库 ⚠️ 仓库路径必须与 Gitee 账号 同名 ⚠️ 是否开源设置为 公开 配置添加 git 用户信息 git config --global user.name &quot;xxx&quot; &#96;&#96;git config –global user.email “&#120;&#x78;&#x78;&#120;&#120;&#x40;&#120;&#120;&#46;&#99;&#x6f;&#x6d;“&#96; 复制仓库地址 打开根目录下的_config.yml，在配置文件最后的位置，做如下修改： repo: [复制下来的仓库地址]（注意 : 后有一个空格） 部署 hexo clean 删除本地缓存和静态文件 hexo g 生成新的博客静态文件 hexo d 提交生成的静态文件 如提示 ERROR Deployer not found: git，则 npm install --save hexo-deployer-git 根据提示输入 gitee 账号和密码，推送完成后，进入 仓库 -&gt; 点击服务 -&gt; Gitee Pages 服务 -&gt; 更新 更新完成后，即可通过 [你的 gitee 账号].gitee.io 访问所搭建的博客 每次修改博客内容提交到 gitee 后，都需要到管理界面更新 Gitee Pages 新的页面才会生效 Smartisan TNT 玩法 自由使用 Termux 使用完整的 Linux 环境","tags":["Hexo","Termux","Android"],"categories":["Notes"]},{"title":"关于","path":"/about/index.html","content":"I am very glad to meet you. 👏 This blog is mainly to document something. 📝 Hexo stellar My WeChat QR code：💬 1echo H4sIAAAAAAAAA91UOQ7CQAzseQVS/v/HiGLluewNIkWEpUAOZzyH4TjuqtdtSE+HelN9rtfd9cnf2GtQha8vImjuNShmhPeK3XquvRsonlqMvoZKZ9PYwSt/BY/RK0+wP8YEtWoJqh3ZeBErjRyT8wBagVkKA5Qg5RtZsSA805VVweSVzk0CmVeboE9PECxs9AobHJgZj8vgdvo2Zb+IlSbkY9DHFkpJ58XMLhlUDt//DzojGlZuPwOkFQ4rym6oL3jVrGheQwZ27lGglgfgvPmNNkH0JsGNUMgozc0rEm3X1ePUklM8boRCuZwj2rKFYqEOhP0br3R2lnnxN+guoaQhwd/r/6FOt/LPYdcKAAA= | base64 --decode | gzip -d qrencode -t ASCIIi https://u.wechat.com/ENziBvO8RUEmOPqMFuQfnTM?s=1 | gzip | base64 Or 12# sudo apt install qrencode qrencode -t ASCIIi https://u.wechat.com/ENziBvO8RUEmOPqMFuQfnTM\\?s\\=1"}]