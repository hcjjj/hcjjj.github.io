<!DOCTYPE html>
<html lang='zh-CN'>

<head>
  <meta name="generator" content="Hexo 7.3.0">
  <meta name="hexo-theme" content="https://github.com/xaoxuu/hexo-theme-stellar/tree/1.19.0">
  <meta charset="utf-8">
  

  <meta http-equiv='x-dns-prefetch-control' content='on' />
  <link rel='dns-prefetch' href='https://gcore.jsdelivr.net'>
  <link rel="preconnect" href="https://gcore.jsdelivr.net" crossorigin>
  <link rel='dns-prefetch' href='//unpkg.com'>

  <meta name="renderer" content="webkit">
  <meta name="force-rendering" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
  <meta name="HandheldFriendly" content="True" >
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="theme-color" content="#f8f8f8">
  
  <title>Kubernetes 基础概念与原理解析 ☸ - H-sediment</title>

  
    <meta name="description" content="K8s 本质上是应用服务和服务器之间的中间层，通过暴露一系列 API 能力，简化了服务的部署运维流程">
<meta property="og:type" content="article">
<meta property="og:title" content="Kubernetes 基础概念与原理解析 ☸">
<meta property="og:url" content="http://example.com/2024/10/15/k8s/index.html">
<meta property="og:site_name" content="H-sediment">
<meta property="og:description" content="K8s 本质上是应用服务和服务器之间的中间层，通过暴露一系列 API 能力，简化了服务的部署运维流程">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2024-10-14T16:00:00.000Z">
<meta property="article:modified_time" content="2024-11-06T10:28:09.134Z">
<meta property="article:author" content="hcjjj">
<meta property="article:tag" content="Docker">
<meta property="article:tag" content="Kubernetes">
<meta name="twitter:card" content="summary">
  
  
  
  <meta name="keywords" content="Docker,Kubernetes">

  <!-- feed -->
  

  
    
<link rel="stylesheet" href="/css/main.css">

  

  
    <link rel="shortcut icon" href="https://cdn.jsdelivr.net/gh/hcjjj/blog-img/icon.png">
  

  

  
    <link rel="stylesheet" href="https://gcore.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css" integrity="sha384-vKruj+a13U8yHIkAyGgK1J3ArTLzrFGBbBc0tDp4ad/EyewESeXE/Iv67Aj8gKZ0" crossorigin="anonymous">
    <script defer src="https://gcore.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js" integrity="sha384-PwRUT/YqbnEjkZO0zZxNqcxACrXe+j766U2amXcgMg5457rve2Y7I6ZJSm2A0mS4" crossorigin="anonymous"></script>
    <script defer src="https://gcore.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"onload="renderMathInElement(document.body);"></script>
  


  
</head>

<body>
  




  <div class='l_body' id='start'>
    <aside class='l_left' layout='post'>
    

  

<header class="header"><div class="logo-wrap"><a class="avatar" href="/about/"><div class="bg" style="opacity:0;background-image:url(https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.4/avatar/round/rainbow64@3x.webp);"></div><img no-lazy class="avatar" src="https://cdn.jsdelivr.net/gh/hcjjj/blog-img/avatar.jpg" onerror="javascript:this.classList.add('error');this.src='https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.4/image/2659360.svg';"></a><a class="title" href="/"><div class="main" ff="title">H-sediment</div><div class="sub cap">dust in the wind</div></a></div>

<nav class="menu dis-select"><a class="nav-item active" href="/">文章</a><a class="nav-item" href="/about/">About</a></nav>
</header>


<div class="widgets">
<widget class="widget-wrapper search"><div class="widget-body"><div class="search-wrapper" id="search"><form class="search-form"><input type="text" class="search-input" id="search-input" data-filter="/blog/" placeholder="文章搜索"><svg t="1670596976048" class="icon search-icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="2676" width="200" height="200"><path d="M938.2 832.6L723.8 618.1c-2.5-2.5-5.3-4.4-7.9-6.4 36.2-55.6 57.3-121.8 57.3-193.1C773.3 222.8 614.6 64 418.7 64S64 222.8 64 418.6c0 195.9 158.8 354.6 354.6 354.6 71.3 0 137.5-21.2 193.2-57.4 2 2.7 3.9 5.4 6.3 7.8L832.5 938c14.6 14.6 33.7 21.9 52.8 21.9 19.1 0 38.2-7.3 52.8-21.8 29.2-29.1 29.2-76.4 0.1-105.5M418.7 661.3C284.9 661.3 176 552.4 176 418.6 176 284.9 284.9 176 418.7 176c133.8 0 242.6 108.9 242.6 242.7 0 133.7-108.9 242.6-242.6 242.6" p-id="2677"></path></svg></form><div id="search-result"></div><div class="search-no-result">没有找到内容！</div></div></div></widget>


<widget class="widget-wrapper toc single" id="data-toc"><div class="widget-header cap dis-select"><span class="name">Kubernetes 基础概念与原理解析 ☸</span></div><div class="widget-body fs14"><div class="doc-tree active"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B4%E4%BD%93%E6%9E%B6%E6%9E%84"><span class="toc-number">1.</span> <span class="toc-text">整体架构</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Master"><span class="toc-number">1.1.</span> <span class="toc-text">Master</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Node"><span class="toc-number">1.2.</span> <span class="toc-text">Node</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5"><span class="toc-number">1.3.</span> <span class="toc-text">基本概念</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#kubectl"><span class="toc-number">1.4.</span> <span class="toc-text">kubectl</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%A4%E8%AF%81%E5%92%8C%E6%8E%88%E6%9D%83"><span class="toc-number">1.5.</span> <span class="toc-text">认证和授权</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Helm"><span class="toc-number">1.6.</span> <span class="toc-text">Helm</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90"><span class="toc-number">2.</span> <span class="toc-text">原理解析</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#kube-apiserver"><span class="toc-number">2.1.</span> <span class="toc-text">kube-apiserver</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#etcd"><span class="toc-number">2.2.</span> <span class="toc-text">etcd</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#controller-manager"><span class="toc-number">2.3.</span> <span class="toc-text">controller-manager</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#kube-scheduler"><span class="toc-number">2.4.</span> <span class="toc-text">kube-scheduler</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#kubelet"><span class="toc-number">2.5.</span> <span class="toc-text">kubelet</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#kube-proxy"><span class="toc-number">2.6.</span> <span class="toc-text">kube-proxy</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Container-Runtime"><span class="toc-number">2.7.</span> <span class="toc-text">Container Runtime</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Troubleshoot"><span class="toc-number">3.</span> <span class="toc-text">Troubleshoot</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%89%A9%E5%B1%95%E5%A2%9E%E5%BC%BA"><span class="toc-number">4.</span> <span class="toc-text">扩展增强</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%83%A8%E7%BD%B2%E5%89%8D%E5%90%8E%E7%AB%AF%E5%BA%94%E7%94%A8"><span class="toc-number">5.</span> <span class="toc-text">部署前后端应用</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Golang"><span class="toc-number">5.1.</span> <span class="toc-text">Golang</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#CI-CD"><span class="toc-number">5.2.</span> <span class="toc-text">CI&#x2F;CD</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#React"><span class="toc-number">5.3.</span> <span class="toc-text">React</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9B%B8%E5%85%B3%E8%B5%84%E6%96%99"><span class="toc-number">6.</span> <span class="toc-text">相关资料</span></a></li></ol></div></div></widget>




</div>
<footer class="footer dis-select"><div class="social-wrap"><a class="social" href="https://github.com/hcjjj" target="_blank" rel="external nofollow noopener noreferrer"><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/social/08a41b181ce68.svg"/></a><a class="social" href="/hcjjj@foxmail.com" rel="noopener noreferrer"><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/social/a1b00e20f425d.svg"/></a><a class="social" href="/H_sediment" rel="noopener noreferrer"><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/social/b32ef3da1162a.svg"/></a><a class="social" href="/" rel="noopener noreferrer"><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/social/3845874.svg"/></a></div></footer>

    </aside>
    <div class='l_main'>
      

      



<div class="bread-nav fs12"><div id="breadcrumb"><a class="cap breadcrumb" href="/">主页</a><span class="sep"></span><a class="cap breadcrumb" href="/">文章</a><span class="sep"></span><a class="cap breadcrumb-link" href="/categories/Kubernetes/">Kubernetes</a></div><div id="post-meta">发布于&nbsp;<time datetime="2024-10-14T16:00:00.000Z">2024-10-15</time></div></div>

<article class='md-text content post'>
<h1 class="article-title"><span>Kubernetes 基础概念与原理解析 ☸</span></h1>
<p>K8s 本质上是应用服务和服务器之间的中间层，通过暴露一系列 API 能力，简化了服务的部署运维流程</p>
<span id="more"></span>

<h2 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h2><p>K8s 整体上遵循 C&#x2F;S 架构，左侧是一个官方提供的名为 <strong>kubectl</strong> 的 CLI （Command Line Interface）工具，用于使用 K8s 开放的 API 来管理集群和操作对象等，右侧则是 K8s 集群的后端服务及开放出的 API 等。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">                               +-------------+                              </span><br><span class="line">                               |             |                              </span><br><span class="line">                               |             |               +---------------+</span><br><span class="line">                               |             |       +-----&gt; |     Node 1    |</span><br><span class="line">                               | Kubernetes  |       |       +---------------+</span><br><span class="line">+-----------------+            |   Server    |       |                      </span><br><span class="line">|       CLI       |            |             |       |       +---------------+</span><br><span class="line">|    (Kubectl)    |-----------&gt;| ( Master )  |&lt;------+-----&gt; |     Node 2    |</span><br><span class="line">|                 |            |             |       |       +---------------+</span><br><span class="line">+-----------------+            |             |       |       </span><br><span class="line">                               |             |       |       +---------------+</span><br><span class="line">                               |             |       +-----&gt; |     Node 3    |</span><br><span class="line">                               |             |               +---------------+</span><br><span class="line">                               +-------------+               </span><br></pre></td></tr></table></figure>

<p>Node 是用于工作的机器，Master 是一种角色（Role），表示在这个 Node 上包含着管理集群的一些必要组件，生产环境中，为了保障集群的高可用，通常会部署多个 Master。</p>
<h3 id="Master"><a href="#Master" class="headerlink" title="Master"></a>Master</h3><p>Master 是整个 K8s 集群的“大脑”，与大脑类似，它有几个重要的功能：</p>
<ul>
<li>接收：外部的请求和集群内部的通知反馈</li>
<li>发布：对集群整体的调度和管理</li>
<li>存储：负责集群状态的存储</li>
</ul>
<p>这些功能，也通过一些组件来共同完成，将其称为 control plane </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">+----------------------------------------------------------+          </span><br><span class="line">| Master                                                   |          </span><br><span class="line">|              +-------------------------+                 |          </span><br><span class="line">|     +-------&gt;|        API Server       |&lt;--------+       |          </span><br><span class="line">|     |        |                         |         |       |          </span><br><span class="line">|     v        +-------------------------+         v       |          </span><br><span class="line">|   +----------------+     ^      +--------------------+   |          </span><br><span class="line">|   |                |     |      |                    |   |          </span><br><span class="line">|   |   Scheduler    |     |      | Controller Manager |   |          </span><br><span class="line">|   |                |     |      |                    |   |          </span><br><span class="line">|   +----------------+     v      +--------------------+   |          </span><br><span class="line">| +------------------------------------------------------+ |          </span><br><span class="line">| |                                                      | |          </span><br><span class="line">| |                Cluster state store                   | |          </span><br><span class="line">| |                                                      | |          </span><br><span class="line">| +------------------------------------------------------+ |          </span><br><span class="line">+----------------------------------------------------------+     </span><br></pre></td></tr></table></figure>

<p><strong>Cluster state store</strong></p>
<p>存储集群所有需持久化的状态，并且提供 watch 的功能支持，可以快速的通知各组件的变更等操作，目前 Kubernetes 的存储层选择是 etcd，一般情况下直接以 etcd 来代表集群状态存储服务，即将所有状态存储到 etcd 实例中。</p>
<blockquote>
<p>得益于 etcd 的开发团队较为活跃，而且根据 K8s 社区的反馈做了相当大的改进，并且当时 K8s 团队主要的关注点也不在此，所以直到现在 etcd 仍不是一个可选项，后续也许将此处插件化也不是不可能</p>
</blockquote>
<p><strong>API Server</strong></p>
<p>整个集群的入口，接收外部的信号和请求，并将一些信息写入到 etcd 中，它提供了认证相关的功能，用于判断是否有权限进行操作，API Server 支持多种认证方法，一般情况下都使用 X.509 证书进行认证。</p>
<blockquote>
<p>X.509 是一种公钥基础设施（PKI）中使用的 <strong>数字证书标准</strong>，用于验证实体（例如用户、设备或服务器）的 <strong>身份</strong>。X.509 证书广泛应用于互联网安全、加密通信等领域，包括 HTTPS、电子邮件加密等。X.509 证书由一个可信任的证书颁发机构（CA）签名，用于证明证书中包含的公钥与持有证书的实体是可信的。</p>
</blockquote>
<p>API Server 的目标是成为一个极简的 server，只提供 REST 操作，更新 etcd ，并充当着集群的网关，至于其他的业务逻辑之类的，通过插件或者在其他组件中完成。</p>
<p><strong>Controller Manager</strong></p>
<p>是 K8s 集群中最繁忙的部分，它在后台运行着许多不同的控制器进程，用来调节集群的状态，当集群的配置发生变更，控制器就会朝着预期的状态开始工作。</p>
<p><strong>Scheduler</strong></p>
<p>集群的调度器，它会持续的关注集群中未被调度的 Pod ，并根据各种条件，比如资源的可用性，节点的亲和性或者其他的一些限制条件，通过绑定的 API 将 Pod 调度&#x2F;绑定到 Node 上。</p>
<blockquote>
<p><strong>节点亲和性 (Node Affinity)</strong> 是一种控制 Pod 调度位置的机制，可以指定 Pod 必须或优先调度到具有特定标签的节点上。节点亲和性比节点选择器 (Node Selector) 更为灵活，可以实现更复杂的调度规则，在资源优化、工作负载隔离、可用性提升等场景中有广泛应用，是 K8s 重要的 <strong>调度策略</strong> 之一。</p>
</blockquote>
<h3 id="Node"><a href="#Node" class="headerlink" title="Node"></a>Node</h3><p>(Worker) Node 是加入集群中的机器，Node 加入集群并接受调度、运行服务，归功于运行在 Node 上的几个核心组件。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">+--------------------------------------------------------+       </span><br><span class="line">| +---------------------+        +---------------------+ |       </span><br><span class="line">| |      kubelet        |        |     kube-proxy      | |       </span><br><span class="line">| |                     |        |                     | |       </span><br><span class="line">| +---------------------+        +---------------------+ |       </span><br><span class="line">| +----------------------------------------------------+ |       </span><br><span class="line">| | Container Runtime (Docker)                         | |       </span><br><span class="line">| | +---------------------+    +---------------------+ | |       </span><br><span class="line">| | |Pod                  |    |Pod                  | | |       </span><br><span class="line">| | | +-----+ +-----+     |    |+-----++-----++-----+| | |       </span><br><span class="line">| | | |C1   | |C2   |     |    ||C1   ||C2   ||C3   || | |       </span><br><span class="line">| | | |     | |     |     |    ||     ||     ||     || | |       </span><br><span class="line">| | | +-----+ +-----+     |    |+-----++-----++-----+| | |       </span><br><span class="line">| | +---------------------+    +---------------------+ | |       </span><br><span class="line">| +----------------------------------------------------+ |       </span><br><span class="line">+--------------------------------------------------------+  </span><br></pre></td></tr></table></figure>

<p><strong>Kubelet</strong></p>
<p>Kubelet 实现了集群中最重要的关于 Node 和 Pod 的控制功能，如果没有 Kubelet 的存在，那 K8s 很可能是一个纯粹的通过 API Server CRUD 的应用程序。</p>
<p>K8s 原生的执行模式是 <strong>操作应用程序的容器</strong>，而不像传统模式那样，直接操作某个包或者是操作某个进程。基于这种模式，可以让应用程序之间相互隔离，和主机也是相互隔离的，毕竟它不依赖于主机，在任何的容器运行时（比如 Docker）上都可以部署和运行。</p>
<p>Pod 可以是一组容器（也可以包含存储卷），K8s 将 Pod 作为可调度的基本单位， 分离开了构建时和部署时的关注点：</p>
<ul>
<li>构建时，重点关注某个容器是否能正确构建，如何快速构建</li>
<li>部署时，关心某个应用程序的服务是否可用，是否符合预期，依赖的相关资源是否都能访问到</li>
</ul>
<p>这种隔离的模式，可以很方便的将应用程序与底层的基础设施解耦，极大的提高集群扩&#x2F;缩容，迁移的灵活性。</p>
<p>Master 节点的 <code>Scheduler</code> 组件，它会调度未绑定的 Pod 到符合条件的 Node 上，而至于最终该 Pod 是否能运行于 Node 上，则是由 <code>Kubelet</code> 来裁定的。</p>
<p><strong>Container runtime</strong></p>
<p>容器运行时最主要的功能是下载镜像和运行容器，最常见的实现是 <a target="_blank" rel="noopener" href="https://www.docker.com/">Docker</a> , 目前还有其他的一些实现，比如 <a target="_blank" rel="noopener" href="https://github.com/rkt/rkt">rkt</a>, <a target="_blank" rel="noopener" href="https://github.com/kubernetes-sigs/cri-o">cri-o</a>。</p>
<p>K8s 提供了一套通用的容器运行时接口 CRI (Container Runtime Interface), 凡是符合这套标准的容器运行时实现，均可在 K8ss 上使用。</p>
<p><strong>Kube Proxy</strong></p>
<p>想要访问某个服务，那要么通过域名，要么通过 IP。每个 Pod 在创建后都会有一个虚拟 IP，K8s 中有一个抽象的概念，叫做 <code>Service</code> ，<code>kube-proxy</code> 便是提供一种代理的服务，可以通过 <code>Service</code> 访问到 Pod。</p>
<p>实际的工作原理是在每个 Node 上启动一个 <code>kube-proxy</code> 的进程，通过编排 <code>iptables</code> 规则来达到此效果。</p>
<h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><ul>
<li><p><strong>Pod</strong> 是 K8s 中最小的可部署单元，中文可以翻译为“容器组”它是用于承载和管理容器的抽象层。一个 Pod 可以包含一个或多个紧密关联的容器，它们共享相同的网络命名空间、IP 地址和存储卷，并在同一个宿主机上运行。</p>
</li>
<li><p><strong>ReplicaSet</strong> 的目的是维护一组在任何时候都处于运行状态的 Pod 副本的稳定集合。因此，它通常用来保证给定数量的、完全相同的 Pod 的可用性。通常不直接使用 ReplicaSet，而是在 Deployment 中声明。</p>
</li>
<li><p><strong>Deployment</strong> 是对 ReplicaSet 和 Pod 更高级的抽象，它可以指挥 Kubernetes 如何创建和更新部署的应用实例，创建 Deployment 后，Kubernetes master 会将应用程序调度到集群中的各个节点上，一般用来部署无状态应用。</p>
<ul>
<li><p>自愈、缩放</p>
</li>
<li><p>滚动更新、版本回滚</p>
</li>
</ul>
</li>
<li><p><strong>Service</strong> 是将运行在一个或一组 Pod 上的网络应用程序公开为网络服务的抽象方法。Service 为一组 Pod 提供相同的 DNS 名，并且在它们之间进行负载均衡。Kubernetes 为 Pod 提供分配了 IP 地址，但 IP 地址可能会发生变化，集群内的容器可以通过 service 名称访问服务，而不需要担心 Pod 的 IP 发生变化。</p>
<ul>
<li><p>ClusterIP：将服务公开在 <strong>集群内部</strong>。kubernetes 会给服务分配一个集群内部的 IP，集群内的所有主机都可以通过这个 Cluster-IP 访问服务。集群内部的 Pod 可以通过 service 名称访问服务。</p>
</li>
<li><p>NodePort：通过每个节点的主机 IP 和静态端口（NodePort）暴露服务。 <strong>集群外部</strong> 的主机可以使用节点 IP 和 NodePort 访问服务。</p>
</li>
<li><p>ExternalName：将集群外部的网络引入集群内部。</p>
</li>
<li><p>LoadBalancer：使用云提供商的负载均衡器向外部暴露服务。</p>
</li>
</ul>
</li>
<li><p><strong>Ingress</strong> 是对集群中服务的外部访问进行管理的 API 对象，典型的访问方式是 HTTP。可以通过 Ingress 资源来配置不同的转发规则，从而达到根据不同的规则设置访问集群内不同的 Service 所对应的后端 Pod。当集群位于公有云或私有云上时，要从互联网进行访问，需要使用公网 IP 或者域名，公网 IP 是相对稀缺的资源，不可能给所有主机都分配公网 IP，并且随着公开的服务变多，众多的端口也变得难以管理。面对这种情况，可以使用 Ingress。</p>
</li>
<li><p><strong>Kubectl</strong> 是 K8s 提供的命令行工具。</p>
</li>
<li><p><strong>Namespace</strong> 是一种资源隔离机制，将同一集群中的资源划分为相互隔离的组。命名空间作用域仅针对带有名字空间的对象，例如 Deployment、Service 等。Kubernetes 会创建四个初始命名空间：</p>
<ul>
<li>default 默认的命名空间，不可删除，未指定命名空间的对象都会被分配到 default 中。</li>
<li>kube-system Kubernetes 系统对象(控制平面和 Node 组件)所使用的命名空间。</li>
<li>kube-public 自动创建的公共命名空间，所有用户（包括未经过身份验证的用户）都可以读取它。通常我们约定，将整个集群中公用的可见和可读的资源放在这个空间中。</li>
<li>kube-node-lease 租约（Lease）对象使用的命名空间。每个节点都有一个关联的 lease 对象，lease 是一种轻量级资源。lease 对象通过发送心跳，检测集群中的每个节点是否发生故障。</li>
</ul>
</li>
<li><p>管理对象的方式</p>
<ul>
<li>命令行指令，使用 kubectl 命令来创建和管理 Kubernetes 对象。命令行就好比口头传达，简单、快速、高效。但它功能有限，不适合复杂场景，操作不容易追溯，多用于开发和调试。</li>
<li>声明式配置，kubernetes 使用 yaml 文件来描述 Kubernetes 对象。声明式配置就好比申请表，学习难度大且配置麻烦。好处是操作留痕，适合操作复杂的对象，多用于生产。</li>
<li>可视化界面，如云平台容器服务</li>
</ul>
</li>
<li><p>服务部署流程，<code>YAML 文件 → kubectl → [API Server → etcd → Scheduler → Controller Mgr] → [Kubelet → Container runtime → Pod]</code></p>
</li>
<li><p>服务调用流程，<code>request → Ingress 控制器 → [Kube Proxy → Pod]</code></p>
</li>
</ul>
<h3 id="kubectl"><a href="#kubectl" class="headerlink" title="kubectl"></a>kubectl</h3><p>K8s 遵循 C&#x2F;S 架构，官方也提供了 CLI 工具 <code>kubectl</code> 用于完成大多数集群管理相关的功能。</p>
<ul>
<li><p>基础配置</p>
<ul>
<li>使用 <code>kubectl options</code> 可以看到所有全局可用的配置项</li>
<li><code>$HOME/.kube/config</code> 中主要包含着：<ul>
<li>K8s 集群的 API 地址</li>
<li>用于认证的证书地址</li>
</ul>
</li>
<li>也可以使用 <code>--kubeconfig</code> 或者环境变量 <code>KUBECONFIG</code> 来传递配置文件</li>
<li>也可以直接传递相关参数来使用，<code>kubectl -client-key=&#39;xxx&#39; --client-certificate=&#39;xxx&#39;</code></li>
</ul>
</li>
<li><p>get（读取数据类）</p>
<ul>
<li>**<code>kubectl cluster-info</code>**：查看集群控制平面的信息，包括 API server 和 DNS 服务的访问地址</li>
<li>**<code>kubectl get nodes</code>**：获取集群节点的详细信息，可以通过 <code>-o</code> 参数选择输出格式</li>
<li>**<code>kubectl api-resources</code>**：列出集群中支持的所有 API 资源，帮助了解 Kubernetes 中可用的资源</li>
<li>**<code>kubectl explain node</code>**：查看 <code>Node</code> 资源的详细字段说明，帮助理解各字段的作用</li>
</ul>
</li>
<li><p><code>kubectl run</code>，运行容器，<code>NAME</code> 和 <code>--image</code> 是必需项，分别代表此次部署的名字及所使用的镜像</p>
<ul>
<li>实际使用时，推荐编写配置文件并通过 <code>kubectl create</code> 进行部署</li>
</ul>
</li>
<li><p><code>kubectl get all</code>，列出当前命名空间中核心资源类型，比如 Pod、Service、ReplicaSet、Deployment、DaemonSet 等</p>
</li>
</ul>
<p><strong>部署一个 Redis 实例</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ kubectl run redis --image=&#x27;redis:alpine&#x27;</span><br><span class="line">deployment.apps/redis created</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ kubectl get all</span><br><span class="line">NAME                         READY     STATUS    RESTARTS   AGE</span><br><span class="line">pod/redis-7c7545cbcb-2m6rp   1/1       Running   0          30s</span><br><span class="line">NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE</span><br><span class="line">service/kubernetes   ClusterIP   10.96.0.1    &lt;none&gt;        443/TCP   32s</span><br><span class="line">NAME                    DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">deployment.apps/redis   1         1         1            1           30s</span><br><span class="line">NAME                               DESIRED   CURRENT   READY     AGE</span><br><span class="line">replicaset.apps/redis-7c7545cbcb   1         1         1         30s</span><br></pre></td></tr></table></figure>

<p>使用 <code>kubectl get all</code> 输出内容的格式 <code>/</code> 前代表类型，<code>/</code> 后是名称</p>
<ul>
<li><p><code>Deployment</code> 是一种高级别的抽象，允许进行扩容，滚动更新及降级等操作</p>
<ul>
<li><p>利用 <code>Deployment</code> 也能很方便的进行金丝雀发布（Canary deployments），这主要也依赖 <code>Label</code> 和 <code>Selector</code></p>
</li>
<li><p><code>Deployment</code> 的创建更推荐的方式便是使用 <code>yaml</code> 格式的配置文件</p>
</li>
<li><p><code>Deployment</code> 主要是声明一种预期的状态，并且会将 <code>Pod</code> 托管给 <code>ReplicaSet</code></p>
</li>
<li><p><code>ReplicaSet</code> 会检查当前的 <code>Pod</code> 数量及状态是否符合预期，并尽量满足这一预期</p>
</li>
</ul>
</li>
<li><p><code>Service</code> 是为了能有个稳定的入口访问应用服务或者是一组 <code>Pod</code></p>
<ul>
<li>通过 <code>Service</code> 可以很方便的实现 <strong>服务发现和负载均衡</strong></li>
<li><code>Service</code> 目前有 4 种类型：<ul>
<li><code>ClusterIP</code>： 是 K8s 当前默认的 <code>Service</code> 类型，将 service 暴露于一个 <strong>仅集群内</strong> 可访问的虚拟 IP 上<ul>
<li><strong>集群内主机</strong> 通过 <code>ClusterIP:port</code> 访问服务</li>
<li><strong>集群内容器</strong> 通过 <code>service name:port</code> 访问服务</li>
</ul>
</li>
<li><code>NodePort</code>： 是通过在集群内所有 <code>Node</code> 上都绑定固定端口的方式将服务暴露出来<ul>
<li><strong>集群外主机</strong> 通过 <code>&lt;NodeIP&gt;:&lt;NodePort&gt;</code> 访问服务</li>
</ul>
</li>
<li><code>LoadBalancer</code>： 是通过 <code>Cloud Provider</code> 创建一个外部的负载均衡器，将服务暴露出来，并且会自动创建外部负载均衡器路由请求所需的 <code>Nodeport</code> 或 <code>ClusterIP</code> </li>
<li><code>ExternalName</code>： 是通过将服务由 DNS CNAME 的方式转发到指定的域名上将服务暴露出来</li>
</ul>
</li>
</ul>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ kubectl expose deploy/redis --port=6379 --protocol=TCP --target-port=6379 --name=redis-server  </span><br><span class="line">service/redis-server exposed</span><br><span class="line">➜  ~ kubectl get svc -o wide                                                                       </span><br><span class="line">NAME           TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE       SELECTOR</span><br><span class="line">kubernetes     ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP    49m       &lt;none&gt;</span><br><span class="line">redis-server   ClusterIP   10.108.105.63   &lt;none&gt;        6379/TCP   4s        run=redis</span><br></pre></td></tr></table></figure>

<p>通过 <code>kubectl expose</code> 命令将 redis server 这个 <code>Service</code> 暴露出来</p>
<ul>
<li><code>port</code>： 是 <code>Service</code> 暴露出来的端口，可通过此端口访问 <code>Service</code></li>
<li><code>protocol</code>： 是所用协议，当前 K8s 支持 TCP&#x2F;UDP 协议，默认是 TCP 协议</li>
<li><code>target-port</code>： 是实际服务所在的目标端口，请求由 <code>port</code> 进入通过上述指定 <code>protocol</code> 最终流向这里配置的端口</li>
<li><code>name</code>： <code>Service</code> 的名字，它的用处主要在 dns 方面</li>
<li><code>type</code>： 是前面提到的类型，如果没指定默认是 <code>ClusterIP</code></li>
</ul>
<p>redis 是使用的默认类型 <code>ClusterIP</code>，所以并不能直接通过外部进行访，使用 <code>port-forward</code> 的方式让它可在集群外部访问</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ kubectl port-forward svc/redis-server 6379:6379</span><br><span class="line">Forwarding from 127.0.0.1:6379 -&gt; 6379</span><br><span class="line">Forwarding from [::1]:6379 -&gt; 6379</span><br><span class="line">Handling connection for 6379</span><br></pre></td></tr></table></figure>
<p>也可以使用 <code>NodePort</code> 的方式对外暴露服务，可以通过任意 <code>Node</code> 上的 <code>NodePort</code> 端口连接 redis 服务，这个端口范围其实是可以通过 <code>kube-apiserver</code> 的 <code>service-node-port-range</code> 进行配置的，默认是 <code>30000-32767</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ kubectl expose deploy/redis --port=6379 --protocol=TCP --target-port=6379 --name=redis-server-nodeport --type=NodePort</span><br><span class="line">service/redis-server-nodeport exposed</span><br><span class="line">➜  ~ kubectl get service/redis-server-nodeport -o wide </span><br><span class="line">NAME                    TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGE       SELECTOR</span><br><span class="line">redis-server-nodeport   NodePort   10.109.248.204   &lt;none&gt;        6379:31913/TCP   11s       run=redis</span><br></pre></td></tr></table></figure>

<h3 id="认证和授权"><a href="#认证和授权" class="headerlink" title="认证和授权"></a>认证和授权</h3><p>K8s 中几乎所有的操作都需要经过 <code>kube-apiserver</code> 处理，所以为了安全起见，K8s 为它提供了三类安全访问的措施：</p>
<ul>
<li>用于识别用户身份的 <strong>认证</strong>（Authentication）</li>
<li>用于控制用户对资源访问的 <strong>授权</strong>（Authorization）</li>
<li>用于资源管理方面的 <strong>准入控制</strong>（Admission Control）</li>
</ul>
<p>来自客户端的请求分别经过认证，授权，准入控制之后，才能真正执行</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">+-----------------------------------------------------------------------------------------------------------+</span><br><span class="line">|                                                                                                           |</span><br><span class="line">|               +---------------------------------------------------------------------------+    +--------+ |</span><br><span class="line">|               |                                                                           |    |        | |</span><br><span class="line">| +--------+    |   +------------------+   +----------------+   +--------------+   +------+ |    |        | |</span><br><span class="line">| |        |    |   |                  |   |                |   | Admission    |   |      | |    |        | |</span><br><span class="line">| | Client +------&gt; | Authentication   +-&gt; | Authorization  +-&gt; | Control      +-&gt; |Logic | +--&gt; | Others | |</span><br><span class="line">| |        |    |   |                  |   |                |   |              |   |      | |    |        | |</span><br><span class="line">| +--------+    |   +------------------+   +----------------+   +--------------+   +------+ |    |        | |</span><br><span class="line">|               |                                                                           |    |        | |</span><br><span class="line">|               |                                                                           |    |        | |</span><br><span class="line">|               |                          Kube-apiserver                                   |    |        | |</span><br><span class="line">|               +---------------------------------------------------------------------------+    +--------+ |</span><br><span class="line">|                                                                                                           |</span><br><span class="line">+-----------------------------------------------------------------------------------------------------------+</span><br></pre></td></tr></table></figure>

<p><strong>认证（Authentication）</strong></p>
<p>认证是判断当前发起请求的用户身份是否正确。例如，通常登录服务器时候需要输入用户名和密码，或者 SSH Keys 之类的。K8S 支持以下认证机制，可选择同时开启多个认证机制：</p>
<ul>
<li>X509 客户端证书</li>
<li>引导 Token</li>
<li>静态 Token 文件</li>
<li>静态密码文件</li>
<li>Service Account Token</li>
<li>OpenID</li>
<li>认证代理</li>
<li>Webhook</li>
</ul>
<p><strong>授权（Authorization）</strong></p>
<p>授权就是在验证当前发起请求的用户是否有相关的权限。例如，在 Linux 系统中常见的文件夹权限之类的。授权是以认证的结果为基础的，授权机制检查用户通过认证后的请求中所包含的属性来进行判断。K8S 支持以下授权机制：</p>
<ul>
<li>ABAC（Attribute-Based Access Control）基于属性的访问控制</li>
<li>RBAC（Role-based access control）基于角色的访问控制</li>
<li>Node：这是一种特殊用途的授权机制，专门用于对 <code>kubelet</code> 发出的 API 请求做授权验证</li>
<li>Webhook：使用外部的 Server 通过 API 进行授权校验</li>
<li>AlwaysAllow：默认配置，允许全部</li>
<li>AlwaysDeny：通常用于测试，禁止全部</li>
</ul>
<h3 id="Helm"><a href="#Helm" class="headerlink" title="Helm"></a>Helm</h3><p>Helm 是构建于 K8S 之上的包管理器，可与平时接触到的 Yum，APT，Homebrew 或者 Pip 等包管理器相类比。使用 Helm 可简化包分发，安装，版本管理等操作流程。同时它也是 CNCF 孵化项目。</p>
<p>Helm 是 C&#x2F;S 架构，主要分为客户端 <code>helm</code> 和服务端 <code>Tiller</code>。<code>helm</code> 通过 <code>gRPC</code> 将 <code>chart</code> 发送至 <code>Tiller</code> ，<code>Tiller</code> 则通过内置的 <code>kubernetes</code> 客户端库与 K8S 的 API server 进行交流，将 <code>chart</code> 进行部署，并生成 <code>Release</code> 用于管理。</p>
<h2 id="原理解析"><a href="#原理解析" class="headerlink" title="原理解析"></a>原理解析</h2><h3 id="kube-apiserver"><a href="#kube-apiserver" class="headerlink" title="kube-apiserver"></a>kube-apiserver</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">+----------------------------------------------------------+          </span><br><span class="line">| Master                                                   |          </span><br><span class="line">|              +-------------------------+                 |          </span><br><span class="line">|     +-------&gt;|        API Server       |&lt;--------+       |          </span><br><span class="line">|     |        |                         |         |       |          </span><br><span class="line">|     v        +-------------------------+         v       |          </span><br><span class="line">|   +----------------+     ^      +--------------------+   |          </span><br><span class="line">|   |                |     |      |                    |   |          </span><br><span class="line">|   |   Scheduler    |     |      | Controller Manager |   |          </span><br><span class="line">|   |                |     |      |                    |   |          </span><br><span class="line">|   +----------------+     v      +--------------------+   |          </span><br><span class="line">| +------------------------------------------------------+ |          </span><br><span class="line">| |                                                      | |          </span><br><span class="line">| |                Cluster state store                   | |          </span><br><span class="line">| |                                                      | |          </span><br><span class="line">| +------------------------------------------------------+ |          </span><br><span class="line">+----------------------------------------------------------+          </span><br></pre></td></tr></table></figure>

<p><code>kube-apiserver</code> 作为集群的统一入口，接收来自外部的信号和请求，并将一些信息存储至 etcd 中</p>
<ul>
<li>REST API Server<ul>
<li>对外提供接口，可处理来自客户端（无论 <code>kubeclt</code> 或者 <code>curl</code> 或者其他语言实现的客户端）的请求，并作出响应</li>
<li><code>kube-apiserver</code> 有个 <code>--secure-port</code> 的参数，通过这个参数来配置它将要监听在哪个端口，默认情况下是 <code>6443</code></li>
</ul>
</li>
<li>认证（Authentication）<ul>
<li><code>kubectl version -v 8</code><ul>
<li>获取集群版本号的时候，其实也是向 <code>kube-apiserver</code> 发送了一个请求进行查询的，可以通过传递 <code>-v</code> 参数来改变 log level </li>
<li>首先会加载 <code>$HOME/.kube/config</code> 下的配置，获的集群地址，进而请求 <code>/version</code> 接口，最后格式化输出</li>
</ul>
</li>
<li><code>curl -k https://172.17.0.99:6443/version</code><ul>
<li>使用 <code>curl -k</code> 相当于忽略认证的过程，忽略掉认证过程的 <code>curl</code> 被判定为 <code>system:anonymous</code> 用户</li>
</ul>
</li>
</ul>
</li>
<li>授权（Authorization）<ul>
<li>K8S 支持多种授权机制，现在多数都在使用 <code>RBAC</code></li>
</ul>
</li>
<li>准入控制（Admission Control）<ul>
<li>在请求进来时，会先经过认证、授权接下来会进入准入控制环节</li>
<li>准入控制和前两项内容不同，它不只是关注用户和行为，它还会处理请求的内容，不过它对读操作无效</li>
<li>准入控制与认证、授权插件类似，支持同时开启多个，几个比较常见的插件：<ul>
<li>NamespaceLifecycle：它可以保证正在终止的 <code>Namespace</code> 不允许创建对象，不允许请求不存在的 <code>Namespace</code> 以及保证默认的 <code>default</code>, <code>kube-system</code> 之类的命名空间不被删除</li>
<li>LimitRanger：为 <code>Pod</code> 设置默认请求资源的限制</li>
<li>ServiceAccount：可按照预设规则创建 <code>Serviceaccount</code>，比如都有统一的前缀：<code>system:serviceaccount:</code></li>
<li>DefaultStorageClass：为 <code>PVC</code> 设置默认 <code>StorageClass</code></li>
<li>DefaultTolerationSeconds：设置 <code>Pod</code> 的默认 forgiveness toleration 为 5 分钟</li>
<li>MutatingAdmissionWebhook 和 ValidatingAdmissionWebhook：这两个都是通过 Webhook 验证或者修改请求，唯一的区别是一个是顺序进行，一个是并行进行的</li>
<li>ResourceQuota：限制 <code>Pod</code> 请求配额</li>
<li>AlwaysPullImages：总是拉取镜像</li>
<li>AlwaysAdmit：总是接受所有请求</li>
</ul>
</li>
</ul>
</li>
<li>处理请求<ul>
<li>一个请求依次会经过认证，授权，准入控制等环节，当这些环节都已经通过后，该请求便到了 <code>kube-apiserver</code> 的实际处理逻辑中了</li>
<li>和普通的 Web server 类似，<code>kube-apiserver</code> 提供了 <code>restful</code> 的接口，增删改查等基本功能都基本类似</li>
</ul>
</li>
<li><code>kube-apiserver</code> 包含的东西有很多，除了认证，授权，准入控制相关功能外，还有审计，证书，存储等配置</li>
</ul>
<h3 id="etcd"><a href="#etcd" class="headerlink" title="etcd"></a>etcd</h3><blockquote>
<p>etcd is a consistent distributed key-value store. Mainly used as a separate coordination service, in distributed systems. And designed to hold small amounts of data that can fit entirely in memory.</p>
</blockquote>
<p><code>etcd</code> 是由 CoreOS 团队发起的一个分布式，强一致的键值存储。它用 Go 语言编写，使用 <code>Raft</code> 协议作为一致性算法。多数情况下会用于分布式系统中的服务注册发现，或是用于存储系统的关键数据。<code>etcd</code> 在 K8S 中，最主要的作用便是其 <strong>高可用</strong>，<strong>强一致</strong> 的键值存储以及 <strong>监听机制</strong></p>
<ul>
<li>在 <code>kube-apiserver</code> 收到对应请求经过一系列的处理后，最终如果是集群所需要存储的数据，便会存储至 <code>etcd</code> 中，主部分主要是 <strong>集群状态信息</strong> 和 <strong>元信息</strong></li>
<li>默认集群中的 etcd 会放到 kube-system Namespace 中，<code>kubectl -n kube-system get pods | grep etcd</code></li>
<li>etcd2 使用 HTTP&#x2F;JSON 作为默认的 API 通信协议，允许客户端通过 HTTP API 与 etcd 集群进行交互</li>
<li>etcd3 引入了 gRPC 作为主要的通信协议，虽然 etcd3 仍支持 HTTP API，但推荐使用 gRPC 进行高效通信，因为 gRPC 比传统的 HTTP API 更高效、更加支持双向流和更好的负载均衡</li>
<li>etcd3 中，HTTP API 一般仅用于兼容性和简单操作，在 K8s 1.13 发布时，etcd 2 的相关代码已经移除</li>
<li>由于 etcd 集群使用 Raft 一致性算法，通常情况下 etcd 集群需要部署奇数个节点，如 3，5，7 等，etcd 集群维护也相对容易，很容易可以做成高可用集群</li>
</ul>
<h3 id="controller-manager"><a href="#controller-manager" class="headerlink" title="controller-manager"></a>controller-manager</h3><blockquote>
<p>Controller Manager 实际由 kube-controller-manager 和 cloud-controller-manager 两部分组成，cloud-controller-manager 则是为各家云厂商提供了一个抽象的封装，便于让各厂商使用各自的 provide</p>
</blockquote>
<p>kube-controller-manager 是一个 <strong>嵌入</strong> 了 K8s 核心 <strong>控制循环</strong> 的 <strong>守护进程</strong>，负责在集群中运行核心控制循环，以确保集群的状态达到并维持在用户期望的状态</p>
<ul>
<li><p><code>kube-controller-manager</code> 运行多个控制器（例如节点控制器、资源配额控制器等），<strong>每个控制器都嵌入了特定的逻辑来管理和协调集群资源的状态</strong></p>
</li>
<li><p><strong>控制</strong>：<code>kube-controller-manager</code> 的任务是维护集群的目标状态。例如，当资源发生变化时，它会通过调用 API Server 将实际状态调整为目标状态</p>
</li>
<li><p><strong>循环</strong>：每个控制器都在一个循环中运行，反复检查资源的状态，并采取必要的操作以确保资源达到预期的状态。循环的执行间隔是可以通过参数配置的，例如 <code>--sync-period</code> 参数，控制各控制器的检查频率</p>
</li>
<li><p><code>kube-controller-manager</code> 是独立部署的一个 <strong>守护进程</strong>，可以在 Kubernetes 集群的控制平面节点上以独立的进程或容器形式运行, 持续监视并管理资源的状态。守护进程的特点是持久运行，不间断地执行控制循环，确保集群资源的一致性和健康状态</p>
</li>
</ul>
<ul>
<li><code>kube-controller-manager</code> 在 <code>10252</code> 端口上不仅暴露出来了一个 <code>/healthz</code> 接口，还暴露出了一个 <code>/metrics</code> 的接口，可用于进行监控之类的</li>
</ul>
<p>通过 <code>kubectl -n kube-system describe pods -l component=kube-controller-manager</code> 命令可以查看 <code>kube-controller-manager</code> 的 Pod 详细信息</p>
<h3 id="kube-scheduler"><a href="#kube-scheduler" class="headerlink" title="kube-scheduler"></a>kube-scheduler</h3><blockquote>
<p>The Kubernetes scheduler is a policy-rich, topology-aware, workload-specific function that significantly impacts availability, performance, and capacity.</p>
</blockquote>
<p><code>kube-scheduler</code> 是一个策略丰富，拓扑感知的调度程序，会显著影响可用性，性能和容量。</p>
<p>资源调度本就是 K8s 这类系统中的一个很复杂的事情，既要能满足系统对资源利用率的需要，同样还需要避免资源竞争，比如说端口冲突之类的，为了能完成这样的需求，<code>kube-scheduler</code> 便在不断的迭代和发展，通过支持多种策略满足各类需求，通过感知拓扑避免资源竞争和保障系统的可用性及容量等。</p>
<p>从上层的角度来看，<code>kube-scheduler</code> 的作用就是将待调度的 <code>Pod</code> 调度至最佳的 <code>Node</code> 上，而这个过程中则需要根据不同的策略，考虑到 <code>Node</code> 的资源使用情况，比如端口，内存，存储等。</p>
<p><code>kube-scheduler</code> 将处理阶段主要分为三个阶段 <code>Computing predicates</code>，<code>Prioritizing</code> 和 <code>Selecting host</code>：</p>
<ul>
<li><code>Computing predicates</code>：主要解决的问题是 <code>Pod</code> 能否调度到集群的 <code>Node</code> 上<ul>
<li>过一个名为 <code>podFitsOnNode</code> 的函数进行实现，在检查的过程中也会先去检查下是否已经有已缓存的判断结果</li>
<li>当然也会检查 <code>Pod</code> 是否是可调度的，以防有 <code>Pod Affinity</code> (亲合性) 之类的存在</li>
</ul>
</li>
<li><code>Prioritizing</code>：主要解决的问题是在上个阶段通过 <code>findNodesThatFit</code> 得到了 <code>filteredNodes</code> 的基础之上解决哪些 <code>Node</code> 是最优的，得到一个优先级列表 <code>priorityList</code><ul>
<li>给每个经过第一步筛选出来的 <code>Node</code> 一个 <code>Score</code>，再按照各种条件进行打分，最终得到一个优先级列表</li>
</ul>
</li>
<li><code>Selecting host</code>：则是最终选择 <code>Node</code> 调度到哪台机器上</li>
</ul>
<p>当实际进行部署操作的时候：</p>
<ol>
<li>通过 <code>kubectl</code> 之类的客户端工具与 <code>kube-apiserver</code> 进行交互</li>
<li>在经过一系列的处理后，数据将持久化到 <code>etcd</code> 中</li>
<li><code>kube-controller-manager</code> 通过持续的观察，开始按照配置，将集群的状态调整至预期状态</li>
<li><code>kube-scheduler</code> 也在发挥作用，决定 <code>Pod</code> 应该调度至哪个或者哪些 <code>Node</code> 上</li>
<li>之后则通过其他组件的协作，最总将该 <code>Pod</code> 在相应的 <code>Node</code> 上部署启动</li>
</ol>
<h3 id="kubelet"><a href="#kubelet" class="headerlink" title="kubelet"></a>kubelet</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">+--------------------------------------------------------+       </span><br><span class="line">| +---------------------+        +---------------------+ |       </span><br><span class="line">| |      kubelet        |        |     kube-proxy      | |       </span><br><span class="line">| |                     |        |                     | |       </span><br><span class="line">| +---------------------+        +---------------------+ |       </span><br><span class="line">| +----------------------------------------------------+ |       </span><br><span class="line">| | Container Runtime (Docker)                         | |       </span><br><span class="line">| | +---------------------+    +---------------------+ | |       </span><br><span class="line">| | |Pod                  |    |Pod                  | | |       </span><br><span class="line">| | | +-----+ +-----+     |    |+-----++-----++-----+| | |       </span><br><span class="line">| | | |C1   | |C2   |     |    ||C1   ||C2   ||C3   || | |       </span><br><span class="line">| | | |     | |     |     |    ||     ||     ||     || | |       </span><br><span class="line">| | | +-----+ +-----+     |    |+-----++-----++-----+| | |       </span><br><span class="line">| | +---------------------+    +---------------------+ | |       </span><br><span class="line">| +----------------------------------------------------+ |       </span><br><span class="line">+--------------------------------------------------------+  </span><br></pre></td></tr></table></figure>

<p>按照一般架构设计上的习惯，<code>kubelet</code> 所承担的角色一般会被叫做 <code>agent</code>，这里叫做 <code>kubelet</code> 很大程度上受 <code>Borg</code> 的命名影响，<code>Borg</code> 里面也有一个 <code>Borglet</code> 的组件存在，<code>kubelet</code> 便是 K8s 中的 <code>agent</code>，负责 <code>Node</code> 和 <code>Pod</code> 相关的管理任务</p>
<p><strong><code>kubelet</code> 的作用</strong></p>
<ul>
<li>节点管理<ul>
<li>当执行 <code>kubelet --help</code> 的时候，会看到它所支持的可配置参数，其中有一个 <code>--register-node</code> 参数便是用于控制是否向 <code>kube-apiserver</code> <strong>注册节点</strong> 的，默认是开启的</li>
<li><code>kubelet</code> 不仅将自己注册给了 <code>kube-apiserver</code>，同时它所在机器的信息也都进行了上报，包括 CPU，内存，IP 信息等</li>
<li>向 <code>kube-apiserver</code> 发送心跳包等</li>
</ul>
</li>
<li>Pod 管理<ul>
<li><p><code>kube-scheduler</code> 处理了 <code>Pod</code> 应该调度至哪个 <code>Node</code>，而 <code>kubelet</code> 则是保障该 <code>Pod</code> 能按照预期，在对应 <code>Node</code> 上启动并保持工作（ <code>kubelet</code> 的作用之一就是负责镜像拉取）</p>
</li>
<li><p><code>kubelet</code> 在保障 <code>Pod</code> 能按预期工作，主要是做了两方面的事情</p>
<ul>
<li>健康检查：通过 <code>LivenessProbe</code> 和 <code>ReadinessProbe</code> 探针进行检查，判断是否健康及是否已经准备好接受请求</li>
<li>资源监控：通过 <code>cAdvisor</code> 进行资源监控</li>
</ul>
</li>
<li><p><code>kubelet</code> 还承担着清理 <code>Node</code> 上一些由 K8s 调度 <code>Pod</code> 所造成的磁盘占用之类的工作</p>
</li>
</ul>
</li>
</ul>
<h3 id="kube-proxy"><a href="#kube-proxy" class="headerlink" title="kube-proxy"></a>kube-proxy</h3><p><code>kube-proxy</code> 是 K8s 运行于每个 <code>Node</code> 上的 <strong>网络代理组件</strong>，提供了 <strong>TCP 和 UDP 的连接转发支持</strong>，当 <code>Pod</code> 在创建和销毁的过程中，IP 可能会发生变化，而这就容易造成对其有依赖的服务的异常，所以通常情况下，我们都会使用 <code>Service</code> 将后端 <code>Pod</code> 暴露出来，而 <code>Service</code> 则较为稳定</p>
<p><code>kube-proxy</code> 对于服务注册发现和代理访问等起到了很大的作用，在 Linux 系统上当前支持三种模式，可通过 <code>--proxy-mode</code> 配置：</p>
<ul>
<li><code>userspace</code>：这是很早期的一种方案，但效率上显著不足，不推荐使用</li>
<li><code>iptables</code>：当前的默认模式，比 <code>userspace</code> 要快，但问题是会给机器上产生很多 <code>iptables</code> 规则</li>
<li><code>ipvs</code>：为了解决 <code>iptables</code> 的性能问题而引入，采用增量的方式进行更新</li>
</ul>
<p>默认情况下使用 <code>iptables</code> 的代理模式，当创建新的 <code>Service</code> ，或者 <code>Pod</code> 进行变化时，<code>kube-proxy</code> 便会去维护 <code>iptables</code> 规则，以确保请求可以正确的到达后端服务、</p>
<blockquote>
<p><code>kube-proxy</code> 和 <code>Ingress</code> 都是 Kubernetes 中用于网络管理的组件，两者都可以实现流量的负载均衡和分发，<code>kube-proxy</code> 更底层、面向内部流量，而 <code>Ingress</code> 更高层、面向外部流量，比如负载均衡层级：</p>
<ul>
<li>kube-proxy：在四层（传输层）工作，只支持基于 IP 的负载均衡</li>
<li>Ingress：工作在七层（应用层），支持基于 HTTP&#x2F;HTTPS 的请求路由</li>
</ul>
</blockquote>
<h3 id="Container-Runtime"><a href="#Container-Runtime" class="headerlink" title="Container Runtime"></a>Container Runtime</h3><p><code>kube-scheduler</code> 决定了 <code>Pod</code> 将被调度到哪个 <code>Node</code> 上，而 <code>kubelet</code> 则负责 <code>Pod</code> 在此 <code>Node</code> 上可按预期工作，如果没有 <code>Container Runtime</code>，那 <code>Pod</code> 中的 <code>container</code> 在该 <code>Node</code> 上也便无法正常启动运行</p>
<p><code>Container Runtime</code> （容器运行时）这一概念的产生也是由于容器化技术和 K8s 的大力发展，为了统一工业标准，也为了避免 K8s 绑定于特定的容器运行时，所以便成立了 <a target="_blank" rel="noopener" href="https://www.opencontainers.org/">OCI</a> （Open Container Initiative）组织，致力于将容器运行时标准化和容器镜像标准化</p>
<p>自 K8s 1.5 （2016 年 11 月）开始，新增了一个容器运行时的插件 API，并称之为 <code>CRI</code> （Container Runtime Interface），通过 <code>CRI</code> 可以支持 <code>kubelet</code> 使用不同的容器运行时，而不需要重新编译</p>
<blockquote>
<p>当前使用最为广泛的是 <a target="_blank" rel="noopener" href="https://github.com/moby/moby/"><code>Docker</code></a>，当前还支持的主要有 <a target="_blank" rel="noopener" href="https://github.com/opencontainers/runc"><code>runc</code></a>，<a target="_blank" rel="noopener" href="https://github.com/containerd/containerd"><code>Containerd</code></a>，<a target="_blank" rel="noopener" href="https://github.com/hyperhq/runv"><code>runV</code></a> 以及 <a target="_blank" rel="noopener" href="https://github.com/rkt/rkt"><code>rkt</code></a> 等</p>
</blockquote>
<h2 id="Troubleshoot"><a href="#Troubleshoot" class="headerlink" title="Troubleshoot"></a>Troubleshoot</h2><ul>
<li>使用 <code>describe</code> 排查问题，<code>kubectl -n work describe pod/xxx</code></li>
<li>使用 <code>events</code> 排查问题，<code>kubectl -n work get events</code></li>
<li>通过详细内容排查错误，比如 <code>kubectl -n work get endpoints</code></li>
</ul>
<h2 id="扩展增强"><a href="#扩展增强" class="headerlink" title="扩展增强"></a>扩展增强</h2><ul>
<li><p>Dashboard - Web 端操作界面</p>
<ul>
<li>Dashboard 并不能完全取代 kubectl，两者应该是相辅相成的</li>
<li>后端使用 Kubernetes 的 <code>client-go</code> 库来与 API Server 通信，前端基于 Angular 框架开发</li>
</ul>
</li>
<li><p>CoreDNS - K8s 集群中的 DNS 和服务发现插件</p>
<ul>
<li>CoreDNS 是一个独立项目，它不仅可支持在 K8s 中使用，也可以在任何需要 DNS 服务的时候使用它</li>
<li>自 K8s1.13 版本起，CoreDNS 成为了集群中的默认 DNS 服务器，替代了以前的 kube-dns 插件</li>
<li>提供域名解析和服务发现功能，使 Pod 之间能通过服务名称直接访问</li>
</ul>
</li>
<li><p>Ingress - K8s 中的流量管理资源</p>
<ul>
<li>Ingress 是 Kubernetes 中的流量管理资源，主要用于集群外部的 HTTP&#x2F;HTTPS 负载均衡、路由和SSL 终止等</li>
<li>允许定义基于路径、主机名等的路由规则，引导流量到集群内的正确服务，需要一个 Ingress Controller 实现，常用的有 NGINX Ingress Controller 和 Traefik 等</li>
</ul>
</li>
<li><p>集群监控，K8s 是一个典型的分布式系统，组件很多，监控的目标就变的很重要了</p>
<ul>
<li>节点情况、K8s 集群自身状态、部署在 K8s 内的应用的状态</li>
<li>用于实时收集和监测 Kubernetes 集群的性能和资源使用情况，帮助管理员发现潜在问题和优化集群资源</li>
<li>rometheus、Grafana 等工具常用于 Kubernetes 的集群监控，帮助展示 CPU、内存、存储等资源的使用情况，还能设置报警和警报管理</li>
</ul>
</li>
</ul>
<h2 id="部署前后端应用"><a href="#部署前后端应用" class="headerlink" title="部署前后端应用"></a>部署前后端应用</h2><p>使用云平台的容器服务</p>
<p><strong>Code → App → Docker Image → Hub → K8s</strong></p>
<h3 id="Golang"><a href="#Golang" class="headerlink" title="Golang"></a>Golang</h3><p>构建 Docker 镜像</p>
<p>交叉编译</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Windows → Linux</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">powershell</span></span><br><span class="line"><span class="meta prompt_">$</span><span class="language-bash"><span class="built_in">env</span>:GOOS=<span class="string">&quot;linux&quot;</span></span></span><br><span class="line"><span class="meta prompt_">$</span><span class="language-bash"><span class="built_in">env</span>:GOARCH=<span class="string">&quot;amd64&quot;</span></span></span><br><span class="line">go build -o .\build\webook</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Mac → Linux</span></span><br><span class="line">GOOS=linux GOARCH=amd64 go build -o /build/webook</span><br></pre></td></tr></table></figure>

<p>编写 Dockerfile</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">基础镜像</span></span><br><span class="line">FROM ubuntu:20.04</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">把编译后的打包进这个镜像，放到工作目录 /app</span></span><br><span class="line">COPY /build/wechatpay /app/wechatpay</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">拷贝配置文件</span></span><br><span class="line">COPY ./etc /app/etc</span><br><span class="line">WORKDIR /app</span><br><span class="line">ENTRYPOINT [&quot;/app/webook&quot;]</span><br></pre></td></tr></table></figure>

<p>打包镜像</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">构建</span></span><br><span class="line">docker build -t wechatpay:v0.0.1 .</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看镜像信息</span></span><br><span class="line">docker images wechatpay:v0.0.1</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">删除</span></span><br><span class="line">docker rmi -f wechatpay:v0.0.1</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">可以将上述命令都写在 Makefile 里面</span></span><br></pre></td></tr></table></figure>

<p>启动服务</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker run --rm -it -p 8888:8888 wechatpay:v0.0.1      </span><br><span class="line">Starting server at 0.0.0.0:8888...</span><br></pre></td></tr></table></figure>

<p>推送到远程仓库</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">登录腾讯云容器镜像服务 Docker Registry</span></span><br><span class="line">docker login xxx.tencentcloudcr.com --username xxx --password xxx</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">向 Registry 中推送镜像</span></span><br><span class="line">docker tag [imageId] xxx.tencentcloudcr.com/xxx/xxx:[tag]</span><br><span class="line">docker push xxx.tencentcloudcr.com/xxx/xxx:[tag]</span><br></pre></td></tr></table></figure>

<h3 id="CI-CD"><a href="#CI-CD" class="headerlink" title="CI&#x2F;CD"></a>CI&#x2F;CD</h3><p><strong>Jenkinsfile</strong></p>
<ol>
<li>Check Workspace</li>
<li>Go Mod Tidy</li>
<li>Build Go Application</li>
<li>Build Docker Image</li>
<li>Push Docker Image</li>
</ol>
<h3 id="React"><a href="#React" class="headerlink" title="React"></a>React</h3><p><strong>Dockerfile</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">使用较新的 Node.js 镜像作为构建环境</span></span><br><span class="line">FROM node:18-alpine AS build</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">设置工作目录</span></span><br><span class="line">WORKDIR /app</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">复制 package.json 和 package-lock.json</span></span><br><span class="line">COPY package*.json ./</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装依赖</span></span><br><span class="line">RUN npm install &amp;&amp; npm cache clean --force</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">复制项目文件</span></span><br><span class="line">COPY . .</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">构建项目</span></span><br><span class="line">RUN npm run build</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">使用 Nginx 作为生产环境的 web 服务器</span></span><br><span class="line">FROM nginx:alpine</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">复制构建的文件到 Nginx 的默认公共目录</span></span><br><span class="line">COPY --from=build /app/build /usr/share/nginx/html</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将 Nginx 配置文件替换为自定义配置文件</span></span><br><span class="line">COPY nginx.conf /etc/nginx/conf.d/default.conf</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">暴露端口</span></span><br><span class="line">EXPOSE 9999</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动 Nginx</span></span><br><span class="line">CMD [&quot;nginx&quot;, &quot;-g&quot;, &quot;daemon off;&quot;]</span><br></pre></td></tr></table></figure>

<h2 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h2><ul>
<li><a target="_blank" rel="noopener" href="https://juejin.cn/book/6844733753063915533/section">Kubernetes 从上手到实践</a></li>
<li><a target="_blank" rel="noopener" href="https://time.geekbang.org/column/intro/100114501">Kubernetes 入门实战课</a></li>
<li><a target="_blank" rel="noopener" href="https://www.thebyte.com.cn/">深入高可用架构原理与实践</a></li>
<li><a target="_blank" rel="noopener" href="https://kubernetes.io/">Kubernetes 官网文档</a></li>
</ul>


<!-- 
<div class="article-footer reveal fs14"><section id="license"><div class="header"><span>许可协议</span></div><div class="body"><p>本文采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">署名-非商业性使用-相同方式共享 4.0 国际</a> 许可协议，转载请注明出处。</p>
</div></section></div> -->

</article>

<div class="related-wrap reveal" id="read-next"><section class="body"><div class="item" id="prev"><div class="note">较新文章</div><a href="/2024/11/04/phoenix/">《凤凰架构：构建可靠的大型分布式系统》🪽</a></div><div class="item" id="next"><div class="note">较早文章</div><a href="/2024/09/23/docker/">容器技术实践与探索 - Docker 🐳</a></div></section></div>






  <div class='related-wrap md-text reveal' id="comments">
    <section class='header cmt-title cap theme'>
      快来参与讨论吧
    </section>
    <section class='body cmt-body giscus'>
      

<svg class="loading" style="vertical-align: middle;fill: currentColor;overflow: hidden;" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="2709"><path d="M832 512c0-176-144-320-320-320V128c211.2 0 384 172.8 384 384h-64zM192 512c0 176 144 320 320 320v64C300.8 896 128 723.2 128 512h64z" p-id="2710"></path></svg>

<div id="giscus" data-repo="hcjjj/blog-comments" data-repo-id="R_kgDOM8H5Mg" data-category="Announcements" data-category-id="DIC_kwDOM8H5Ms4CjGw7" data-mapping="pathname" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="preferred_color_scheme" data-lang="zh-CN" data-loading="lazy" crossorigin="anonymous"></div>

    </section>
  </div>



      <!-- 
<footer class="page-footer reveal fs12"><hr><div class="text"><p>本站由 <a href="/">@anonymity</a> 使用 <a target="_blank" rel="noopener" href="https://github.com/xaoxuu/hexo-theme-stellar">Stellar</a> 主题创建。<br>本博客所有文章除特别声明外，均采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议，转载请注明出处。</p>
</div></footer> -->

      <div class='float-panel mobile-only blur' style='display:none'>
  <button type='button' class='sidebar-toggle mobile' onclick='sidebar.toggle()'>
    <svg class="icon" style="width: 1em; height: 1em;vertical-align: middle;fill: currentColor;overflow: hidden;" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="15301"><path d="M566.407 808.3c26.9-0.1 49.3-20.8 51.6-47.6-1.9-27.7-23.9-49.7-51.6-51.6h-412.6c-28.2-1.4-52.6 19.5-55.5 47.6 2.3 26.8 24.6 47.5 51.6 47.6h416.5v4z m309.3-249.9c26.9-0.1 49.3-20.8 51.6-47.6-2.2-26.8-24.6-47.5-51.6-47.6h-721.9c-27.7-2.8-52.5 17.4-55.3 45.1-0.1 0.8-0.1 1.7-0.2 2.5 0.9 27.2 23.6 48.5 50.7 47.6H875.707z m-103.1-245.9c26.9-0.1 49.3-20.8 51.6-47.6-0.4-28.3-23.2-51.1-51.5-51.6h-618.9c-29.5-1.1-54.3 21.9-55.5 51.4v0.2c1.4 27.8 25.2 49.2 53 47.8 0.8 0 1.7-0.1 2.5-0.2h618.8z" p-id="15302"></path><path d="M566.407 808.3c26.9-0.1 49.3-20.8 51.6-47.6-1.9-27.7-23.9-49.7-51.6-51.6h-412.6c-28.2-1.4-52.6 19.5-55.5 47.6 1.9 27.7 23.9 49.7 51.6 51.6h416.5z m309.3-249.9c26.9-0.1 49.3-20.8 51.6-47.6-2.2-26.8-24.6-47.5-51.6-47.6h-721.9c-27.7-2.8-52.5 17.4-55.3 45.1-0.1 0.8-0.1 1.7-0.2 2.5 0.9 27.2 23.6 48.5 50.7 47.6H875.707z m-103.1-245.9c26.9-0.1 49.3-20.8 51.6-47.6-0.4-28.3-23.2-51.1-51.5-51.6h-618.9c-29.5-1.1-54.3 21.9-55.5 51.4v0.2c1.4 27.8 25.2 49.2 53 47.8 0.8 0 1.7-0.1 2.5-0.2h618.8z" p-id="15303"></path></svg>
  </button>
</div>

    </div>
  </div>
  <div class='scripts'>
    <script type="text/javascript">
  const stellar = {
    // 懒加载 css https://github.com/filamentgroup/loadCSS
    loadCSS: (href, before, media, attributes) => {
      var doc = window.document;
      var ss = doc.createElement("link");
      var ref;
      if (before) {
        ref = before;
      } else {
        var refs = (doc.body || doc.getElementsByTagName("head")[0]).childNodes;
        ref = refs[refs.length - 1];
      }
      var sheets = doc.styleSheets;
      if (attributes) {
        for (var attributeName in attributes) {
          if (attributes.hasOwnProperty(attributeName)) {
            ss.setAttribute(attributeName, attributes[attributeName]);
          }
        }
      }
      ss.rel = "stylesheet";
      ss.href = href;
      ss.media = "only x";
      function ready(cb) {
        if (doc.body) {
          return cb();
        }
        setTimeout(function () {
          ready(cb);
        });
      }
      ready(function () {
        ref.parentNode.insertBefore(ss, before ? ref : ref.nextSibling);
      });
      var onloadcssdefined = function (cb) {
        var resolvedHref = ss.href;
        var i = sheets.length;
        while (i--) {
          if (sheets[i].href === resolvedHref) {
            return cb();
          }
        }
        setTimeout(function () {
          onloadcssdefined(cb);
        });
      };
      function loadCB() {
        if (ss.addEventListener) {
          ss.removeEventListener("load", loadCB);
        }
        ss.media = media || "all";
      }
      if (ss.addEventListener) {
        ss.addEventListener("load", loadCB);
      }
      ss.onloadcssdefined = onloadcssdefined;
      onloadcssdefined(loadCB);
      return ss;
    },

    // 从 butterfly 和 volantis 获得灵感
    loadScript: (src, opt) => new Promise((resolve, reject) => {
      var script = document.createElement('script');
      if (src.startsWith('/')){
        src = stellar.config.root + src.substring(1);
      }
      script.src = src;
      if (opt) {
        for (let key of Object.keys(opt)) {
          script[key] = opt[key]
        }
      } else {
        // 默认异步，如果需要同步，第二个参数传入 {} 即可
        script.async = true
      }
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    }),

    // https://github.com/jerryc127/hexo-theme-butterfly
    jQuery: (fn) => {
      if (typeof jQuery === 'undefined') {
        stellar.loadScript(stellar.plugins.jQuery).then(fn)
      } else {
        fn()
      }
    }
  };
  stellar.version = '1.19.0';
  stellar.github = 'https://github.com/xaoxuu/hexo-theme-stellar/tree/1.19.0';
  stellar.config = {
    date_suffix: {
      just: '刚刚',
      min: '分钟前',
      hour: '小时前',
      day: '天前',
      month: '个月前',
    },
    root : '/',
  };

  // required plugins (only load if needs)
  stellar.plugins = {
    jQuery: 'https://gcore.jsdelivr.net/npm/jquery@3.6.2/dist/jquery.min.js'
  };

  if ('local_search') {
    stellar.search = {};
    stellar.search.service = 'local_search';
    if (stellar.search.service == 'local_search') {
      let service_obj = Object.assign({}, {"field":"all","path":"/search.json","content":true,"sort":"-date"});
      stellar.search[stellar.search.service] = service_obj;
    }
  }

  // stellar js
  stellar.plugins.stellar = Object.assign({"sites":"/js/plugins/sites.js","friends":"/js/plugins/friends.js","ghinfo":"/js/plugins/ghinfo.js","timeline":"/js/plugins/timeline.js","linkcard":"/js/plugins/linkcard.js","fcircle":"/js/plugins/fcircle.js","weibo":"/js/plugins/weibo.js"});

  stellar.plugins.marked = Object.assign("https://cdn.bootcdn.net/ajax/libs/marked/4.0.18/marked.min.js");
  // optional plugins
  if ('true' == 'true') {
    stellar.plugins.lazyload = Object.assign({"enable":true,"js":"https://gcore.jsdelivr.net/npm/vanilla-lazyload@17.8.3/dist/lazyload.min.js","transition":"blur"});
  }
  if ('true' == 'true') {
    stellar.plugins.swiper = Object.assign({"enable":true,"css":"https://unpkg.com/swiper@8.4.5/swiper-bundle.min.css","js":"https://unpkg.com/swiper@8.4.5/swiper-bundle.min.js"});
  }
  if ('' == 'true') {
    stellar.plugins.scrollreveal = Object.assign({"enable":null,"js":"https://gcore.jsdelivr.net/npm/scrollreveal@4.0.9/dist/scrollreveal.min.js","distance":"8px","duration":500,"interval":100,"scale":1});
  }
  if ('true' == 'true') {
    stellar.plugins.preload = Object.assign({"enable":true,"service":"flying_pages","instant_page":"https://gcore.jsdelivr.net/gh/volantis-x/cdn-volantis@4.1.2/js/instant_page.js","flying_pages":"https://gcore.jsdelivr.net/gh/gijo-varghese/flying-pages@2.1.2/flying-pages.min.js"});
  }
  if ('true' == 'true') {
    stellar.plugins.fancybox = Object.assign({"enable":true,"js":"https://gcore.jsdelivr.net/npm/@fancyapps/ui@4.0/dist/fancybox.umd.js","css":"https://gcore.jsdelivr.net/npm/@fancyapps/ui@4.0/dist/fancybox.css","selector":".swiper-slide img"});
  }
  if ('false' == 'true') {
    stellar.plugins.heti = Object.assign({"enable":false,"css":"https://unpkg.com/heti@0.9.2/umd/heti.min.css","js":"https://unpkg.com/heti@0.9.2/umd/heti-addon.min.js"});
  }
  if ('true' == 'true') {
    stellar.plugins.copycode = Object.assign({"enable":true,"js":"/js/plugins/copycode.js","default_text":"Copy","success_text":"Copied"});
  }
</script>

<!-- required -->

  
<script src="/js/main.js" async></script>



<!-- optional -->

  <script>
  function loadJS() {
    const els = document.querySelectorAll("#comments #giscus");
    if (els.length === 0) return;
    els.forEach((el, i) => {
      try {
        el.innerHTML = '';
      } catch (error) {
        console.log(error);
      }
      var script = document.createElement('script');
      script.src = 'https://giscus.app/client.js';
      script.async = true;
      for (let key of Object.keys(el.attributes)) {
        let attr = el.attributes[key];
        if (['class', 'id'].includes(attr.name) === false) {
          script.setAttribute(attr.name, attr.value);
        }
      }
      el.appendChild(script);
    });
  }
  window.addEventListener('DOMContentLoaded', (event) => {
    loadJS();
  });
</script>




<!-- inject -->


  </div>
</body>
</html>
